{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.rllib.agents.ppo import PPOTrainer, DEFAULT_CONFIG\n",
    "from ray import tune\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '127.0.0.1',\n",
       " 'raylet_ip_address': '127.0.0.1',\n",
       " 'redis_address': '127.0.0.1:6379',\n",
       " 'object_store_address': 'tcp://127.0.0.1:60851',\n",
       " 'raylet_socket_name': 'tcp://127.0.0.1:59310',\n",
       " 'webui_url': None,\n",
       " 'session_dir': 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2022-01-10_22-01-50_099384_12400',\n",
       " 'metrics_export_port': 64732,\n",
       " 'node_id': '05da4d3997c3f0e6386282a4ee296f78bca78c8f513f62c6976e4cfa'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_disable_preprocessor_api': False,\n",
      " '_fake_gpus': False,\n",
      " '_tf_policy_handles_more_than_one_loss': False,\n",
      " 'action_space': None,\n",
      " 'actions_in_input_normalized': False,\n",
      " 'batch_mode': 'truncate_episodes',\n",
      " 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>,\n",
      " 'clip_actions': False,\n",
      " 'clip_param': 0.3,\n",
      " 'clip_rewards': None,\n",
      " 'collect_metrics_timeout': 180,\n",
      " 'compress_observations': False,\n",
      " 'create_env_on_driver': False,\n",
      " 'custom_eval_function': None,\n",
      " 'custom_resources_per_worker': {},\n",
      " 'eager_max_retraces': 20,\n",
      " 'eager_tracing': False,\n",
      " 'entropy_coeff': 0.0,\n",
      " 'entropy_coeff_schedule': None,\n",
      " 'env': None,\n",
      " 'env_config': {},\n",
      " 'env_task_fn': None,\n",
      " 'evaluation_config': {},\n",
      " 'evaluation_interval': None,\n",
      " 'evaluation_num_episodes': 10,\n",
      " 'evaluation_num_workers': 0,\n",
      " 'evaluation_parallel_to_training': False,\n",
      " 'exploration_config': {'type': 'StochasticSampling'},\n",
      " 'explore': True,\n",
      " 'extra_python_environs_for_driver': {},\n",
      " 'extra_python_environs_for_worker': {},\n",
      " 'fake_sampler': False,\n",
      " 'framework': 'tf',\n",
      " 'gamma': 0.99,\n",
      " 'grad_clip': None,\n",
      " 'horizon': None,\n",
      " 'ignore_worker_failures': False,\n",
      " 'in_evaluation': False,\n",
      " 'input': 'sampler',\n",
      " 'input_config': {},\n",
      " 'input_evaluation': ['is', 'wis'],\n",
      " 'kl_coeff': 0.2,\n",
      " 'kl_target': 0.01,\n",
      " 'lambda': 1.0,\n",
      " 'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                           'intra_op_parallelism_threads': 8},\n",
      " 'log_level': 'WARN',\n",
      " 'log_sys_usage': True,\n",
      " 'logger_config': None,\n",
      " 'lr': 5e-05,\n",
      " 'lr_schedule': None,\n",
      " 'metrics_smoothing_episodes': 100,\n",
      " 'min_iter_time_s': 0,\n",
      " 'model': {'_disable_preprocessor_api': False,\n",
      "           '_time_major': False,\n",
      "           '_use_default_native_models': False,\n",
      "           'attention_dim': 64,\n",
      "           'attention_head_dim': 32,\n",
      "           'attention_init_gru_gate_bias': 2.0,\n",
      "           'attention_memory_inference': 50,\n",
      "           'attention_memory_training': 50,\n",
      "           'attention_num_heads': 1,\n",
      "           'attention_num_transformer_units': 1,\n",
      "           'attention_position_wise_mlp_dim': 32,\n",
      "           'attention_use_n_prev_actions': 0,\n",
      "           'attention_use_n_prev_rewards': 0,\n",
      "           'conv_activation': 'relu',\n",
      "           'conv_filters': None,\n",
      "           'custom_action_dist': None,\n",
      "           'custom_model': None,\n",
      "           'custom_model_config': {},\n",
      "           'custom_preprocessor': None,\n",
      "           'dim': 84,\n",
      "           'fcnet_activation': 'tanh',\n",
      "           'fcnet_hiddens': [256, 256],\n",
      "           'framestack': True,\n",
      "           'free_log_std': False,\n",
      "           'grayscale': False,\n",
      "           'lstm_cell_size': 256,\n",
      "           'lstm_use_prev_action': False,\n",
      "           'lstm_use_prev_action_reward': -1,\n",
      "           'lstm_use_prev_reward': False,\n",
      "           'max_seq_len': 20,\n",
      "           'no_final_linear': False,\n",
      "           'post_fcnet_activation': 'relu',\n",
      "           'post_fcnet_hiddens': [],\n",
      "           'use_attention': False,\n",
      "           'use_lstm': False,\n",
      "           'vf_share_layers': False,\n",
      "           'zero_mean': True},\n",
      " 'monitor': -1,\n",
      " 'multiagent': {'count_steps_by': 'env_steps',\n",
      "                'observation_fn': None,\n",
      "                'policies': {},\n",
      "                'policies_to_train': None,\n",
      "                'policy_map_cache': None,\n",
      "                'policy_map_capacity': 100,\n",
      "                'policy_mapping_fn': None,\n",
      "                'replay_mode': 'independent'},\n",
      " 'no_done_at_end': False,\n",
      " 'normalize_actions': True,\n",
      " 'num_cpus_for_driver': 1,\n",
      " 'num_cpus_per_worker': 1,\n",
      " 'num_envs_per_worker': 1,\n",
      " 'num_gpus': 0,\n",
      " 'num_gpus_per_worker': 0,\n",
      " 'num_sgd_iter': 30,\n",
      " 'num_workers': 2,\n",
      " 'observation_filter': 'NoFilter',\n",
      " 'observation_space': None,\n",
      " 'optimizer': {},\n",
      " 'output': None,\n",
      " 'output_compress_columns': ['obs', 'new_obs'],\n",
      " 'output_max_file_size': 67108864,\n",
      " 'placement_strategy': 'PACK',\n",
      " 'postprocess_inputs': False,\n",
      " 'preprocessor_pref': 'deepmind',\n",
      " 'record_env': False,\n",
      " 'remote_env_batch_wait_ms': 0,\n",
      " 'remote_worker_envs': False,\n",
      " 'render_env': False,\n",
      " 'rollout_fragment_length': 200,\n",
      " 'sample_async': False,\n",
      " 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      " 'seed': None,\n",
      " 'sgd_minibatch_size': 128,\n",
      " 'shuffle_buffer_size': 0,\n",
      " 'shuffle_sequences': True,\n",
      " 'simple_optimizer': -1,\n",
      " 'soft_horizon': False,\n",
      " 'synchronize_filters': True,\n",
      " 'tf_session_args': {'allow_soft_placement': True,\n",
      "                     'device_count': {'CPU': 1},\n",
      "                     'gpu_options': {'allow_growth': True},\n",
      "                     'inter_op_parallelism_threads': 2,\n",
      "                     'intra_op_parallelism_threads': 2,\n",
      "                     'log_device_placement': False},\n",
      " 'timesteps_per_iteration': 0,\n",
      " 'train_batch_size': 4000,\n",
      " 'use_critic': True,\n",
      " 'use_gae': True,\n",
      " 'vf_clip_param': 10.0,\n",
      " 'vf_loss_coeff': 1.0,\n",
      " 'vf_share_layers': -1}\n"
     ]
    }
   ],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['env'] = 'BipedalWalker-v3'\n",
    "config['framework'] = 'tf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['lr'] = tune.grid_search([5e-05, 5e-08])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = {\n",
    "    #'episodes_total':1000\n",
    "    'timesteps_total':500000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:19:56 (running for 00:00:00.14)<br>Memory usage on this node: 7.6/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">5e-05</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">5e-08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 21:19:56,487\tERROR syncer.py:111 -- Log sync requires rsync to be installed.\n",
      " pid=16012)\u001b[0m 2022-01-10 21:20:00,348\tINFO trainer.py:722 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also want to then set `eager_tracing=True` in order to reach similar execution speed as with static-graph mode.\n",
      " pid=16012)\u001b[0m 2022-01-10 21:20:00,348\tINFO ppo.py:166 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      " pid=16012)\u001b[0m 2022-01-10 21:20:00,348\tINFO trainer.py:743 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      " pid=14984)\u001b[0m 2022-01-10 21:20:00,360\tINFO trainer.py:722 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also want to then set `eager_tracing=True` in order to reach similar execution speed as with static-graph mode.\n",
      " pid=14984)\u001b[0m 2022-01-10 21:20:00,360\tINFO ppo.py:166 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      " pid=14984)\u001b[0m 2022-01-10 21:20:00,360\tINFO trainer.py:743 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      " pid=16620)\u001b[0m 2022-01-10 21:20:07,683\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      " pid=16436)\u001b[0m 2022-01-10 21:20:07,683\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      " pid=16012)\u001b[0m 2022-01-10 21:20:09,936\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      " pid=14984)\u001b[0m 2022-01-10 21:20:09,959\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      " pid=16012)\u001b[0m 2022-01-10 21:20:11,278\tINFO trainable.py:124 -- Trainable.setup took 10.931 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      " pid=16012)\u001b[0m 2022-01-10 21:20:11,279\tWARNING util.py:57 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:20:11 (running for 00:00:15.08)<br>Memory usage on this node: 14.3/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " pid=14984)\u001b[0m 2022-01-10 21:20:11,347\tINFO trainable.py:124 -- Trainable.setup took 10.989 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      " pid=14984)\u001b[0m 2022-01-10 21:20:11,349\tWARNING util.py:57 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:20:12 (running for 00:00:16.11)<br>Memory usage on this node: 14.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:20:17 (running for 00:00:21.15)<br>Memory usage on this node: 14.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " pid=16012)\u001b[0m 2022-01-10 21:20:19,722\tWARNING deprecation.py:45 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n",
      " pid=14984)\u001b[0m 2022-01-10 21:20:19,710\tWARNING deprecation.py:45 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:20:22 (running for 00:00:26.20)<br>Memory usage on this node: 14.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 4000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-20-25\n",
      "  done: false\n",
      "  episode_len_mean: 593.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -103.24617945954762\n",
      "  episode_reward_mean: -113.23386422397267\n",
      "  episode_reward_min: -128.94831305721644\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 6\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.67146110534668\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.4594853559610783e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0028977307956665754\n",
      "          total_loss: 423.8655700683594\n",
      "          vf_explained_var: -4.284990791347809e-05\n",
      "          vf_loss: 423.8626708984375\n",
      "    num_agent_steps_sampled: 4000\n",
      "    num_agent_steps_trained: 4000\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 4000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 67.02499999999999\n",
      "    ram_util_percent: 59.220000000000006\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16888935884078227\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.6059638146815569\n",
      "    mean_inference_ms: 3.220317662804798\n",
      "    mean_raw_obs_processing_ms: 0.15347150490916653\n",
      "  time_since_restore: 14.17223834991455\n",
      "  time_this_iter_s: 14.17223834991455\n",
      "  time_total_s: 14.17223834991455\n",
      "  timers:\n",
      "    learn_throughput: 700.436\n",
      "    learn_time_ms: 5710.728\n",
      "    load_throughput: 4013688.038\n",
      "    load_time_ms: 0.997\n",
      "    sample_throughput: 473.758\n",
      "    sample_time_ms: 8443.132\n",
      "    update_time_ms: 1.994\n",
      "  timestamp: 1641871225\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 1\n",
      "  trial_id: 59aed_00001\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 4000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-20-25\n",
      "  done: false\n",
      "  episode_len_mean: 510.85714285714283\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -99.00758361800077\n",
      "  episode_reward_mean: -111.73739958410526\n",
      "  episode_reward_min: -131.66451502161357\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 7\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.744920253753662\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01556177157908678\n",
      "          model: {}\n",
      "          policy_loss: -0.02496432140469551\n",
      "          total_loss: 425.9485778808594\n",
      "          vf_explained_var: -0.0028483415953814983\n",
      "          vf_loss: 425.970458984375\n",
      "    num_agent_steps_sampled: 4000\n",
      "    num_agent_steps_trained: 4000\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 4000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.21428571428572\n",
      "    ram_util_percent: 59.2142857142857\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16818969469471462\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.6060197895153812\n",
      "    mean_inference_ms: 3.170657329813966\n",
      "    mean_raw_obs_processing_ms: 0.140228950297321\n",
      "  time_since_restore: 14.218117475509644\n",
      "  time_this_iter_s: 14.218117475509644\n",
      "  time_total_s: 14.218117475509644\n",
      "  timers:\n",
      "    learn_throughput: 682.904\n",
      "    learn_time_ms: 5857.335\n",
      "    load_throughput: 0.0\n",
      "    load_time_ms: 0.0\n",
      "    sample_throughput: 478.338\n",
      "    sample_time_ms: 8362.295\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871225\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 1\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:20:27 (running for 00:00:31.33)<br>Memory usage on this node: 14.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2181</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">-111.737</td><td style=\"text-align: right;\">            -99.0076</td><td style=\"text-align: right;\">            -131.665</td><td style=\"text-align: right;\">           510.857</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1722</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">-113.234</td><td style=\"text-align: right;\">           -103.246 </td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           593.5  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:20:32 (running for 00:00:36.38)<br>Memory usage on this node: 13.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2181</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">-111.737</td><td style=\"text-align: right;\">            -99.0076</td><td style=\"text-align: right;\">            -131.665</td><td style=\"text-align: right;\">           510.857</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1722</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">-113.234</td><td style=\"text-align: right;\">           -103.246 </td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           593.5  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:20:37 (running for 00:00:41.42)<br>Memory usage on this node: 13.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.2181</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">-111.737</td><td style=\"text-align: right;\">            -99.0076</td><td style=\"text-align: right;\">            -131.665</td><td style=\"text-align: right;\">           510.857</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         14.1722</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">-113.234</td><td style=\"text-align: right;\">           -103.246 </td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           593.5  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 8000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-20-37\n",
      "  done: false\n",
      "  episode_len_mean: 469.3125\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -101.88926767716308\n",
      "  episode_reward_mean: -111.65188878268037\n",
      "  episode_reward_min: -128.94831305721644\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 16\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.670351028442383\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.045882976948633e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.004005632363259792\n",
      "          total_loss: 816.9810180664062\n",
      "          vf_explained_var: -2.1007497707614675e-05\n",
      "          vf_loss: 816.9771118164062\n",
      "    num_agent_steps_sampled: 8000\n",
      "    num_agent_steps_trained: 8000\n",
      "    num_steps_sampled: 8000\n",
      "    num_steps_trained: 8000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.944444444444436\n",
      "    ram_util_percent: 58.47222222222222\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15810228398235915\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5658558513146634\n",
      "    mean_inference_ms: 3.044127237542312\n",
      "    mean_raw_obs_processing_ms: 0.13906329268039228\n",
      "  time_since_restore: 26.511237621307373\n",
      "  time_this_iter_s: 12.338999271392822\n",
      "  time_total_s: 26.511237621307373\n",
      "  timers:\n",
      "    learn_throughput: 714.346\n",
      "    learn_time_ms: 5599.524\n",
      "    load_throughput: 4011768.532\n",
      "    load_time_ms: 0.997\n",
      "    sample_throughput: 380.075\n",
      "    sample_time_ms: 10524.246\n",
      "    update_time_ms: 1.994\n",
      "  timestamp: 1641871237\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 8000\n",
      "  training_iteration: 2\n",
      "  trial_id: 59aed_00001\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 8000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-20-38\n",
      "  done: false\n",
      "  episode_len_mean: 631.8181818181819\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -99.00758361800077\n",
      "  episode_reward_mean: -111.74119245871849\n",
      "  episode_reward_min: -131.66451502161357\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 11\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.83524751663208\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011797137558460236\n",
      "          model: {}\n",
      "          policy_loss: -0.020452294498682022\n",
      "          total_loss: 132.94593811035156\n",
      "          vf_explained_var: -0.046537846326828\n",
      "          vf_loss: 132.9640350341797\n",
      "    num_agent_steps_sampled: 8000\n",
      "    num_agent_steps_trained: 8000\n",
      "    num_steps_sampled: 8000\n",
      "    num_steps_trained: 8000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.182352941176475\n",
      "    ram_util_percent: 58.470588235294116\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16153747395510415\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5866875863856387\n",
      "    mean_inference_ms: 3.0684856518662698\n",
      "    mean_raw_obs_processing_ms: 0.13472643733070627\n",
      "  time_since_restore: 26.660838842391968\n",
      "  time_this_iter_s: 12.442721366882324\n",
      "  time_total_s: 26.660838842391968\n",
      "  timers:\n",
      "    learn_throughput: 694.975\n",
      "    learn_time_ms: 5755.606\n",
      "    load_throughput: 0.0\n",
      "    load_time_ms: 0.0\n",
      "    sample_throughput: 380.38\n",
      "    sample_time_ms: 10515.795\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871238\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 8000\n",
      "  training_iteration: 2\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:20:43 (running for 00:00:46.82)<br>Memory usage on this node: 13.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         26.6608</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">-111.741</td><td style=\"text-align: right;\">            -99.0076</td><td style=\"text-align: right;\">            -131.665</td><td style=\"text-align: right;\">           631.818</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         26.5112</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">-111.652</td><td style=\"text-align: right;\">           -101.889 </td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           469.312</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:20:48 (running for 00:00:51.86)<br>Memory usage on this node: 13.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         26.6608</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">-111.741</td><td style=\"text-align: right;\">            -99.0076</td><td style=\"text-align: right;\">            -131.665</td><td style=\"text-align: right;\">           631.818</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         26.5112</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">-111.652</td><td style=\"text-align: right;\">           -101.889 </td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           469.312</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 12000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-20-50\n",
      "  done: false\n",
      "  episode_len_mean: 518.2857142857143\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -101.88926767716308\n",
      "  episode_reward_mean: -111.18519416809752\n",
      "  episode_reward_min: -128.94831305721644\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 21\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.05000000074505806\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.669009208679199\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.2046983499658381e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003163139568641782\n",
      "          total_loss: 303.13311767578125\n",
      "          vf_explained_var: -0.00011116015957668424\n",
      "          vf_loss: 303.1299743652344\n",
      "    num_agent_steps_sampled: 12000\n",
      "    num_agent_steps_trained: 12000\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 12000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.83529411764705\n",
      "    ram_util_percent: 58.35294117647058\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1550621554466417\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5570913938044744\n",
      "    mean_inference_ms: 2.997882439942251\n",
      "    mean_raw_obs_processing_ms: 0.1364367907954677\n",
      "  time_since_restore: 38.834280252456665\n",
      "  time_this_iter_s: 12.323042631149292\n",
      "  time_total_s: 38.834280252456665\n",
      "  timers:\n",
      "    learn_throughput: 724.301\n",
      "    learn_time_ms: 5522.563\n",
      "    load_throughput: 6017652.798\n",
      "    load_time_ms: 0.665\n",
      "    sample_throughput: 358.051\n",
      "    sample_time_ms: 11171.583\n",
      "    update_time_ms: 1.662\n",
      "  timestamp: 1641871250\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 3\n",
      "  trial_id: 59aed_00001\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 12000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-20-50\n",
      "  done: false\n",
      "  episode_len_mean: 555.3157894736842\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -99.00758361800077\n",
      "  episode_reward_mean: -111.46522452118647\n",
      "  episode_reward_min: -131.66451502161357\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 19\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.868007183074951\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020330684259533882\n",
      "          model: {}\n",
      "          policy_loss: -0.03320107236504555\n",
      "          total_loss: 366.17889404296875\n",
      "          vf_explained_var: -0.020191315561532974\n",
      "          vf_loss: 366.2080078125\n",
      "    num_agent_steps_sampled: 12000\n",
      "    num_agent_steps_trained: 12000\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 12000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.37222222222223\n",
      "    ram_util_percent: 58.36666666666666\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15341790473932124\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5617242891796641\n",
      "    mean_inference_ms: 2.9577331067160157\n",
      "    mean_raw_obs_processing_ms: 0.1291713211371663\n",
      "  time_since_restore: 39.08261728286743\n",
      "  time_this_iter_s: 12.421778440475464\n",
      "  time_total_s: 39.08261728286743\n",
      "  timers:\n",
      "    learn_throughput: 705.116\n",
      "    learn_time_ms: 5672.828\n",
      "    load_throughput: 12015194.08\n",
      "    load_time_ms: 0.333\n",
      "    sample_throughput: 357.055\n",
      "    sample_time_ms: 11202.749\n",
      "    update_time_ms: 2.328\n",
      "  timestamp: 1641871250\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 3\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:20:53 (running for 00:00:57.24)<br>Memory usage on this node: 13.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         39.0826</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">-111.465</td><td style=\"text-align: right;\">            -99.0076</td><td style=\"text-align: right;\">            -131.665</td><td style=\"text-align: right;\">           555.316</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         38.8343</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">-111.185</td><td style=\"text-align: right;\">           -101.889 </td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           518.286</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:20:58 (running for 00:01:02.28)<br>Memory usage on this node: 13.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         39.0826</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">-111.465</td><td style=\"text-align: right;\">            -99.0076</td><td style=\"text-align: right;\">            -131.665</td><td style=\"text-align: right;\">           555.316</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         38.8343</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">-111.185</td><td style=\"text-align: right;\">           -101.889 </td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           518.286</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 16000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-21-02\n",
      "  done: false\n",
      "  episode_len_mean: 450.3030303030303\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -100.40463899341722\n",
      "  episode_reward_mean: -111.28610895334852\n",
      "  episode_reward_min: -128.94831305721644\n",
      "  episodes_this_iter: 12\n",
      "  episodes_total: 33\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.02500000037252903\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.6688432693481445\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.957915512524778e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0038357768207788467\n",
      "          total_loss: 859.1214599609375\n",
      "          vf_explained_var: -0.0001636989036342129\n",
      "          vf_loss: 859.1176147460938\n",
      "    num_agent_steps_sampled: 16000\n",
      "    num_agent_steps_trained: 16000\n",
      "    num_steps_sampled: 16000\n",
      "    num_steps_trained: 16000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.722222222222214\n",
      "    ram_util_percent: 58.34444444444445\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14972849982538877\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5425726639087605\n",
      "    mean_inference_ms: 2.9300619154163035\n",
      "    mean_raw_obs_processing_ms: 0.1327527618998257\n",
      "  time_since_restore: 51.21317410469055\n",
      "  time_this_iter_s: 12.378893852233887\n",
      "  time_total_s: 51.21317410469055\n",
      "  timers:\n",
      "    learn_throughput: 727.993\n",
      "    learn_time_ms: 5494.555\n",
      "    load_throughput: 8023537.064\n",
      "    load_time_ms: 0.499\n",
      "    sample_throughput: 348.805\n",
      "    sample_time_ms: 11467.741\n",
      "    update_time_ms: 1.745\n",
      "  timestamp: 1641871262\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 16000\n",
      "  training_iteration: 4\n",
      "  trial_id: 59aed_00001\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 16000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-21-02\n",
      "  done: false\n",
      "  episode_len_mean: 629.5454545454545\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -99.00758361800077\n",
      "  episode_reward_mean: -112.24804707501917\n",
      "  episode_reward_min: -131.66451502161357\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 22\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.729316234588623\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009825948625802994\n",
      "          model: {}\n",
      "          policy_loss: -0.024860862642526627\n",
      "          total_loss: 116.51917266845703\n",
      "          vf_explained_var: -0.10897161066532135\n",
      "          vf_loss: 116.54107666015625\n",
      "    num_agent_steps_sampled: 16000\n",
      "    num_agent_steps_trained: 16000\n",
      "    num_steps_sampled: 16000\n",
      "    num_steps_trained: 16000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.06470588235294\n",
      "    ram_util_percent: 58.3470588235294\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15145444345038842\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.557037204759329\n",
      "    mean_inference_ms: 2.93160063994932\n",
      "    mean_raw_obs_processing_ms: 0.12786094367612702\n",
      "  time_since_restore: 51.388704776763916\n",
      "  time_this_iter_s: 12.306087493896484\n",
      "  time_total_s: 51.388704776763916\n",
      "  timers:\n",
      "    learn_throughput: 711.59\n",
      "    learn_time_ms: 5621.216\n",
      "    load_throughput: 16020258.773\n",
      "    load_time_ms: 0.25\n",
      "    sample_throughput: 347.891\n",
      "    sample_time_ms: 11497.862\n",
      "    update_time_ms: 2.244\n",
      "  timestamp: 1641871262\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 16000\n",
      "  training_iteration: 4\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:21:03 (running for 00:01:07.57)<br>Memory usage on this node: 13.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         51.3887</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\">-112.248</td><td style=\"text-align: right;\">            -99.0076</td><td style=\"text-align: right;\">            -131.665</td><td style=\"text-align: right;\">           629.545</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         51.2132</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\">-111.286</td><td style=\"text-align: right;\">           -100.405 </td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           450.303</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:21:08 (running for 00:01:12.61)<br>Memory usage on this node: 13.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         51.3887</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\">-112.248</td><td style=\"text-align: right;\">            -99.0076</td><td style=\"text-align: right;\">            -131.665</td><td style=\"text-align: right;\">           629.545</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         51.2132</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\">-111.286</td><td style=\"text-align: right;\">           -100.405 </td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           450.303</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:21:13 (running for 00:01:17.66)<br>Memory usage on this node: 13.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         51.3887</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\">-112.248</td><td style=\"text-align: right;\">            -99.0076</td><td style=\"text-align: right;\">            -131.665</td><td style=\"text-align: right;\">           629.545</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         51.2132</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\">-111.286</td><td style=\"text-align: right;\">           -100.405 </td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           450.303</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 20000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-21-14\n",
      "  done: false\n",
      "  episode_len_mean: 492.43243243243245\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -99.73759102416473\n",
      "  episode_reward_mean: -110.45603252612374\n",
      "  episode_reward_min: -128.94831305721644\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 37\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.012500000186264515\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.66903018951416\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.144841116409225e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003387675853446126\n",
      "          total_loss: 176.13194274902344\n",
      "          vf_explained_var: 2.334585769858677e-05\n",
      "          vf_loss: 176.1285400390625\n",
      "    num_agent_steps_sampled: 20000\n",
      "    num_agent_steps_trained: 20000\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.71176470588235\n",
      "    ram_util_percent: 58.3235294117647\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1481912359230474\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.539467580388974\n",
      "    mean_inference_ms: 2.9144773059716087\n",
      "    mean_raw_obs_processing_ms: 0.13177941497138224\n",
      "  time_since_restore: 63.52424740791321\n",
      "  time_this_iter_s: 12.311073303222656\n",
      "  time_total_s: 63.52424740791321\n",
      "  timers:\n",
      "    learn_throughput: 731.666\n",
      "    learn_time_ms: 5466.979\n",
      "    load_throughput: 10029421.33\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 343.332\n",
      "    sample_time_ms: 11650.537\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871274\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 5\n",
      "  trial_id: 59aed_00001\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 20000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-21-15\n",
      "  done: false\n",
      "  episode_len_mean: 525.2058823529412\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -95.97292031335583\n",
      "  episode_reward_mean: -110.51249573361545\n",
      "  episode_reward_min: -131.66451502161357\n",
      "  episodes_this_iter: 12\n",
      "  episodes_total: 34\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.990804672241211\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02214786224067211\n",
      "          model: {}\n",
      "          policy_loss: -0.0344102568924427\n",
      "          total_loss: 640.601318359375\n",
      "          vf_explained_var: -0.3599016070365906\n",
      "          vf_loss: 640.6290283203125\n",
      "    num_agent_steps_sampled: 20000\n",
      "    num_agent_steps_trained: 20000\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.6764705882353\n",
      "    ram_util_percent: 58.3235294117647\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14572314200972497\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.544121555712971\n",
      "    mean_inference_ms: 2.8591963508116054\n",
      "    mean_raw_obs_processing_ms: 0.12475411573041317\n",
      "  time_since_restore: 63.69479179382324\n",
      "  time_this_iter_s: 12.306087017059326\n",
      "  time_total_s: 63.69479179382324\n",
      "  timers:\n",
      "    learn_throughput: 713.14\n",
      "    learn_time_ms: 5608.998\n",
      "    load_throughput: 20025323.466\n",
      "    load_time_ms: 0.2\n",
      "    sample_throughput: 343.483\n",
      "    sample_time_ms: 11645.422\n",
      "    update_time_ms: 2.195\n",
      "  timestamp: 1641871275\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 5\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:21:19 (running for 00:01:22.92)<br>Memory usage on this node: 13.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         63.6948</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">-110.512</td><td style=\"text-align: right;\">            -95.9729</td><td style=\"text-align: right;\">            -131.665</td><td style=\"text-align: right;\">           525.206</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         63.5242</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">-110.456</td><td style=\"text-align: right;\">            -99.7376</td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           492.432</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:21:24 (running for 00:01:27.97)<br>Memory usage on this node: 13.8/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         63.6948</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">-110.512</td><td style=\"text-align: right;\">            -95.9729</td><td style=\"text-align: right;\">            -131.665</td><td style=\"text-align: right;\">           525.206</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         63.5242</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">-110.456</td><td style=\"text-align: right;\">            -99.7376</td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           492.432</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 24000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-21-27\n",
      "  done: false\n",
      "  episode_len_mean: 563.1219512195122\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -99.73759102416473\n",
      "  episode_reward_mean: -110.10179113134654\n",
      "  episode_reward_min: -128.94831305721644\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 41\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0062500000931322575\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.668276786804199\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.5816837023739936e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0035498803481459618\n",
      "          total_loss: 115.53926086425781\n",
      "          vf_explained_var: -0.00013972797023598105\n",
      "          vf_loss: 115.53572082519531\n",
      "    num_agent_steps_sampled: 24000\n",
      "    num_agent_steps_trained: 24000\n",
      "    num_steps_sampled: 24000\n",
      "    num_steps_trained: 24000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.988888888888894\n",
      "    ram_util_percent: 58.13333333333334\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14680830935040043\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5364532751991578\n",
      "    mean_inference_ms: 2.8994935465103437\n",
      "    mean_raw_obs_processing_ms: 0.13095045060540914\n",
      "  time_since_restore: 76.01982855796814\n",
      "  time_this_iter_s: 12.495581150054932\n",
      "  time_total_s: 76.01982855796814\n",
      "  timers:\n",
      "    learn_throughput: 729.417\n",
      "    learn_time_ms: 5483.833\n",
      "    load_throughput: 12035305.595\n",
      "    load_time_ms: 0.332\n",
      "    sample_throughput: 340.114\n",
      "    sample_time_ms: 11760.765\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871287\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 24000\n",
      "  training_iteration: 6\n",
      "  trial_id: 59aed_00001\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 24000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-21-27\n",
      "  done: false\n",
      "  episode_len_mean: 563.1282051282051\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -95.97292031335583\n",
      "  episode_reward_mean: -112.43301192451621\n",
      "  episode_reward_min: -174.7469390741705\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 39\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.71239709854126\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009132576175034046\n",
      "          model: {}\n",
      "          policy_loss: -0.031017187982797623\n",
      "          total_loss: 222.90219116210938\n",
      "          vf_explained_var: -0.17086312174797058\n",
      "          vf_loss: 222.92909240722656\n",
      "    num_agent_steps_sampled: 24000\n",
      "    num_agent_steps_trained: 24000\n",
      "    num_steps_sampled: 24000\n",
      "    num_steps_trained: 24000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.016666666666666\n",
      "    ram_util_percent: 58.14444444444444\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14394430124461446\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.539953128696724\n",
      "    mean_inference_ms: 2.837462408126957\n",
      "    mean_raw_obs_processing_ms: 0.12392189716269116\n",
      "  time_since_restore: 75.95500206947327\n",
      "  time_this_iter_s: 12.260210275650024\n",
      "  time_total_s: 75.95500206947327\n",
      "  timers:\n",
      "    learn_throughput: 714.962\n",
      "    learn_time_ms: 5594.704\n",
      "    load_throughput: 24030388.159\n",
      "    load_time_ms: 0.166\n",
      "    sample_throughput: 340.212\n",
      "    sample_time_ms: 11757.37\n",
      "    update_time_ms: 2.161\n",
      "  timestamp: 1641871287\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 24000\n",
      "  training_iteration: 6\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:21:29 (running for 00:01:33.20)<br>Memory usage on this node: 14.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         75.955 </td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">-112.433</td><td style=\"text-align: right;\">            -95.9729</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           563.128</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         76.0198</td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">-110.102</td><td style=\"text-align: right;\">            -99.7376</td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           563.122</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:21:34 (running for 00:01:38.25)<br>Memory usage on this node: 14.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         75.955 </td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">-112.433</td><td style=\"text-align: right;\">            -95.9729</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           563.128</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         76.0198</td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">-110.102</td><td style=\"text-align: right;\">            -99.7376</td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           563.122</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:21:39 (running for 00:01:43.30)<br>Memory usage on this node: 14.6/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         75.955 </td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">-112.433</td><td style=\"text-align: right;\">            -95.9729</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           563.128</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         76.0198</td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">-110.102</td><td style=\"text-align: right;\">            -99.7376</td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           563.122</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 28000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-21-41\n",
      "  done: false\n",
      "  episode_len_mean: 599.1136363636364\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -99.73759102416473\n",
      "  episode_reward_mean: -110.4359533129833\n",
      "  episode_reward_min: -128.94831305721644\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 44\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0031250000465661287\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.66783332824707\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.765454721360584e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003296629758551717\n",
      "          total_loss: 123.50698852539062\n",
      "          vf_explained_var: 1.2406033420120366e-05\n",
      "          vf_loss: 123.5036849975586\n",
      "    num_agent_steps_sampled: 28000\n",
      "    num_agent_steps_trained: 28000\n",
      "    num_steps_sampled: 28000\n",
      "    num_steps_trained: 28000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.00000000000001\n",
      "    ram_util_percent: 59.67368421052631\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14605887906046114\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5344435199033845\n",
      "    mean_inference_ms: 2.8904669184055\n",
      "    mean_raw_obs_processing_ms: 0.1302598142066498\n",
      "  time_since_restore: 89.75527596473694\n",
      "  time_this_iter_s: 13.735447406768799\n",
      "  time_total_s: 89.75527596473694\n",
      "  timers:\n",
      "    learn_throughput: 709.012\n",
      "    learn_time_ms: 5641.651\n",
      "    load_throughput: 14041189.861\n",
      "    load_time_ms: 0.285\n",
      "    sample_throughput: 336.136\n",
      "    sample_time_ms: 11899.938\n",
      "    update_time_ms: 1.852\n",
      "  timestamp: 1641871301\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 7\n",
      "  trial_id: 59aed_00001\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 28000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-21-41\n",
      "  done: false\n",
      "  episode_len_mean: 565.7291666666666\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -95.97292031335583\n",
      "  episode_reward_mean: -110.91259671166252\n",
      "  episode_reward_min: -174.7469390741705\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 48\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 6.050714015960693\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01680940017104149\n",
      "          model: {}\n",
      "          policy_loss: -0.03516533970832825\n",
      "          total_loss: 310.9514465332031\n",
      "          vf_explained_var: -0.26384109258651733\n",
      "          vf_loss: 310.9790344238281\n",
      "    num_agent_steps_sampled: 28000\n",
      "    num_agent_steps_trained: 28000\n",
      "    num_steps_sampled: 28000\n",
      "    num_steps_trained: 28000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.05263157894737\n",
      "    ram_util_percent: 59.70526315789474\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14169896566601878\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5349351297412427\n",
      "    mean_inference_ms: 2.810542050214263\n",
      "    mean_raw_obs_processing_ms: 0.12307114220629582\n",
      "  time_since_restore: 89.71239018440247\n",
      "  time_this_iter_s: 13.7573881149292\n",
      "  time_total_s: 89.71239018440247\n",
      "  timers:\n",
      "    learn_throughput: 694.92\n",
      "    learn_time_ms: 5756.06\n",
      "    load_throughput: 28035452.853\n",
      "    load_time_ms: 0.143\n",
      "    sample_throughput: 336.798\n",
      "    sample_time_ms: 11876.565\n",
      "    update_time_ms: 2.28\n",
      "  timestamp: 1641871301\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 7\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:21:45 (running for 00:01:49.00)<br>Memory usage on this node: 14.6/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         89.7124</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">-110.913</td><td style=\"text-align: right;\">            -95.9729</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           565.729</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         89.7553</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">-110.436</td><td style=\"text-align: right;\">            -99.7376</td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           599.114</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:21:50 (running for 00:01:54.05)<br>Memory usage on this node: 14.6/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         89.7124</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">-110.913</td><td style=\"text-align: right;\">            -95.9729</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           565.729</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         89.7553</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">-110.436</td><td style=\"text-align: right;\">            -99.7376</td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           599.114</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 32000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-21-54\n",
      "  done: false\n",
      "  episode_len_mean: 568.4905660377359\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.5673152313872\n",
      "  episode_reward_mean: -109.91401458011228\n",
      "  episode_reward_min: -128.94831305721644\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 53\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0015625000232830644\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.6678876876831055\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.7384813588705583e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0033293452579528093\n",
      "          total_loss: 633.1707763671875\n",
      "          vf_explained_var: 0.00012435298413038254\n",
      "          vf_loss: 633.16748046875\n",
      "    num_agent_steps_sampled: 32000\n",
      "    num_agent_steps_trained: 32000\n",
      "    num_steps_sampled: 32000\n",
      "    num_steps_trained: 32000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.95789473684211\n",
      "    ram_util_percent: 61.18947368421052\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14427231630327084\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5305714539402567\n",
      "    mean_inference_ms: 2.872705582201744\n",
      "    mean_raw_obs_processing_ms: 0.12929565531543227\n",
      "  time_since_restore: 102.97649002075195\n",
      "  time_this_iter_s: 13.221214056015015\n",
      "  time_total_s: 102.97649002075195\n",
      "  timers:\n",
      "    learn_throughput: 710.948\n",
      "    learn_time_ms: 5626.291\n",
      "    load_throughput: 16047074.127\n",
      "    load_time_ms: 0.249\n",
      "    sample_throughput: 327.826\n",
      "    sample_time_ms: 12201.587\n",
      "    update_time_ms: 1.87\n",
      "  timestamp: 1641871314\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 32000\n",
      "  training_iteration: 8\n",
      "  trial_id: 59aed_00001\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 32000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-21-54\n",
      "  done: false\n",
      "  episode_len_mean: 577.1132075471698\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -95.97292031335583\n",
      "  episode_reward_mean: -111.16803532086374\n",
      "  episode_reward_min: -174.7469390741705\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 53\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.771394729614258\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00871240720152855\n",
      "          model: {}\n",
      "          policy_loss: -0.027371421456336975\n",
      "          total_loss: 216.04635620117188\n",
      "          vf_explained_var: -0.2257852852344513\n",
      "          vf_loss: 216.06980895996094\n",
      "    num_agent_steps_sampled: 32000\n",
      "    num_agent_steps_trained: 32000\n",
      "    num_steps_sampled: 32000\n",
      "    num_steps_trained: 32000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.77894736842105\n",
      "    ram_util_percent: 61.178947368421056\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14080137476873356\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5336243484300133\n",
      "    mean_inference_ms: 2.8025522190059315\n",
      "    mean_raw_obs_processing_ms: 0.12283968464572276\n",
      "  time_since_restore: 102.91964197158813\n",
      "  time_this_iter_s: 13.207251787185669\n",
      "  time_total_s: 102.91964197158813\n",
      "  timers:\n",
      "    learn_throughput: 696.79\n",
      "    learn_time_ms: 5740.61\n",
      "    load_throughput: 32040517.546\n",
      "    load_time_ms: 0.125\n",
      "    sample_throughput: 328.343\n",
      "    sample_time_ms: 12182.372\n",
      "    update_time_ms: 2.244\n",
      "  timestamp: 1641871314\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 32000\n",
      "  training_iteration: 8\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:21:55 (running for 00:01:59.20)<br>Memory usage on this node: 14.5/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         102.92 </td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\">-111.168</td><td style=\"text-align: right;\">            -95.9729</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           577.113</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         102.976</td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\">-109.914</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           568.491</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:22:00 (running for 00:02:04.24)<br>Memory usage on this node: 14.6/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         102.92 </td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\">-111.168</td><td style=\"text-align: right;\">            -95.9729</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           577.113</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         102.976</td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\">-109.914</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           568.491</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:22:05 (running for 00:02:09.31)<br>Memory usage on this node: 14.6/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         102.92 </td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\">-111.168</td><td style=\"text-align: right;\">            -95.9729</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           577.113</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         102.976</td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\">-109.914</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           568.491</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 36000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-22-07\n",
      "  done: false\n",
      "  episode_len_mean: 595.3559322033898\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.5673152313872\n",
      "  episode_reward_mean: -110.4833752575314\n",
      "  episode_reward_min: -128.94831305721644\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 59\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0007812500116415322\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.668208599090576\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 4.6928869323892286e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.00182586710434407\n",
      "          total_loss: 316.4660949707031\n",
      "          vf_explained_var: 8.231081301346421e-05\n",
      "          vf_loss: 316.4642333984375\n",
      "    num_agent_steps_sampled: 36000\n",
      "    num_agent_steps_trained: 36000\n",
      "    num_steps_sampled: 36000\n",
      "    num_steps_trained: 36000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.55555555555556\n",
      "    ram_util_percent: 61.10555555555555\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14364082015084095\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5285542001800525\n",
      "    mean_inference_ms: 2.8644460791072395\n",
      "    mean_raw_obs_processing_ms: 0.128567761955349\n",
      "  time_since_restore: 115.55086064338684\n",
      "  time_this_iter_s: 12.574370622634888\n",
      "  time_total_s: 115.55086064338684\n",
      "  timers:\n",
      "    learn_throughput: 713.496\n",
      "    learn_time_ms: 5606.196\n",
      "    load_throughput: 18052958.393\n",
      "    load_time_ms: 0.222\n",
      "    sample_throughput: 326.44\n",
      "    sample_time_ms: 12253.386\n",
      "    update_time_ms: 1.884\n",
      "  timestamp: 1641871327\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 9\n",
      "  trial_id: 59aed_00001\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 36000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-22-07\n",
      "  done: false\n",
      "  episode_len_mean: 576.5254237288135\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -95.97292031335583\n",
      "  episode_reward_mean: -110.6539568398103\n",
      "  episode_reward_min: -174.7469390741705\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 59\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.740038871765137\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007247689180076122\n",
      "          model: {}\n",
      "          policy_loss: -0.02155139483511448\n",
      "          total_loss: 202.94544982910156\n",
      "          vf_explained_var: -0.10506559163331985\n",
      "          vf_loss: 202.9637451171875\n",
      "    num_agent_steps_sampled: 36000\n",
      "    num_agent_steps_trained: 36000\n",
      "    num_steps_sampled: 36000\n",
      "    num_steps_trained: 36000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.92941176470589\n",
      "    ram_util_percent: 61.11176470588236\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1400179174885903\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5317286307177146\n",
      "    mean_inference_ms: 2.7929678963254485\n",
      "    mean_raw_obs_processing_ms: 0.12251809082878502\n",
      "  time_since_restore: 115.54487633705139\n",
      "  time_this_iter_s: 12.625234365463257\n",
      "  time_total_s: 115.54487633705139\n",
      "  timers:\n",
      "    learn_throughput: 698.881\n",
      "    learn_time_ms: 5723.438\n",
      "    load_throughput: 36045582.239\n",
      "    load_time_ms: 0.111\n",
      "    sample_throughput: 326.83\n",
      "    sample_time_ms: 12238.766\n",
      "    update_time_ms: 2.217\n",
      "  timestamp: 1641871327\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 9\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:22:11 (running for 00:02:14.87)<br>Memory usage on this node: 14.6/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         115.545</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\">-110.654</td><td style=\"text-align: right;\">            -95.9729</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           576.525</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         115.551</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\">-110.483</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           595.356</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:22:16 (running for 00:02:19.92)<br>Memory usage on this node: 14.6/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         115.545</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\">-110.654</td><td style=\"text-align: right;\">            -95.9729</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           576.525</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         115.551</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\">-110.483</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -128.948</td><td style=\"text-align: right;\">           595.356</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 40000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-22-19\n",
      "  done: false\n",
      "  episode_len_mean: 592.4626865671642\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.5673152313872\n",
      "  episode_reward_mean: -111.70412611652412\n",
      "  episode_reward_min: -185.32600351624558\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 67\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0003906250058207661\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.667436599731445\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.9228758080535044e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003412125864997506\n",
      "          total_loss: 645.3225708007812\n",
      "          vf_explained_var: -2.5656916022853693e-06\n",
      "          vf_loss: 645.3191528320312\n",
      "    num_agent_steps_sampled: 40000\n",
      "    num_agent_steps_trained: 40000\n",
      "    num_steps_sampled: 40000\n",
      "    num_steps_trained: 40000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.75294117647059\n",
      "    ram_util_percent: 60.95294117647059\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14285807710529186\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5261318613706211\n",
      "    mean_inference_ms: 2.853730795319984\n",
      "    mean_raw_obs_processing_ms: 0.12777486561373883\n",
      "  time_since_restore: 128.0933153629303\n",
      "  time_this_iter_s: 12.542454719543457\n",
      "  time_total_s: 128.0933153629303\n",
      "  timers:\n",
      "    learn_throughput: 713.499\n",
      "    learn_time_ms: 5606.177\n",
      "    load_throughput: 20058842.659\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 326.057\n",
      "    sample_time_ms: 12267.799\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641871339\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 10\n",
      "  trial_id: 59aed_00001\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 40000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-22-19\n",
      "  done: false\n",
      "  episode_len_mean: 600.0153846153846\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -95.97292031335583\n",
      "  episode_reward_mean: -110.39510224567366\n",
      "  episode_reward_min: -174.7469390741705\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 65\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.652368068695068\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007924700155854225\n",
      "          model: {}\n",
      "          policy_loss: -0.028839390724897385\n",
      "          total_loss: 134.562255859375\n",
      "          vf_explained_var: -0.17918044328689575\n",
      "          vf_loss: 134.5875244140625\n",
      "    num_agent_steps_sampled: 40000\n",
      "    num_agent_steps_trained: 40000\n",
      "    num_steps_sampled: 40000\n",
      "    num_steps_trained: 40000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.3111111111111\n",
      "    ram_util_percent: 60.96666666666667\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13918770278783246\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5302229950827576\n",
      "    mean_inference_ms: 2.785166484848377\n",
      "    mean_raw_obs_processing_ms: 0.12224379544373794\n",
      "  time_since_restore: 128.02350306510925\n",
      "  time_this_iter_s: 12.478626728057861\n",
      "  time_total_s: 128.02350306510925\n",
      "  timers:\n",
      "    learn_throughput: 699.694\n",
      "    learn_time_ms: 5716.781\n",
      "    load_throughput: 40050646.932\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 326.31\n",
      "    sample_time_ms: 12258.276\n",
      "    update_time_ms: 2.095\n",
      "  timestamp: 1641871339\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 10\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:22:21 (running for 00:02:25.35)<br>Memory usage on this node: 14.4/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         128.024</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">-110.395</td><td style=\"text-align: right;\">            -95.9729</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           600.015</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         128.093</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">-111.704</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           592.463</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:22:26 (running for 00:02:30.42)<br>Memory usage on this node: 14.3/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         128.024</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">-110.395</td><td style=\"text-align: right;\">            -95.9729</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           600.015</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         128.093</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">-111.704</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           592.463</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 44000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-22-31\n",
      "  done: false\n",
      "  episode_len_mean: 621.6666666666666\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.5673152313872\n",
      "  episode_reward_mean: -111.69441426554613\n",
      "  episode_reward_min: -185.32600351624558\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 69\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.00019531250291038305\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.668426036834717\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 5.088804186925699e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.006621320731937885\n",
      "          total_loss: 20.710227966308594\n",
      "          vf_explained_var: 0.00011223881301702932\n",
      "          vf_loss: 20.7036075592041\n",
      "    num_agent_steps_sampled: 44000\n",
      "    num_agent_steps_trained: 44000\n",
      "    num_steps_sampled: 44000\n",
      "    num_steps_trained: 44000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.14705882352941\n",
      "    ram_util_percent: 60.170588235294126\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14265878655035796\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5255248843325112\n",
      "    mean_inference_ms: 2.8506567683432693\n",
      "    mean_raw_obs_processing_ms: 0.12757256681734574\n",
      "  time_since_restore: 139.76410174369812\n",
      "  time_this_iter_s: 11.670786380767822\n",
      "  time_total_s: 139.76410174369812\n",
      "  timers:\n",
      "    learn_throughput: 721.106\n",
      "    learn_time_ms: 5547.035\n",
      "    load_throughput: 40098508.604\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 316.408\n",
      "    sample_time_ms: 12641.896\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871351\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 44000\n",
      "  training_iteration: 11\n",
      "  trial_id: 59aed_00001\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 44000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-22-31\n",
      "  done: false\n",
      "  episode_len_mean: 577.2837837837837\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -95.97292031335583\n",
      "  episode_reward_mean: -110.128142239484\n",
      "  episode_reward_min: -174.7469390741705\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 74\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.838955402374268\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011863481253385544\n",
      "          model: {}\n",
      "          policy_loss: -0.027785826474428177\n",
      "          total_loss: 330.66387939453125\n",
      "          vf_explained_var: -0.5222680568695068\n",
      "          vf_loss: 330.6863708496094\n",
      "    num_agent_steps_sampled: 44000\n",
      "    num_agent_steps_trained: 44000\n",
      "    num_steps_sampled: 44000\n",
      "    num_steps_trained: 44000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.99375\n",
      "    ram_util_percent: 60.1625\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13825525557726462\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5277381549160876\n",
      "    mean_inference_ms: 2.7724697574366006\n",
      "    mean_raw_obs_processing_ms: 0.12183479783696657\n",
      "  time_since_restore: 139.69229459762573\n",
      "  time_this_iter_s: 11.66879153251648\n",
      "  time_total_s: 139.69229459762573\n",
      "  timers:\n",
      "    learn_throughput: 708.032\n",
      "    learn_time_ms: 5649.461\n",
      "    load_throughput: 40050646.932\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 316.504\n",
      "    sample_time_ms: 12638.072\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871351\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 44000\n",
      "  training_iteration: 11\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:22:32 (running for 00:02:36.03)<br>Memory usage on this node: 14.3/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         139.692</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\">-110.128</td><td style=\"text-align: right;\">            -95.9729</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           577.284</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         139.764</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\">-111.694</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           621.667</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:22:37 (running for 00:02:41.08)<br>Memory usage on this node: 14.4/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         139.692</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\">-110.128</td><td style=\"text-align: right;\">            -95.9729</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           577.284</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         139.764</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\">-111.694</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           621.667</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:22:42 (running for 00:02:46.14)<br>Memory usage on this node: 14.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         139.692</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\">-110.128</td><td style=\"text-align: right;\">            -95.9729</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           577.284</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         139.764</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\">-111.694</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           621.667</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 48000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-22-43\n",
      "  done: false\n",
      "  episode_len_mean: 548.8823529411765\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -91.35624372091766\n",
      "  episode_reward_mean: -110.13750792969574\n",
      "  episode_reward_min: -174.7469390741705\n",
      "  episodes_this_iter: 11\n",
      "  episodes_total: 85\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.8206467628479\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009905263781547546\n",
      "          model: {}\n",
      "          policy_loss: -0.02379979006946087\n",
      "          total_loss: 366.1580505371094\n",
      "          vf_explained_var: -0.1729094535112381\n",
      "          vf_loss: 366.1773986816406\n",
      "    num_agent_steps_sampled: 48000\n",
      "    num_agent_steps_trained: 48000\n",
      "    num_steps_sampled: 48000\n",
      "    num_steps_trained: 48000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.06470588235294\n",
      "    ram_util_percent: 59.805882352941175\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13721598839630497\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5253701782806796\n",
      "    mean_inference_ms: 2.7582419619246203\n",
      "    mean_raw_obs_processing_ms: 0.12140022823756917\n",
      "  time_since_restore: 151.5067720413208\n",
      "  time_this_iter_s: 11.814477443695068\n",
      "  time_total_s: 151.5067720413208\n",
      "  timers:\n",
      "    learn_throughput: 710.767\n",
      "    learn_time_ms: 5627.719\n",
      "    load_throughput: 40050646.932\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 319.258\n",
      "    sample_time_ms: 12529.038\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871363\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 48000\n",
      "  training_iteration: 12\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 48000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-22-43\n",
      "  done: false\n",
      "  episode_len_mean: 649.2253521126761\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.5673152313872\n",
      "  episode_reward_mean: -111.6413395202724\n",
      "  episode_reward_min: -185.32600351624558\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 71\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 9.765625145519152e-05\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.666059494018555\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 5.223598122938711e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.010315154679119587\n",
      "          total_loss: 17.23636245727539\n",
      "          vf_explained_var: -8.49709686008282e-05\n",
      "          vf_loss: 17.226045608520508\n",
      "    num_agent_steps_sampled: 48000\n",
      "    num_agent_steps_trained: 48000\n",
      "    num_steps_sampled: 48000\n",
      "    num_steps_trained: 48000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.8\n",
      "    ram_util_percent: 59.8125\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14243307973783056\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5249135362336108\n",
      "    mean_inference_ms: 2.8470891000459853\n",
      "    mean_raw_obs_processing_ms: 0.12734806334690743\n",
      "  time_since_restore: 151.59353923797607\n",
      "  time_this_iter_s: 11.829437494277954\n",
      "  time_total_s: 151.59353923797607\n",
      "  timers:\n",
      "    learn_throughput: 722.6\n",
      "    learn_time_ms: 5535.566\n",
      "    load_throughput: 40098508.604\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 318.96\n",
      "    sample_time_ms: 12540.751\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871363\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 48000\n",
      "  training_iteration: 12\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:22:48 (running for 00:02:51.93)<br>Memory usage on this node: 14.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         151.507</td><td style=\"text-align: right;\">48000</td><td style=\"text-align: right;\">-110.138</td><td style=\"text-align: right;\">            -91.3562</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           548.882</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         151.594</td><td style=\"text-align: right;\">48000</td><td style=\"text-align: right;\">-111.641</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           649.225</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:22:53 (running for 00:02:56.99)<br>Memory usage on this node: 14.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         151.507</td><td style=\"text-align: right;\">48000</td><td style=\"text-align: right;\">-110.138</td><td style=\"text-align: right;\">            -91.3562</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           548.882</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         151.594</td><td style=\"text-align: right;\">48000</td><td style=\"text-align: right;\">-111.641</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           649.225</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 52000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-22-54\n",
      "  done: false\n",
      "  episode_len_mean: 608.7439024390244\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.5673152313872\n",
      "  episode_reward_mean: -111.72672400849284\n",
      "  episode_reward_min: -185.32600351624558\n",
      "  episodes_this_iter: 11\n",
      "  episodes_total: 82\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.882812572759576e-05\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.666398048400879\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.1807894629309885e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0037327520549297333\n",
      "          total_loss: 836.8002319335938\n",
      "          vf_explained_var: -5.153046004124917e-06\n",
      "          vf_loss: 836.7965087890625\n",
      "    num_agent_steps_sampled: 52000\n",
      "    num_agent_steps_trained: 52000\n",
      "    num_steps_sampled: 52000\n",
      "    num_steps_trained: 52000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.294117647058826\n",
      "    ram_util_percent: 58.817647058823525\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14131740629454137\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5216702645791798\n",
      "    mean_inference_ms: 2.8285702549231844\n",
      "    mean_raw_obs_processing_ms: 0.1263254859080503\n",
      "  time_since_restore: 163.237398147583\n",
      "  time_this_iter_s: 11.643858909606934\n",
      "  time_total_s: 163.237398147583\n",
      "  timers:\n",
      "    learn_throughput: 725.292\n",
      "    learn_time_ms: 5515.021\n",
      "    load_throughput: 40098508.604\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 320.436\n",
      "    sample_time_ms: 12483.01\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871374\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 52000\n",
      "  training_iteration: 13\n",
      "  trial_id: 59aed_00001\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 52000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-22-54\n",
      "  done: false\n",
      "  episode_len_mean: 552.054347826087\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -91.35624372091766\n",
      "  episode_reward_mean: -111.03608773095544\n",
      "  episode_reward_min: -174.7469390741705\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 92\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.605287551879883\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010043171234428883\n",
      "          model: {}\n",
      "          policy_loss: -0.04656782001256943\n",
      "          total_loss: 266.6904296875\n",
      "          vf_explained_var: -0.706907331943512\n",
      "          vf_loss: 266.7324523925781\n",
      "    num_agent_steps_sampled: 52000\n",
      "    num_agent_steps_trained: 52000\n",
      "    num_steps_sampled: 52000\n",
      "    num_steps_trained: 52000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.41764705882353\n",
      "    ram_util_percent: 58.8\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1365940645371492\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5240541545866403\n",
      "    mean_inference_ms: 2.7500588853786256\n",
      "    mean_raw_obs_processing_ms: 0.12111763239751387\n",
      "  time_since_restore: 163.25634908676147\n",
      "  time_this_iter_s: 11.749577045440674\n",
      "  time_total_s: 163.25634908676147\n",
      "  timers:\n",
      "    learn_throughput: 713.676\n",
      "    learn_time_ms: 5604.781\n",
      "    load_throughput: 40127280.555\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 320.926\n",
      "    sample_time_ms: 12463.932\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641871374\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 52000\n",
      "  training_iteration: 13\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:22:58 (running for 00:03:02.66)<br>Memory usage on this node: 14.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         163.256</td><td style=\"text-align: right;\">52000</td><td style=\"text-align: right;\">-111.036</td><td style=\"text-align: right;\">            -91.3562</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           552.054</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         163.237</td><td style=\"text-align: right;\">52000</td><td style=\"text-align: right;\">-111.727</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           608.744</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:23:04 (running for 00:03:07.73)<br>Memory usage on this node: 14.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         163.256</td><td style=\"text-align: right;\">52000</td><td style=\"text-align: right;\">-111.036</td><td style=\"text-align: right;\">            -91.3562</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           552.054</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         163.237</td><td style=\"text-align: right;\">52000</td><td style=\"text-align: right;\">-111.727</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           608.744</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 56000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-23-06\n",
      "  done: false\n",
      "  episode_len_mean: 558.5773195876288\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -91.35624372091766\n",
      "  episode_reward_mean: -110.8158708871416\n",
      "  episode_reward_min: -174.7469390741705\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 97\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.590597629547119\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007609482388943434\n",
      "          model: {}\n",
      "          policy_loss: -0.025134950876235962\n",
      "          total_loss: 111.6821517944336\n",
      "          vf_explained_var: -0.15984444320201874\n",
      "          vf_loss: 111.70386505126953\n",
      "    num_agent_steps_sampled: 56000\n",
      "    num_agent_steps_trained: 56000\n",
      "    num_steps_sampled: 56000\n",
      "    num_steps_trained: 56000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.243750000000006\n",
      "    ram_util_percent: 59.01875\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13618986116778714\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5230998167104104\n",
      "    mean_inference_ms: 2.7437452651470338\n",
      "    mean_raw_obs_processing_ms: 0.12087846059483558\n",
      "  time_since_restore: 175.15053796768188\n",
      "  time_this_iter_s: 11.89418888092041\n",
      "  time_total_s: 175.15053796768188\n",
      "  timers:\n",
      "    learn_throughput: 713.664\n",
      "    learn_time_ms: 5604.881\n",
      "    load_throughput: 40127280.555\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 322.622\n",
      "    sample_time_ms: 12398.404\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871386\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 56000\n",
      "  training_iteration: 14\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 56000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-23-06\n",
      "  done: false\n",
      "  episode_len_mean: 643.7294117647059\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.5673152313872\n",
      "  episode_reward_mean: -111.98884177263878\n",
      "  episode_reward_min: -185.32600351624558\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 85\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.441406286379788e-05\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.665780544281006\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 8.802743423075299e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.012455224059522152\n",
      "          total_loss: 19.581195831298828\n",
      "          vf_explained_var: 7.417932647513226e-05\n",
      "          vf_loss: 19.568740844726562\n",
      "    num_agent_steps_sampled: 56000\n",
      "    num_agent_steps_trained: 56000\n",
      "    num_steps_sampled: 56000\n",
      "    num_steps_trained: 56000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.74705882352941\n",
      "    ram_util_percent: 59.0\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1409866118459037\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5209403128615321\n",
      "    mean_inference_ms: 2.8235375250910053\n",
      "    mean_raw_obs_processing_ms: 0.12603380153461907\n",
      "  time_since_restore: 175.3101100921631\n",
      "  time_this_iter_s: 12.072711944580078\n",
      "  time_total_s: 175.3101100921631\n",
      "  timers:\n",
      "    learn_throughput: 723.395\n",
      "    learn_time_ms: 5529.482\n",
      "    load_throughput: 20054047.334\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 322.134\n",
      "    sample_time_ms: 12417.206\n",
      "    update_time_ms: 2.095\n",
      "  timestamp: 1641871386\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 56000\n",
      "  training_iteration: 14\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:23:09 (running for 00:03:13.66)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         175.151</td><td style=\"text-align: right;\">56000</td><td style=\"text-align: right;\">-110.816</td><td style=\"text-align: right;\">            -91.3562</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           558.577</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         175.31 </td><td style=\"text-align: right;\">56000</td><td style=\"text-align: right;\">-111.989</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           643.729</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:23:14 (running for 00:03:18.71)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         175.151</td><td style=\"text-align: right;\">56000</td><td style=\"text-align: right;\">-110.816</td><td style=\"text-align: right;\">            -91.3562</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           558.577</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         175.31 </td><td style=\"text-align: right;\">56000</td><td style=\"text-align: right;\">-111.989</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           643.729</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 60000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-23-18\n",
      "  done: false\n",
      "  episode_len_mean: 559.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -91.35624372091766\n",
      "  episode_reward_mean: -110.68927038654287\n",
      "  episode_reward_min: -174.7469390741705\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 106\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.750681400299072\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011010969989001751\n",
      "          model: {}\n",
      "          policy_loss: -0.02950676716864109\n",
      "          total_loss: 208.635009765625\n",
      "          vf_explained_var: -0.19247539341449738\n",
      "          vf_loss: 208.65956115722656\n",
      "    num_agent_steps_sampled: 60000\n",
      "    num_agent_steps_trained: 60000\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.34117647058823\n",
      "    ram_util_percent: 51.747058823529414\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13355396275592912\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5167164718921903\n",
      "    mean_inference_ms: 2.7070151201701957\n",
      "    mean_raw_obs_processing_ms: 0.11929425499479006\n",
      "  time_since_restore: 186.93203020095825\n",
      "  time_this_iter_s: 11.781492233276367\n",
      "  time_total_s: 186.93203020095825\n",
      "  timers:\n",
      "    learn_throughput: 718.728\n",
      "    learn_time_ms: 5565.386\n",
      "    load_throughput: 40127280.555\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 322.956\n",
      "    sample_time_ms: 12385.607\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871398\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 15\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 60000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-23-18\n",
      "  done: false\n",
      "  episode_len_mean: 639.5384615384615\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.5673152313872\n",
      "  episode_reward_mean: -111.64268748054167\n",
      "  episode_reward_min: -185.32600351624558\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 91\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.220703143189894e-05\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.66384744644165\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.9801220219051174e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003021777607500553\n",
      "          total_loss: 297.2061767578125\n",
      "          vf_explained_var: -0.0002471272018738091\n",
      "          vf_loss: 297.2031555175781\n",
      "    num_agent_steps_sampled: 60000\n",
      "    num_agent_steps_trained: 60000\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.07647058823529\n",
      "    ram_util_percent: 51.44705882352942\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14041984498807766\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5195343445186533\n",
      "    mean_inference_ms: 2.814066170534736\n",
      "    mean_raw_obs_processing_ms: 0.1255047395433728\n",
      "  time_since_restore: 187.10855674743652\n",
      "  time_this_iter_s: 11.798446655273438\n",
      "  time_total_s: 187.10855674743652\n",
      "  timers:\n",
      "    learn_throughput: 726.185\n",
      "    learn_time_ms: 5508.239\n",
      "    load_throughput: 20054047.334\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 322.506\n",
      "    sample_time_ms: 12402.887\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641871398\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 15\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:23:20 (running for 00:03:24.48)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         186.932</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">-110.689</td><td style=\"text-align: right;\">            -91.3562</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           559.72 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         187.109</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">-111.643</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           639.538</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:23:25 (running for 00:03:29.54)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         186.932</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">-110.689</td><td style=\"text-align: right;\">            -91.3562</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           559.72 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         187.109</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">-111.643</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           639.538</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 64000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-23-30\n",
      "  done: false\n",
      "  episode_len_mean: 543.57\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -91.35624372091766\n",
      "  episode_reward_mean: -110.70297548280391\n",
      "  episode_reward_min: -174.7469390741705\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 114\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.66562032699585\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01254603173583746\n",
      "          model: {}\n",
      "          policy_loss: -0.0352342426776886\n",
      "          total_loss: 175.81202697753906\n",
      "          vf_explained_var: -0.23918741941452026\n",
      "          vf_loss: 175.8415985107422\n",
      "    num_agent_steps_sampled: 64000\n",
      "    num_agent_steps_trained: 64000\n",
      "    num_steps_sampled: 64000\n",
      "    num_steps_trained: 64000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.629411764705885\n",
      "    ram_util_percent: 50.682352941176475\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13182667677114357\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5129366605617582\n",
      "    mean_inference_ms: 2.6833505743006576\n",
      "    mean_raw_obs_processing_ms: 0.11860318800966745\n",
      "  time_since_restore: 198.4720344543457\n",
      "  time_this_iter_s: 11.540004253387451\n",
      "  time_total_s: 198.4720344543457\n",
      "  timers:\n",
      "    learn_throughput: 723.617\n",
      "    learn_time_ms: 5527.787\n",
      "    load_throughput: 20070841.01\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 324.882\n",
      "    sample_time_ms: 12312.144\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871410\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 64000\n",
      "  training_iteration: 16\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 64000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-23-30\n",
      "  done: false\n",
      "  episode_len_mean: 663.6421052631579\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.5673152313872\n",
      "  episode_reward_mean: -111.6077971068901\n",
      "  episode_reward_min: -185.32600351624558\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 95\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 6.10351571594947e-06\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663818836212158\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.7285148007649696e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0019452337874099612\n",
      "          total_loss: 109.70892333984375\n",
      "          vf_explained_var: 0.00017261049652006477\n",
      "          vf_loss: 109.70697021484375\n",
      "    num_agent_steps_sampled: 64000\n",
      "    num_agent_steps_trained: 64000\n",
      "    num_steps_sampled: 64000\n",
      "    num_steps_trained: 64000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.375\n",
      "    ram_util_percent: 50.681250000000006\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14007454739827158\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5185967817991343\n",
      "    mean_inference_ms: 2.8081353384744583\n",
      "    mean_raw_obs_processing_ms: 0.12521885239888048\n",
      "  time_since_restore: 198.75527501106262\n",
      "  time_this_iter_s: 11.646718263626099\n",
      "  time_total_s: 198.75527501106262\n",
      "  timers:\n",
      "    learn_throughput: 731.816\n",
      "    learn_time_ms: 5465.852\n",
      "    load_throughput: 20054047.334\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 324.186\n",
      "    sample_time_ms: 12338.6\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641871410\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 64000\n",
      "  training_iteration: 16\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:23:31 (running for 00:03:35.14)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         198.472</td><td style=\"text-align: right;\">64000</td><td style=\"text-align: right;\">-110.703</td><td style=\"text-align: right;\">            -91.3562</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           543.57 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         198.755</td><td style=\"text-align: right;\">64000</td><td style=\"text-align: right;\">-111.608</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           663.642</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:23:36 (running for 00:03:40.20)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         198.472</td><td style=\"text-align: right;\">64000</td><td style=\"text-align: right;\">-110.703</td><td style=\"text-align: right;\">            -91.3562</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           543.57 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         198.755</td><td style=\"text-align: right;\">64000</td><td style=\"text-align: right;\">-111.608</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           663.642</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:23:41 (running for 00:03:45.27)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         198.472</td><td style=\"text-align: right;\">64000</td><td style=\"text-align: right;\">-110.703</td><td style=\"text-align: right;\">            -91.3562</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           543.57 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         198.755</td><td style=\"text-align: right;\">64000</td><td style=\"text-align: right;\">-111.608</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           663.642</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 68000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-23-41\n",
      "  done: false\n",
      "  episode_len_mean: 512.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -91.35624372091766\n",
      "  episode_reward_mean: -110.56991322224938\n",
      "  episode_reward_min: -174.7469390741705\n",
      "  episodes_this_iter: 12\n",
      "  episodes_total: 126\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.966154098510742\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01315194834023714\n",
      "          model: {}\n",
      "          policy_loss: -0.028432514518499374\n",
      "          total_loss: 259.2101745605469\n",
      "          vf_explained_var: -0.16869564354419708\n",
      "          vf_loss: 259.232666015625\n",
      "    num_agent_steps_sampled: 68000\n",
      "    num_agent_steps_trained: 68000\n",
      "    num_steps_sampled: 68000\n",
      "    num_steps_trained: 68000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.9375\n",
      "    ram_util_percent: 50.70625\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13043225728730903\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5106651206231443\n",
      "    mean_inference_ms: 2.663933607872382\n",
      "    mean_raw_obs_processing_ms: 0.11822979259317272\n",
      "  time_since_restore: 210.0560531616211\n",
      "  time_this_iter_s: 11.58401870727539\n",
      "  time_total_s: 210.0560531616211\n",
      "  timers:\n",
      "    learn_throughput: 743.403\n",
      "    learn_time_ms: 5380.662\n",
      "    load_throughput: 20070841.01\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 327.798\n",
      "    sample_time_ms: 12202.624\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871421\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 68000\n",
      "  training_iteration: 17\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 68000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-23-42\n",
      "  done: false\n",
      "  episode_len_mean: 682.9484536082474\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.5673152313872\n",
      "  episode_reward_mean: -111.62151160959588\n",
      "  episode_reward_min: -185.32600351624558\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 97\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.051757857974735e-06\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663585186004639\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.9896179398747336e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.011272799223661423\n",
      "          total_loss: 20.125600814819336\n",
      "          vf_explained_var: 0.0001645789307076484\n",
      "          vf_loss: 20.11433219909668\n",
      "    num_agent_steps_sampled: 68000\n",
      "    num_agent_steps_trained: 68000\n",
      "    num_steps_sampled: 68000\n",
      "    num_steps_trained: 68000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.51176470588236\n",
      "    ram_util_percent: 50.72941176470588\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13987261699577347\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5182030270865048\n",
      "    mean_inference_ms: 2.8049662287510095\n",
      "    mean_raw_obs_processing_ms: 0.12505494850279641\n",
      "  time_since_restore: 210.5477352142334\n",
      "  time_this_iter_s: 11.792460203170776\n",
      "  time_total_s: 210.5477352142334\n",
      "  timers:\n",
      "    learn_throughput: 749.194\n",
      "    learn_time_ms: 5339.073\n",
      "    load_throughput: 20054047.334\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 327.09\n",
      "    sample_time_ms: 12229.054\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871422\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 68000\n",
      "  training_iteration: 17\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:23:47 (running for 00:03:50.99)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         210.056</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\">-110.57 </td><td style=\"text-align: right;\">            -91.3562</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           512.35 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         210.548</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\">-111.622</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           682.948</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:23:52 (running for 00:03:56.06)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         210.056</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\">-110.57 </td><td style=\"text-align: right;\">            -91.3562</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           512.35 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         210.548</td><td style=\"text-align: right;\">68000</td><td style=\"text-align: right;\">-111.622</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           682.948</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 72000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-23-53\n",
      "  done: false\n",
      "  episode_len_mean: 527.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -90.75731457961847\n",
      "  episode_reward_mean: -110.463320452031\n",
      "  episode_reward_min: -174.7469390741705\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 129\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.5456013679504395\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007829129695892334\n",
      "          model: {}\n",
      "          policy_loss: -0.03434627875685692\n",
      "          total_loss: 71.95195007324219\n",
      "          vf_explained_var: -0.14676012098789215\n",
      "          vf_loss: 71.98278045654297\n",
      "    num_agent_steps_sampled: 72000\n",
      "    num_agent_steps_trained: 72000\n",
      "    num_steps_sampled: 72000\n",
      "    num_steps_trained: 72000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.81875\n",
      "    ram_util_percent: 50.76875\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13016819249064077\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.510078113386574\n",
      "    mean_inference_ms: 2.659450783339237\n",
      "    mean_raw_obs_processing_ms: 0.11812698851180786\n",
      "  time_since_restore: 221.6061623096466\n",
      "  time_this_iter_s: 11.550109148025513\n",
      "  time_total_s: 221.6061623096466\n",
      "  timers:\n",
      "    learn_throughput: 748.614\n",
      "    learn_time_ms: 5343.209\n",
      "    load_throughput: 20070841.01\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 335.369\n",
      "    sample_time_ms: 11927.178\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871433\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 72000\n",
      "  training_iteration: 18\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 72000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-23-53\n",
      "  done: false\n",
      "  episode_len_mean: 701.4747474747475\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.5673152313872\n",
      "  episode_reward_mean: -111.54813900131214\n",
      "  episode_reward_min: -185.32600351624558\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 99\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5258789289873675e-06\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663720607757568\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 6.827222591709869e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.012232555076479912\n",
      "          total_loss: 18.503271102905273\n",
      "          vf_explained_var: 0.00018560892203822732\n",
      "          vf_loss: 18.491039276123047\n",
      "    num_agent_steps_sampled: 72000\n",
      "    num_agent_steps_trained: 72000\n",
      "    num_steps_sampled: 72000\n",
      "    num_steps_trained: 72000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.443749999999994\n",
      "    ram_util_percent: 50.775\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13966528005250942\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5177930013261455\n",
      "    mean_inference_ms: 2.801714850438433\n",
      "    mean_raw_obs_processing_ms: 0.12488248087004512\n",
      "  time_since_restore: 222.18461203575134\n",
      "  time_this_iter_s: 11.636876821517944\n",
      "  time_total_s: 222.18461203575134\n",
      "  timers:\n",
      "    learn_throughput: 753.777\n",
      "    learn_time_ms: 5306.608\n",
      "    load_throughput: 20054047.334\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 333.987\n",
      "    sample_time_ms: 11976.526\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871433\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 72000\n",
      "  training_iteration: 18\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:23:57 (running for 00:04:01.64)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         221.606</td><td style=\"text-align: right;\">72000</td><td style=\"text-align: right;\">-110.463</td><td style=\"text-align: right;\">            -90.7573</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           527.92 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         222.185</td><td style=\"text-align: right;\">72000</td><td style=\"text-align: right;\">-111.548</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           701.475</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:24:02 (running for 00:04:06.71)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         221.606</td><td style=\"text-align: right;\">72000</td><td style=\"text-align: right;\">-110.463</td><td style=\"text-align: right;\">            -90.7573</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">           527.92 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         222.185</td><td style=\"text-align: right;\">72000</td><td style=\"text-align: right;\">-111.548</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">           701.475</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 76000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-24-04\n",
      "  done: false\n",
      "  episode_len_mean: 573.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -90.75731457961847\n",
      "  episode_reward_mean: -109.99103586745449\n",
      "  episode_reward_min: -174.7469390741705\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 132\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.414536952972412\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005684615578502417\n",
      "          model: {}\n",
      "          policy_loss: -0.024445265531539917\n",
      "          total_loss: 13.048270225524902\n",
      "          vf_explained_var: -0.16388274729251862\n",
      "          vf_loss: 13.070158004760742\n",
      "    num_agent_steps_sampled: 76000\n",
      "    num_agent_steps_trained: 76000\n",
      "    num_steps_sampled: 76000\n",
      "    num_steps_trained: 76000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.32941176470588\n",
      "    ram_util_percent: 50.78823529411764\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1298342812957161\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5094382781334699\n",
      "    mean_inference_ms: 2.654711664606208\n",
      "    mean_raw_obs_processing_ms: 0.118002606338289\n",
      "  time_since_restore: 233.1453013420105\n",
      "  time_this_iter_s: 11.539139032363892\n",
      "  time_total_s: 233.1453013420105\n",
      "  timers:\n",
      "    learn_throughput: 753.961\n",
      "    learn_time_ms: 5305.311\n",
      "    load_throughput: 20070841.01\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 338.446\n",
      "    sample_time_ms: 11818.74\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871444\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 76000\n",
      "  training_iteration: 19\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 76000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-24-05\n",
      "  done: false\n",
      "  episode_len_mean: 693.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.5673152313872\n",
      "  episode_reward_mean: -111.59561500203804\n",
      "  episode_reward_min: -185.32600351624558\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 108\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 7.629394644936838e-07\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663498401641846\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.4669958520462387e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0030295257456600666\n",
      "          total_loss: 531.0910034179688\n",
      "          vf_explained_var: 0.00015526638890150934\n",
      "          vf_loss: 531.0879516601562\n",
      "    num_agent_steps_sampled: 76000\n",
      "    num_agent_steps_trained: 76000\n",
      "    num_steps_sampled: 76000\n",
      "    num_steps_trained: 76000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.71176470588236\n",
      "    ram_util_percent: 50.805882352941175\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1365985524573939\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.510215952442107\n",
      "    mean_inference_ms: 2.758587498853079\n",
      "    mean_raw_obs_processing_ms: 0.12227588912468573\n",
      "  time_since_restore: 233.7327265739441\n",
      "  time_this_iter_s: 11.548114538192749\n",
      "  time_total_s: 233.7327265739441\n",
      "  timers:\n",
      "    learn_throughput: 757.736\n",
      "    learn_time_ms: 5278.882\n",
      "    load_throughput: 13369364.89\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 337.01\n",
      "    sample_time_ms: 11869.074\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871445\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 76000\n",
      "  training_iteration: 19\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:24:08 (running for 00:04:12.20)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         233.145</td><td style=\"text-align: right;\">76000</td><td style=\"text-align: right;\">-109.991</td><td style=\"text-align: right;\">            -90.7573</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">            573.81</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         233.733</td><td style=\"text-align: right;\">76000</td><td style=\"text-align: right;\">-111.596</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">            693.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:24:13 (running for 00:04:17.27)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         233.145</td><td style=\"text-align: right;\">76000</td><td style=\"text-align: right;\">-109.991</td><td style=\"text-align: right;\">            -90.7573</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">            573.81</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         233.733</td><td style=\"text-align: right;\">76000</td><td style=\"text-align: right;\">-111.596</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -185.326</td><td style=\"text-align: right;\">            693.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 80000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-24-16\n",
      "  done: false\n",
      "  episode_len_mean: 603.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -90.75731457961847\n",
      "  episode_reward_mean: -110.00967636334536\n",
      "  episode_reward_min: -174.7469390741705\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 134\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.427882671356201\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006499773357063532\n",
      "          model: {}\n",
      "          policy_loss: -0.02588694915175438\n",
      "          total_loss: 25.63756561279297\n",
      "          vf_explained_var: -0.10101110488176346\n",
      "          vf_loss: 25.6605281829834\n",
      "    num_agent_steps_sampled: 80000\n",
      "    num_agent_steps_trained: 80000\n",
      "    num_steps_sampled: 80000\n",
      "    num_steps_trained: 80000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.493750000000006\n",
      "    ram_util_percent: 50.75625\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1296157166090802\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5089600213430789\n",
      "    mean_inference_ms: 2.6512678605796247\n",
      "    mean_raw_obs_processing_ms: 0.11790701453347788\n",
      "  time_since_restore: 244.8480031490326\n",
      "  time_this_iter_s: 11.702701807022095\n",
      "  time_total_s: 244.8480031490326\n",
      "  timers:\n",
      "    learn_throughput: 758.582\n",
      "    learn_time_ms: 5272.997\n",
      "    load_throughput: 20070841.01\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 340.858\n",
      "    sample_time_ms: 11735.102\n",
      "    update_time_ms: 2.095\n",
      "  timestamp: 1641871456\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 80000\n",
      "  training_iteration: 20\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 80000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-24-17\n",
      "  done: false\n",
      "  episode_len_mean: 706.15\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.5673152313872\n",
      "  episode_reward_mean: -112.83406150615403\n",
      "  episode_reward_min: -222.12501436001168\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 116\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.814697322468419e-07\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663505554199219\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.3165272839141835e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.00420422712340951\n",
      "          total_loss: 726.4929809570312\n",
      "          vf_explained_var: 2.2681106202071533e-05\n",
      "          vf_loss: 726.4888305664062\n",
      "    num_agent_steps_sampled: 80000\n",
      "    num_agent_steps_trained: 80000\n",
      "    num_steps_sampled: 80000\n",
      "    num_steps_trained: 80000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.43125\n",
      "    ram_util_percent: 50.737500000000004\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13475738297681858\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5064872145768016\n",
      "    mean_inference_ms: 2.7334399172569124\n",
      "    mean_raw_obs_processing_ms: 0.12105866011420773\n",
      "  time_since_restore: 245.31574749946594\n",
      "  time_this_iter_s: 11.58302092552185\n",
      "  time_total_s: 245.31574749946594\n",
      "  timers:\n",
      "    learn_throughput: 763.986\n",
      "    learn_time_ms: 5235.697\n",
      "    load_throughput: 13369364.89\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 339.292\n",
      "    sample_time_ms: 11789.239\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871457\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 80000\n",
      "  training_iteration: 20\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:24:19 (running for 00:04:22.79)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         244.848</td><td style=\"text-align: right;\">80000</td><td style=\"text-align: right;\">-110.01 </td><td style=\"text-align: right;\">            -90.7573</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">            603.72</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         245.316</td><td style=\"text-align: right;\">80000</td><td style=\"text-align: right;\">-112.834</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            706.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:24:24 (running for 00:04:27.85)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         244.848</td><td style=\"text-align: right;\">80000</td><td style=\"text-align: right;\">-110.01 </td><td style=\"text-align: right;\">            -90.7573</td><td style=\"text-align: right;\">            -174.747</td><td style=\"text-align: right;\">            603.72</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         245.316</td><td style=\"text-align: right;\">80000</td><td style=\"text-align: right;\">-112.834</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            706.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 84000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-24-28\n",
      "  done: false\n",
      "  episode_len_mean: 614.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -88.44028395164572\n",
      "  episode_reward_mean: -109.4943329446458\n",
      "  episode_reward_min: -168.98403632784255\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 138\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.644771575927734\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009832584299147129\n",
      "          model: {}\n",
      "          policy_loss: -0.03227449581027031\n",
      "          total_loss: 138.97799682617188\n",
      "          vf_explained_var: 0.0008530890918336809\n",
      "          vf_loss: 139.00584411621094\n",
      "    num_agent_steps_sampled: 84000\n",
      "    num_agent_steps_trained: 84000\n",
      "    num_steps_sampled: 84000\n",
      "    num_steps_trained: 84000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.756249999999994\n",
      "    ram_util_percent: 50.6875\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1293567503509922\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5085112916582684\n",
      "    mean_inference_ms: 2.6460526374798814\n",
      "    mean_raw_obs_processing_ms: 0.11774973124253264\n",
      "  time_since_restore: 256.4320228099823\n",
      "  time_this_iter_s: 11.584019660949707\n",
      "  time_total_s: 256.4320228099823\n",
      "  timers:\n",
      "    learn_throughput: 758.123\n",
      "    learn_time_ms: 5276.189\n",
      "    load_throughput: 20070841.01\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 342.128\n",
      "    sample_time_ms: 11691.528\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871468\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 84000\n",
      "  training_iteration: 21\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 84000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-24-28\n",
      "  done: false\n",
      "  episode_len_mean: 708.33\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.5673152313872\n",
      "  episode_reward_mean: -113.23200185327649\n",
      "  episode_reward_min: -222.12501436001168\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 123\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.9073486612342094e-07\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663361072540283\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.1608009486963056e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0036372540052980185\n",
      "          total_loss: 527.1417846679688\n",
      "          vf_explained_var: -6.33874224149622e-05\n",
      "          vf_loss: 527.13818359375\n",
      "    num_agent_steps_sampled: 84000\n",
      "    num_agent_steps_trained: 84000\n",
      "    num_steps_sampled: 84000\n",
      "    num_steps_trained: 84000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.65625\n",
      "    ram_util_percent: 50.6875\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13362041608312494\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5043633211252534\n",
      "    mean_inference_ms: 2.7178694524700524\n",
      "    mean_raw_obs_processing_ms: 0.12020847447034588\n",
      "  time_since_restore: 256.8309519290924\n",
      "  time_this_iter_s: 11.515204429626465\n",
      "  time_total_s: 256.8309519290924\n",
      "  timers:\n",
      "    learn_throughput: 764.19\n",
      "    learn_time_ms: 5234.301\n",
      "    load_throughput: 13369364.89\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 340.973\n",
      "    sample_time_ms: 11731.119\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641871468\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 84000\n",
      "  training_iteration: 21\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:24:29 (running for 00:04:33.32)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         256.432</td><td style=\"text-align: right;\">84000</td><td style=\"text-align: right;\">-109.494</td><td style=\"text-align: right;\">            -88.4403</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            614.13</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         256.831</td><td style=\"text-align: right;\">84000</td><td style=\"text-align: right;\">-113.232</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            708.33</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:24:34 (running for 00:04:38.37)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         256.432</td><td style=\"text-align: right;\">84000</td><td style=\"text-align: right;\">-109.494</td><td style=\"text-align: right;\">            -88.4403</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            614.13</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         256.831</td><td style=\"text-align: right;\">84000</td><td style=\"text-align: right;\">-113.232</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            708.33</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:24:39 (running for 00:04:43.42)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         256.432</td><td style=\"text-align: right;\">84000</td><td style=\"text-align: right;\">-109.494</td><td style=\"text-align: right;\">            -88.4403</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            614.13</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         256.831</td><td style=\"text-align: right;\">84000</td><td style=\"text-align: right;\">-113.232</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            708.33</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 88000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-24-40\n",
      "  done: false\n",
      "  episode_len_mean: 614.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -88.44028395164572\n",
      "  episode_reward_mean: -109.72480695588929\n",
      "  episode_reward_min: -168.98403632784255\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 147\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.72452449798584\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010676597245037556\n",
      "          model: {}\n",
      "          policy_loss: -0.03336523473262787\n",
      "          total_loss: 170.485107421875\n",
      "          vf_explained_var: -0.11766231060028076\n",
      "          vf_loss: 170.51368713378906\n",
      "    num_agent_steps_sampled: 88000\n",
      "    num_agent_steps_trained: 88000\n",
      "    num_steps_sampled: 88000\n",
      "    num_steps_trained: 88000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.94117647058823\n",
      "    ram_util_percent: 50.6529411764706\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12870755205995646\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5074413047105237\n",
      "    mean_inference_ms: 2.6346206818219273\n",
      "    mean_raw_obs_processing_ms: 0.11742585655657577\n",
      "  time_since_restore: 268.2494173049927\n",
      "  time_this_iter_s: 11.817394495010376\n",
      "  time_total_s: 268.2494173049927\n",
      "  timers:\n",
      "    learn_throughput: 760.856\n",
      "    learn_time_ms: 5257.24\n",
      "    load_throughput: 13384296.769\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 341.468\n",
      "    sample_time_ms: 11714.123\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871480\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 88000\n",
      "  training_iteration: 22\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 88000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-24-40\n",
      "  done: false\n",
      "  episode_len_mean: 738.37\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.5673152313872\n",
      "  episode_reward_mean: -112.94678806020555\n",
      "  episode_reward_min: -222.12501436001168\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 131\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 9.536743306171047e-08\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.662997722625732\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.722155727497011e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.002849030774086714\n",
      "          total_loss: 548.8003540039062\n",
      "          vf_explained_var: -0.00016396513092331588\n",
      "          vf_loss: 548.7974243164062\n",
      "    num_agent_steps_sampled: 88000\n",
      "    num_agent_steps_trained: 88000\n",
      "    num_steps_sampled: 88000\n",
      "    num_steps_trained: 88000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.01176470588235\n",
      "    ram_util_percent: 50.6529411764706\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13260358431195324\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5025870264756019\n",
      "    mean_inference_ms: 2.7023385279380197\n",
      "    mean_raw_obs_processing_ms: 0.11936948175241983\n",
      "  time_since_restore: 268.580527305603\n",
      "  time_this_iter_s: 11.74957537651062\n",
      "  time_total_s: 268.580527305603\n",
      "  timers:\n",
      "    learn_throughput: 768.627\n",
      "    learn_time_ms: 5204.082\n",
      "    load_throughput: 20056444.71\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 340.341\n",
      "    sample_time_ms: 11752.924\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641871480\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 88000\n",
      "  training_iteration: 22\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:24:45 (running for 00:04:49.15)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         268.249</td><td style=\"text-align: right;\">88000</td><td style=\"text-align: right;\">-109.725</td><td style=\"text-align: right;\">            -88.4403</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            614.92</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         268.581</td><td style=\"text-align: right;\">88000</td><td style=\"text-align: right;\">-112.947</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            738.37</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:24:50 (running for 00:04:54.21)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         268.249</td><td style=\"text-align: right;\">88000</td><td style=\"text-align: right;\">-109.725</td><td style=\"text-align: right;\">            -88.4403</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            614.92</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         268.581</td><td style=\"text-align: right;\">88000</td><td style=\"text-align: right;\">-112.947</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            738.37</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 92000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-24-51\n",
      "  done: false\n",
      "  episode_len_mean: 614.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -84.9182685661863\n",
      "  episode_reward_mean: -109.35607983086993\n",
      "  episode_reward_min: -168.98403632784255\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 150\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.39568567276001\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005593380890786648\n",
      "          model: {}\n",
      "          policy_loss: -0.02235119231045246\n",
      "          total_loss: 30.51934242248535\n",
      "          vf_explained_var: -0.11930706351995468\n",
      "          vf_loss: 30.539173126220703\n",
      "    num_agent_steps_sampled: 92000\n",
      "    num_agent_steps_trained: 92000\n",
      "    num_steps_sampled: 92000\n",
      "    num_steps_trained: 92000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.98823529411765\n",
      "    ram_util_percent: 50.60588235294118\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1284815721908741\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5068925581683651\n",
      "    mean_inference_ms: 2.6301054112492412\n",
      "    mean_raw_obs_processing_ms: 0.11730582994210746\n",
      "  time_since_restore: 279.8773195743561\n",
      "  time_this_iter_s: 11.627902269363403\n",
      "  time_total_s: 279.8773195743561\n",
      "  timers:\n",
      "    learn_throughput: 760.971\n",
      "    learn_time_ms: 5256.441\n",
      "    load_throughput: 13380027.115\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 342.353\n",
      "    sample_time_ms: 11683.848\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871491\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 92000\n",
      "  training_iteration: 23\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 92000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-24-51\n",
      "  done: false\n",
      "  episode_len_mean: 631.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.5673152313872\n",
      "  episode_reward_mean: -112.87200169359102\n",
      "  episode_reward_min: -222.12501436001168\n",
      "  episodes_this_iter: 14\n",
      "  episodes_total: 145\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.7683716530855236e-08\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.6631574630737305\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 7.986416505900706e-08\n",
      "          model: {}\n",
      "          policy_loss: 0.004203633405268192\n",
      "          total_loss: 1102.4857177734375\n",
      "          vf_explained_var: -0.00010626963194226846\n",
      "          vf_loss: 1102.4815673828125\n",
      "    num_agent_steps_sampled: 92000\n",
      "    num_agent_steps_trained: 92000\n",
      "    num_steps_sampled: 92000\n",
      "    num_steps_trained: 92000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.3375\n",
      "    ram_util_percent: 50.6375\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1313731193480071\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5002119624620768\n",
      "    mean_inference_ms: 2.677529431290966\n",
      "    mean_raw_obs_processing_ms: 0.11823051983827026\n",
      "  time_since_restore: 280.1445996761322\n",
      "  time_this_iter_s: 11.564072370529175\n",
      "  time_total_s: 280.1445996761322\n",
      "  timers:\n",
      "    learn_throughput: 769.35\n",
      "    learn_time_ms: 5199.195\n",
      "    load_throughput: 20056444.71\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 341.346\n",
      "    sample_time_ms: 11718.327\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641871491\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 92000\n",
      "  training_iteration: 23\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:24:56 (running for 00:04:59.72)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         279.877</td><td style=\"text-align: right;\">92000</td><td style=\"text-align: right;\">-109.356</td><td style=\"text-align: right;\">            -84.9183</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            614.5 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         280.145</td><td style=\"text-align: right;\">92000</td><td style=\"text-align: right;\">-112.872</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            631.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:25:01 (running for 00:05:04.78)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         279.877</td><td style=\"text-align: right;\">92000</td><td style=\"text-align: right;\">-109.356</td><td style=\"text-align: right;\">            -84.9183</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            614.5 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         280.145</td><td style=\"text-align: right;\">92000</td><td style=\"text-align: right;\">-112.872</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            631.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 96000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-25-03\n",
      "  done: false\n",
      "  episode_len_mean: 629.79\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -84.9182685661863\n",
      "  episode_reward_mean: -108.93535591649321\n",
      "  episode_reward_min: -168.98403632784255\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 154\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.453554630279541\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006785376463085413\n",
      "          model: {}\n",
      "          policy_loss: -0.020627610385417938\n",
      "          total_loss: 38.48429870605469\n",
      "          vf_explained_var: -0.09689810127019882\n",
      "          vf_loss: 38.501869201660156\n",
      "    num_agent_steps_sampled: 96000\n",
      "    num_agent_steps_trained: 96000\n",
      "    num_steps_sampled: 96000\n",
      "    num_steps_trained: 96000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.85294117647059\n",
      "    ram_util_percent: 50.72941176470588\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12818030350186363\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5060676103292197\n",
      "    mean_inference_ms: 2.6231584766765015\n",
      "    mean_raw_obs_processing_ms: 0.11706275222869753\n",
      "  time_since_restore: 292.11957812309265\n",
      "  time_this_iter_s: 12.242258548736572\n",
      "  time_total_s: 292.11957812309265\n",
      "  timers:\n",
      "    learn_throughput: 758.496\n",
      "    learn_time_ms: 5273.596\n",
      "    load_throughput: 13380027.115\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 341.869\n",
      "    sample_time_ms: 11700.404\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871503\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 96000\n",
      "  training_iteration: 24\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 96000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-25-04\n",
      "  done: false\n",
      "  episode_len_mean: 645.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.5673152313872\n",
      "  episode_reward_mean: -112.93536821663416\n",
      "  episode_reward_min: -222.12501436001168\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 149\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.3841858265427618e-08\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.664134979248047\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.678959501485224e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003271035850048065\n",
      "          total_loss: 212.71875\n",
      "          vf_explained_var: -6.503187250928022e-06\n",
      "          vf_loss: 212.71546936035156\n",
      "    num_agent_steps_sampled: 96000\n",
      "    num_agent_steps_trained: 96000\n",
      "    num_steps_sampled: 96000\n",
      "    num_steps_trained: 96000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.550000000000004\n",
      "    ram_util_percent: 50.73333333333333\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1309428652228426\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4995802776419441\n",
      "    mean_inference_ms: 2.669875029668736\n",
      "    mean_raw_obs_processing_ms: 0.11788469453222172\n",
      "  time_since_restore: 292.4676423072815\n",
      "  time_this_iter_s: 12.323042631149292\n",
      "  time_total_s: 292.4676423072815\n",
      "  timers:\n",
      "    learn_throughput: 767.906\n",
      "    learn_time_ms: 5208.969\n",
      "    load_throughput: 40108094.669\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 341.028\n",
      "    sample_time_ms: 11729.245\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641871504\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 96000\n",
      "  training_iteration: 24\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:25:06 (running for 00:05:10.04)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         292.12 </td><td style=\"text-align: right;\">96000</td><td style=\"text-align: right;\">-108.935</td><td style=\"text-align: right;\">            -84.9183</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            629.79</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         292.468</td><td style=\"text-align: right;\">96000</td><td style=\"text-align: right;\">-112.935</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            645.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:25:11 (running for 00:05:15.08)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         292.12 </td><td style=\"text-align: right;\">96000</td><td style=\"text-align: right;\">-108.935</td><td style=\"text-align: right;\">            -84.9183</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            629.79</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         292.468</td><td style=\"text-align: right;\">96000</td><td style=\"text-align: right;\">-112.935</td><td style=\"text-align: right;\">            -97.5673</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            645.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 100000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-25-15\n",
      "  done: false\n",
      "  episode_len_mean: 660.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -84.9182685661863\n",
      "  episode_reward_mean: -108.71353139029671\n",
      "  episode_reward_min: -168.98403632784255\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 156\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.3984856605529785\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.006192890461534262\n",
      "          model: {}\n",
      "          policy_loss: -0.018973398953676224\n",
      "          total_loss: 5.096117973327637\n",
      "          vf_explained_var: -0.08974012732505798\n",
      "          vf_loss: 5.1123046875\n",
      "    num_agent_steps_sampled: 100000\n",
      "    num_agent_steps_trained: 100000\n",
      "    num_steps_sampled: 100000\n",
      "    num_steps_trained: 100000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.056250000000006\n",
      "    ram_util_percent: 50.8\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1280068736931163\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5057837289420839\n",
      "    mean_inference_ms: 2.6200244672580455\n",
      "    mean_raw_obs_processing_ms: 0.11695590917511843\n",
      "  time_since_restore: 303.8791289329529\n",
      "  time_this_iter_s: 11.75955080986023\n",
      "  time_total_s: 303.8791289329529\n",
      "  timers:\n",
      "    learn_throughput: 757.178\n",
      "    learn_time_ms: 5282.771\n",
      "    load_throughput: 10031820.139\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 341.713\n",
      "    sample_time_ms: 11705.742\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641871515\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 100000\n",
      "  training_iteration: 25\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 100000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-25-16\n",
      "  done: false\n",
      "  episode_len_mean: 661.18\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.98580135690607\n",
      "  episode_reward_mean: -113.33492474443273\n",
      "  episode_reward_min: -222.12501436001168\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 155\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1920929132713809e-08\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.664275646209717\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.5678465931378014e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0029285999480634928\n",
      "          total_loss: 294.8863525390625\n",
      "          vf_explained_var: 0.0001252897927770391\n",
      "          vf_loss: 294.8834533691406\n",
      "    num_agent_steps_sampled: 100000\n",
      "    num_agent_steps_trained: 100000\n",
      "    num_steps_sampled: 100000\n",
      "    num_steps_trained: 100000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.806250000000006\n",
      "    ram_util_percent: 50.787499999999994\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1303760760805489\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4986171314148885\n",
      "    mean_inference_ms: 2.6582755661157704\n",
      "    mean_raw_obs_processing_ms: 0.11732913432651233\n",
      "  time_since_restore: 304.1813151836395\n",
      "  time_this_iter_s: 11.713672876358032\n",
      "  time_total_s: 304.1813151836395\n",
      "  timers:\n",
      "    learn_throughput: 767.319\n",
      "    learn_time_ms: 5212.958\n",
      "    load_throughput: 40108094.669\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 341.118\n",
      "    sample_time_ms: 11726.147\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871516\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 100000\n",
      "  training_iteration: 25\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:25:17 (running for 00:05:20.77)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         303.879</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">-108.714</td><td style=\"text-align: right;\">            -84.9183</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            660.64</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         304.181</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">-113.335</td><td style=\"text-align: right;\">            -97.9858</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            661.18</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:25:22 (running for 00:05:25.82)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         303.879</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">-108.714</td><td style=\"text-align: right;\">            -84.9183</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            660.64</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         304.181</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">-113.335</td><td style=\"text-align: right;\">            -97.9858</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            661.18</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:25:27 (running for 00:05:30.89)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         303.879</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">-108.714</td><td style=\"text-align: right;\">            -84.9183</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            660.64</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         304.181</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">-113.335</td><td style=\"text-align: right;\">            -97.9858</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            661.18</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 104000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-25-27\n",
      "  done: false\n",
      "  episode_len_mean: 691.51\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -84.9182685661863\n",
      "  episode_reward_mean: -108.18461272728709\n",
      "  episode_reward_min: -168.98403632784255\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 159\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.413121700286865\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008153668604791164\n",
      "          model: {}\n",
      "          policy_loss: -0.02441266179084778\n",
      "          total_loss: 3.4804069995880127\n",
      "          vf_explained_var: -0.027438009157776833\n",
      "          vf_loss: 3.5011508464813232\n",
      "    num_agent_steps_sampled: 104000\n",
      "    num_agent_steps_trained: 104000\n",
      "    num_steps_sampled: 104000\n",
      "    num_steps_trained: 104000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.14705882352941\n",
      "    ram_util_percent: 50.7764705882353\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12777635193630063\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.505202176778851\n",
      "    mean_inference_ms: 2.614608503606722\n",
      "    mean_raw_obs_processing_ms: 0.11676743889103221\n",
      "  time_since_restore: 315.4292378425598\n",
      "  time_this_iter_s: 11.550108909606934\n",
      "  time_total_s: 315.4292378425598\n",
      "  timers:\n",
      "    learn_throughput: 755.14\n",
      "    learn_time_ms: 5297.033\n",
      "    load_throughput: 13372561.773\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 341.835\n",
      "    sample_time_ms: 11701.56\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871527\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 104000\n",
      "  training_iteration: 26\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 104000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-25-27\n",
      "  done: false\n",
      "  episode_len_mean: 646.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.98580135690607\n",
      "  episode_reward_mean: -113.22393949766438\n",
      "  episode_reward_min: -222.12501436001168\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 162\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 5.9604645663569045e-09\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663620471954346\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.9597555339933024e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0033440091647207737\n",
      "          total_loss: 478.6541748046875\n",
      "          vf_explained_var: 3.464151450316422e-05\n",
      "          vf_loss: 478.65087890625\n",
      "    num_agent_steps_sampled: 104000\n",
      "    num_agent_steps_trained: 104000\n",
      "    num_steps_sampled: 104000\n",
      "    num_steps_trained: 104000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.13529411764706\n",
      "    ram_util_percent: 50.800000000000004\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1295547805142208\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4975672382516567\n",
      "    mean_inference_ms: 2.6445262306439092\n",
      "    mean_raw_obs_processing_ms: 0.11681509087242156\n",
      "  time_since_restore: 315.987740278244\n",
      "  time_this_iter_s: 11.806425094604492\n",
      "  time_total_s: 315.987740278244\n",
      "  timers:\n",
      "    learn_throughput: 764.525\n",
      "    learn_time_ms: 5232.007\n",
      "    load_throughput: 40108094.669\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 341.102\n",
      "    sample_time_ms: 11726.707\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871527\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 104000\n",
      "  training_iteration: 26\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:25:32 (running for 00:05:36.64)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         315.429</td><td style=\"text-align: right;\">104000</td><td style=\"text-align: right;\">-108.185</td><td style=\"text-align: right;\">            -84.9183</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            691.51</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         315.988</td><td style=\"text-align: right;\">104000</td><td style=\"text-align: right;\">-113.224</td><td style=\"text-align: right;\">            -97.9858</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            646.52</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:25:37 (running for 00:05:41.71)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         315.429</td><td style=\"text-align: right;\">104000</td><td style=\"text-align: right;\">-108.185</td><td style=\"text-align: right;\">            -84.9183</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            691.51</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         315.988</td><td style=\"text-align: right;\">104000</td><td style=\"text-align: right;\">-113.224</td><td style=\"text-align: right;\">            -97.9858</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            646.52</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 108000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-25-38\n",
      "  done: false\n",
      "  episode_len_mean: 691.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -84.9182685661863\n",
      "  episode_reward_mean: -107.75696507938989\n",
      "  episode_reward_min: -168.98403632784255\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 162\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.375399112701416\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0048933010548353195\n",
      "          model: {}\n",
      "          policy_loss: -0.026826638728380203\n",
      "          total_loss: 39.79771423339844\n",
      "          vf_explained_var: -0.04805869609117508\n",
      "          vf_loss: 39.82234191894531\n",
      "    num_agent_steps_sampled: 108000\n",
      "    num_agent_steps_trained: 108000\n",
      "    num_steps_sampled: 108000\n",
      "    num_steps_trained: 108000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.0875\n",
      "    ram_util_percent: 50.743750000000006\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1275639459840393\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5047828399941835\n",
      "    mean_inference_ms: 2.6098066318059043\n",
      "    mean_raw_obs_processing_ms: 0.11660155588243613\n",
      "  time_since_restore: 327.0262224674225\n",
      "  time_this_iter_s: 11.596984624862671\n",
      "  time_total_s: 327.0262224674225\n",
      "  timers:\n",
      "    learn_throughput: 755.012\n",
      "    learn_time_ms: 5297.931\n",
      "    load_throughput: 13372561.773\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 341.399\n",
      "    sample_time_ms: 11716.5\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641871538\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 108000\n",
      "  training_iteration: 27\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 108000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-25-39\n",
      "  done: false\n",
      "  episode_len_mean: 667.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.98580135690607\n",
      "  episode_reward_mean: -112.08849749597573\n",
      "  episode_reward_min: -222.12501436001168\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 167\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.9802322831784522e-09\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663330554962158\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.032541459584536e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003132763784378767\n",
      "          total_loss: 206.1591033935547\n",
      "          vf_explained_var: -9.397794201504439e-06\n",
      "          vf_loss: 206.15597534179688\n",
      "    num_agent_steps_sampled: 108000\n",
      "    num_agent_steps_trained: 108000\n",
      "    num_steps_sampled: 108000\n",
      "    num_steps_trained: 108000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.04375\n",
      "    ram_util_percent: 50.743750000000006\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1290620119047758\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4968474530873769\n",
      "    mean_inference_ms: 2.635302428445885\n",
      "    mean_raw_obs_processing_ms: 0.11642893800801281\n",
      "  time_since_restore: 327.63957929611206\n",
      "  time_this_iter_s: 11.651839017868042\n",
      "  time_total_s: 327.63957929611206\n",
      "  timers:\n",
      "    learn_throughput: 764.729\n",
      "    learn_time_ms: 5230.611\n",
      "    load_throughput: 40108094.669\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 340.907\n",
      "    sample_time_ms: 11733.415\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871539\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 108000\n",
      "  training_iteration: 27\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:25:43 (running for 00:05:47.28)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         327.026</td><td style=\"text-align: right;\">108000</td><td style=\"text-align: right;\">-107.757</td><td style=\"text-align: right;\">            -84.9183</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            691.58</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         327.64 </td><td style=\"text-align: right;\">108000</td><td style=\"text-align: right;\">-112.088</td><td style=\"text-align: right;\">            -97.9858</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            667.5 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:25:48 (running for 00:05:52.34)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         327.026</td><td style=\"text-align: right;\">108000</td><td style=\"text-align: right;\">-107.757</td><td style=\"text-align: right;\">            -84.9183</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            691.58</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         327.64 </td><td style=\"text-align: right;\">108000</td><td style=\"text-align: right;\">-112.088</td><td style=\"text-align: right;\">            -97.9858</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            667.5 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 112000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-25-50\n",
      "  done: false\n",
      "  episode_len_mean: 722.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -83.08658119463973\n",
      "  episode_reward_mean: -107.05495243820847\n",
      "  episode_reward_min: -168.98403632784255\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 165\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22499999403953552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.39013147354126\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013292473740875721\n",
      "          model: {}\n",
      "          policy_loss: 0.0015518334694206715\n",
      "          total_loss: 2.5103092193603516\n",
      "          vf_explained_var: -0.017777424305677414\n",
      "          vf_loss: 2.5057668685913086\n",
      "    num_agent_steps_sampled: 112000\n",
      "    num_agent_steps_trained: 112000\n",
      "    num_steps_sampled: 112000\n",
      "    num_steps_trained: 112000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.3625\n",
      "    ram_util_percent: 50.75\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12738239816895963\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5041444828282535\n",
      "    mean_inference_ms: 2.6039862572875863\n",
      "    mean_raw_obs_processing_ms: 0.11640224655225243\n",
      "  time_since_restore: 338.5224769115448\n",
      "  time_this_iter_s: 11.496254444122314\n",
      "  time_total_s: 338.5224769115448\n",
      "  timers:\n",
      "    learn_throughput: 755.14\n",
      "    learn_time_ms: 5297.033\n",
      "    load_throughput: 13372561.773\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 341.512\n",
      "    sample_time_ms: 11712.631\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641871550\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 112000\n",
      "  training_iteration: 28\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 112000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-25-51\n",
      "  done: false\n",
      "  episode_len_mean: 636.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.98580135690607\n",
      "  episode_reward_mean: -111.97226585532256\n",
      "  episode_reward_min: -222.12501436001168\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 175\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.4901161415892261e-09\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663784980773926\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.0056607752394484e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003150032367557287\n",
      "          total_loss: 476.72412109375\n",
      "          vf_explained_var: 0.0003683742543216795\n",
      "          vf_loss: 476.7209777832031\n",
      "    num_agent_steps_sampled: 112000\n",
      "    num_agent_steps_trained: 112000\n",
      "    num_steps_sampled: 112000\n",
      "    num_steps_trained: 112000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.25882352941177\n",
      "    ram_util_percent: 50.72352941176471\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12836493719417771\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4960538568683214\n",
      "    mean_inference_ms: 2.6238671059535488\n",
      "    mean_raw_obs_processing_ms: 0.1159667517064306\n",
      "  time_since_restore: 339.2196090221405\n",
      "  time_this_iter_s: 11.580029726028442\n",
      "  time_total_s: 339.2196090221405\n",
      "  timers:\n",
      "    learn_throughput: 764.321\n",
      "    learn_time_ms: 5233.404\n",
      "    load_throughput: 40108094.669\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 341.199\n",
      "    sample_time_ms: 11723.356\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871551\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 112000\n",
      "  training_iteration: 28\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:25:54 (running for 00:05:57.88)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         338.522</td><td style=\"text-align: right;\">112000</td><td style=\"text-align: right;\">-107.055</td><td style=\"text-align: right;\">            -83.0866</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            722.3 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         339.22 </td><td style=\"text-align: right;\">112000</td><td style=\"text-align: right;\">-111.972</td><td style=\"text-align: right;\">            -97.9858</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            636.36</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:25:59 (running for 00:06:02.93)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         338.522</td><td style=\"text-align: right;\">112000</td><td style=\"text-align: right;\">-107.055</td><td style=\"text-align: right;\">            -83.0866</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            722.3 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         339.22 </td><td style=\"text-align: right;\">112000</td><td style=\"text-align: right;\">-111.972</td><td style=\"text-align: right;\">            -97.9858</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            636.36</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 116000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-26-02\n",
      "  done: false\n",
      "  episode_len_mean: 752.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -83.08658119463973\n",
      "  episode_reward_mean: -106.8307262171188\n",
      "  episode_reward_min: -168.98403632784255\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 168\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22499999403953552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.441249847412109\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00860997661948204\n",
      "          model: {}\n",
      "          policy_loss: -0.02689562551677227\n",
      "          total_loss: 41.21055221557617\n",
      "          vf_explained_var: -0.04983963072299957\n",
      "          vf_loss: 41.23550796508789\n",
      "    num_agent_steps_sampled: 116000\n",
      "    num_agent_steps_trained: 116000\n",
      "    num_steps_sampled: 116000\n",
      "    num_steps_trained: 116000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.72941176470587\n",
      "    ram_util_percent: 50.79411764705882\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12715815152175852\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5038715730330854\n",
      "    mean_inference_ms: 2.5998629301138663\n",
      "    mean_raw_obs_processing_ms: 0.11623502762507988\n",
      "  time_since_restore: 350.17331862449646\n",
      "  time_this_iter_s: 11.65084171295166\n",
      "  time_total_s: 350.17331862449646\n",
      "  timers:\n",
      "    learn_throughput: 754.373\n",
      "    learn_time_ms: 5302.419\n",
      "    load_throughput: 13372561.773\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 341.349\n",
      "    sample_time_ms: 11718.203\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641871562\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 116000\n",
      "  training_iteration: 29\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 116000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-26-02\n",
      "  done: false\n",
      "  episode_len_mean: 667.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.03822997576562\n",
      "  episode_reward_mean: -111.8586309491141\n",
      "  episode_reward_min: -222.12501436001168\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 178\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 7.450580707946131e-10\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663498401641846\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.9357891523650324e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003135642735287547\n",
      "          total_loss: 132.3783721923828\n",
      "          vf_explained_var: 0.0001877326430985704\n",
      "          vf_loss: 132.37522888183594\n",
      "    num_agent_steps_sampled: 116000\n",
      "    num_agent_steps_trained: 116000\n",
      "    num_steps_sampled: 116000\n",
      "    num_steps_trained: 116000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.71875\n",
      "    ram_util_percent: 50.78125\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12804867305663944\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49587166519038\n",
      "    mean_inference_ms: 2.6195073327119127\n",
      "    mean_raw_obs_processing_ms: 0.11577196015297948\n",
      "  time_since_restore: 350.70389461517334\n",
      "  time_this_iter_s: 11.484285593032837\n",
      "  time_total_s: 350.70389461517334\n",
      "  timers:\n",
      "    learn_throughput: 765.78\n",
      "    learn_time_ms: 5223.43\n",
      "    load_throughput: 40117685.318\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 340.993\n",
      "    sample_time_ms: 11730.435\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871562\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 116000\n",
      "  training_iteration: 29\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:26:04 (running for 00:06:08.39)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         350.173</td><td style=\"text-align: right;\">116000</td><td style=\"text-align: right;\">-106.831</td><td style=\"text-align: right;\">            -83.0866</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            752.78</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         350.704</td><td style=\"text-align: right;\">116000</td><td style=\"text-align: right;\">-111.859</td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            667   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:26:09 (running for 00:06:13.44)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         350.173</td><td style=\"text-align: right;\">116000</td><td style=\"text-align: right;\">-106.831</td><td style=\"text-align: right;\">            -83.0866</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            752.78</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         350.704</td><td style=\"text-align: right;\">116000</td><td style=\"text-align: right;\">-111.859</td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            667   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 120000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-26-13\n",
      "  done: false\n",
      "  episode_len_mean: 767.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -73.38331220140691\n",
      "  episode_reward_mean: -106.21389489064127\n",
      "  episode_reward_min: -168.98403632784255\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 170\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22499999403953552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.274560451507568\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01610645093023777\n",
      "          model: {}\n",
      "          policy_loss: -0.028122378513216972\n",
      "          total_loss: 1.4919047355651855\n",
      "          vf_explained_var: 0.0010753608075901866\n",
      "          vf_loss: 1.516403317451477\n",
      "    num_agent_steps_sampled: 120000\n",
      "    num_agent_steps_trained: 120000\n",
      "    num_steps_sampled: 120000\n",
      "    num_steps_trained: 120000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.1625\n",
      "    ram_util_percent: 50.793749999999996\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1270021521082555\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5036726623101564\n",
      "    mean_inference_ms: 2.5969131188540358\n",
      "    mean_raw_obs_processing_ms: 0.11611031655696548\n",
      "  time_since_restore: 361.834130525589\n",
      "  time_this_iter_s: 11.66081190109253\n",
      "  time_total_s: 361.834130525589\n",
      "  timers:\n",
      "    learn_throughput: 754.784\n",
      "    learn_time_ms: 5299.526\n",
      "    load_throughput: 13372561.773\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 341.244\n",
      "    sample_time_ms: 11721.818\n",
      "    update_time_ms: 1.695\n",
      "  timestamp: 1641871573\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 120000\n",
      "  training_iteration: 30\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 120000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-26-14\n",
      "  done: false\n",
      "  episode_len_mean: 682.15\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.03822997576562\n",
      "  episode_reward_mean: -111.80810770952938\n",
      "  episode_reward_min: -222.12501436001168\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 182\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.7252903539730653e-10\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663229465484619\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.6092528198896616e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.002109467750415206\n",
      "          total_loss: 211.0880889892578\n",
      "          vf_explained_var: -2.648695772222709e-05\n",
      "          vf_loss: 211.0859832763672\n",
      "    num_agent_steps_sampled: 120000\n",
      "    num_agent_steps_trained: 120000\n",
      "    num_steps_sampled: 120000\n",
      "    num_steps_trained: 120000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.0875\n",
      "    ram_util_percent: 50.8\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12782943966190494\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4954590605456797\n",
      "    mean_inference_ms: 2.6146415804585605\n",
      "    mean_raw_obs_processing_ms: 0.11557096489906352\n",
      "  time_since_restore: 362.2559986114502\n",
      "  time_this_iter_s: 11.552103996276855\n",
      "  time_total_s: 362.2559986114502\n",
      "  timers:\n",
      "    learn_throughput: 767.216\n",
      "    learn_time_ms: 5213.656\n",
      "    load_throughput: 40117685.318\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 341.086\n",
      "    sample_time_ms: 11727.249\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871574\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 120000\n",
      "  training_iteration: 30\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:26:15 (running for 00:06:18.95)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         361.834</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-106.214</td><td style=\"text-align: right;\">            -73.3833</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            767.82</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         362.256</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-111.808</td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            682.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:26:20 (running for 00:06:24.01)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         361.834</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-106.214</td><td style=\"text-align: right;\">            -73.3833</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            767.82</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         362.256</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-111.808</td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            682.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:26:25 (running for 00:06:29.06)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         361.834</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-106.214</td><td style=\"text-align: right;\">            -73.3833</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            767.82</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         362.256</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-111.808</td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            682.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 124000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-26-25\n",
      "  done: false\n",
      "  episode_len_mean: 798.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -73.38331220140691\n",
      "  episode_reward_mean: -105.49494778679356\n",
      "  episode_reward_min: -168.98403632784255\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 174\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22499999403953552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.445816516876221\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0109774274751544\n",
      "          model: {}\n",
      "          policy_loss: -0.027664311230182648\n",
      "          total_loss: 87.57353210449219\n",
      "          vf_explained_var: -0.1761130839586258\n",
      "          vf_loss: 87.5987319946289\n",
      "    num_agent_steps_sampled: 124000\n",
      "    num_agent_steps_trained: 124000\n",
      "    num_steps_sampled: 124000\n",
      "    num_steps_trained: 124000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.94705882352941\n",
      "    ram_util_percent: 50.7764705882353\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1266917384216746\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5029928424624289\n",
      "    mean_inference_ms: 2.5893415458807425\n",
      "    mean_raw_obs_processing_ms: 0.11585374695637989\n",
      "  time_since_restore: 373.64653849601746\n",
      "  time_this_iter_s: 11.812407970428467\n",
      "  time_total_s: 373.64653849601746\n",
      "  timers:\n",
      "    learn_throughput: 751.644\n",
      "    learn_time_ms: 5321.667\n",
      "    load_throughput: 13372561.773\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 341.31\n",
      "    sample_time_ms: 11719.565\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641871585\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 124000\n",
      "  training_iteration: 31\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 124000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-26-26\n",
      "  done: false\n",
      "  episode_len_mean: 644.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.03822997576562\n",
      "  episode_reward_mean: -112.51833514075197\n",
      "  episode_reward_min: -222.12501436001168\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 190\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.8626451769865326e-10\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663226127624512\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 4.3163245777577686e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0032449131831526756\n",
      "          total_loss: 622.8051147460938\n",
      "          vf_explained_var: -7.30087049305439e-05\n",
      "          vf_loss: 622.8018188476562\n",
      "    num_agent_steps_sampled: 124000\n",
      "    num_agent_steps_trained: 124000\n",
      "    num_steps_sampled: 124000\n",
      "    num_steps_trained: 124000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.305882352941175\n",
      "    ram_util_percent: 50.76470588235294\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1273682569388179\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4947848122607678\n",
      "    mean_inference_ms: 2.6060092810750346\n",
      "    mean_raw_obs_processing_ms: 0.1151954570584696\n",
      "  time_since_restore: 374.1940701007843\n",
      "  time_this_iter_s: 11.938071489334106\n",
      "  time_total_s: 374.1940701007843\n",
      "  timers:\n",
      "    learn_throughput: 763.637\n",
      "    learn_time_ms: 5238.091\n",
      "    load_throughput: 20058842.659\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 340.855\n",
      "    sample_time_ms: 11735.186\n",
      "    update_time_ms: 2.394\n",
      "  timestamp: 1641871586\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 124000\n",
      "  training_iteration: 31\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:26:31 (running for 00:06:34.95)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         373.647</td><td style=\"text-align: right;\">124000</td><td style=\"text-align: right;\">-105.495</td><td style=\"text-align: right;\">            -73.3833</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            798.39</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         374.194</td><td style=\"text-align: right;\">124000</td><td style=\"text-align: right;\">-112.518</td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            644.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:26:36 (running for 00:06:40.00)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         373.647</td><td style=\"text-align: right;\">124000</td><td style=\"text-align: right;\">-105.495</td><td style=\"text-align: right;\">            -73.3833</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            798.39</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         374.194</td><td style=\"text-align: right;\">124000</td><td style=\"text-align: right;\">-112.518</td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            644.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 128000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-26-37\n",
      "  done: false\n",
      "  episode_len_mean: 828.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -68.94317558438948\n",
      "  episode_reward_mean: -104.8680738843032\n",
      "  episode_reward_min: -168.98403632784255\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 176\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22499999403953552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.416308403015137\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012979681603610516\n",
      "          model: {}\n",
      "          policy_loss: -0.02584955282509327\n",
      "          total_loss: 2.162205934524536\n",
      "          vf_explained_var: -0.16681872308254242\n",
      "          vf_loss: 2.1851348876953125\n",
      "    num_agent_steps_sampled: 128000\n",
      "    num_agent_steps_trained: 128000\n",
      "    num_steps_sampled: 128000\n",
      "    num_steps_trained: 128000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.11764705882353\n",
      "    ram_util_percent: 50.8\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1265585265246813\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5028384810517914\n",
      "    mean_inference_ms: 2.5867383029357853\n",
      "    mean_raw_obs_processing_ms: 0.11573733273274722\n",
      "  time_since_restore: 385.69431591033936\n",
      "  time_this_iter_s: 12.0477774143219\n",
      "  time_total_s: 385.69431591033936\n",
      "  timers:\n",
      "    learn_throughput: 748.851\n",
      "    learn_time_ms: 5341.514\n",
      "    load_throughput: 20044463.56\n",
      "    load_time_ms: 0.2\n",
      "    sample_throughput: 340.571\n",
      "    sample_time_ms: 11744.977\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641871597\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 128000\n",
      "  training_iteration: 32\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 128000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-26-38\n",
      "  done: false\n",
      "  episode_len_mean: 588.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.03822997576562\n",
      "  episode_reward_mean: -113.28048762433843\n",
      "  episode_reward_min: -222.12501436001168\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 198\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 9.313225884932663e-11\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.6629719734191895\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.5184814117219503e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0036659769248217344\n",
      "          total_loss: 595.1465454101562\n",
      "          vf_explained_var: -7.400262984447181e-05\n",
      "          vf_loss: 595.1429443359375\n",
      "    num_agent_steps_sampled: 128000\n",
      "    num_agent_steps_trained: 128000\n",
      "    num_steps_sampled: 128000\n",
      "    num_steps_trained: 128000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.1\n",
      "    ram_util_percent: 50.8\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12689224936766494\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49434100356738225\n",
      "    mean_inference_ms: 2.5983267174709335\n",
      "    mean_raw_obs_processing_ms: 0.11482845543010349\n",
      "  time_since_restore: 386.2957043647766\n",
      "  time_this_iter_s: 12.10163426399231\n",
      "  time_total_s: 386.2957043647766\n",
      "  timers:\n",
      "    learn_throughput: 759.099\n",
      "    learn_time_ms: 5269.407\n",
      "    load_throughput: 20058842.659\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 340.046\n",
      "    sample_time_ms: 11763.13\n",
      "    update_time_ms: 2.394\n",
      "  timestamp: 1641871598\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 128000\n",
      "  training_iteration: 32\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:26:41 (running for 00:06:45.08)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         385.694</td><td style=\"text-align: right;\">128000</td><td style=\"text-align: right;\">-104.868</td><td style=\"text-align: right;\">            -68.9432</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            828.82</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         386.296</td><td style=\"text-align: right;\">128000</td><td style=\"text-align: right;\">-113.28 </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            588.1 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:26:46 (running for 00:06:50.14)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         385.694</td><td style=\"text-align: right;\">128000</td><td style=\"text-align: right;\">-104.868</td><td style=\"text-align: right;\">            -68.9432</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            828.82</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         386.296</td><td style=\"text-align: right;\">128000</td><td style=\"text-align: right;\">-113.28 </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            588.1 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 132000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-26-49\n",
      "  done: false\n",
      "  episode_len_mean: 859.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -63.343442919503985\n",
      "  episode_reward_mean: -103.76685784919815\n",
      "  episode_reward_min: -168.98403632784255\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 179\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22499999403953552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.437910556793213\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0130928298458457\n",
      "          model: {}\n",
      "          policy_loss: -0.02326878160238266\n",
      "          total_loss: 1.978788137435913\n",
      "          vf_explained_var: -0.07227642089128494\n",
      "          vf_loss: 1.9991108179092407\n",
      "    num_agent_steps_sampled: 132000\n",
      "    num_agent_steps_trained: 132000\n",
      "    num_steps_sampled: 132000\n",
      "    num_steps_trained: 132000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.629411764705885\n",
      "    ram_util_percent: 50.835294117647045\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12635943875259525\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5026401571723719\n",
      "    mean_inference_ms: 2.582989598219029\n",
      "    mean_raw_obs_processing_ms: 0.11556298320181276\n",
      "  time_since_restore: 397.6274015903473\n",
      "  time_this_iter_s: 11.933085680007935\n",
      "  time_total_s: 397.6274015903473\n",
      "  timers:\n",
      "    learn_throughput: 748.237\n",
      "    learn_time_ms: 5345.902\n",
      "    load_throughput: 40088927.121\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 339.219\n",
      "    sample_time_ms: 11791.794\n",
      "    update_time_ms: 1.695\n",
      "  timestamp: 1641871609\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 132000\n",
      "  training_iteration: 33\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 132000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-26-50\n",
      "  done: false\n",
      "  episode_len_mean: 558.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.03822997576562\n",
      "  episode_reward_mean: -113.24533770845171\n",
      "  episode_reward_min: -222.12501436001168\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 206\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.6566129424663316e-11\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663209915161133\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.3835498552671197e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003563536563888192\n",
      "          total_loss: 587.19189453125\n",
      "          vf_explained_var: 0.00020758554455824196\n",
      "          vf_loss: 587.1882934570312\n",
      "    num_agent_steps_sampled: 132000\n",
      "    num_agent_steps_trained: 132000\n",
      "    num_steps_sampled: 132000\n",
      "    num_steps_trained: 132000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.370588235294115\n",
      "    ram_util_percent: 50.84117647058823\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12670114995113438\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49394085542369237\n",
      "    mean_inference_ms: 2.593261920503201\n",
      "    mean_raw_obs_processing_ms: 0.11464781994743908\n",
      "  time_since_restore: 398.0612373352051\n",
      "  time_this_iter_s: 11.765532970428467\n",
      "  time_total_s: 398.0612373352051\n",
      "  timers:\n",
      "    learn_throughput: 758.481\n",
      "    learn_time_ms: 5273.695\n",
      "    load_throughput: 20058842.659\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 338.654\n",
      "    sample_time_ms: 11811.448\n",
      "    update_time_ms: 2.394\n",
      "  timestamp: 1641871610\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 132000\n",
      "  training_iteration: 33\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:26:52 (running for 00:06:55.85)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         397.627</td><td style=\"text-align: right;\">132000</td><td style=\"text-align: right;\">-103.767</td><td style=\"text-align: right;\">            -63.3434</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            859.1 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         398.061</td><td style=\"text-align: right;\">132000</td><td style=\"text-align: right;\">-113.245</td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            558.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:26:57 (running for 00:07:00.89)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         397.627</td><td style=\"text-align: right;\">132000</td><td style=\"text-align: right;\">-103.767</td><td style=\"text-align: right;\">            -63.3434</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            859.1 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         398.061</td><td style=\"text-align: right;\">132000</td><td style=\"text-align: right;\">-113.245</td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -222.125</td><td style=\"text-align: right;\">            558.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 136000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-27-01\n",
      "  done: false\n",
      "  episode_len_mean: 874.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -60.48446797935798\n",
      "  episode_reward_mean: -102.76735664377334\n",
      "  episode_reward_min: -168.98403632784255\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 181\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22499999403953552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.386776447296143\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012525070458650589\n",
      "          model: {}\n",
      "          policy_loss: -0.025143051519989967\n",
      "          total_loss: 2.0632271766662598\n",
      "          vf_explained_var: -0.011686875484883785\n",
      "          vf_loss: 2.085552215576172\n",
      "    num_agent_steps_sampled: 136000\n",
      "    num_agent_steps_trained: 136000\n",
      "    num_steps_sampled: 136000\n",
      "    num_steps_trained: 136000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.26875\n",
      "    ram_util_percent: 50.85\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1262266006200517\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5023964994326672\n",
      "    mean_inference_ms: 2.5799649243165557\n",
      "    mean_raw_obs_processing_ms: 0.11543631488514788\n",
      "  time_since_restore: 409.2373514175415\n",
      "  time_this_iter_s: 11.609949827194214\n",
      "  time_total_s: 409.2373514175415\n",
      "  timers:\n",
      "    learn_throughput: 753.721\n",
      "    learn_time_ms: 5307.006\n",
      "    load_throughput: 40088927.121\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 339.797\n",
      "    sample_time_ms: 11771.732\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641871621\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 136000\n",
      "  training_iteration: 34\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 136000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-27-01\n",
      "  done: false\n",
      "  episode_len_mean: 560.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.03822997576562\n",
      "  episode_reward_mean: -112.09957868397976\n",
      "  episode_reward_min: -182.58037984422288\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 215\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.3283064712331658e-11\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663326263427734\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.1590937510372896e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003430252196267247\n",
      "          total_loss: 701.5153198242188\n",
      "          vf_explained_var: 9.290403249906376e-05\n",
      "          vf_loss: 701.5119018554688\n",
      "    num_agent_steps_sampled: 136000\n",
      "    num_agent_steps_trained: 136000\n",
      "    num_steps_sampled: 136000\n",
      "    num_steps_trained: 136000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.08125\n",
      "    ram_util_percent: 50.8125\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12650641416008004\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49352236645910513\n",
      "    mean_inference_ms: 2.5880240190864394\n",
      "    mean_raw_obs_processing_ms: 0.11448115017089908\n",
      "  time_since_restore: 409.62630701065063\n",
      "  time_this_iter_s: 11.565069675445557\n",
      "  time_total_s: 409.62630701065063\n",
      "  timers:\n",
      "    learn_throughput: 765.459\n",
      "    learn_time_ms: 5225.624\n",
      "    load_throughput: 20058842.659\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 339.34\n",
      "    sample_time_ms: 11787.583\n",
      "    update_time_ms: 2.394\n",
      "  timestamp: 1641871621\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 136000\n",
      "  training_iteration: 34\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:27:02 (running for 00:07:06.43)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         409.237</td><td style=\"text-align: right;\">136000</td><td style=\"text-align: right;\">-102.767</td><td style=\"text-align: right;\">            -60.4845</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            874.54</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         409.626</td><td style=\"text-align: right;\">136000</td><td style=\"text-align: right;\">-112.1  </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -182.58 </td><td style=\"text-align: right;\">            560.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:27:07 (running for 00:07:11.47)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         409.237</td><td style=\"text-align: right;\">136000</td><td style=\"text-align: right;\">-102.767</td><td style=\"text-align: right;\">            -60.4845</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            874.54</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         409.626</td><td style=\"text-align: right;\">136000</td><td style=\"text-align: right;\">-112.1  </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -182.58 </td><td style=\"text-align: right;\">            560.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:27:12 (running for 00:07:16.54)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         409.237</td><td style=\"text-align: right;\">136000</td><td style=\"text-align: right;\">-102.767</td><td style=\"text-align: right;\">            -60.4845</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            874.54</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         409.626</td><td style=\"text-align: right;\">136000</td><td style=\"text-align: right;\">-112.1  </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -182.58 </td><td style=\"text-align: right;\">            560.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 140000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-27-13\n",
      "  done: false\n",
      "  episode_len_mean: 919.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -46.45943946451706\n",
      "  episode_reward_mean: -100.73454887550317\n",
      "  episode_reward_min: -168.98403632784255\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 184\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22499999403953552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.483051776885986\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013237842358648777\n",
      "          model: {}\n",
      "          policy_loss: -0.029341699555516243\n",
      "          total_loss: 2.3382833003997803\n",
      "          vf_explained_var: 0.04475507140159607\n",
      "          vf_loss: 2.3646464347839355\n",
      "    num_agent_steps_sampled: 140000\n",
      "    num_agent_steps_trained: 140000\n",
      "    num_steps_sampled: 140000\n",
      "    num_steps_trained: 140000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.476470588235294\n",
      "    ram_util_percent: 50.835294117647045\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12603401382814292\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5018621206078444\n",
      "    mean_inference_ms: 2.5746157686166606\n",
      "    mean_raw_obs_processing_ms: 0.1152292708894569\n",
      "  time_since_restore: 420.92708802223206\n",
      "  time_this_iter_s: 11.689736604690552\n",
      "  time_total_s: 420.92708802223206\n",
      "  timers:\n",
      "    learn_throughput: 752.095\n",
      "    learn_time_ms: 5318.475\n",
      "    load_throughput: 0.0\n",
      "    load_time_ms: 0.0\n",
      "    sample_throughput: 341.459\n",
      "    sample_time_ms: 11714.441\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641871633\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 140000\n",
      "  training_iteration: 35\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 140000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-27-13\n",
      "  done: false\n",
      "  episode_len_mean: 560.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.03822997576562\n",
      "  episode_reward_mean: -111.8360454664793\n",
      "  episode_reward_min: -182.58037984422288\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 221\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1641532356165829e-11\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663421630859375\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.7912537348129263e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0031351582147181034\n",
      "          total_loss: 358.91009521484375\n",
      "          vf_explained_var: -2.442393270030152e-05\n",
      "          vf_loss: 358.9069519042969\n",
      "    num_agent_steps_sampled: 140000\n",
      "    num_agent_steps_trained: 140000\n",
      "    num_steps_sampled: 140000\n",
      "    num_steps_trained: 140000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.741176470588236\n",
      "    ram_util_percent: 50.84117647058822\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1263518468604088\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4932938008789814\n",
      "    mean_inference_ms: 2.584787025605176\n",
      "    mean_raw_obs_processing_ms: 0.11435091735870183\n",
      "  time_since_restore: 421.24622893333435\n",
      "  time_this_iter_s: 11.619921922683716\n",
      "  time_total_s: 421.24622893333435\n",
      "  timers:\n",
      "    learn_throughput: 765.211\n",
      "    learn_time_ms: 5227.32\n",
      "    load_throughput: 20058842.659\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 341.058\n",
      "    sample_time_ms: 11728.226\n",
      "    update_time_ms: 2.394\n",
      "  timestamp: 1641871633\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 140000\n",
      "  training_iteration: 35\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:27:18 (running for 00:07:22.09)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         420.927</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\">-100.735</td><td style=\"text-align: right;\">            -46.4594</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            919.66</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         421.246</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\">-111.836</td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -182.58 </td><td style=\"text-align: right;\">            560.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:27:23 (running for 00:07:27.15)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         420.927</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\">-100.735</td><td style=\"text-align: right;\">            -46.4594</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            919.66</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         421.246</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\">-111.836</td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -182.58 </td><td style=\"text-align: right;\">            560.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 144000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-27-24\n",
      "  done: false\n",
      "  episode_len_mean: 950.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -46.45943946451706\n",
      "  episode_reward_mean: -99.36873231594954\n",
      "  episode_reward_min: -168.98403632784255\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 186\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22499999403953552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.52421760559082\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015266308560967445\n",
      "          model: {}\n",
      "          policy_loss: -0.027873266488313675\n",
      "          total_loss: 1.0556226968765259\n",
      "          vf_explained_var: 0.131561741232872\n",
      "          vf_loss: 1.0800610780715942\n",
      "    num_agent_steps_sampled: 144000\n",
      "    num_agent_steps_trained: 144000\n",
      "    num_steps_sampled: 144000\n",
      "    num_steps_trained: 144000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.474999999999994\n",
      "    ram_util_percent: 50.75625\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12590515448407696\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.501620728871954\n",
      "    mean_inference_ms: 2.571620007013507\n",
      "    mean_raw_obs_processing_ms: 0.11510058961772594\n",
      "  time_since_restore: 432.4462802410126\n",
      "  time_this_iter_s: 11.519192218780518\n",
      "  time_total_s: 432.4462802410126\n",
      "  timers:\n",
      "    learn_throughput: 752.222\n",
      "    learn_time_ms: 5317.578\n",
      "    load_throughput: 0.0\n",
      "    load_time_ms: 0.0\n",
      "    sample_throughput: 341.196\n",
      "    sample_time_ms: 11723.468\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641871644\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 144000\n",
      "  training_iteration: 36\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 144000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-27-24\n",
      "  done: false\n",
      "  episode_len_mean: 551.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.03822997576562\n",
      "  episode_reward_mean: -112.58527212409484\n",
      "  episode_reward_min: -182.58037984422288\n",
      "  episodes_this_iter: 11\n",
      "  episodes_total: 232\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 5.8207661780829145e-12\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.664870738983154\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.863431234345626e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0043409462086856365\n",
      "          total_loss: 1044.9478759765625\n",
      "          vf_explained_var: 0.0002630542148835957\n",
      "          vf_loss: 1044.943603515625\n",
      "    num_agent_steps_sampled: 144000\n",
      "    num_agent_steps_trained: 144000\n",
      "    num_steps_sampled: 144000\n",
      "    num_steps_trained: 144000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.037499999999994\n",
      "    ram_util_percent: 50.725\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12585503906803824\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4931633004738569\n",
      "    mean_inference_ms: 2.5779113831753477\n",
      "    mean_raw_obs_processing_ms: 0.11407953092675781\n",
      "  time_since_restore: 432.7903552055359\n",
      "  time_this_iter_s: 11.544126272201538\n",
      "  time_total_s: 432.7903552055359\n",
      "  timers:\n",
      "    learn_throughput: 768.922\n",
      "    learn_time_ms: 5202.087\n",
      "    load_throughput: 20058842.659\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 341.022\n",
      "    sample_time_ms: 11729.448\n",
      "    update_time_ms: 2.394\n",
      "  timestamp: 1641871644\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 144000\n",
      "  training_iteration: 36\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:27:28 (running for 00:07:32.66)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         432.446</td><td style=\"text-align: right;\">144000</td><td style=\"text-align: right;\"> -99.3687</td><td style=\"text-align: right;\">            -46.4594</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            950.11</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         432.79 </td><td style=\"text-align: right;\">144000</td><td style=\"text-align: right;\">-112.585 </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -182.58 </td><td style=\"text-align: right;\">            551.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:27:34 (running for 00:07:37.72)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         432.446</td><td style=\"text-align: right;\">144000</td><td style=\"text-align: right;\"> -99.3687</td><td style=\"text-align: right;\">            -46.4594</td><td style=\"text-align: right;\">            -168.984</td><td style=\"text-align: right;\">            950.11</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         432.79 </td><td style=\"text-align: right;\">144000</td><td style=\"text-align: right;\">-112.585 </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -182.58 </td><td style=\"text-align: right;\">            551.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 148000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-27-36\n",
      "  done: false\n",
      "  episode_len_mean: 974.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -46.45943946451706\n",
      "  episode_reward_mean: -96.8541915211891\n",
      "  episode_reward_min: -154.47587586525705\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 189\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22499999403953552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.254261016845703\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013341814279556274\n",
      "          model: {}\n",
      "          policy_loss: -0.023137951269745827\n",
      "          total_loss: 1.4991466999053955\n",
      "          vf_explained_var: 0.11018868535757065\n",
      "          vf_loss: 1.5192826986312866\n",
      "    num_agent_steps_sampled: 148000\n",
      "    num_agent_steps_trained: 148000\n",
      "    num_steps_sampled: 148000\n",
      "    num_steps_trained: 148000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.6375\n",
      "    ram_util_percent: 50.78125\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1257257654975059\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5013598500126675\n",
      "    mean_inference_ms: 2.5676405873840933\n",
      "    mean_raw_obs_processing_ms: 0.11491264713644317\n",
      "  time_since_restore: 444.058224439621\n",
      "  time_this_iter_s: 11.611944198608398\n",
      "  time_total_s: 444.058224439621\n",
      "  timers:\n",
      "    learn_throughput: 752.49\n",
      "    learn_time_ms: 5315.683\n",
      "    load_throughput: 0.0\n",
      "    load_time_ms: 0.0\n",
      "    sample_throughput: 341.116\n",
      "    sample_time_ms: 11726.228\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641871656\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 148000\n",
      "  training_iteration: 37\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 148000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-27-36\n",
      "  done: false\n",
      "  episode_len_mean: 582.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.03822997576562\n",
      "  episode_reward_mean: -112.8583443235109\n",
      "  episode_reward_min: -182.58037984422288\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 235\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.9103830890414573e-12\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663885593414307\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.1682866702121828e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.013685300946235657\n",
      "          total_loss: 20.71210289001465\n",
      "          vf_explained_var: 0.00011245819769101217\n",
      "          vf_loss: 20.69841766357422\n",
      "    num_agent_steps_sampled: 148000\n",
      "    num_agent_steps_trained: 148000\n",
      "    num_steps_sampled: 148000\n",
      "    num_steps_trained: 148000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.0625\n",
      "    ram_util_percent: 50.76875\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12572982368428076\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49311481147361624\n",
      "    mean_inference_ms: 2.576189024081123\n",
      "    mean_raw_obs_processing_ms: 0.11398018229291733\n",
      "  time_since_restore: 444.2886047363281\n",
      "  time_this_iter_s: 11.498249530792236\n",
      "  time_total_s: 444.2886047363281\n",
      "  timers:\n",
      "    learn_throughput: 772.581\n",
      "    learn_time_ms: 5177.453\n",
      "    load_throughput: 20058842.659\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 341.5\n",
      "    sample_time_ms: 11713.015\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641871656\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 148000\n",
      "  training_iteration: 37\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:27:39 (running for 00:07:43.16)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         444.058</td><td style=\"text-align: right;\">148000</td><td style=\"text-align: right;\"> -96.8542</td><td style=\"text-align: right;\">            -46.4594</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">            974.87</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         444.289</td><td style=\"text-align: right;\">148000</td><td style=\"text-align: right;\">-112.858 </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -182.58 </td><td style=\"text-align: right;\">            582.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:27:44 (running for 00:07:48.22)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         444.058</td><td style=\"text-align: right;\">148000</td><td style=\"text-align: right;\"> -96.8542</td><td style=\"text-align: right;\">            -46.4594</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">            974.87</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         444.289</td><td style=\"text-align: right;\">148000</td><td style=\"text-align: right;\">-112.858 </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -182.58 </td><td style=\"text-align: right;\">            582.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 152000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-27-47\n",
      "  done: false\n",
      "  episode_len_mean: 990.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -46.45943946451706\n",
      "  episode_reward_mean: -95.80526792914999\n",
      "  episode_reward_min: -154.47587586525705\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 191\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22499999403953552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.474360466003418\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015294340439140797\n",
      "          model: {}\n",
      "          policy_loss: -0.030113060027360916\n",
      "          total_loss: 2.1615676879882812\n",
      "          vf_explained_var: 0.1360412985086441\n",
      "          vf_loss: 2.188239812850952\n",
      "    num_agent_steps_sampled: 152000\n",
      "    num_agent_steps_trained: 152000\n",
      "    num_steps_sampled: 152000\n",
      "    num_steps_trained: 152000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.035294117647055\n",
      "    ram_util_percent: 50.78823529411765\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12561311411678966\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5010576815576698\n",
      "    mean_inference_ms: 2.5643350932193316\n",
      "    mean_raw_obs_processing_ms: 0.11476447622103252\n",
      "  time_since_restore: 455.64822721481323\n",
      "  time_this_iter_s: 11.59000277519226\n",
      "  time_total_s: 455.64822721481323\n",
      "  timers:\n",
      "    learn_throughput: 753.211\n",
      "    learn_time_ms: 5310.596\n",
      "    load_throughput: 0.0\n",
      "    load_time_ms: 0.0\n",
      "    sample_throughput: 340.763\n",
      "    sample_time_ms: 11738.361\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871667\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 152000\n",
      "  training_iteration: 38\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 152000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-27-48\n",
      "  done: false\n",
      "  episode_len_mean: 596.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.03822997576562\n",
      "  episode_reward_mean: -114.00648914086808\n",
      "  episode_reward_min: -228.06776964484786\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 243\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.4551915445207286e-12\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.665268421173096\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 4.3612658373604063e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003689913544803858\n",
      "          total_loss: 692.0870361328125\n",
      "          vf_explained_var: 0.0004192992637399584\n",
      "          vf_loss: 692.0833129882812\n",
      "    num_agent_steps_sampled: 152000\n",
      "    num_agent_steps_trained: 152000\n",
      "    num_steps_sampled: 152000\n",
      "    num_steps_trained: 152000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.17058823529412\n",
      "    ram_util_percent: 50.794117647058826\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12564938429805422\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49267705798823114\n",
      "    mean_inference_ms: 2.5729771681573137\n",
      "    mean_raw_obs_processing_ms: 0.11390689318376446\n",
      "  time_since_restore: 455.9494183063507\n",
      "  time_this_iter_s: 11.660813570022583\n",
      "  time_total_s: 455.9494183063507\n",
      "  timers:\n",
      "    learn_throughput: 774.057\n",
      "    learn_time_ms: 5167.579\n",
      "    load_throughput: 13372561.773\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 341.7\n",
      "    sample_time_ms: 11706.188\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641871668\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 152000\n",
      "  training_iteration: 38\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:27:50 (running for 00:07:53.84)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         455.648</td><td style=\"text-align: right;\">152000</td><td style=\"text-align: right;\"> -95.8053</td><td style=\"text-align: right;\">            -46.4594</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">            990.21</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         455.949</td><td style=\"text-align: right;\">152000</td><td style=\"text-align: right;\">-114.006 </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -228.068</td><td style=\"text-align: right;\">            596.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:27:55 (running for 00:07:58.90)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         455.648</td><td style=\"text-align: right;\">152000</td><td style=\"text-align: right;\"> -95.8053</td><td style=\"text-align: right;\">            -46.4594</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">            990.21</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         455.949</td><td style=\"text-align: right;\">152000</td><td style=\"text-align: right;\">-114.006 </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -228.068</td><td style=\"text-align: right;\">            596.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 156000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-27-59\n",
      "  done: false\n",
      "  episode_len_mean: 1020.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -34.52645513822635\n",
      "  episode_reward_mean: -93.70135789044285\n",
      "  episode_reward_min: -154.47587586525705\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 194\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22499999403953552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.309175491333008\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013502619229257107\n",
      "          model: {}\n",
      "          policy_loss: -0.022801674902439117\n",
      "          total_loss: 1.752776861190796\n",
      "          vf_explained_var: 0.15711578726768494\n",
      "          vf_loss: 1.77254056930542\n",
      "    num_agent_steps_sampled: 156000\n",
      "    num_agent_steps_trained: 156000\n",
      "    num_steps_sampled: 156000\n",
      "    num_steps_trained: 156000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.0125\n",
      "    ram_util_percent: 50.787499999999994\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1254250494099898\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5007465681697164\n",
      "    mean_inference_ms: 2.5602855108605276\n",
      "    mean_raw_obs_processing_ms: 0.11457461929171969\n",
      "  time_since_restore: 467.16841650009155\n",
      "  time_this_iter_s: 11.52018928527832\n",
      "  time_total_s: 467.16841650009155\n",
      "  timers:\n",
      "    learn_throughput: 754.217\n",
      "    learn_time_ms: 5303.515\n",
      "    load_throughput: 0.0\n",
      "    load_time_ms: 0.0\n",
      "    sample_throughput: 341.089\n",
      "    sample_time_ms: 11727.146\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641871679\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 156000\n",
      "  training_iteration: 39\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 156000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-27-59\n",
      "  done: false\n",
      "  episode_len_mean: 566.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.03822997576562\n",
      "  episode_reward_mean: -115.20368652147995\n",
      "  episode_reward_min: -235.86440480207543\n",
      "  episodes_this_iter: 11\n",
      "  episodes_total: 254\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 7.275957722603643e-13\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.665294170379639\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 5.326359087121091e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.00381487631238997\n",
      "          total_loss: 866.099365234375\n",
      "          vf_explained_var: -0.0001184558350360021\n",
      "          vf_loss: 866.0955810546875\n",
      "    num_agent_steps_sampled: 156000\n",
      "    num_agent_steps_trained: 156000\n",
      "    num_steps_sampled: 156000\n",
      "    num_steps_trained: 156000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.587500000000006\n",
      "    ram_util_percent: 50.8\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12546102510163304\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4922214391460292\n",
      "    mean_inference_ms: 2.5681254344075297\n",
      "    mean_raw_obs_processing_ms: 0.11369579588073425\n",
      "  time_since_restore: 467.65610790252686\n",
      "  time_this_iter_s: 11.706689596176147\n",
      "  time_total_s: 467.65610790252686\n",
      "  timers:\n",
      "    learn_throughput: 772.045\n",
      "    learn_time_ms: 5181.043\n",
      "    load_throughput: 20058842.659\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 341.734\n",
      "    sample_time_ms: 11705.01\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641871679\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 156000\n",
      "  training_iteration: 39\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:28:00 (running for 00:08:04.56)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         467.168</td><td style=\"text-align: right;\">156000</td><td style=\"text-align: right;\"> -93.7014</td><td style=\"text-align: right;\">            -34.5265</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1020.98</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         467.656</td><td style=\"text-align: right;\">156000</td><td style=\"text-align: right;\">-115.204 </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            566.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:28:05 (running for 00:08:09.61)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         467.168</td><td style=\"text-align: right;\">156000</td><td style=\"text-align: right;\"> -93.7014</td><td style=\"text-align: right;\">            -34.5265</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1020.98</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         467.656</td><td style=\"text-align: right;\">156000</td><td style=\"text-align: right;\">-115.204 </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            566.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:28:10 (running for 00:08:14.66)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         467.168</td><td style=\"text-align: right;\">156000</td><td style=\"text-align: right;\"> -93.7014</td><td style=\"text-align: right;\">            -34.5265</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1020.98</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         467.656</td><td style=\"text-align: right;\">156000</td><td style=\"text-align: right;\">-115.204 </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            566.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 160000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-28-11\n",
      "  done: false\n",
      "  episode_len_mean: 1036.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -34.52645513822635\n",
      "  episode_reward_mean: -92.38258757956059\n",
      "  episode_reward_min: -154.47587586525705\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 196\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22499999403953552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.179391860961914\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01432204619050026\n",
      "          model: {}\n",
      "          policy_loss: -0.028755147010087967\n",
      "          total_loss: 2.0047731399536133\n",
      "          vf_explained_var: 0.2857024073600769\n",
      "          vf_loss: 2.030305862426758\n",
      "    num_agent_steps_sampled: 160000\n",
      "    num_agent_steps_trained: 160000\n",
      "    num_steps_sampled: 160000\n",
      "    num_steps_trained: 160000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.688235294117646\n",
      "    ram_util_percent: 50.94705882352941\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12531124332255006\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5005364095956608\n",
      "    mean_inference_ms: 2.557620524728207\n",
      "    mean_raw_obs_processing_ms: 0.11445083377782472\n",
      "  time_since_restore: 479.06061029434204\n",
      "  time_this_iter_s: 11.892193794250488\n",
      "  time_total_s: 479.06061029434204\n",
      "  timers:\n",
      "    learn_throughput: 753.154\n",
      "    learn_time_ms: 5310.995\n",
      "    load_throughput: 40127280.555\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 340.827\n",
      "    sample_time_ms: 11736.163\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871691\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 160000\n",
      "  training_iteration: 40\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 160000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-28-11\n",
      "  done: false\n",
      "  episode_len_mean: 581.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.03822997576562\n",
      "  episode_reward_mean: -115.31249064360613\n",
      "  episode_reward_min: -235.86440480207543\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 258\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.6379788613018216e-13\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.6650471687316895\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.7805887725662615e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0013601431855931878\n",
      "          total_loss: 102.72632598876953\n",
      "          vf_explained_var: 0.00027069076895713806\n",
      "          vf_loss: 102.72496795654297\n",
      "    num_agent_steps_sampled: 160000\n",
      "    num_agent_steps_trained: 160000\n",
      "    num_steps_sampled: 160000\n",
      "    num_steps_trained: 160000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.758823529411764\n",
      "    ram_util_percent: 50.93529411764706\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12529507895625056\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49220399526038944\n",
      "    mean_inference_ms: 2.565986194179644\n",
      "    mean_raw_obs_processing_ms: 0.11362944521717752\n",
      "  time_since_restore: 479.50840973854065\n",
      "  time_this_iter_s: 11.852301836013794\n",
      "  time_total_s: 479.50840973854065\n",
      "  timers:\n",
      "    learn_throughput: 767.451\n",
      "    learn_time_ms: 5212.06\n",
      "    load_throughput: 20058842.659\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 341.365\n",
      "    sample_time_ms: 11717.651\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641871691\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 160000\n",
      "  training_iteration: 40\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:28:16 (running for 00:08:20.49)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         479.061</td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\"> -92.3826</td><td style=\"text-align: right;\">            -34.5265</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1036.53</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         479.508</td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\">-115.312 </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            581.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:28:21 (running for 00:08:25.54)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         479.061</td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\"> -92.3826</td><td style=\"text-align: right;\">            -34.5265</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1036.53</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         479.508</td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\">-115.312 </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            581.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 164000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-28-22\n",
      "  done: false\n",
      "  episode_len_mean: 1051.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -25.621185266916896\n",
      "  episode_reward_mean: -89.96354554557253\n",
      "  episode_reward_min: -154.47587586525705\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 199\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22499999403953552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.242025852203369\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014692220836877823\n",
      "          model: {}\n",
      "          policy_loss: -0.019935104995965958\n",
      "          total_loss: 1.7084684371948242\n",
      "          vf_explained_var: 0.23553825914859772\n",
      "          vf_loss: 1.7250977754592896\n",
      "    num_agent_steps_sampled: 164000\n",
      "    num_agent_steps_trained: 164000\n",
      "    num_steps_sampled: 164000\n",
      "    num_steps_trained: 164000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.40625\n",
      "    ram_util_percent: 50.962500000000006\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12513618179885483\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5002462006784796\n",
      "    mean_inference_ms: 2.5540921344390908\n",
      "    mean_raw_obs_processing_ms: 0.1142755983826301\n",
      "  time_since_restore: 490.65659856796265\n",
      "  time_this_iter_s: 11.595988273620605\n",
      "  time_total_s: 490.65659856796265\n",
      "  timers:\n",
      "    learn_throughput: 755.567\n",
      "    learn_time_ms: 5294.041\n",
      "    load_throughput: 20061241.181\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 340.758\n",
      "    sample_time_ms: 11738.522\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871702\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 164000\n",
      "  training_iteration: 41\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 164000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-28-23\n",
      "  done: false\n",
      "  episode_len_mean: 558.06\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.03822997576562\n",
      "  episode_reward_mean: -116.31348351351772\n",
      "  episode_reward_min: -235.86440480207543\n",
      "  episodes_this_iter: 11\n",
      "  episodes_total: 269\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.8189894306509108e-13\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.6659770011901855\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.913770345003286e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003502243896946311\n",
      "          total_loss: 893.5135498046875\n",
      "          vf_explained_var: 0.00012482321471907198\n",
      "          vf_loss: 893.5100708007812\n",
      "    num_agent_steps_sampled: 164000\n",
      "    num_agent_steps_trained: 164000\n",
      "    num_steps_sampled: 164000\n",
      "    num_steps_trained: 164000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.6125\n",
      "    ram_util_percent: 50.962500000000006\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12506307282239149\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4918951069820615\n",
      "    mean_inference_ms: 2.5616658638556795\n",
      "    mean_raw_obs_processing_ms: 0.11349752777976875\n",
      "  time_since_restore: 491.0784649848938\n",
      "  time_this_iter_s: 11.57005524635315\n",
      "  time_total_s: 491.0784649848938\n",
      "  timers:\n",
      "    learn_throughput: 770.606\n",
      "    learn_time_ms: 5190.718\n",
      "    load_throughput: 40117685.318\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 340.901\n",
      "    sample_time_ms: 11733.598\n",
      "    update_time_ms: 2.095\n",
      "  timestamp: 1641871703\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 164000\n",
      "  training_iteration: 41\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:28:27 (running for 00:08:31.07)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         490.657</td><td style=\"text-align: right;\">164000</td><td style=\"text-align: right;\"> -89.9635</td><td style=\"text-align: right;\">            -25.6212</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1051.76</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         491.078</td><td style=\"text-align: right;\">164000</td><td style=\"text-align: right;\">-116.313 </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            558.06</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:28:32 (running for 00:08:36.11)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         490.657</td><td style=\"text-align: right;\">164000</td><td style=\"text-align: right;\"> -89.9635</td><td style=\"text-align: right;\">            -25.6212</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1051.76</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         491.078</td><td style=\"text-align: right;\">164000</td><td style=\"text-align: right;\">-116.313 </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            558.06</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 168000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-28-34\n",
      "  done: false\n",
      "  episode_len_mean: 1081.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -21.1313576355924\n",
      "  episode_reward_mean: -88.67131349218882\n",
      "  episode_reward_min: -154.47587586525705\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 202\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22499999403953552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.169839382171631\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0076589141972362995\n",
      "          model: {}\n",
      "          policy_loss: -0.021598167717456818\n",
      "          total_loss: 52.59632110595703\n",
      "          vf_explained_var: 0.29647183418273926\n",
      "          vf_loss: 52.61619567871094\n",
      "    num_agent_steps_sampled: 168000\n",
      "    num_agent_steps_trained: 168000\n",
      "    num_steps_sampled: 168000\n",
      "    num_steps_trained: 168000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.07058823529412\n",
      "    ram_util_percent: 51.088235294117645\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12493642550416073\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4999632065412624\n",
      "    mean_inference_ms: 2.550683990824376\n",
      "    mean_raw_obs_processing_ms: 0.11410206784736712\n",
      "  time_since_restore: 502.6694712638855\n",
      "  time_this_iter_s: 12.012872695922852\n",
      "  time_total_s: 502.6694712638855\n",
      "  timers:\n",
      "    learn_throughput: 752.476\n",
      "    learn_time_ms: 5315.783\n",
      "    load_throughput: 20061241.181\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 341.971\n",
      "    sample_time_ms: 11696.891\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871714\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 168000\n",
      "  training_iteration: 42\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 168000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-28-35\n",
      "  done: false\n",
      "  episode_len_mean: 588.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.03822997576562\n",
      "  episode_reward_mean: -116.34284927292832\n",
      "  episode_reward_min: -235.86440480207543\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 271\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 9.094947153254554e-14\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.665399074554443\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 7.26153189134493e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.012442577630281448\n",
      "          total_loss: 23.909008026123047\n",
      "          vf_explained_var: 0.00027649805997498333\n",
      "          vf_loss: 23.89656639099121\n",
      "    num_agent_steps_sampled: 168000\n",
      "    num_agent_steps_trained: 168000\n",
      "    num_steps_sampled: 168000\n",
      "    num_steps_trained: 168000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.23529411764706\n",
      "    ram_util_percent: 51.129411764705885\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12498751304307419\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49189517149790163\n",
      "    mean_inference_ms: 2.5608094603770746\n",
      "    mean_raw_obs_processing_ms: 0.11347110042698144\n",
      "  time_since_restore: 503.2339553833008\n",
      "  time_this_iter_s: 12.155490398406982\n",
      "  time_total_s: 503.2339553833008\n",
      "  timers:\n",
      "    learn_throughput: 767.363\n",
      "    learn_time_ms: 5212.659\n",
      "    load_throughput: 40117685.318\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 342.015\n",
      "    sample_time_ms: 11695.385\n",
      "    update_time_ms: 2.095\n",
      "  timestamp: 1641871715\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 168000\n",
      "  training_iteration: 42\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:28:37 (running for 00:08:41.23)<br>Memory usage on this node: 12.4/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         502.669</td><td style=\"text-align: right;\">168000</td><td style=\"text-align: right;\"> -88.6713</td><td style=\"text-align: right;\">            -21.1314</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1081.86</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         503.234</td><td style=\"text-align: right;\">168000</td><td style=\"text-align: right;\">-116.343 </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            588.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:28:42 (running for 00:08:46.30)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         502.669</td><td style=\"text-align: right;\">168000</td><td style=\"text-align: right;\"> -88.6713</td><td style=\"text-align: right;\">            -21.1314</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1081.86</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         503.234</td><td style=\"text-align: right;\">168000</td><td style=\"text-align: right;\">-116.343 </td><td style=\"text-align: right;\">            -96.0382</td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            588.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 172000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-28-46\n",
      "  done: false\n",
      "  episode_len_mean: 1112.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -16.606189428367326\n",
      "  episode_reward_mean: -86.01728827786147\n",
      "  episode_reward_min: -154.47587586525705\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 205\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22499999403953552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.159963130950928\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015298395417630672\n",
      "          model: {}\n",
      "          policy_loss: -0.02436700649559498\n",
      "          total_loss: 1.2799570560455322\n",
      "          vf_explained_var: 0.18668866157531738\n",
      "          vf_loss: 1.3008819818496704\n",
      "    num_agent_steps_sampled: 172000\n",
      "    num_agent_steps_trained: 172000\n",
      "    num_steps_sampled: 172000\n",
      "    num_steps_trained: 172000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.805882352941175\n",
      "    ram_util_percent: 51.23529411764705\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12480935701795172\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4994698847586296\n",
      "    mean_inference_ms: 2.5460533232008355\n",
      "    mean_raw_obs_processing_ms: 0.11388830211147201\n",
      "  time_since_restore: 514.6005616188049\n",
      "  time_this_iter_s: 11.931090354919434\n",
      "  time_total_s: 514.6005616188049\n",
      "  timers:\n",
      "    learn_throughput: 752.406\n",
      "    learn_time_ms: 5316.281\n",
      "    load_throughput: 20061241.181\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 341.373\n",
      "    sample_time_ms: 11717.376\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871726\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 172000\n",
      "  training_iteration: 43\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 172000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-28-47\n",
      "  done: false\n",
      "  episode_len_mean: 526.69\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.62500044576014\n",
      "  episode_reward_mean: -117.27543897459796\n",
      "  episode_reward_min: -235.86440480207543\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 281\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.547473576627277e-14\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.664736747741699\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.107190025275486e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0041777826845645905\n",
      "          total_loss: 838.4354858398438\n",
      "          vf_explained_var: -4.667921893997118e-05\n",
      "          vf_loss: 838.4313354492188\n",
      "    num_agent_steps_sampled: 172000\n",
      "    num_agent_steps_trained: 172000\n",
      "    num_steps_sampled: 172000\n",
      "    num_steps_trained: 172000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.71764705882353\n",
      "    ram_util_percent: 51.188235294117646\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12484968587923198\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49154309162894727\n",
      "    mean_inference_ms: 2.558402228727881\n",
      "    mean_raw_obs_processing_ms: 0.11345876138401238\n",
      "  time_since_restore: 515.241840839386\n",
      "  time_this_iter_s: 12.007885456085205\n",
      "  time_total_s: 515.241840839386\n",
      "  timers:\n",
      "    learn_throughput: 765.167\n",
      "    learn_time_ms: 5227.619\n",
      "    load_throughput: 40117685.318\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 341.135\n",
      "    sample_time_ms: 11725.572\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871727\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 172000\n",
      "  training_iteration: 43\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:28:48 (running for 00:08:52.25)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         514.601</td><td style=\"text-align: right;\">172000</td><td style=\"text-align: right;\"> -86.0173</td><td style=\"text-align: right;\">            -16.6062</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1112.41</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         515.242</td><td style=\"text-align: right;\">172000</td><td style=\"text-align: right;\">-117.275 </td><td style=\"text-align: right;\">            -96.625 </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            526.69</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:28:53 (running for 00:08:57.31)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         514.601</td><td style=\"text-align: right;\">172000</td><td style=\"text-align: right;\"> -86.0173</td><td style=\"text-align: right;\">            -16.6062</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1112.41</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         515.242</td><td style=\"text-align: right;\">172000</td><td style=\"text-align: right;\">-117.275 </td><td style=\"text-align: right;\">            -96.625 </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            526.69</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:28:58 (running for 00:09:02.38)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         514.601</td><td style=\"text-align: right;\">172000</td><td style=\"text-align: right;\"> -86.0173</td><td style=\"text-align: right;\">            -16.6062</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1112.41</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         515.242</td><td style=\"text-align: right;\">172000</td><td style=\"text-align: right;\">-117.275 </td><td style=\"text-align: right;\">            -96.625 </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            526.69</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 176000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-28-58\n",
      "  done: false\n",
      "  episode_len_mean: 1143.16\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -16.606189428367326\n",
      "  episode_reward_mean: -84.07172481536013\n",
      "  episode_reward_min: -154.47587586525705\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 207\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22499999403953552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.161112308502197\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014364995062351227\n",
      "          model: {}\n",
      "          policy_loss: -0.02225068211555481\n",
      "          total_loss: 0.9308487176895142\n",
      "          vf_explained_var: 0.3719504177570343\n",
      "          vf_loss: 0.9498672485351562\n",
      "    num_agent_steps_sampled: 176000\n",
      "    num_agent_steps_trained: 176000\n",
      "    num_steps_sampled: 176000\n",
      "    num_steps_trained: 176000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.37058823529412\n",
      "    ram_util_percent: 50.83529411764705\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12471299029154485\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49922777483315933\n",
      "    mean_inference_ms: 2.5435551037548203\n",
      "    mean_raw_obs_processing_ms: 0.11375195939987826\n",
      "  time_since_restore: 526.6383674144745\n",
      "  time_this_iter_s: 12.037805795669556\n",
      "  time_total_s: 526.6383674144745\n",
      "  timers:\n",
      "    learn_throughput: 744.652\n",
      "    learn_time_ms: 5371.633\n",
      "    load_throughput: 20061241.181\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 341.729\n",
      "    sample_time_ms: 11705.194\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871738\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 176000\n",
      "  training_iteration: 44\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 176000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-28-59\n",
      "  done: false\n",
      "  episode_len_mean: 534.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.62500044576014\n",
      "  episode_reward_mean: -116.54185067657485\n",
      "  episode_reward_min: -235.86440480207543\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 286\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2737367883136385e-14\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663796901702881\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.820482905008248e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0031749114859849215\n",
      "          total_loss: 296.1061706542969\n",
      "          vf_explained_var: 6.14546297583729e-05\n",
      "          vf_loss: 296.1029968261719\n",
      "    num_agent_steps_sampled: 176000\n",
      "    num_agent_steps_trained: 176000\n",
      "    num_steps_sampled: 176000\n",
      "    num_steps_trained: 176000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.41176470588236\n",
      "    ram_util_percent: 50.829411764705874\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12471917144426942\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4914857486501656\n",
      "    mean_inference_ms: 2.5569266587942208\n",
      "    mean_raw_obs_processing_ms: 0.11345181968930779\n",
      "  time_since_restore: 527.312557220459\n",
      "  time_this_iter_s: 12.070716381072998\n",
      "  time_total_s: 527.312557220459\n",
      "  timers:\n",
      "    learn_throughput: 758.768\n",
      "    learn_time_ms: 5271.701\n",
      "    load_throughput: 40117685.318\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 340.496\n",
      "    sample_time_ms: 11747.576\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871739\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 176000\n",
      "  training_iteration: 44\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:29:04 (running for 00:09:08.38)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         526.638</td><td style=\"text-align: right;\">176000</td><td style=\"text-align: right;\"> -84.0717</td><td style=\"text-align: right;\">            -16.6062</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1143.16</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         527.313</td><td style=\"text-align: right;\">176000</td><td style=\"text-align: right;\">-116.542 </td><td style=\"text-align: right;\">            -96.625 </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            534.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:29:09 (running for 00:09:13.43)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         526.638</td><td style=\"text-align: right;\">176000</td><td style=\"text-align: right;\"> -84.0717</td><td style=\"text-align: right;\">            -16.6062</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1143.16</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         527.313</td><td style=\"text-align: right;\">176000</td><td style=\"text-align: right;\">-116.542 </td><td style=\"text-align: right;\">            -96.625 </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            534.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 180000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-29-11\n",
      "  done: false\n",
      "  episode_len_mean: 1173.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -3.3587533559265315\n",
      "  episode_reward_mean: -81.13558506397426\n",
      "  episode_reward_min: -154.47587586525705\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 211\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22499999403953552\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 4.9277849197387695\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.049644388258457184\n",
      "          model: {}\n",
      "          policy_loss: -0.016545983031392097\n",
      "          total_loss: 33.25233459472656\n",
      "          vf_explained_var: 0.3371572494506836\n",
      "          vf_loss: 33.257713317871094\n",
      "    num_agent_steps_sampled: 180000\n",
      "    num_agent_steps_trained: 180000\n",
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 180000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.949999999999996\n",
      "    ram_util_percent: 50.96111111111111\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1245069601982567\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4989460649543702\n",
      "    mean_inference_ms: 2.539728638883943\n",
      "    mean_raw_obs_processing_ms: 0.11349667120041555\n",
      "  time_since_restore: 539.142924785614\n",
      "  time_this_iter_s: 12.504557371139526\n",
      "  time_total_s: 539.142924785614\n",
      "  timers:\n",
      "    learn_throughput: 741.472\n",
      "    learn_time_ms: 5394.672\n",
      "    load_throughput: 20061241.181\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 338.42\n",
      "    sample_time_ms: 11819.639\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871751\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 45\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 180000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-29-12\n",
      "  done: false\n",
      "  episode_len_mean: 580.24\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.62500044576014\n",
      "  episode_reward_mean: -116.52614727156305\n",
      "  episode_reward_min: -235.86440480207543\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 289\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1368683941568192e-14\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663923740386963\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 7.00795965258294e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.009064959362149239\n",
      "          total_loss: 18.79422378540039\n",
      "          vf_explained_var: 0.00010505972022656351\n",
      "          vf_loss: 18.785158157348633\n",
      "    num_agent_steps_sampled: 180000\n",
      "    num_agent_steps_trained: 180000\n",
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 180000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.97222222222222\n",
      "    ram_util_percent: 50.94444444444444\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12462099810170207\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49152653647541217\n",
      "    mean_inference_ms: 2.5558997086764963\n",
      "    mean_raw_obs_processing_ms: 0.11345363742810452\n",
      "  time_since_restore: 539.964720249176\n",
      "  time_this_iter_s: 12.652163028717041\n",
      "  time_total_s: 539.964720249176\n",
      "  timers:\n",
      "    learn_throughput: 752.518\n",
      "    learn_time_ms: 5315.484\n",
      "    load_throughput: 20056444.71\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 337.513\n",
      "    sample_time_ms: 11851.411\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871752\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 45\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:29:15 (running for 00:09:19.04)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         539.143</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\"> -81.1356</td><td style=\"text-align: right;\">            -3.35875</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1173.41</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         539.965</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\">-116.526 </td><td style=\"text-align: right;\">           -96.625  </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            580.24</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:29:20 (running for 00:09:24.08)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         539.143</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\"> -81.1356</td><td style=\"text-align: right;\">            -3.35875</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1173.41</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         539.965</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\">-116.526 </td><td style=\"text-align: right;\">           -96.625  </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            580.24</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 184000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-29-23\n",
      "  done: false\n",
      "  episode_len_mean: 1204.22\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -3.3587533559265315\n",
      "  episode_reward_mean: -79.28177360453395\n",
      "  episode_reward_min: -154.47587586525705\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 213\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3375000059604645\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.084542274475098\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010714744217693806\n",
      "          model: {}\n",
      "          policy_loss: -0.018799571320414543\n",
      "          total_loss: 1.8845891952514648\n",
      "          vf_explained_var: 0.3738701045513153\n",
      "          vf_loss: 1.8997726440429688\n",
      "    num_agent_steps_sampled: 184000\n",
      "    num_agent_steps_trained: 184000\n",
      "    num_steps_sampled: 184000\n",
      "    num_steps_trained: 184000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.905882352941184\n",
      "    ram_util_percent: 50.94705882352941\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1244094205009835\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49882003902108724\n",
      "    mean_inference_ms: 2.5378673249751085\n",
      "    mean_raw_obs_processing_ms: 0.11337013409556494\n",
      "  time_since_restore: 551.5497434139252\n",
      "  time_this_iter_s: 12.406818628311157\n",
      "  time_total_s: 551.5497434139252\n",
      "  timers:\n",
      "    learn_throughput: 738.564\n",
      "    learn_time_ms: 5415.915\n",
      "    load_throughput: 20061241.181\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 335.836\n",
      "    sample_time_ms: 11910.558\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871763\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 184000\n",
      "  training_iteration: 46\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 184000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-29-24\n",
      "  done: false\n",
      "  episode_len_mean: 579.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.62500044576014\n",
      "  episode_reward_mean: -116.33956404081175\n",
      "  episode_reward_min: -235.86440480207543\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 294\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 5.684341970784096e-15\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663341045379639\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 4.1219510649170843e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0031759506091475487\n",
      "          total_loss: 322.114013671875\n",
      "          vf_explained_var: 0.00038115395000204444\n",
      "          vf_loss: 322.1108093261719\n",
      "    num_agent_steps_sampled: 184000\n",
      "    num_agent_steps_trained: 184000\n",
      "    num_steps_sampled: 184000\n",
      "    num_steps_trained: 184000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.82777777777777\n",
      "    ram_util_percent: 50.94444444444444\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12452872747655043\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4915172130394293\n",
      "    mean_inference_ms: 2.55478932859655\n",
      "    mean_raw_obs_processing_ms: 0.1134723249022813\n",
      "  time_since_restore: 552.399463891983\n",
      "  time_this_iter_s: 12.434743642807007\n",
      "  time_total_s: 552.399463891983\n",
      "  timers:\n",
      "    learn_throughput: 748.46\n",
      "    learn_time_ms: 5344.307\n",
      "    load_throughput: 13369364.89\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 334.572\n",
      "    sample_time_ms: 11955.556\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871764\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 184000\n",
      "  training_iteration: 46\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:29:25 (running for 00:09:29.48)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         551.55 </td><td style=\"text-align: right;\">184000</td><td style=\"text-align: right;\"> -79.2818</td><td style=\"text-align: right;\">            -3.35875</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1204.22</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         552.399</td><td style=\"text-align: right;\">184000</td><td style=\"text-align: right;\">-116.34  </td><td style=\"text-align: right;\">           -96.625  </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            579.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:29:30 (running for 00:09:34.52)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         551.55 </td><td style=\"text-align: right;\">184000</td><td style=\"text-align: right;\"> -79.2818</td><td style=\"text-align: right;\">            -3.35875</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1204.22</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         552.399</td><td style=\"text-align: right;\">184000</td><td style=\"text-align: right;\">-116.34  </td><td style=\"text-align: right;\">           -96.625  </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            579.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 188000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-29-35\n",
      "  done: false\n",
      "  episode_len_mean: 1218.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -3.3587533559265315\n",
      "  episode_reward_mean: -76.43492131096902\n",
      "  episode_reward_min: -154.47587586525705\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 216\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3375000059604645\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.0241193771362305\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014373717829585075\n",
      "          model: {}\n",
      "          policy_loss: -0.018800469115376472\n",
      "          total_loss: 1.6598467826843262\n",
      "          vf_explained_var: 0.45843255519866943\n",
      "          vf_loss: 1.6737961769104004\n",
      "    num_agent_steps_sampled: 188000\n",
      "    num_agent_steps_trained: 188000\n",
      "    num_steps_sampled: 188000\n",
      "    num_steps_trained: 188000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.83529411764706\n",
      "    ram_util_percent: 50.94705882352941\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12427623242803726\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49855802226582996\n",
      "    mean_inference_ms: 2.5346950208572667\n",
      "    mean_raw_obs_processing_ms: 0.11317178154244559\n",
      "  time_since_restore: 563.1447329521179\n",
      "  time_this_iter_s: 11.594989538192749\n",
      "  time_total_s: 563.1447329521179\n",
      "  timers:\n",
      "    learn_throughput: 737.952\n",
      "    learn_time_ms: 5420.403\n",
      "    load_throughput: 13372561.773\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 335.425\n",
      "    sample_time_ms: 11925.164\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871775\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 188000\n",
      "  training_iteration: 47\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 188000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-29-36\n",
      "  done: false\n",
      "  episode_len_mean: 543.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.62500044576014\n",
      "  episode_reward_mean: -115.08254275703592\n",
      "  episode_reward_min: -235.86440480207543\n",
      "  episodes_this_iter: 13\n",
      "  episodes_total: 307\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.842170985392048e-15\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.662724494934082\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.686830444214138e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0041102212853729725\n",
      "          total_loss: 924.4752807617188\n",
      "          vf_explained_var: 0.00015997033915482461\n",
      "          vf_loss: 924.4711303710938\n",
      "    num_agent_steps_sampled: 188000\n",
      "    num_agent_steps_trained: 188000\n",
      "    num_steps_sampled: 188000\n",
      "    num_steps_trained: 188000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.48125\n",
      "    ram_util_percent: 50.95\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12429841806871458\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49156942844540796\n",
      "    mean_inference_ms: 2.5515417219544876\n",
      "    mean_raw_obs_processing_ms: 0.11349912555659106\n",
      "  time_since_restore: 563.9884691238403\n",
      "  time_this_iter_s: 11.5890052318573\n",
      "  time_total_s: 563.9884691238403\n",
      "  timers:\n",
      "    learn_throughput: 746.843\n",
      "    learn_time_ms: 5355.876\n",
      "    load_throughput: 13369364.89\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 333.817\n",
      "    sample_time_ms: 11982.624\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871776\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 188000\n",
      "  training_iteration: 47\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:29:36 (running for 00:09:40.09)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         563.145</td><td style=\"text-align: right;\">188000</td><td style=\"text-align: right;\"> -76.4349</td><td style=\"text-align: right;\">            -3.35875</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1218.95</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         563.988</td><td style=\"text-align: right;\">188000</td><td style=\"text-align: right;\">-115.083 </td><td style=\"text-align: right;\">           -96.625  </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            543.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:29:41 (running for 00:09:45.14)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         563.145</td><td style=\"text-align: right;\">188000</td><td style=\"text-align: right;\"> -76.4349</td><td style=\"text-align: right;\">            -3.35875</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1218.95</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         563.988</td><td style=\"text-align: right;\">188000</td><td style=\"text-align: right;\">-115.083 </td><td style=\"text-align: right;\">           -96.625  </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            543.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:29:46 (running for 00:09:50.21)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         563.145</td><td style=\"text-align: right;\">188000</td><td style=\"text-align: right;\"> -76.4349</td><td style=\"text-align: right;\">            -3.35875</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1218.95</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         563.988</td><td style=\"text-align: right;\">188000</td><td style=\"text-align: right;\">-115.083 </td><td style=\"text-align: right;\">           -96.625  </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            543.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 192000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-29-47\n",
      "  done: false\n",
      "  episode_len_mean: 1259.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2.419195447801916\n",
      "  episode_reward_mean: -74.43208227524691\n",
      "  episode_reward_min: -154.47587586525705\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 219\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3375000059604645\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.394023418426514\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010476725175976753\n",
      "          model: {}\n",
      "          policy_loss: -0.02560262940824032\n",
      "          total_loss: 66.6270523071289\n",
      "          vf_explained_var: 0.21117347478866577\n",
      "          vf_loss: 66.64912414550781\n",
      "    num_agent_steps_sampled: 192000\n",
      "    num_agent_steps_trained: 192000\n",
      "    num_steps_sampled: 192000\n",
      "    num_steps_trained: 192000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.5\n",
      "    ram_util_percent: 51.0\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.124143016111702\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4983925920392292\n",
      "    mean_inference_ms: 2.532346958064458\n",
      "    mean_raw_obs_processing_ms: 0.11297627042891736\n",
      "  time_since_restore: 574.8055460453033\n",
      "  time_this_iter_s: 11.660813093185425\n",
      "  time_total_s: 574.8055460453033\n",
      "  timers:\n",
      "    learn_throughput: 736.273\n",
      "    learn_time_ms: 5432.77\n",
      "    load_throughput: 13372561.773\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 335.426\n",
      "    sample_time_ms: 11925.116\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641871787\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 192000\n",
      "  training_iteration: 48\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 192000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-29-48\n",
      "  done: false\n",
      "  episode_len_mean: 589.48\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.62500044576014\n",
      "  episode_reward_mean: -115.21815056009838\n",
      "  episode_reward_min: -235.86440480207543\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 311\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.421085492696024e-15\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.664321422576904\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.7983913380703598e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0027599160093814135\n",
      "          total_loss: 147.8473663330078\n",
      "          vf_explained_var: 0.0007692126673646271\n",
      "          vf_loss: 147.84458923339844\n",
      "    num_agent_steps_sampled: 192000\n",
      "    num_agent_steps_trained: 192000\n",
      "    num_steps_sampled: 192000\n",
      "    num_steps_trained: 192000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.78235294117647\n",
      "    ram_util_percent: 51.0\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12420497074619721\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4915610913943246\n",
      "    mean_inference_ms: 2.550631211812882\n",
      "    mean_raw_obs_processing_ms: 0.11348788526976096\n",
      "  time_since_restore: 575.6323263645172\n",
      "  time_this_iter_s: 11.64385724067688\n",
      "  time_total_s: 575.6323263645172\n",
      "  timers:\n",
      "    learn_throughput: 744.417\n",
      "    learn_time_ms: 5373.329\n",
      "    load_throughput: 20051650.532\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 334.02\n",
      "    sample_time_ms: 11975.332\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871788\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 192000\n",
      "  training_iteration: 48\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:29:52 (running for 00:09:55.80)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         574.806</td><td style=\"text-align: right;\">192000</td><td style=\"text-align: right;\"> -74.4321</td><td style=\"text-align: right;\">             -2.4192</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1259.3 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         575.632</td><td style=\"text-align: right;\">192000</td><td style=\"text-align: right;\">-115.218 </td><td style=\"text-align: right;\">            -96.625 </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            589.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:29:57 (running for 00:10:00.85)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         574.806</td><td style=\"text-align: right;\">192000</td><td style=\"text-align: right;\"> -74.4321</td><td style=\"text-align: right;\">             -2.4192</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1259.3 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         575.632</td><td style=\"text-align: right;\">192000</td><td style=\"text-align: right;\">-115.218 </td><td style=\"text-align: right;\">            -96.625 </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            589.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 196000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-29-58\n",
      "  done: false\n",
      "  episode_len_mean: 1274.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2.419195447801916\n",
      "  episode_reward_mean: -72.78705407334947\n",
      "  episode_reward_min: -154.47587586525705\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 222\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3375000059604645\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.197861194610596\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0628485158085823\n",
      "          model: {}\n",
      "          policy_loss: -0.026721592992544174\n",
      "          total_loss: 102.82452392578125\n",
      "          vf_explained_var: 0.16146963834762573\n",
      "          vf_loss: 102.83003234863281\n",
      "    num_agent_steps_sampled: 196000\n",
      "    num_agent_steps_trained: 196000\n",
      "    num_steps_sampled: 196000\n",
      "    num_steps_trained: 196000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.78235294117648\n",
      "    ram_util_percent: 50.99411764705882\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12405140533870213\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4979930225003054\n",
      "    mean_inference_ms: 2.5287742516713867\n",
      "    mean_raw_obs_processing_ms: 0.11276005876780251\n",
      "  time_since_restore: 586.6000025272369\n",
      "  time_this_iter_s: 11.794456481933594\n",
      "  time_total_s: 586.6000025272369\n",
      "  timers:\n",
      "    learn_throughput: 732.789\n",
      "    learn_time_ms: 5458.601\n",
      "    load_throughput: 13372561.773\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 335.041\n",
      "    sample_time_ms: 11938.838\n",
      "    update_time_ms: 2.095\n",
      "  timestamp: 1641871798\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 196000\n",
      "  training_iteration: 49\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 196000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-29-59\n",
      "  done: false\n",
      "  episode_len_mean: 604.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.62500044576014\n",
      "  episode_reward_mean: -115.10617888106914\n",
      "  episode_reward_min: -235.86440480207543\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 313\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 7.10542746348012e-16\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663312911987305\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 4.586270563322614e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.009356154128909111\n",
      "          total_loss: 23.47825050354004\n",
      "          vf_explained_var: 0.0009482702007517219\n",
      "          vf_loss: 23.468896865844727\n",
      "    num_agent_steps_sampled: 196000\n",
      "    num_agent_steps_trained: 196000\n",
      "    num_steps_sampled: 196000\n",
      "    num_steps_trained: 196000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.3125\n",
      "    ram_util_percent: 50.9875\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12417606647971155\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4915428576014636\n",
      "    mean_inference_ms: 2.5502432266468373\n",
      "    mean_raw_obs_processing_ms: 0.11348257351369868\n",
      "  time_since_restore: 587.4307723045349\n",
      "  time_this_iter_s: 11.7984459400177\n",
      "  time_total_s: 587.4307723045349\n",
      "  timers:\n",
      "    learn_throughput: 743.81\n",
      "    learn_time_ms: 5377.718\n",
      "    load_throughput: 13370430.347\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 333.417\n",
      "    sample_time_ms: 11996.98\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871799\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 196000\n",
      "  training_iteration: 49\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:30:02 (running for 00:10:06.61)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         586.6  </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\"> -72.7871</td><td style=\"text-align: right;\">             -2.4192</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1274.74</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         587.431</td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">-115.106 </td><td style=\"text-align: right;\">            -96.625 </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            604.52</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:30:07 (running for 00:10:11.66)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         586.6  </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\"> -72.7871</td><td style=\"text-align: right;\">             -2.4192</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1274.74</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         587.431</td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">-115.106 </td><td style=\"text-align: right;\">            -96.625 </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            604.52</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 200000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-30-10\n",
      "  done: false\n",
      "  episode_len_mean: 1305.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -2.419195447801916\n",
      "  episode_reward_mean: -71.03595419277981\n",
      "  episode_reward_min: -154.47587586525705\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 224\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.378319263458252\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0071598198264837265\n",
      "          model: {}\n",
      "          policy_loss: -0.019782550632953644\n",
      "          total_loss: 3.1355535984039307\n",
      "          vf_explained_var: 0.16302843391895294\n",
      "          vf_loss: 3.1517117023468018\n",
      "    num_agent_steps_sampled: 200000\n",
      "    num_agent_steps_trained: 200000\n",
      "    num_steps_sampled: 200000\n",
      "    num_steps_trained: 200000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.45\n",
      "    ram_util_percent: 51.04375\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12398378454899134\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49770171360137155\n",
      "    mean_inference_ms: 2.526251384363202\n",
      "    mean_raw_obs_processing_ms: 0.11261092041971157\n",
      "  time_since_restore: 598.283754825592\n",
      "  time_this_iter_s: 11.683752298355103\n",
      "  time_total_s: 598.283754825592\n",
      "  timers:\n",
      "    learn_throughput: 732.842\n",
      "    learn_time_ms: 5458.202\n",
      "    load_throughput: 13372561.773\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 334.889\n",
      "    sample_time_ms: 11944.246\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871810\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 200000\n",
      "  training_iteration: 50\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 200000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-30-11\n",
      "  done: false\n",
      "  episode_len_mean: 565.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.62500044576014\n",
      "  episode_reward_mean: -114.3113619217384\n",
      "  episode_reward_min: -235.86440480207543\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 323\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.55271373174006e-16\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.662511348724365\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.22520498027734e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0034768381156027317\n",
      "          total_loss: 589.6849365234375\n",
      "          vf_explained_var: -0.0004800720198545605\n",
      "          vf_loss: 589.6814575195312\n",
      "    num_agent_steps_sampled: 200000\n",
      "    num_agent_steps_trained: 200000\n",
      "    num_steps_sampled: 200000\n",
      "    num_steps_trained: 200000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.04117647058824\n",
      "    ram_util_percent: 51.04705882352941\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12400004005487605\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4915616284233218\n",
      "    mean_inference_ms: 2.547964123938422\n",
      "    mean_raw_obs_processing_ms: 0.11346108540779148\n",
      "  time_since_restore: 599.1424486637115\n",
      "  time_this_iter_s: 11.711676359176636\n",
      "  time_total_s: 599.1424486637115\n",
      "  timers:\n",
      "    learn_throughput: 744.846\n",
      "    learn_time_ms: 5370.238\n",
      "    load_throughput: 13370430.347\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 333.493\n",
      "    sample_time_ms: 11994.239\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871811\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 200000\n",
      "  training_iteration: 50\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:30:13 (running for 00:10:17.33)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         598.284</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -71.036</td><td style=\"text-align: right;\">             -2.4192</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1305.94</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         599.142</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">-114.311</td><td style=\"text-align: right;\">            -96.625 </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            565.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:30:18 (running for 00:10:22.38)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         598.284</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -71.036</td><td style=\"text-align: right;\">             -2.4192</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1305.94</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         599.142</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">-114.311</td><td style=\"text-align: right;\">            -96.625 </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            565.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 204000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-30-22\n",
      "  done: false\n",
      "  episode_len_mean: 1351.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.5152781709674548\n",
      "  episode_reward_mean: -67.0001466665823\n",
      "  episode_reward_min: -154.47587586525705\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 228\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 5.076641082763672\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009826544672250748\n",
      "          model: {}\n",
      "          policy_loss: -0.01786727085709572\n",
      "          total_loss: 3.2856032848358154\n",
      "          vf_explained_var: 0.34693142771720886\n",
      "          vf_loss: 3.2984957695007324\n",
      "    num_agent_steps_sampled: 204000\n",
      "    num_agent_steps_trained: 204000\n",
      "    num_steps_sampled: 204000\n",
      "    num_steps_trained: 204000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.56470588235294\n",
      "    ram_util_percent: 50.99411764705882\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1238234486199773\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49726633012937965\n",
      "    mean_inference_ms: 2.5221500439503513\n",
      "    mean_raw_obs_processing_ms: 0.11234154040951626\n",
      "  time_since_restore: 609.9026792049408\n",
      "  time_this_iter_s: 11.618924379348755\n",
      "  time_total_s: 609.9026792049408\n",
      "  timers:\n",
      "    learn_throughput: 731.933\n",
      "    learn_time_ms: 5464.984\n",
      "    load_throughput: 13368299.602\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 335.028\n",
      "    sample_time_ms: 11939.293\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641871822\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 204000\n",
      "  training_iteration: 51\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 204000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-30-23\n",
      "  done: false\n",
      "  episode_len_mean: 596.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.62500044576014\n",
      "  episode_reward_mean: -114.19577064015662\n",
      "  episode_reward_min: -235.86440480207543\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 329\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.77635686587003e-16\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.662257671356201\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.664083129071514e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0030359048396348953\n",
      "          total_loss: 311.89825439453125\n",
      "          vf_explained_var: 0.00023632741067558527\n",
      "          vf_loss: 311.8952331542969\n",
      "    num_agent_steps_sampled: 204000\n",
      "    num_agent_steps_trained: 204000\n",
      "    num_steps_sampled: 204000\n",
      "    num_steps_trained: 204000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.05625\n",
      "    ram_util_percent: 50.98125\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12399261504521714\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4914638912175272\n",
      "    mean_inference_ms: 2.547051078096992\n",
      "    mean_raw_obs_processing_ms: 0.11345672413790422\n",
      "  time_since_restore: 610.7623703479767\n",
      "  time_this_iter_s: 11.619921684265137\n",
      "  time_total_s: 610.7623703479767\n",
      "  timers:\n",
      "    learn_throughput: 742.846\n",
      "    learn_time_ms: 5384.699\n",
      "    load_throughput: 13370430.347\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 333.939\n",
      "    sample_time_ms: 11978.24\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871823\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 204000\n",
      "  training_iteration: 51\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:30:24 (running for 00:10:27.96)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         609.903</td><td style=\"text-align: right;\">204000</td><td style=\"text-align: right;\"> -67.0001</td><td style=\"text-align: right;\">             2.51528</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1351.44</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         610.762</td><td style=\"text-align: right;\">204000</td><td style=\"text-align: right;\">-114.196 </td><td style=\"text-align: right;\">           -96.625  </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            596.7 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:30:29 (running for 00:10:33.01)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         609.903</td><td style=\"text-align: right;\">204000</td><td style=\"text-align: right;\"> -67.0001</td><td style=\"text-align: right;\">             2.51528</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1351.44</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         610.762</td><td style=\"text-align: right;\">204000</td><td style=\"text-align: right;\">-114.196 </td><td style=\"text-align: right;\">           -96.625  </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            596.7 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 208000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-30-33\n",
      "  done: false\n",
      "  episode_len_mean: 1351.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.5152781709674548\n",
      "  episode_reward_mean: -65.41765639909953\n",
      "  episode_reward_min: -154.47587586525705\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 230\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 4.9574785232543945\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013322180137038231\n",
      "          model: {}\n",
      "          policy_loss: -0.01855579949915409\n",
      "          total_loss: 2.5427379608154297\n",
      "          vf_explained_var: 0.26859501004219055\n",
      "          vf_loss: 2.5545494556427\n",
      "    num_agent_steps_sampled: 208000\n",
      "    num_agent_steps_trained: 208000\n",
      "    num_steps_sampled: 208000\n",
      "    num_steps_trained: 208000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.64375\n",
      "    ram_util_percent: 50.96875\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12375027338180436\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49706367367542853\n",
      "    mean_inference_ms: 2.5202891486062464\n",
      "    mean_raw_obs_processing_ms: 0.11222611236194288\n",
      "  time_since_restore: 621.5116312503815\n",
      "  time_this_iter_s: 11.608952045440674\n",
      "  time_total_s: 621.5116312503815\n",
      "  timers:\n",
      "    learn_throughput: 737.342\n",
      "    learn_time_ms: 5424.891\n",
      "    load_throughput: 13368299.602\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 334.838\n",
      "    sample_time_ms: 11946.062\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641871833\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 208000\n",
      "  training_iteration: 52\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 208000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-30-34\n",
      "  done: false\n",
      "  episode_len_mean: 567.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.73267346610191\n",
      "  episode_reward_mean: -113.45088539462535\n",
      "  episode_reward_min: -235.86440480207543\n",
      "  episodes_this_iter: 11\n",
      "  episodes_total: 340\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8.88178432935015e-17\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.662513732910156\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 4.214960540593893e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0033664272632449865\n",
      "          total_loss: 751.1207275390625\n",
      "          vf_explained_var: -5.042424891144037e-05\n",
      "          vf_loss: 751.1172485351562\n",
      "    num_agent_steps_sampled: 208000\n",
      "    num_agent_steps_trained: 208000\n",
      "    num_steps_sampled: 208000\n",
      "    num_steps_trained: 208000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.12941176470588\n",
      "    ram_util_percent: 50.95294117647059\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12387599318534791\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4913279071476775\n",
      "    mean_inference_ms: 2.5452626881041427\n",
      "    mean_raw_obs_processing_ms: 0.11343046427234928\n",
      "  time_since_restore: 622.4311625957489\n",
      "  time_this_iter_s: 11.668792247772217\n",
      "  time_total_s: 622.4311625957489\n",
      "  timers:\n",
      "    learn_throughput: 747.804\n",
      "    learn_time_ms: 5348.995\n",
      "    load_throughput: 10026424.431\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 333.908\n",
      "    sample_time_ms: 11979.337\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871834\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 208000\n",
      "  training_iteration: 52\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:30:34 (running for 00:10:38.64)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         621.512</td><td style=\"text-align: right;\">208000</td><td style=\"text-align: right;\"> -65.4177</td><td style=\"text-align: right;\">             2.51528</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1351.44</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         622.431</td><td style=\"text-align: right;\">208000</td><td style=\"text-align: right;\">-113.451 </td><td style=\"text-align: right;\">           -96.7327 </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            567.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:30:39 (running for 00:10:43.70)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         621.512</td><td style=\"text-align: right;\">208000</td><td style=\"text-align: right;\"> -65.4177</td><td style=\"text-align: right;\">             2.51528</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1351.44</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         622.431</td><td style=\"text-align: right;\">208000</td><td style=\"text-align: right;\">-113.451 </td><td style=\"text-align: right;\">           -96.7327 </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            567.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:30:45 (running for 00:10:48.75)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         621.512</td><td style=\"text-align: right;\">208000</td><td style=\"text-align: right;\"> -65.4177</td><td style=\"text-align: right;\">             2.51528</td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1351.44</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         622.431</td><td style=\"text-align: right;\">208000</td><td style=\"text-align: right;\">-113.451 </td><td style=\"text-align: right;\">           -96.7327 </td><td style=\"text-align: right;\">            -235.864</td><td style=\"text-align: right;\">            567.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 212000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-30-45\n",
      "  done: false\n",
      "  episode_len_mean: 1343.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.160014902279386\n",
      "  episode_reward_mean: -63.258820569104444\n",
      "  episode_reward_min: -154.47587586525705\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 233\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 4.895600318908691\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.005341643467545509\n",
      "          model: {}\n",
      "          policy_loss: -0.021980293095111847\n",
      "          total_loss: 38.33516311645508\n",
      "          vf_explained_var: 0.1468878537416458\n",
      "          vf_loss: 38.35443878173828\n",
      "    num_agent_steps_sampled: 212000\n",
      "    num_agent_steps_trained: 212000\n",
      "    num_steps_sampled: 212000\n",
      "    num_steps_trained: 212000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.41176470588235\n",
      "    ram_util_percent: 50.95294117647059\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1236557911775923\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49670710580472305\n",
      "    mean_inference_ms: 2.517389739325214\n",
      "    mean_raw_obs_processing_ms: 0.11205329691211434\n",
      "  time_since_restore: 633.1475102901459\n",
      "  time_this_iter_s: 11.635879039764404\n",
      "  time_total_s: 633.1475102901459\n",
      "  timers:\n",
      "    learn_throughput: 737.762\n",
      "    learn_time_ms: 5421.799\n",
      "    load_throughput: 10025226.173\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 336.712\n",
      "    sample_time_ms: 11879.573\n",
      "    update_time_ms: 2.394\n",
      "  timestamp: 1641871845\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 212000\n",
      "  training_iteration: 53\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 212000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-30-46\n",
      "  done: false\n",
      "  episode_len_mean: 522.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.73267346610191\n",
      "  episode_reward_mean: -111.8629919112694\n",
      "  episode_reward_min: -217.14251855411732\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 358\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.440892164675075e-17\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.661571025848389\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.160328105877852e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.004833087790757418\n",
      "          total_loss: 1407.378173828125\n",
      "          vf_explained_var: 0.00036797215580008924\n",
      "          vf_loss: 1407.3734130859375\n",
      "    num_agent_steps_sampled: 212000\n",
      "    num_agent_steps_trained: 212000\n",
      "    num_steps_sampled: 212000\n",
      "    num_steps_trained: 212000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.3875\n",
      "    ram_util_percent: 50.95\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12368942211985598\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4912741974930329\n",
      "    mean_inference_ms: 2.5417590136730714\n",
      "    mean_raw_obs_processing_ms: 0.11353524751835434\n",
      "  time_since_restore: 634.0241575241089\n",
      "  time_this_iter_s: 11.592994928359985\n",
      "  time_total_s: 634.0241575241089\n",
      "  timers:\n",
      "    learn_throughput: 749.467\n",
      "    learn_time_ms: 5337.126\n",
      "    load_throughput: 10026424.431\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 335.733\n",
      "    sample_time_ms: 11914.239\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871846\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 212000\n",
      "  training_iteration: 53\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:30:50 (running for 00:10:54.30)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         633.148</td><td style=\"text-align: right;\">212000</td><td style=\"text-align: right;\"> -63.2588</td><td style=\"text-align: right;\">             18.16  </td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1343.72</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         634.024</td><td style=\"text-align: right;\">212000</td><td style=\"text-align: right;\">-111.863 </td><td style=\"text-align: right;\">            -96.7327</td><td style=\"text-align: right;\">            -217.143</td><td style=\"text-align: right;\">            522.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:30:55 (running for 00:10:59.36)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         633.148</td><td style=\"text-align: right;\">212000</td><td style=\"text-align: right;\"> -63.2588</td><td style=\"text-align: right;\">             18.16  </td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1343.72</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         634.024</td><td style=\"text-align: right;\">212000</td><td style=\"text-align: right;\">-111.863 </td><td style=\"text-align: right;\">            -96.7327</td><td style=\"text-align: right;\">            -217.143</td><td style=\"text-align: right;\">            522.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 216000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-30-57\n",
      "  done: false\n",
      "  episode_len_mean: 1343.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.160014902279386\n",
      "  episode_reward_mean: -61.440642359270534\n",
      "  episode_reward_min: -154.47587586525705\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 235\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 4.736311435699463\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009750235825777054\n",
      "          model: {}\n",
      "          policy_loss: -0.020643841475248337\n",
      "          total_loss: 1.3651478290557861\n",
      "          vf_explained_var: 0.3610896170139313\n",
      "          vf_loss: 1.380855679512024\n",
      "    num_agent_steps_sampled: 216000\n",
      "    num_agent_steps_trained: 216000\n",
      "    num_steps_sampled: 216000\n",
      "    num_steps_trained: 216000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.5875\n",
      "    ram_util_percent: 50.9375\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12359229013749293\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4965216391577911\n",
      "    mean_inference_ms: 2.5158293069301765\n",
      "    mean_raw_obs_processing_ms: 0.1119491925027984\n",
      "  time_since_restore: 644.8960888385773\n",
      "  time_this_iter_s: 11.748578548431396\n",
      "  time_total_s: 644.8960888385773\n",
      "  timers:\n",
      "    learn_throughput: 743.962\n",
      "    learn_time_ms: 5376.62\n",
      "    load_throughput: 10025226.173\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 336.323\n",
      "    sample_time_ms: 11893.321\n",
      "    update_time_ms: 2.394\n",
      "  timestamp: 1641871857\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 216000\n",
      "  training_iteration: 54\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 216000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-30-58\n",
      "  done: false\n",
      "  episode_len_mean: 515.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.73267346610191\n",
      "  episode_reward_mean: -111.23662642188351\n",
      "  episode_reward_min: -217.14251855411732\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 365\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2204460823375376e-17\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659703254699707\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.503600396470574e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0029396458994597197\n",
      "          total_loss: 404.4921569824219\n",
      "          vf_explained_var: 0.00020936958026140928\n",
      "          vf_loss: 404.4892272949219\n",
      "    num_agent_steps_sampled: 216000\n",
      "    num_agent_steps_trained: 216000\n",
      "    num_steps_sampled: 216000\n",
      "    num_steps_trained: 216000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.6764705882353\n",
      "    ram_util_percent: 50.970588235294116\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12359051658232673\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49133610339758993\n",
      "    mean_inference_ms: 2.540529701144004\n",
      "    mean_raw_obs_processing_ms: 0.1135383293576994\n",
      "  time_since_restore: 645.7168853282928\n",
      "  time_this_iter_s: 11.69272780418396\n",
      "  time_total_s: 645.7168853282928\n",
      "  timers:\n",
      "    learn_throughput: 755.851\n",
      "    learn_time_ms: 5292.047\n",
      "    load_throughput: 10026424.431\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 335.867\n",
      "    sample_time_ms: 11909.478\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641871858\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 216000\n",
      "  training_iteration: 54\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:31:01 (running for 00:11:05.00)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         644.896</td><td style=\"text-align: right;\">216000</td><td style=\"text-align: right;\"> -61.4406</td><td style=\"text-align: right;\">             18.16  </td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1343.72</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         645.717</td><td style=\"text-align: right;\">216000</td><td style=\"text-align: right;\">-111.237 </td><td style=\"text-align: right;\">            -96.7327</td><td style=\"text-align: right;\">            -217.143</td><td style=\"text-align: right;\">            515.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:31:06 (running for 00:11:10.06)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         644.896</td><td style=\"text-align: right;\">216000</td><td style=\"text-align: right;\"> -61.4406</td><td style=\"text-align: right;\">             18.16  </td><td style=\"text-align: right;\">            -154.476</td><td style=\"text-align: right;\">           1343.72</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         645.717</td><td style=\"text-align: right;\">216000</td><td style=\"text-align: right;\">-111.237 </td><td style=\"text-align: right;\">            -96.7327</td><td style=\"text-align: right;\">            -217.143</td><td style=\"text-align: right;\">            515.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 220000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-31-09\n",
      "  done: false\n",
      "  episode_len_mean: 1372.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.160014902279386\n",
      "  episode_reward_mean: -57.5889903832033\n",
      "  episode_reward_min: -137.61958789929062\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 238\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 4.711802005767822\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012917469255626202\n",
      "          model: {}\n",
      "          policy_loss: -0.02201283723115921\n",
      "          total_loss: 1.3254976272583008\n",
      "          vf_explained_var: 0.3823469281196594\n",
      "          vf_loss: 1.3409709930419922\n",
      "    num_agent_steps_sampled: 220000\n",
      "    num_agent_steps_trained: 220000\n",
      "    num_steps_sampled: 220000\n",
      "    num_steps_trained: 220000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.517647058823535\n",
      "    ram_util_percent: 51.01176470588236\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12349760277412178\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4962952220306191\n",
      "    mean_inference_ms: 2.5138897578222927\n",
      "    mean_raw_obs_processing_ms: 0.11179952100879209\n",
      "  time_since_restore: 656.5180063247681\n",
      "  time_this_iter_s: 11.621917486190796\n",
      "  time_total_s: 656.5180063247681\n",
      "  timers:\n",
      "    learn_throughput: 748.544\n",
      "    learn_time_ms: 5343.708\n",
      "    load_throughput: 10025226.173\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 339.205\n",
      "    sample_time_ms: 11792.281\n",
      "    update_time_ms: 2.394\n",
      "  timestamp: 1641871869\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 220000\n",
      "  training_iteration: 55\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 220000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-31-09\n",
      "  done: false\n",
      "  episode_len_mean: 471.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.73267346610191\n",
      "  episode_reward_mean: -109.96208354759659\n",
      "  episode_reward_min: -133.88067029833795\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 381\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1102230411687688e-17\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.6599273681640625\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.9833490227938455e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.004364014603197575\n",
      "          total_loss: 1300.676025390625\n",
      "          vf_explained_var: 0.0006679041543975472\n",
      "          vf_loss: 1300.6715087890625\n",
      "    num_agent_steps_sampled: 220000\n",
      "    num_agent_steps_trained: 220000\n",
      "    num_steps_sampled: 220000\n",
      "    num_steps_trained: 220000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.025\n",
      "    ram_util_percent: 51.0125\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12353925473516911\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49097156461257485\n",
      "    mean_inference_ms: 2.539197288164958\n",
      "    mean_raw_obs_processing_ms: 0.11353951818678644\n",
      "  time_since_restore: 657.3737103939056\n",
      "  time_this_iter_s: 11.656825065612793\n",
      "  time_total_s: 657.3737103939056\n",
      "  timers:\n",
      "    learn_throughput: 762.621\n",
      "    learn_time_ms: 5245.072\n",
      "    load_throughput: 10026424.431\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 338.657\n",
      "    sample_time_ms: 11811.357\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871869\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 220000\n",
      "  training_iteration: 55\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:31:11 (running for 00:11:15.68)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         656.518</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\"> -57.589</td><td style=\"text-align: right;\">             18.16  </td><td style=\"text-align: right;\">            -137.62 </td><td style=\"text-align: right;\">           1372.26</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         657.374</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\">-109.962</td><td style=\"text-align: right;\">            -96.7327</td><td style=\"text-align: right;\">            -133.881</td><td style=\"text-align: right;\">            471.35</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:31:17 (running for 00:11:20.74)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         656.518</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\"> -57.589</td><td style=\"text-align: right;\">             18.16  </td><td style=\"text-align: right;\">            -137.62 </td><td style=\"text-align: right;\">           1372.26</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         657.374</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\">-109.962</td><td style=\"text-align: right;\">            -96.7327</td><td style=\"text-align: right;\">            -133.881</td><td style=\"text-align: right;\">            471.35</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 224000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-31-20\n",
      "  done: false\n",
      "  episode_len_mean: 1372.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.637126106528545\n",
      "  episode_reward_mean: -55.50690715182376\n",
      "  episode_reward_min: -137.61958789929062\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 240\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 4.542843341827393\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009064803831279278\n",
      "          model: {}\n",
      "          policy_loss: -0.013518919236958027\n",
      "          total_loss: 1.605319857597351\n",
      "          vf_explained_var: 0.4526387155056\n",
      "          vf_loss: 1.6142498254776\n",
      "    num_agent_steps_sampled: 224000\n",
      "    num_agent_steps_trained: 224000\n",
      "    num_steps_sampled: 224000\n",
      "    num_steps_trained: 224000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.912499999999994\n",
      "    ram_util_percent: 51.0\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12341756892542571\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4961889822383091\n",
      "    mean_inference_ms: 2.512736834742245\n",
      "    mean_raw_obs_processing_ms: 0.1117100263893702\n",
      "  time_since_restore: 668.1020250320435\n",
      "  time_this_iter_s: 11.58401870727539\n",
      "  time_total_s: 668.1020250320435\n",
      "  timers:\n",
      "    learn_throughput: 750.898\n",
      "    learn_time_ms: 5326.953\n",
      "    load_throughput: 10025226.173\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 342.065\n",
      "    sample_time_ms: 11693.684\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641871880\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 224000\n",
      "  training_iteration: 56\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 224000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-31-21\n",
      "  done: false\n",
      "  episode_len_mean: 487.48\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.73267346610191\n",
      "  episode_reward_mean: -109.990926332502\n",
      "  episode_reward_min: -133.88067029833795\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 384\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 5.551115205843844e-18\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.660069942474365\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.1257611731707584e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003614552319049835\n",
      "          total_loss: 130.49188232421875\n",
      "          vf_explained_var: 0.00021505862241610885\n",
      "          vf_loss: 130.48826599121094\n",
      "    num_agent_steps_sampled: 224000\n",
      "    num_agent_steps_trained: 224000\n",
      "    num_steps_sampled: 224000\n",
      "    num_steps_trained: 224000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.98235294117647\n",
      "    ram_util_percent: 50.98235294117647\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12350394994976412\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.490990292610068\n",
      "    mean_inference_ms: 2.5386705868498516\n",
      "    mean_raw_obs_processing_ms: 0.11353497286217433\n",
      "  time_since_restore: 669.1242842674255\n",
      "  time_this_iter_s: 11.750573873519897\n",
      "  time_total_s: 669.1242842674255\n",
      "  timers:\n",
      "    learn_throughput: 763.346\n",
      "    learn_time_ms: 5240.086\n",
      "    load_throughput: 13369364.89\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 341.858\n",
      "    sample_time_ms: 11700.757\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871881\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 224000\n",
      "  training_iteration: 56\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:31:22 (running for 00:11:26.44)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         668.102</td><td style=\"text-align: right;\">224000</td><td style=\"text-align: right;\"> -55.5069</td><td style=\"text-align: right;\">             20.6371</td><td style=\"text-align: right;\">            -137.62 </td><td style=\"text-align: right;\">           1372.26</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         669.124</td><td style=\"text-align: right;\">224000</td><td style=\"text-align: right;\">-109.991 </td><td style=\"text-align: right;\">            -96.7327</td><td style=\"text-align: right;\">            -133.881</td><td style=\"text-align: right;\">            487.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:31:27 (running for 00:11:31.48)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         668.102</td><td style=\"text-align: right;\">224000</td><td style=\"text-align: right;\"> -55.5069</td><td style=\"text-align: right;\">             20.6371</td><td style=\"text-align: right;\">            -137.62 </td><td style=\"text-align: right;\">           1372.26</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         669.124</td><td style=\"text-align: right;\">224000</td><td style=\"text-align: right;\">-109.991 </td><td style=\"text-align: right;\">            -96.7327</td><td style=\"text-align: right;\">            -133.881</td><td style=\"text-align: right;\">            487.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 228000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-31-32\n",
      "  done: false\n",
      "  episode_len_mean: 1403.17\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 27.81632965053059\n",
      "  episode_reward_mean: -51.69770530547834\n",
      "  episode_reward_min: -137.61958789929062\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 243\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 4.18548583984375\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012135091237723827\n",
      "          model: {}\n",
      "          policy_loss: -0.01947583071887493\n",
      "          total_loss: 1.2930054664611816\n",
      "          vf_explained_var: 0.5206338763237\n",
      "          vf_loss: 1.3063379526138306\n",
      "    num_agent_steps_sampled: 228000\n",
      "    num_agent_steps_trained: 228000\n",
      "    num_steps_sampled: 228000\n",
      "    num_steps_trained: 228000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.96470588235294\n",
      "    ram_util_percent: 51.06470588235294\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12335166279713645\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4958115467826994\n",
      "    mean_inference_ms: 2.5098506447235276\n",
      "    mean_raw_obs_processing_ms: 0.11149601774574887\n",
      "  time_since_restore: 679.9433543682098\n",
      "  time_this_iter_s: 11.841329336166382\n",
      "  time_total_s: 679.9433543682098\n",
      "  timers:\n",
      "    learn_throughput: 749.916\n",
      "    learn_time_ms: 5333.934\n",
      "    load_throughput: 10025825.266\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 342.035\n",
      "    sample_time_ms: 11694.717\n",
      "    update_time_ms: 2.394\n",
      "  timestamp: 1641871892\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 228000\n",
      "  training_iteration: 57\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 228000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-31-33\n",
      "  done: false\n",
      "  episode_len_mean: 455.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.73267346610191\n",
      "  episode_reward_mean: -109.70004425197963\n",
      "  episode_reward_min: -133.88067029833795\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 392\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.775557602921922e-18\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659595489501953\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.3050233721733093e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003146065166220069\n",
      "          total_loss: 453.7828369140625\n",
      "          vf_explained_var: -0.0001192603085655719\n",
      "          vf_loss: 453.7796936035156\n",
      "    num_agent_steps_sampled: 228000\n",
      "    num_agent_steps_trained: 228000\n",
      "    num_steps_sampled: 228000\n",
      "    num_steps_trained: 228000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.9\n",
      "    ram_util_percent: 51.06875\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12342271626687991\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4908879933399781\n",
      "    mean_inference_ms: 2.53732242127873\n",
      "    mean_raw_obs_processing_ms: 0.11352431784580695\n",
      "  time_since_restore: 680.8748579025269\n",
      "  time_this_iter_s: 11.750573635101318\n",
      "  time_total_s: 680.8748579025269\n",
      "  timers:\n",
      "    learn_throughput: 763.216\n",
      "    learn_time_ms: 5240.983\n",
      "    load_throughput: 10027622.975\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 341.568\n",
      "    sample_time_ms: 11710.711\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871893\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 228000\n",
      "  training_iteration: 57\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:31:33 (running for 00:11:37.22)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         679.943</td><td style=\"text-align: right;\">228000</td><td style=\"text-align: right;\"> -51.6977</td><td style=\"text-align: right;\">             27.8163</td><td style=\"text-align: right;\">            -137.62 </td><td style=\"text-align: right;\">           1403.17</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         680.875</td><td style=\"text-align: right;\">228000</td><td style=\"text-align: right;\">-109.7   </td><td style=\"text-align: right;\">            -96.7327</td><td style=\"text-align: right;\">            -133.881</td><td style=\"text-align: right;\">            455.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:31:38 (running for 00:11:42.27)<br>Memory usage on this node: 12.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         679.943</td><td style=\"text-align: right;\">228000</td><td style=\"text-align: right;\"> -51.6977</td><td style=\"text-align: right;\">             27.8163</td><td style=\"text-align: right;\">            -137.62 </td><td style=\"text-align: right;\">           1403.17</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         680.875</td><td style=\"text-align: right;\">228000</td><td style=\"text-align: right;\">-109.7   </td><td style=\"text-align: right;\">            -96.7327</td><td style=\"text-align: right;\">            -133.881</td><td style=\"text-align: right;\">            455.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:31:43 (running for 00:11:47.33)<br>Memory usage on this node: 11.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         679.943</td><td style=\"text-align: right;\">228000</td><td style=\"text-align: right;\"> -51.6977</td><td style=\"text-align: right;\">             27.8163</td><td style=\"text-align: right;\">            -137.62 </td><td style=\"text-align: right;\">           1403.17</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         680.875</td><td style=\"text-align: right;\">228000</td><td style=\"text-align: right;\">-109.7   </td><td style=\"text-align: right;\">            -96.7327</td><td style=\"text-align: right;\">            -133.881</td><td style=\"text-align: right;\">            455.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 232000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-31-44\n",
      "  done: false\n",
      "  episode_len_mean: 1433.99\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 39.46235310880405\n",
      "  episode_reward_mean: -48.72448060796318\n",
      "  episode_reward_min: -137.61958789929062\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 245\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 4.104129791259766\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010097919031977654\n",
      "          model: {}\n",
      "          policy_loss: -0.024078574031591415\n",
      "          total_loss: 2.0172243118286133\n",
      "          vf_explained_var: 0.5471456050872803\n",
      "          vf_loss: 2.0361907482147217\n",
      "    num_agent_steps_sampled: 232000\n",
      "    num_agent_steps_trained: 232000\n",
      "    num_steps_sampled: 232000\n",
      "    num_steps_trained: 232000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.456250000000004\n",
      "    ram_util_percent: 50.65625\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12330939590193253\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4955643163047647\n",
      "    mean_inference_ms: 2.508003225110427\n",
      "    mean_raw_obs_processing_ms: 0.111354219455222\n",
      "  time_since_restore: 691.8525035381317\n",
      "  time_this_iter_s: 11.909149169921875\n",
      "  time_total_s: 691.8525035381317\n",
      "  timers:\n",
      "    learn_throughput: 746.524\n",
      "    learn_time_ms: 5358.169\n",
      "    load_throughput: 10025825.266\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 341.806\n",
      "    sample_time_ms: 11702.531\n",
      "    update_time_ms: 2.394\n",
      "  timestamp: 1641871904\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 232000\n",
      "  training_iteration: 58\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 232000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-31-45\n",
      "  done: false\n",
      "  episode_len_mean: 454.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -98.87792498319223\n",
      "  episode_reward_mean: -110.70460158059568\n",
      "  episode_reward_min: -215.807228654813\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 402\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.387778801460961e-18\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.660022735595703\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.7721716833184473e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0037155235186219215\n",
      "          total_loss: 749.8491821289062\n",
      "          vf_explained_var: 0.00039988872595131397\n",
      "          vf_loss: 749.845458984375\n",
      "    num_agent_steps_sampled: 232000\n",
      "    num_agent_steps_trained: 232000\n",
      "    num_steps_sampled: 232000\n",
      "    num_steps_trained: 232000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.42222222222222\n",
      "    ram_util_percent: 50.50555555555556\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12341907331626832\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4903788859448933\n",
      "    mean_inference_ms: 2.5365271813535712\n",
      "    mean_raw_obs_processing_ms: 0.113506508149243\n",
      "  time_since_restore: 693.0552823543549\n",
      "  time_this_iter_s: 12.180424451828003\n",
      "  time_total_s: 693.0552823543549\n",
      "  timers:\n",
      "    learn_throughput: 759.012\n",
      "    learn_time_ms: 5270.006\n",
      "    load_throughput: 10027622.975\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 340.789\n",
      "    sample_time_ms: 11737.483\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871905\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 232000\n",
      "  training_iteration: 58\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:31:48 (running for 00:11:52.44)<br>Memory usage on this node: 11.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         691.853</td><td style=\"text-align: right;\">232000</td><td style=\"text-align: right;\"> -48.7245</td><td style=\"text-align: right;\">             39.4624</td><td style=\"text-align: right;\">            -137.62 </td><td style=\"text-align: right;\">           1433.99</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         693.055</td><td style=\"text-align: right;\">232000</td><td style=\"text-align: right;\">-110.705 </td><td style=\"text-align: right;\">            -98.8779</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            454.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:31:53 (running for 00:11:57.50)<br>Memory usage on this node: 11.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         691.853</td><td style=\"text-align: right;\">232000</td><td style=\"text-align: right;\"> -48.7245</td><td style=\"text-align: right;\">             39.4624</td><td style=\"text-align: right;\">            -137.62 </td><td style=\"text-align: right;\">           1433.99</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         693.055</td><td style=\"text-align: right;\">232000</td><td style=\"text-align: right;\">-110.705 </td><td style=\"text-align: right;\">            -98.8779</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            454.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 236000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-31-56\n",
      "  done: false\n",
      "  episode_len_mean: 1463.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 39.46235310880405\n",
      "  episode_reward_mean: -44.56326357752918\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 248\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 4.124948024749756\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011027020402252674\n",
      "          model: {}\n",
      "          policy_loss: -0.02402718923985958\n",
      "          total_loss: 1.3918448686599731\n",
      "          vf_explained_var: 0.6314877271652222\n",
      "          vf_loss: 1.4102896451950073\n",
      "    num_agent_steps_sampled: 236000\n",
      "    num_agent_steps_trained: 236000\n",
      "    num_steps_sampled: 236000\n",
      "    num_steps_trained: 236000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.18235294117647\n",
      "    ram_util_percent: 49.92941176470588\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12323444115886749\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4952695113803807\n",
      "    mean_inference_ms: 2.5057722402176865\n",
      "    mean_raw_obs_processing_ms: 0.11117101498742615\n",
      "  time_since_restore: 703.7427041530609\n",
      "  time_this_iter_s: 11.8902006149292\n",
      "  time_total_s: 703.7427041530609\n",
      "  timers:\n",
      "    learn_throughput: 746.19\n",
      "    learn_time_ms: 5360.563\n",
      "    load_throughput: 10025825.266\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 340.869\n",
      "    sample_time_ms: 11734.724\n",
      "    update_time_ms: 2.394\n",
      "  timestamp: 1641871916\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 236000\n",
      "  training_iteration: 59\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 236000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-31-57\n",
      "  done: false\n",
      "  episode_len_mean: 417.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -98.87792498319223\n",
      "  episode_reward_mean: -111.37254661577384\n",
      "  episode_reward_min: -215.807228654813\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 412\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 6.938894007304805e-19\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659534454345703\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.5198382641301578e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0037904991768300533\n",
      "          total_loss: 909.6409301757812\n",
      "          vf_explained_var: -0.00028580293292179704\n",
      "          vf_loss: 909.6370849609375\n",
      "    num_agent_steps_sampled: 236000\n",
      "    num_agent_steps_trained: 236000\n",
      "    num_steps_sampled: 236000\n",
      "    num_steps_trained: 236000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.1235294117647\n",
      "    ram_util_percent: 49.917647058823526\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12336553613006142\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4901340251803369\n",
      "    mean_inference_ms: 2.535157423107652\n",
      "    mean_raw_obs_processing_ms: 0.11348515308466986\n",
      "  time_since_restore: 705.0342438220978\n",
      "  time_this_iter_s: 11.97896146774292\n",
      "  time_total_s: 705.0342438220978\n",
      "  timers:\n",
      "    learn_throughput: 757.221\n",
      "    learn_time_ms: 5282.472\n",
      "    load_throughput: 13368299.602\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 339.765\n",
      "    sample_time_ms: 11772.85\n",
      "    update_time_ms: 2.095\n",
      "  timestamp: 1641871917\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 236000\n",
      "  training_iteration: 59\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:31:59 (running for 00:12:03.44)<br>Memory usage on this node: 11.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         703.743</td><td style=\"text-align: right;\">236000</td><td style=\"text-align: right;\"> -44.5633</td><td style=\"text-align: right;\">             39.4624</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1463.54</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         705.034</td><td style=\"text-align: right;\">236000</td><td style=\"text-align: right;\">-111.373 </td><td style=\"text-align: right;\">            -98.8779</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            417.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:32:04 (running for 00:12:08.50)<br>Memory usage on this node: 11.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         703.743</td><td style=\"text-align: right;\">236000</td><td style=\"text-align: right;\"> -44.5633</td><td style=\"text-align: right;\">             39.4624</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1463.54</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         705.034</td><td style=\"text-align: right;\">236000</td><td style=\"text-align: right;\">-111.373 </td><td style=\"text-align: right;\">            -98.8779</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            417.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 240000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-32-08\n",
      "  done: false\n",
      "  episode_len_mean: 1479.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 43.132318359820175\n",
      "  episode_reward_mean: -41.63958909575238\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 250\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 4.041848182678223\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016593025997281075\n",
      "          model: {}\n",
      "          policy_loss: -0.023464694619178772\n",
      "          total_loss: 1.7086695432662964\n",
      "          vf_explained_var: 0.4862726330757141\n",
      "          vf_loss: 1.723733901977539\n",
      "    num_agent_steps_sampled: 240000\n",
      "    num_agent_steps_trained: 240000\n",
      "    num_steps_sampled: 240000\n",
      "    num_steps_trained: 240000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.20588235294117\n",
      "    ram_util_percent: 49.95882352941177\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12319058505804044\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4950476489724067\n",
      "    mean_inference_ms: 2.5040216818423513\n",
      "    mean_raw_obs_processing_ms: 0.11103139309505951\n",
      "  time_since_restore: 715.6269202232361\n",
      "  time_this_iter_s: 11.884216070175171\n",
      "  time_total_s: 715.6269202232361\n",
      "  timers:\n",
      "    learn_throughput: 744.528\n",
      "    learn_time_ms: 5372.531\n",
      "    load_throughput: 13365104.756\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 340.56\n",
      "    sample_time_ms: 11745.353\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641871928\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 240000\n",
      "  training_iteration: 60\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 240000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-32-09\n",
      "  done: false\n",
      "  episode_len_mean: 402.83\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -91.70684484250907\n",
      "  episode_reward_mean: -111.0770076536568\n",
      "  episode_reward_min: -215.807228654813\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 419\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.4694470036524025e-19\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659926414489746\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.1661411153672816e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0036851107142865658\n",
      "          total_loss: 487.916748046875\n",
      "          vf_explained_var: 0.00011047118459828198\n",
      "          vf_loss: 487.91302490234375\n",
      "    num_agent_steps_sampled: 240000\n",
      "    num_agent_steps_trained: 240000\n",
      "    num_steps_sampled: 240000\n",
      "    num_steps_trained: 240000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.800000000000004\n",
      "    ram_util_percent: 49.98125\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1233533221804966\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4900307171420147\n",
      "    mean_inference_ms: 2.5343034225496526\n",
      "    mean_raw_obs_processing_ms: 0.11350689472846401\n",
      "  time_since_restore: 716.8865435123444\n",
      "  time_this_iter_s: 11.852299690246582\n",
      "  time_total_s: 716.8865435123444\n",
      "  timers:\n",
      "    learn_throughput: 757.836\n",
      "    learn_time_ms: 5278.184\n",
      "    load_throughput: 13368299.602\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 338.865\n",
      "    sample_time_ms: 11804.103\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871929\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 240000\n",
      "  training_iteration: 60\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:32:10 (running for 00:12:14.31)<br>Memory usage on this node: 11.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         715.627</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -41.6396</td><td style=\"text-align: right;\">             43.1323</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1479.03</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         716.887</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">-111.077 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            402.83</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:32:15 (running for 00:12:19.35)<br>Memory usage on this node: 11.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         715.627</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -41.6396</td><td style=\"text-align: right;\">             43.1323</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1479.03</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         716.887</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">-111.077 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            402.83</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 244000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-32-20\n",
      "  done: false\n",
      "  episode_len_mean: 1494.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 49.18886661327945\n",
      "  episode_reward_mean: -37.27490743855366\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 253\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 3.7985284328460693\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011519186198711395\n",
      "          model: {}\n",
      "          policy_loss: -0.020905278623104095\n",
      "          total_loss: 2.2015748023986816\n",
      "          vf_explained_var: 0.4453141987323761\n",
      "          vf_loss: 2.2166483402252197\n",
      "    num_agent_steps_sampled: 244000\n",
      "    num_agent_steps_trained: 244000\n",
      "    num_steps_sampled: 244000\n",
      "    num_steps_trained: 244000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.22222222222222\n",
      "    ram_util_percent: 50.03333333333333\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12311072445382135\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4947439295763391\n",
      "    mean_inference_ms: 2.5016484339997\n",
      "    mean_raw_obs_processing_ms: 0.11085407561028339\n",
      "  time_since_restore: 727.9828746318817\n",
      "  time_this_iter_s: 12.35595440864563\n",
      "  time_total_s: 727.9828746318817\n",
      "  timers:\n",
      "    learn_throughput: 738.618\n",
      "    learn_time_ms: 5415.516\n",
      "    load_throughput: 13368299.602\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 339.301\n",
      "    sample_time_ms: 11788.957\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871940\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 244000\n",
      "  training_iteration: 61\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:32:20 (running for 00:12:24.39)<br>Memory usage on this node: 11.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         727.983</td><td style=\"text-align: right;\">244000</td><td style=\"text-align: right;\"> -37.2749</td><td style=\"text-align: right;\">             49.1889</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1494.35</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         716.887</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">-111.077 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            402.83</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 244000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-32-22\n",
      "  done: false\n",
      "  episode_len_mean: 433.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -91.70684484250907\n",
      "  episode_reward_mean: -111.27984437749754\n",
      "  episode_reward_min: -215.807228654813\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 422\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.7347235018262012e-19\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.660828590393066\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.3727594705414958e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.004273613914847374\n",
      "          total_loss: 64.9225082397461\n",
      "          vf_explained_var: -0.00012021775910397992\n",
      "          vf_loss: 64.9182357788086\n",
      "    num_agent_steps_sampled: 244000\n",
      "    num_agent_steps_trained: 244000\n",
      "    num_steps_sampled: 244000\n",
      "    num_steps_trained: 244000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.40000000000001\n",
      "    ram_util_percent: 50.06666666666667\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12336507256106743\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.48997041734064356\n",
      "    mean_inference_ms: 2.5341294139852284\n",
      "    mean_raw_obs_processing_ms: 0.11351844306075944\n",
      "  time_since_restore: 729.4489464759827\n",
      "  time_this_iter_s: 12.562402963638306\n",
      "  time_total_s: 729.4489464759827\n",
      "  timers:\n",
      "    learn_throughput: 751.982\n",
      "    learn_time_ms: 5319.274\n",
      "    load_throughput: 10027023.667\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 337.503\n",
      "    sample_time_ms: 11851.736\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871942\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 244000\n",
      "  training_iteration: 61\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:32:26 (running for 00:12:29.93)<br>Memory usage on this node: 11.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         727.983</td><td style=\"text-align: right;\">244000</td><td style=\"text-align: right;\"> -37.2749</td><td style=\"text-align: right;\">             49.1889</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1494.35</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         729.449</td><td style=\"text-align: right;\">244000</td><td style=\"text-align: right;\">-111.28  </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            433.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:32:31 (running for 00:12:34.98)<br>Memory usage on this node: 11.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         727.983</td><td style=\"text-align: right;\">244000</td><td style=\"text-align: right;\"> -37.2749</td><td style=\"text-align: right;\">             49.1889</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1494.35</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         729.449</td><td style=\"text-align: right;\">244000</td><td style=\"text-align: right;\">-111.28  </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            433.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 248000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-32-33\n",
      "  done: false\n",
      "  episode_len_mean: 1494.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 49.18886661327945\n",
      "  episode_reward_mean: -34.74106360829825\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 255\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 3.6834871768951416\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0129800233989954\n",
      "          model: {}\n",
      "          policy_loss: -0.02382483147084713\n",
      "          total_loss: 1.9410606622695923\n",
      "          vf_explained_var: 0.6011613607406616\n",
      "          vf_loss: 1.958314299583435\n",
      "    num_agent_steps_sampled: 248000\n",
      "    num_agent_steps_trained: 248000\n",
      "    num_steps_sampled: 248000\n",
      "    num_steps_trained: 248000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.705555555555556\n",
      "    ram_util_percent: 50.07222222222222\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1230601896664309\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4945772852631829\n",
      "    mean_inference_ms: 2.5003671536954037\n",
      "    mean_raw_obs_processing_ms: 0.11074814041082076\n",
      "  time_since_restore: 740.7178144454956\n",
      "  time_this_iter_s: 12.734939813613892\n",
      "  time_total_s: 740.7178144454956\n",
      "  timers:\n",
      "    learn_throughput: 730.919\n",
      "    learn_time_ms: 5472.563\n",
      "    load_throughput: 13368299.602\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 336.5\n",
      "    sample_time_ms: 11887.062\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641871953\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 248000\n",
      "  training_iteration: 62\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 248000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-32-34\n",
      "  done: false\n",
      "  episode_len_mean: 403.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -91.70684484250907\n",
      "  episode_reward_mean: -110.87923859543245\n",
      "  episode_reward_min: -215.807228654813\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 439\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8.673617509131006e-20\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.6597580909729\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.63180993442802e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0047551789321005344\n",
      "          total_loss: 1371.032470703125\n",
      "          vf_explained_var: 0.0001378488086629659\n",
      "          vf_loss: 1371.0277099609375\n",
      "    num_agent_steps_sampled: 248000\n",
      "    num_agent_steps_trained: 248000\n",
      "    num_steps_sampled: 248000\n",
      "    num_steps_trained: 248000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.766666666666666\n",
      "    ram_util_percent: 50.07222222222222\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12337727004896568\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49006805590961805\n",
      "    mean_inference_ms: 2.5327630624830304\n",
      "    mean_raw_obs_processing_ms: 0.11367212128741605\n",
      "  time_since_restore: 742.2716522216797\n",
      "  time_this_iter_s: 12.822705745697021\n",
      "  time_total_s: 742.2716522216797\n",
      "  timers:\n",
      "    learn_throughput: 743.148\n",
      "    learn_time_ms: 5382.505\n",
      "    load_throughput: 10027622.975\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 334.833\n",
      "    sample_time_ms: 11946.242\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871954\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 248000\n",
      "  training_iteration: 62\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:32:37 (running for 00:12:40.75)<br>Memory usage on this node: 11.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         740.718</td><td style=\"text-align: right;\">248000</td><td style=\"text-align: right;\"> -34.7411</td><td style=\"text-align: right;\">             49.1889</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1494.35</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         742.272</td><td style=\"text-align: right;\">248000</td><td style=\"text-align: right;\">-110.879 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            403.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:32:42 (running for 00:12:45.80)<br>Memory usage on this node: 11.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         740.718</td><td style=\"text-align: right;\">248000</td><td style=\"text-align: right;\"> -34.7411</td><td style=\"text-align: right;\">             49.1889</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1494.35</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         742.272</td><td style=\"text-align: right;\">248000</td><td style=\"text-align: right;\">-110.879 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            403.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 252000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-32-46\n",
      "  done: false\n",
      "  episode_len_mean: 1494.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 60.303134133985324\n",
      "  episode_reward_mean: -30.696565836095665\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 258\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 3.6443207263946533\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01015364471822977\n",
      "          model: {}\n",
      "          policy_loss: -0.011026308871805668\n",
      "          total_loss: 1.5921332836151123\n",
      "          vf_explained_var: 0.5547828078269958\n",
      "          vf_loss: 1.5980194807052612\n",
      "    num_agent_steps_sampled: 252000\n",
      "    num_agent_steps_trained: 252000\n",
      "    num_steps_sampled: 252000\n",
      "    num_steps_trained: 252000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.77777777777779\n",
      "    ram_util_percent: 50.13333333333334\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1229896107617901\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49438036677826136\n",
      "    mean_inference_ms: 2.4990056962820764\n",
      "    mean_raw_obs_processing_ms: 0.1106148960433117\n",
      "  time_since_restore: 753.8586690425873\n",
      "  time_this_iter_s: 13.140854597091675\n",
      "  time_total_s: 753.8586690425873\n",
      "  timers:\n",
      "    learn_throughput: 716.324\n",
      "    learn_time_ms: 5584.065\n",
      "    load_throughput: 20056444.71\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 333.79\n",
      "    sample_time_ms: 11983.574\n",
      "    update_time_ms: 2.095\n",
      "  timestamp: 1641871966\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 252000\n",
      "  training_iteration: 63\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:32:47 (running for 00:12:51.33)<br>Memory usage on this node: 12.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         753.859</td><td style=\"text-align: right;\">252000</td><td style=\"text-align: right;\"> -30.6966</td><td style=\"text-align: right;\">             60.3031</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1494.35</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         742.272</td><td style=\"text-align: right;\">248000</td><td style=\"text-align: right;\">-110.879 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            403.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 252000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-32-48\n",
      "  done: false\n",
      "  episode_len_mean: 416.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -91.70684484250907\n",
      "  episode_reward_mean: -111.17700947572907\n",
      "  episode_reward_min: -215.807228654813\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 449\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.336808754565503e-20\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.660027027130127\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.8353038910845498e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003558308118954301\n",
      "          total_loss: 632.1070556640625\n",
      "          vf_explained_var: 8.012415491975844e-05\n",
      "          vf_loss: 632.103515625\n",
      "    num_agent_steps_sampled: 252000\n",
      "    num_agent_steps_trained: 252000\n",
      "    num_steps_sampled: 252000\n",
      "    num_steps_trained: 252000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.07368421052631\n",
      "    ram_util_percent: 50.12105263157895\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12348155403321542\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49000044443529683\n",
      "    mean_inference_ms: 2.5331830180030583\n",
      "    mean_raw_obs_processing_ms: 0.11371701153307859\n",
      "  time_since_restore: 755.4344477653503\n",
      "  time_this_iter_s: 13.162795543670654\n",
      "  time_total_s: 755.4344477653503\n",
      "  timers:\n",
      "    learn_throughput: 728.82\n",
      "    learn_time_ms: 5488.322\n",
      "    load_throughput: 8022386.076\n",
      "    load_time_ms: 0.499\n",
      "    sample_throughput: 331.664\n",
      "    sample_time_ms: 12060.409\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641871968\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 252000\n",
      "  training_iteration: 63\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:32:53 (running for 00:12:56.98)<br>Memory usage on this node: 12.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         753.859</td><td style=\"text-align: right;\">252000</td><td style=\"text-align: right;\"> -30.6966</td><td style=\"text-align: right;\">             60.3031</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1494.35</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         755.434</td><td style=\"text-align: right;\">252000</td><td style=\"text-align: right;\">-111.177 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            416.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:32:58 (running for 00:13:02.02)<br>Memory usage on this node: 12.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         753.859</td><td style=\"text-align: right;\">252000</td><td style=\"text-align: right;\"> -30.6966</td><td style=\"text-align: right;\">             60.3031</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1494.35</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         755.434</td><td style=\"text-align: right;\">252000</td><td style=\"text-align: right;\">-111.177 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            416.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 256000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-33-00\n",
      "  done: false\n",
      "  episode_len_mean: 1509.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 60.303134133985324\n",
      "  episode_reward_mean: -27.78471583019547\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 260\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 3.6376874446868896\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010841982439160347\n",
      "          model: {}\n",
      "          policy_loss: -0.022181179374456406\n",
      "          total_loss: 1.7377992868423462\n",
      "          vf_explained_var: 0.5301246643066406\n",
      "          vf_loss: 1.7544916868209839\n",
      "    num_agent_steps_sampled: 256000\n",
      "    num_agent_steps_trained: 256000\n",
      "    num_steps_sampled: 256000\n",
      "    num_steps_trained: 256000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.24000000000001\n",
      "    ram_util_percent: 50.415\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12296209539849419\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49425994064009565\n",
      "    mean_inference_ms: 2.4980682464356647\n",
      "    mean_raw_obs_processing_ms: 0.1105265926773264\n",
      "  time_since_restore: 767.7664730548859\n",
      "  time_this_iter_s: 13.907804012298584\n",
      "  time_total_s: 767.7664730548859\n",
      "  timers:\n",
      "    learn_throughput: 703.471\n",
      "    learn_time_ms: 5686.092\n",
      "    load_throughput: 13369364.89\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 327.615\n",
      "    sample_time_ms: 12209.451\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871980\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 256000\n",
      "  training_iteration: 64\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 256000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-33-02\n",
      "  done: false\n",
      "  episode_len_mean: 447.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -91.70684484250907\n",
      "  episode_reward_mean: -111.08256927083518\n",
      "  episode_reward_min: -215.807228654813\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 457\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.1684043772827515e-20\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.660034656524658\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.7656648765296268e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0031424497719854116\n",
      "          total_loss: 454.7289123535156\n",
      "          vf_explained_var: 0.00047344411723315716\n",
      "          vf_loss: 454.72576904296875\n",
      "    num_agent_steps_sampled: 256000\n",
      "    num_agent_steps_trained: 256000\n",
      "    num_steps_sampled: 256000\n",
      "    num_steps_trained: 256000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.05263157894737\n",
      "    ram_util_percent: 50.42631578947368\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12363928352819306\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.48995832586850857\n",
      "    mean_inference_ms: 2.534399285941636\n",
      "    mean_raw_obs_processing_ms: 0.11374572342801048\n",
      "  time_since_restore: 769.3193125724792\n",
      "  time_this_iter_s: 13.884864807128906\n",
      "  time_total_s: 769.3193125724792\n",
      "  timers:\n",
      "    learn_throughput: 715.621\n",
      "    learn_time_ms: 5589.551\n",
      "    load_throughput: 8022386.076\n",
      "    load_time_ms: 0.499\n",
      "    sample_throughput: 325.607\n",
      "    sample_time_ms: 12284.739\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871982\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 256000\n",
      "  training_iteration: 64\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:33:04 (running for 00:13:07.85)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         767.766</td><td style=\"text-align: right;\">256000</td><td style=\"text-align: right;\"> -27.7847</td><td style=\"text-align: right;\">             60.3031</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1509.7 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         769.319</td><td style=\"text-align: right;\">256000</td><td style=\"text-align: right;\">-111.083 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            447.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:33:09 (running for 00:13:12.89)<br>Memory usage on this node: 12.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         767.766</td><td style=\"text-align: right;\">256000</td><td style=\"text-align: right;\"> -27.7847</td><td style=\"text-align: right;\">             60.3031</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1509.7 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         769.319</td><td style=\"text-align: right;\">256000</td><td style=\"text-align: right;\">-111.083 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            447.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 260000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-33-13\n",
      "  done: false\n",
      "  episode_len_mean: 1509.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 69.99805062432466\n",
      "  episode_reward_mean: -23.294140215825156\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 263\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 3.2870049476623535\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011933066882193089\n",
      "          model: {}\n",
      "          policy_loss: -0.019378433004021645\n",
      "          total_loss: 2.511739730834961\n",
      "          vf_explained_var: 0.5470580458641052\n",
      "          vf_loss: 2.5250771045684814\n",
      "    num_agent_steps_sampled: 260000\n",
      "    num_agent_steps_trained: 260000\n",
      "    num_steps_sampled: 260000\n",
      "    num_steps_trained: 260000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.1611111111111\n",
      "    ram_util_percent: 50.44444444444444\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12292502674131167\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4941325042494028\n",
      "    mean_inference_ms: 2.496927394937168\n",
      "    mean_raw_obs_processing_ms: 0.1104075219538253\n",
      "  time_since_restore: 780.7587258815765\n",
      "  time_this_iter_s: 12.992252826690674\n",
      "  time_total_s: 780.7587258815765\n",
      "  timers:\n",
      "    learn_throughput: 697.658\n",
      "    learn_time_ms: 5733.466\n",
      "    load_throughput: 13369364.89\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 322.499\n",
      "    sample_time_ms: 12403.147\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871993\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 260000\n",
      "  training_iteration: 65\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:33:14 (running for 00:13:18.29)<br>Memory usage on this node: 12.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         780.759</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\"> -23.2941</td><td style=\"text-align: right;\">             69.9981</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1509.7 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         769.319</td><td style=\"text-align: right;\">256000</td><td style=\"text-align: right;\">-111.083 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            447.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 260000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-33-15\n",
      "  done: false\n",
      "  episode_len_mean: 417.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -91.70684484250907\n",
      "  episode_reward_mean: -110.79155217507456\n",
      "  episode_reward_min: -215.807228654813\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 466\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0842021886413758e-20\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659718036651611\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 4.5060491515869217e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0036629021633416414\n",
      "          total_loss: 684.9227294921875\n",
      "          vf_explained_var: 0.00028075408772565424\n",
      "          vf_loss: 684.9190673828125\n",
      "    num_agent_steps_sampled: 260000\n",
      "    num_agent_steps_trained: 260000\n",
      "    num_steps_sampled: 260000\n",
      "    num_steps_trained: 260000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.72631578947369\n",
      "    ram_util_percent: 50.45789473684211\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12381356659703714\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4900814246680247\n",
      "    mean_inference_ms: 2.535680699238744\n",
      "    mean_raw_obs_processing_ms: 0.11382056156249185\n",
      "  time_since_restore: 782.278653383255\n",
      "  time_this_iter_s: 12.959340810775757\n",
      "  time_total_s: 782.278653383255\n",
      "  timers:\n",
      "    learn_throughput: 708.166\n",
      "    learn_time_ms: 5648.394\n",
      "    load_throughput: 10028222.355\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 321.073\n",
      "    sample_time_ms: 12458.207\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641871995\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 260000\n",
      "  training_iteration: 65\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:33:20 (running for 00:13:23.87)<br>Memory usage on this node: 12.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         780.759</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\"> -23.2941</td><td style=\"text-align: right;\">             69.9981</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">            1509.7</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         782.279</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\">-110.792 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">             417.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:33:25 (running for 00:13:28.93)<br>Memory usage on this node: 12.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         780.759</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\"> -23.2941</td><td style=\"text-align: right;\">             69.9981</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">            1509.7</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         782.279</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\">-110.792 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">             417.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 264000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-33-26\n",
      "  done: false\n",
      "  episode_len_mean: 1509.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 75.34227164018958\n",
      "  episode_reward_mean: -20.28110894181339\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 265\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 3.1205854415893555\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012170068919658661\n",
      "          model: {}\n",
      "          policy_loss: -0.027786409482359886\n",
      "          total_loss: 1.718011498451233\n",
      "          vf_explained_var: 0.5893537402153015\n",
      "          vf_loss: 1.7396368980407715\n",
      "    num_agent_steps_sampled: 264000\n",
      "    num_agent_steps_trained: 264000\n",
      "    num_steps_sampled: 264000\n",
      "    num_steps_trained: 264000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.611111111111114\n",
      "    ram_util_percent: 50.37777777777777\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1229078091157712\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49400212368448204\n",
      "    mean_inference_ms: 2.4959193390795567\n",
      "    mean_raw_obs_processing_ms: 0.1103199481905014\n",
      "  time_since_restore: 793.5884132385254\n",
      "  time_this_iter_s: 12.829687356948853\n",
      "  time_total_s: 793.5884132385254\n",
      "  timers:\n",
      "    learn_throughput: 690.666\n",
      "    learn_time_ms: 5791.51\n",
      "    load_throughput: 13369364.89\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 319.561\n",
      "    sample_time_ms: 12517.156\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641872006\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 264000\n",
      "  training_iteration: 66\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 264000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-33-27\n",
      "  done: false\n",
      "  episode_len_mean: 464.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -91.70684484250907\n",
      "  episode_reward_mean: -110.62935263039287\n",
      "  episode_reward_min: -215.807228654813\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 476\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 5.421010943206879e-21\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.660125255584717\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.8073941987495346e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003762779990211129\n",
      "          total_loss: 683.0821533203125\n",
      "          vf_explained_var: 0.0002470989420544356\n",
      "          vf_loss: 683.078369140625\n",
      "    num_agent_steps_sampled: 264000\n",
      "    num_agent_steps_trained: 264000\n",
      "    num_steps_sampled: 264000\n",
      "    num_steps_trained: 264000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.766666666666666\n",
      "    ram_util_percent: 50.41111111111111\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12390236073061846\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4906946910317063\n",
      "    mean_inference_ms: 2.5360571819684896\n",
      "    mean_raw_obs_processing_ms: 0.11392352193991875\n",
      "  time_since_restore: 795.1023573875427\n",
      "  time_this_iter_s: 12.82370400428772\n",
      "  time_total_s: 795.1023573875427\n",
      "  timers:\n",
      "    learn_throughput: 702.128\n",
      "    learn_time_ms: 5696.964\n",
      "    load_throughput: 10028222.355\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 318.064\n",
      "    sample_time_ms: 12576.072\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872007\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 264000\n",
      "  training_iteration: 66\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:33:30 (running for 00:13:34.71)<br>Memory usage on this node: 12.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         793.588</td><td style=\"text-align: right;\">264000</td><td style=\"text-align: right;\"> -20.2811</td><td style=\"text-align: right;\">             75.3423</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">            1509.7</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         795.102</td><td style=\"text-align: right;\">264000</td><td style=\"text-align: right;\">-110.629 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">             464.7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:33:36 (running for 00:13:39.75)<br>Memory usage on this node: 12.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         793.588</td><td style=\"text-align: right;\">264000</td><td style=\"text-align: right;\"> -20.2811</td><td style=\"text-align: right;\">             75.3423</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">            1509.7</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         795.102</td><td style=\"text-align: right;\">264000</td><td style=\"text-align: right;\">-110.629 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">             464.7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 268000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-33-39\n",
      "  done: false\n",
      "  episode_len_mean: 1525.12\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 75.34227164018958\n",
      "  episode_reward_mean: -15.318050597096722\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 268\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 3.1189656257629395\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012239896692335606\n",
      "          model: {}\n",
      "          policy_loss: -0.024932002648711205\n",
      "          total_loss: 1.7790700197219849\n",
      "          vf_explained_var: 0.5330806970596313\n",
      "          vf_loss: 1.7978055477142334\n",
      "    num_agent_steps_sampled: 268000\n",
      "    num_agent_steps_trained: 268000\n",
      "    num_steps_sampled: 268000\n",
      "    num_steps_trained: 268000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.51052631578948\n",
      "    ram_util_percent: 50.473684210526315\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12289955659910128\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4938877827144553\n",
      "    mean_inference_ms: 2.4951411493934232\n",
      "    mean_raw_obs_processing_ms: 0.11021649602772256\n",
      "  time_since_restore: 806.5956268310547\n",
      "  time_this_iter_s: 13.007213592529297\n",
      "  time_total_s: 806.5956268310547\n",
      "  timers:\n",
      "    learn_throughput: 684.011\n",
      "    learn_time_ms: 5847.86\n",
      "    load_throughput: 13368299.602\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 316.518\n",
      "    sample_time_ms: 12637.498\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872019\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 268000\n",
      "  training_iteration: 67\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 268000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-33-40\n",
      "  done: false\n",
      "  episode_len_mean: 433.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -91.70684484250907\n",
      "  episode_reward_mean: -111.26850698619029\n",
      "  episode_reward_min: -215.807228654813\n",
      "  episodes_this_iter: 13\n",
      "  episodes_total: 489\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.7105054716034394e-21\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.660220146179199\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.9556949243669806e-07\n",
      "          model: {}\n",
      "          policy_loss: -0.01039188914000988\n",
      "          total_loss: 850.1218872070312\n",
      "          vf_explained_var: 5.211246752878651e-05\n",
      "          vf_loss: 850.1322631835938\n",
      "    num_agent_steps_sampled: 268000\n",
      "    num_agent_steps_trained: 268000\n",
      "    num_steps_sampled: 268000\n",
      "    num_steps_trained: 268000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.75555555555555\n",
      "    ram_util_percent: 50.47222222222222\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1241009593314239\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49139457596266156\n",
      "    mean_inference_ms: 2.537666351930626\n",
      "    mean_raw_obs_processing_ms: 0.11410622622739322\n",
      "  time_since_restore: 808.0656871795654\n",
      "  time_this_iter_s: 12.963329792022705\n",
      "  time_total_s: 808.0656871795654\n",
      "  timers:\n",
      "    learn_throughput: 694.265\n",
      "    learn_time_ms: 5761.491\n",
      "    load_throughput: 10027023.667\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 315.42\n",
      "    sample_time_ms: 12681.493\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872020\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 268000\n",
      "  training_iteration: 67\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:33:41 (running for 00:13:45.67)<br>Memory usage on this node: 12.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         806.596</td><td style=\"text-align: right;\">268000</td><td style=\"text-align: right;\"> -15.3181</td><td style=\"text-align: right;\">             75.3423</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1525.12</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         808.066</td><td style=\"text-align: right;\">268000</td><td style=\"text-align: right;\">-111.269 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            433.26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:33:46 (running for 00:13:50.71)<br>Memory usage on this node: 12.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         806.596</td><td style=\"text-align: right;\">268000</td><td style=\"text-align: right;\"> -15.3181</td><td style=\"text-align: right;\">             75.3423</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1525.12</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         808.066</td><td style=\"text-align: right;\">268000</td><td style=\"text-align: right;\">-111.269 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            433.26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:33:52 (running for 00:13:55.77)<br>Memory usage on this node: 12.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         806.596</td><td style=\"text-align: right;\">268000</td><td style=\"text-align: right;\"> -15.3181</td><td style=\"text-align: right;\">             75.3423</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1525.12</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         808.066</td><td style=\"text-align: right;\">268000</td><td style=\"text-align: right;\">-111.269 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -215.807</td><td style=\"text-align: right;\">            433.26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 272000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-33-52\n",
      "  done: false\n",
      "  episode_len_mean: 1525.12\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 75.34227164018958\n",
      "  episode_reward_mean: -12.37032304756124\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 270\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 3.129807233810425\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012875248678028584\n",
      "          model: {}\n",
      "          policy_loss: -0.020117368549108505\n",
      "          total_loss: 2.025639772415161\n",
      "          vf_explained_var: 0.6313477754592896\n",
      "          vf_loss: 2.0392391681671143\n",
      "    num_agent_steps_sampled: 272000\n",
      "    num_agent_steps_trained: 272000\n",
      "    num_steps_sampled: 272000\n",
      "    num_steps_trained: 272000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.0235294117647\n",
      "    ram_util_percent: 50.51176470588235\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12290103304256564\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4938276362352208\n",
      "    mean_inference_ms: 2.4947429684492786\n",
      "    mean_raw_obs_processing_ms: 0.1101575680555614\n",
      "  time_since_restore: 819.321592092514\n",
      "  time_this_iter_s: 12.72596526145935\n",
      "  time_total_s: 819.321592092514\n",
      "  timers:\n",
      "    learn_throughput: 680.494\n",
      "    learn_time_ms: 5878.079\n",
      "    load_throughput: 13368299.602\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 313.84\n",
      "    sample_time_ms: 12745.368\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872032\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 272000\n",
      "  training_iteration: 68\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 272000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-33-53\n",
      "  done: false\n",
      "  episode_len_mean: 408.16\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -91.70684484250907\n",
      "  episode_reward_mean: -110.34619681709364\n",
      "  episode_reward_min: -190.55963745069064\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 498\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.3552527358017197e-21\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.660198211669922\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 4.0254039390674734e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0035063240211457014\n",
      "          total_loss: 614.5029296875\n",
      "          vf_explained_var: -0.0005101624992676079\n",
      "          vf_loss: 614.4994506835938\n",
      "    num_agent_steps_sampled: 272000\n",
      "    num_agent_steps_trained: 272000\n",
      "    num_steps_sampled: 272000\n",
      "    num_steps_trained: 272000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.75\n",
      "    ram_util_percent: 50.51111111111111\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1242428692537196\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49199249308029885\n",
      "    mean_inference_ms: 2.539000276876564\n",
      "    mean_raw_obs_processing_ms: 0.11424366963234502\n",
      "  time_since_restore: 820.9163184165955\n",
      "  time_this_iter_s: 12.85063123703003\n",
      "  time_total_s: 820.9163184165955\n",
      "  timers:\n",
      "    learn_throughput: 692.598\n",
      "    learn_time_ms: 5775.354\n",
      "    load_throughput: 8022002.486\n",
      "    load_time_ms: 0.499\n",
      "    sample_throughput: 312.552\n",
      "    sample_time_ms: 12797.855\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872033\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 272000\n",
      "  training_iteration: 68\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:33:57 (running for 00:14:01.59)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         819.322</td><td style=\"text-align: right;\">272000</td><td style=\"text-align: right;\"> -12.3703</td><td style=\"text-align: right;\">             75.3423</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1525.12</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         820.916</td><td style=\"text-align: right;\">272000</td><td style=\"text-align: right;\">-110.346 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -190.56 </td><td style=\"text-align: right;\">            408.16</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:34:02 (running for 00:14:06.64)<br>Memory usage on this node: 12.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         819.322</td><td style=\"text-align: right;\">272000</td><td style=\"text-align: right;\"> -12.3703</td><td style=\"text-align: right;\">             75.3423</td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1525.12</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         820.916</td><td style=\"text-align: right;\">272000</td><td style=\"text-align: right;\">-110.346 </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -190.56 </td><td style=\"text-align: right;\">            408.16</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 276000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-34-04\n",
      "  done: false\n",
      "  episode_len_mean: 1540.43\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 90.57696599205956\n",
      "  episode_reward_mean: -7.269844776647869\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 273\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.8681137561798096\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01169997826218605\n",
      "          model: {}\n",
      "          policy_loss: -0.025432689115405083\n",
      "          total_loss: 3.302081823348999\n",
      "          vf_explained_var: 0.5489267706871033\n",
      "          vf_loss: 3.321591377258301\n",
      "    num_agent_steps_sampled: 276000\n",
      "    num_agent_steps_trained: 276000\n",
      "    num_steps_sampled: 276000\n",
      "    num_steps_trained: 276000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.63333333333334\n",
      "    ram_util_percent: 50.52777777777778\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12291412589573046\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4938127285627745\n",
      "    mean_inference_ms: 2.4946183080852515\n",
      "    mean_raw_obs_processing_ms: 0.11006968674475508\n",
      "  time_since_restore: 831.8710289001465\n",
      "  time_this_iter_s: 12.549436807632446\n",
      "  time_total_s: 831.8710289001465\n",
      "  timers:\n",
      "    learn_throughput: 675.065\n",
      "    learn_time_ms: 5925.353\n",
      "    load_throughput: 10027023.667\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 312.663\n",
      "    sample_time_ms: 12793.316\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872044\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 276000\n",
      "  training_iteration: 69\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 276000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-34-06\n",
      "  done: false\n",
      "  episode_len_mean: 432.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -91.70684484250907\n",
      "  episode_reward_mean: -111.07318066974113\n",
      "  episode_reward_min: -190.55963745069064\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 506\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 6.776263679008599e-22\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.6602582931518555\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.12530829660318e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0037989336997270584\n",
      "          total_loss: 596.8803100585938\n",
      "          vf_explained_var: 0.0010325642069801688\n",
      "          vf_loss: 596.87646484375\n",
      "    num_agent_steps_sampled: 276000\n",
      "    num_agent_steps_trained: 276000\n",
      "    num_steps_sampled: 276000\n",
      "    num_steps_trained: 276000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.18333333333333\n",
      "    ram_util_percent: 50.516666666666666\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1243284852605362\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4927038636753258\n",
      "    mean_inference_ms: 2.5398164085714154\n",
      "    mean_raw_obs_processing_ms: 0.11438542290412401\n",
      "  time_since_restore: 833.4168863296509\n",
      "  time_this_iter_s: 12.50056791305542\n",
      "  time_total_s: 833.4168863296509\n",
      "  timers:\n",
      "    learn_throughput: 688.839\n",
      "    learn_time_ms: 5806.87\n",
      "    load_throughput: 6685481.57\n",
      "    load_time_ms: 0.598\n",
      "    sample_throughput: 311.71\n",
      "    sample_time_ms: 12832.446\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872046\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 276000\n",
      "  training_iteration: 69\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:34:08 (running for 00:14:12.09)<br>Memory usage on this node: 12.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         831.871</td><td style=\"text-align: right;\">276000</td><td style=\"text-align: right;\">  -7.26984</td><td style=\"text-align: right;\">             90.577 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1540.43</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         833.417</td><td style=\"text-align: right;\">276000</td><td style=\"text-align: right;\">-111.073  </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -190.56 </td><td style=\"text-align: right;\">            432.9 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:34:13 (running for 00:14:17.14)<br>Memory usage on this node: 12.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         831.871</td><td style=\"text-align: right;\">276000</td><td style=\"text-align: right;\">  -7.26984</td><td style=\"text-align: right;\">             90.577 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1540.43</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         833.417</td><td style=\"text-align: right;\">276000</td><td style=\"text-align: right;\">-111.073  </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -190.56 </td><td style=\"text-align: right;\">            432.9 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 280000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-34-17\n",
      "  done: false\n",
      "  episode_len_mean: 1540.43\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 98.05904651895662\n",
      "  episode_reward_mean: -4.061106361663916\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 275\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.966331720352173\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012006410397589207\n",
      "          model: {}\n",
      "          policy_loss: -0.023574333637952805\n",
      "          total_loss: 4.438797950744629\n",
      "          vf_explained_var: 0.5066364407539368\n",
      "          vf_loss: 4.456294059753418\n",
      "    num_agent_steps_sampled: 280000\n",
      "    num_agent_steps_trained: 280000\n",
      "    num_steps_sampled: 280000\n",
      "    num_steps_trained: 280000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.19444444444443\n",
      "    ram_util_percent: 50.45\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12292430942172566\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49375462943692616\n",
      "    mean_inference_ms: 2.4943345767380234\n",
      "    mean_raw_obs_processing_ms: 0.11001395649294145\n",
      "  time_since_restore: 844.7027106285095\n",
      "  time_this_iter_s: 12.831681728363037\n",
      "  time_total_s: 844.7027106285095\n",
      "  timers:\n",
      "    learn_throughput: 670.551\n",
      "    learn_time_ms: 5965.246\n",
      "    load_throughput: 10027023.667\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 310.174\n",
      "    sample_time_ms: 12895.995\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872057\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 280000\n",
      "  training_iteration: 70\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:34:18 (running for 00:14:22.38)<br>Memory usage on this node: 12.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         844.703</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\">  -4.06111</td><td style=\"text-align: right;\">             98.059 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1540.43</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         833.417</td><td style=\"text-align: right;\">276000</td><td style=\"text-align: right;\">-111.073  </td><td style=\"text-align: right;\">            -91.7068</td><td style=\"text-align: right;\">            -190.56 </td><td style=\"text-align: right;\">            432.9 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 280000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-34-19\n",
      "  done: false\n",
      "  episode_len_mean: 422.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.59544133175287\n",
      "  episode_reward_mean: -111.13576908244323\n",
      "  episode_reward_min: -178.72150971784936\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 515\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.3881318395042993e-22\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.660462856292725\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.6382415424232022e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003873606910929084\n",
      "          total_loss: 751.1768188476562\n",
      "          vf_explained_var: -0.0001539855875307694\n",
      "          vf_loss: 751.1729736328125\n",
      "    num_agent_steps_sampled: 280000\n",
      "    num_agent_steps_trained: 280000\n",
      "    num_steps_sampled: 280000\n",
      "    num_steps_trained: 280000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.40555555555554\n",
      "    ram_util_percent: 50.455555555555556\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12447481234185818\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49339372784432056\n",
      "    mean_inference_ms: 2.5413697532575914\n",
      "    mean_raw_obs_processing_ms: 0.11458494265699073\n",
      "  time_since_restore: 846.4889259338379\n",
      "  time_this_iter_s: 13.072039604187012\n",
      "  time_total_s: 846.4889259338379\n",
      "  timers:\n",
      "    learn_throughput: 680.356\n",
      "    learn_time_ms: 5879.276\n",
      "    load_throughput: 6685481.57\n",
      "    load_time_ms: 0.598\n",
      "    sample_throughput: 309.748\n",
      "    sample_time_ms: 12913.703\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872059\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 280000\n",
      "  training_iteration: 70\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:34:24 (running for 00:14:28.22)<br>Memory usage on this node: 12.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         844.703</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\">  -4.06111</td><td style=\"text-align: right;\">             98.059 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1540.43</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         846.489</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\">-111.136  </td><td style=\"text-align: right;\">            -94.5954</td><td style=\"text-align: right;\">            -178.722</td><td style=\"text-align: right;\">            422.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:34:29 (running for 00:14:33.27)<br>Memory usage on this node: 12.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         844.703</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\">  -4.06111</td><td style=\"text-align: right;\">             98.059 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1540.43</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         846.489</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\">-111.136  </td><td style=\"text-align: right;\">            -94.5954</td><td style=\"text-align: right;\">            -178.722</td><td style=\"text-align: right;\">            422.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 284000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-34-30\n",
      "  done: false\n",
      "  episode_len_mean: 1530.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 101.06846175417688\n",
      "  episode_reward_mean: 0.628302481896291\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 279\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.788496971130371\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00856782402843237\n",
      "          model: {}\n",
      "          policy_loss: -0.012686489149928093\n",
      "          total_loss: 4.58939790725708\n",
      "          vf_explained_var: 0.6013082265853882\n",
      "          vf_loss: 4.5977463722229\n",
      "    num_agent_steps_sampled: 284000\n",
      "    num_agent_steps_trained: 284000\n",
      "    num_steps_sampled: 284000\n",
      "    num_steps_trained: 284000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.33684210526317\n",
      "    ram_util_percent: 50.426315789473676\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12294829015754764\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4935895719796794\n",
      "    mean_inference_ms: 2.4935716406619495\n",
      "    mean_raw_obs_processing_ms: 0.1099002073631279\n",
      "  time_since_restore: 857.7139127254486\n",
      "  time_this_iter_s: 13.011202096939087\n",
      "  time_total_s: 857.7139127254486\n",
      "  timers:\n",
      "    learn_throughput: 668.216\n",
      "    learn_time_ms: 5986.09\n",
      "    load_throughput: 13369364.89\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 308.157\n",
      "    sample_time_ms: 12980.402\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872070\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 284000\n",
      "  training_iteration: 71\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 284000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-34-32\n",
      "  done: false\n",
      "  episode_len_mean: 410.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.59544133175287\n",
      "  episode_reward_mean: -111.27771791707461\n",
      "  episode_reward_min: -178.72150971784936\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 522\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.6940659197521496e-22\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.660312652587891\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.1562069346382486e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0034447633661329746\n",
      "          total_loss: 488.4898376464844\n",
      "          vf_explained_var: -6.665741238975897e-05\n",
      "          vf_loss: 488.4864196777344\n",
      "    num_agent_steps_sampled: 284000\n",
      "    num_agent_steps_trained: 284000\n",
      "    num_steps_sampled: 284000\n",
      "    num_steps_trained: 284000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.66842105263157\n",
      "    ram_util_percent: 50.421052631578945\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12463314274541532\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49381271399662835\n",
      "    mean_inference_ms: 2.543135472812736\n",
      "    mean_raw_obs_processing_ms: 0.11473271203929468\n",
      "  time_since_restore: 859.5061111450195\n",
      "  time_this_iter_s: 13.01718521118164\n",
      "  time_total_s: 859.5061111450195\n",
      "  timers:\n",
      "    learn_throughput: 678.182\n",
      "    learn_time_ms: 5898.126\n",
      "    load_throughput: 6684948.799\n",
      "    load_time_ms: 0.598\n",
      "    sample_throughput: 307.383\n",
      "    sample_time_ms: 13013.102\n",
      "    update_time_ms: 2.393\n",
      "  timestamp: 1641872072\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 284000\n",
      "  training_iteration: 71\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:34:35 (running for 00:14:39.24)<br>Memory usage on this node: 11.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         857.714</td><td style=\"text-align: right;\">284000</td><td style=\"text-align: right;\">   0.628302</td><td style=\"text-align: right;\">            101.068 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         859.506</td><td style=\"text-align: right;\">284000</td><td style=\"text-align: right;\">-111.278   </td><td style=\"text-align: right;\">            -94.5954</td><td style=\"text-align: right;\">            -178.722</td><td style=\"text-align: right;\">            410.2 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:34:40 (running for 00:14:44.30)<br>Memory usage on this node: 10.4/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">     reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         857.714</td><td style=\"text-align: right;\">284000</td><td style=\"text-align: right;\">   0.628302</td><td style=\"text-align: right;\">            101.068 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         859.506</td><td style=\"text-align: right;\">284000</td><td style=\"text-align: right;\">-111.278   </td><td style=\"text-align: right;\">            -94.5954</td><td style=\"text-align: right;\">            -178.722</td><td style=\"text-align: right;\">            410.2 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 288000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-34-44\n",
      "  done: false\n",
      "  episode_len_mean: 1530.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 115.31794301471918\n",
      "  episode_reward_mean: 4.028055512871852\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 281\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.5158066749572754\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014581932686269283\n",
      "          model: {}\n",
      "          policy_loss: -0.026319319382309914\n",
      "          total_loss: 1.9654362201690674\n",
      "          vf_explained_var: 0.623293399810791\n",
      "          vf_loss: 1.9843734502792358\n",
      "    num_agent_steps_sampled: 288000\n",
      "    num_agent_steps_trained: 288000\n",
      "    num_steps_sampled: 288000\n",
      "    num_steps_trained: 288000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.8\n",
      "    ram_util_percent: 45.73684210526316\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12297138283889603\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49356267262192666\n",
      "    mean_inference_ms: 2.4934897741313202\n",
      "    mean_raw_obs_processing_ms: 0.10985564128283863\n",
      "  time_since_restore: 871.5229806900024\n",
      "  time_this_iter_s: 13.809067964553833\n",
      "  time_total_s: 871.5229806900024\n",
      "  timers:\n",
      "    learn_throughput: 662.236\n",
      "    learn_time_ms: 6040.146\n",
      "    load_throughput: 13369364.89\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 306.411\n",
      "    sample_time_ms: 13054.37\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872084\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 288000\n",
      "  training_iteration: 72\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:34:46 (running for 00:14:50.27)<br>Memory usage on this node: 9.4/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         871.523</td><td style=\"text-align: right;\">288000</td><td style=\"text-align: right;\">   4.02806</td><td style=\"text-align: right;\">            115.318 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         859.506</td><td style=\"text-align: right;\">284000</td><td style=\"text-align: right;\">-111.278  </td><td style=\"text-align: right;\">            -94.5954</td><td style=\"text-align: right;\">            -178.722</td><td style=\"text-align: right;\">            410.2 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 288000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-34-46\n",
      "  done: false\n",
      "  episode_len_mean: 425.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.59544133175287\n",
      "  episode_reward_mean: -111.10163872433179\n",
      "  episode_reward_min: -178.72150971784936\n",
      "  episodes_this_iter: 12\n",
      "  episodes_total: 534\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8.470329598760748e-23\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.660644054412842\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.533410222189559e-07\n",
      "          model: {}\n",
      "          policy_loss: -0.0064215282909572124\n",
      "          total_loss: 822.2587890625\n",
      "          vf_explained_var: -0.0003455857513472438\n",
      "          vf_loss: 822.2651977539062\n",
      "    num_agent_steps_sampled: 288000\n",
      "    num_agent_steps_trained: 288000\n",
      "    num_steps_sampled: 288000\n",
      "    num_steps_trained: 288000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.35999999999999\n",
      "    ram_util_percent: 44.13499999999999\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12485092189251212\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49480897412061464\n",
      "    mean_inference_ms: 2.5458489763613943\n",
      "    mean_raw_obs_processing_ms: 0.11501727808821478\n",
      "  time_since_restore: 873.6612539291382\n",
      "  time_this_iter_s: 14.155142784118652\n",
      "  time_total_s: 873.6612539291382\n",
      "  timers:\n",
      "    learn_throughput: 672.293\n",
      "    learn_time_ms: 5949.788\n",
      "    load_throughput: 8022386.076\n",
      "    load_time_ms: 0.499\n",
      "    sample_throughput: 305.019\n",
      "    sample_time_ms: 13113.943\n",
      "    update_time_ms: 2.393\n",
      "  timestamp: 1641872086\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 288000\n",
      "  training_iteration: 72\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:34:51 (running for 00:14:55.44)<br>Memory usage on this node: 8.7/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         871.523</td><td style=\"text-align: right;\">288000</td><td style=\"text-align: right;\">   4.02806</td><td style=\"text-align: right;\">            115.318 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         873.661</td><td style=\"text-align: right;\">288000</td><td style=\"text-align: right;\">-111.102  </td><td style=\"text-align: right;\">            -94.5954</td><td style=\"text-align: right;\">            -178.722</td><td style=\"text-align: right;\">            425.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:34:56 (running for 00:15:00.50)<br>Memory usage on this node: 8.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         871.523</td><td style=\"text-align: right;\">288000</td><td style=\"text-align: right;\">   4.02806</td><td style=\"text-align: right;\">            115.318 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         873.661</td><td style=\"text-align: right;\">288000</td><td style=\"text-align: right;\">-111.102  </td><td style=\"text-align: right;\">            -94.5954</td><td style=\"text-align: right;\">            -178.722</td><td style=\"text-align: right;\">            425.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 292000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-34-58\n",
      "  done: false\n",
      "  episode_len_mean: 1530.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 115.31794301471918\n",
      "  episode_reward_mean: 7.137510946028845\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 283\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.6224424839019775\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012842613272368908\n",
      "          model: {}\n",
      "          policy_loss: -0.030152294784784317\n",
      "          total_loss: 1.8851814270019531\n",
      "          vf_explained_var: 0.6038287878036499\n",
      "          vf_loss: 1.90883207321167\n",
      "    num_agent_steps_sampled: 292000\n",
      "    num_agent_steps_trained: 292000\n",
      "    num_steps_sampled: 292000\n",
      "    num_steps_trained: 292000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.17499999999998\n",
      "    ram_util_percent: 36.55\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12300681520954582\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4936149611098717\n",
      "    mean_inference_ms: 2.4939055246359585\n",
      "    mean_raw_obs_processing_ms: 0.10983163779560233\n",
      "  time_since_restore: 885.5724065303802\n",
      "  time_this_iter_s: 14.049425840377808\n",
      "  time_total_s: 885.5724065303802\n",
      "  timers:\n",
      "    learn_throughput: 661.864\n",
      "    learn_time_ms: 6043.537\n",
      "    load_throughput: 13369364.89\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 303.115\n",
      "    sample_time_ms: 13196.311\n",
      "    update_time_ms: 2.393\n",
      "  timestamp: 1641872098\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 292000\n",
      "  training_iteration: 73\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 292000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-35-00\n",
      "  done: false\n",
      "  episode_len_mean: 448.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.59544133175287\n",
      "  episode_reward_mean: -111.890465147335\n",
      "  episode_reward_min: -187.2602008764396\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 539\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.235164799380374e-23\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.662257671356201\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.0672083539684536e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0037806020118296146\n",
      "          total_loss: 451.4427795410156\n",
      "          vf_explained_var: 0.0003279388474766165\n",
      "          vf_loss: 451.43896484375\n",
      "    num_agent_steps_sampled: 292000\n",
      "    num_agent_steps_trained: 292000\n",
      "    num_steps_sampled: 292000\n",
      "    num_steps_trained: 292000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.4578947368421\n",
      "    ram_util_percent: 35.43684210526315\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12502014465124323\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4950583457170656\n",
      "    mean_inference_ms: 2.5478270446904165\n",
      "    mean_raw_obs_processing_ms: 0.1150937177744275\n",
      "  time_since_restore: 887.4613461494446\n",
      "  time_this_iter_s: 13.800092220306396\n",
      "  time_total_s: 887.4613461494446\n",
      "  timers:\n",
      "    learn_throughput: 672.361\n",
      "    learn_time_ms: 5949.189\n",
      "    load_throughput: 10027622.975\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 302.324\n",
      "    sample_time_ms: 13230.819\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641872100\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 292000\n",
      "  training_iteration: 73\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:35:02 (running for 00:15:06.26)<br>Memory usage on this node: 7.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         885.572</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">   7.13751</td><td style=\"text-align: right;\">            115.318 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         887.461</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">-111.89   </td><td style=\"text-align: right;\">            -94.5954</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            448.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:35:07 (running for 00:15:11.33)<br>Memory usage on this node: 7.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">    reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         885.572</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">   7.13751</td><td style=\"text-align: right;\">            115.318 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         887.461</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">-111.89   </td><td style=\"text-align: right;\">            -94.5954</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            448.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 296000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-35-11\n",
      "  done: false\n",
      "  episode_len_mean: 1530.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 115.31794301471918\n",
      "  episode_reward_mean: 10.086122580242337\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 285\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.754927396774292\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012239021249115467\n",
      "          model: {}\n",
      "          policy_loss: -0.016064178198575974\n",
      "          total_loss: 1.8357136249542236\n",
      "          vf_explained_var: 0.6148512363433838\n",
      "          vf_loss: 1.8455817699432373\n",
      "    num_agent_steps_sampled: 296000\n",
      "    num_agent_steps_trained: 296000\n",
      "    num_steps_sampled: 296000\n",
      "    num_steps_trained: 296000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.816666666666656\n",
      "    ram_util_percent: 33.05\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12304071459538143\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4936237433546992\n",
      "    mean_inference_ms: 2.4940476952274837\n",
      "    mean_raw_obs_processing_ms: 0.10980796383032469\n",
      "  time_since_restore: 898.3592081069946\n",
      "  time_this_iter_s: 12.78680157661438\n",
      "  time_total_s: 898.3592081069946\n",
      "  timers:\n",
      "    learn_throughput: 667.138\n",
      "    learn_time_ms: 5995.764\n",
      "    load_throughput: 20056444.71\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 304.525\n",
      "    sample_time_ms: 13135.222\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872111\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 296000\n",
      "  training_iteration: 74\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 296000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-35-13\n",
      "  done: false\n",
      "  episode_len_mean: 434.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.59544133175287\n",
      "  episode_reward_mean: -111.79437345217008\n",
      "  episode_reward_min: -187.2602008764396\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 545\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.117582399690187e-23\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.661304950714111\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.595691057649674e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.00390536873601377\n",
      "          total_loss: 330.6672668457031\n",
      "          vf_explained_var: 0.00014744170766789466\n",
      "          vf_loss: 330.663330078125\n",
      "    num_agent_steps_sampled: 296000\n",
      "    num_agent_steps_trained: 296000\n",
      "    num_steps_sampled: 296000\n",
      "    num_steps_trained: 296000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.91111111111112\n",
      "    ram_util_percent: 33.04444444444445\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12511247095449274\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49568058638776935\n",
      "    mean_inference_ms: 2.549218378250263\n",
      "    mean_raw_obs_processing_ms: 0.11525167800553898\n",
      "  time_since_restore: 900.1653690338135\n",
      "  time_this_iter_s: 12.704022884368896\n",
      "  time_total_s: 900.1653690338135\n",
      "  timers:\n",
      "    learn_throughput: 677.014\n",
      "    learn_time_ms: 5908.299\n",
      "    load_throughput: 10027622.975\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 304.089\n",
      "    sample_time_ms: 13154.025\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641872113\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 296000\n",
      "  training_iteration: 74\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:35:13 (running for 00:15:16.97)<br>Memory usage on this node: 7.8/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         898.359</td><td style=\"text-align: right;\">296000</td><td style=\"text-align: right;\">  10.0861</td><td style=\"text-align: right;\">            115.318 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         900.165</td><td style=\"text-align: right;\">296000</td><td style=\"text-align: right;\">-111.794 </td><td style=\"text-align: right;\">            -94.5954</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            434.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:35:18 (running for 00:15:22.03)<br>Memory usage on this node: 7.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         898.359</td><td style=\"text-align: right;\">296000</td><td style=\"text-align: right;\">  10.0861</td><td style=\"text-align: right;\">            115.318 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         900.165</td><td style=\"text-align: right;\">296000</td><td style=\"text-align: right;\">-111.794 </td><td style=\"text-align: right;\">            -94.5954</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            434.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:35:23 (running for 00:15:27.08)<br>Memory usage on this node: 7.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         898.359</td><td style=\"text-align: right;\">296000</td><td style=\"text-align: right;\">  10.0861</td><td style=\"text-align: right;\">            115.318 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         900.165</td><td style=\"text-align: right;\">296000</td><td style=\"text-align: right;\">-111.794 </td><td style=\"text-align: right;\">            -94.5954</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            434.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 300000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-35-24\n",
      "  done: false\n",
      "  episode_len_mean: 1530.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 115.31794301471918\n",
      "  episode_reward_mean: 15.967328526748975\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 289\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.461855173110962\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013643777929246426\n",
      "          model: {}\n",
      "          policy_loss: -0.017003027722239494\n",
      "          total_loss: 2.009589910507202\n",
      "          vf_explained_var: 0.6724385619163513\n",
      "          vf_loss: 2.019685745239258\n",
      "    num_agent_steps_sampled: 300000\n",
      "    num_agent_steps_trained: 300000\n",
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 300000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.73888888888889\n",
      "    ram_util_percent: 33.050000000000004\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12311105561320573\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4936034220643238\n",
      "    mean_inference_ms: 2.49420002017363\n",
      "    mean_raw_obs_processing_ms: 0.10977024177257258\n",
      "  time_since_restore: 911.1460108757019\n",
      "  time_this_iter_s: 12.786802768707275\n",
      "  time_total_s: 911.1460108757019\n",
      "  timers:\n",
      "    learn_throughput: 664.21\n",
      "    learn_time_ms: 6022.194\n",
      "    load_throughput: 20056444.71\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 306.787\n",
      "    sample_time_ms: 13038.36\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872124\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 75\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 300000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-35-25\n",
      "  done: false\n",
      "  episode_len_mean: 449.34\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -98.8260895659756\n",
      "  episode_reward_mean: -112.03728655965845\n",
      "  episode_reward_min: -187.2602008764396\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 554\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0587911998450935e-23\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.660429954528809\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.2590630521790445e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003296135226264596\n",
      "          total_loss: 688.4057006835938\n",
      "          vf_explained_var: 0.0005491407355293632\n",
      "          vf_loss: 688.4024047851562\n",
      "    num_agent_steps_sampled: 300000\n",
      "    num_agent_steps_trained: 300000\n",
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 300000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.48888888888889\n",
      "    ram_util_percent: 33.07222222222222\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1252805719747353\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4963788841770611\n",
      "    mean_inference_ms: 2.551553028221925\n",
      "    mean_raw_obs_processing_ms: 0.11544477344985608\n",
      "  time_since_restore: 912.7975859642029\n",
      "  time_this_iter_s: 12.632216930389404\n",
      "  time_total_s: 912.7975859642029\n",
      "  timers:\n",
      "    learn_throughput: 676.044\n",
      "    learn_time_ms: 5916.776\n",
      "    load_throughput: 10027622.975\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 306.008\n",
      "    sample_time_ms: 13071.573\n",
      "    update_time_ms: 1.994\n",
      "  timestamp: 1641872125\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 75\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:35:28 (running for 00:15:32.66)<br>Memory usage on this node: 7.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         911.146</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  15.9673</td><td style=\"text-align: right;\">            115.318 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         912.798</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">-112.037 </td><td style=\"text-align: right;\">            -98.8261</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            449.34</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:35:33 (running for 00:15:37.70)<br>Memory usage on this node: 7.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         911.146</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  15.9673</td><td style=\"text-align: right;\">            115.318 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         912.798</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">-112.037 </td><td style=\"text-align: right;\">            -98.8261</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            449.34</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 304000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-35-36\n",
      "  done: false\n",
      "  episode_len_mean: 1530.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 125.00613582245586\n",
      "  episode_reward_mean: 19.288396565022282\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 291\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.171229362487793\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014873540960252285\n",
      "          model: {}\n",
      "          policy_loss: -0.020432643592357635\n",
      "          total_loss: 2.4596259593963623\n",
      "          vf_explained_var: 0.6370815634727478\n",
      "          vf_loss: 2.4725286960601807\n",
      "    num_agent_steps_sampled: 304000\n",
      "    num_agent_steps_trained: 304000\n",
      "    num_steps_sampled: 304000\n",
      "    num_steps_trained: 304000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.483333333333334\n",
      "    ram_util_percent: 33.22777777777779\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12315650549515808\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49362712800798436\n",
      "    mean_inference_ms: 2.4944938747858827\n",
      "    mean_raw_obs_processing_ms: 0.1097618233944887\n",
      "  time_since_restore: 923.6535589694977\n",
      "  time_this_iter_s: 12.507548093795776\n",
      "  time_total_s: 923.6535589694977\n",
      "  timers:\n",
      "    learn_throughput: 665.775\n",
      "    learn_time_ms: 6008.032\n",
      "    load_throughput: 20056444.71\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 306.576\n",
      "    sample_time_ms: 13047.351\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872136\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 304000\n",
      "  training_iteration: 76\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 304000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-35-38\n",
      "  done: false\n",
      "  episode_len_mean: 464.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8986481800011\n",
      "  episode_reward_mean: -111.8903250849477\n",
      "  episode_reward_min: -187.2602008764396\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 563\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 5.293955999225468e-24\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659900188446045\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.4793734471350035e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003132122801616788\n",
      "          total_loss: 595.1322631835938\n",
      "          vf_explained_var: -0.0003010596556123346\n",
      "          vf_loss: 595.1290893554688\n",
      "    num_agent_steps_sampled: 304000\n",
      "    num_agent_steps_trained: 304000\n",
      "    num_steps_sampled: 304000\n",
      "    num_steps_trained: 304000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.294444444444444\n",
      "    ram_util_percent: 33.22222222222223\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12536219416933392\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4971883026397397\n",
      "    mean_inference_ms: 2.5529674119945027\n",
      "    mean_raw_obs_processing_ms: 0.11565796427569626\n",
      "  time_since_restore: 925.4726872444153\n",
      "  time_this_iter_s: 12.675101280212402\n",
      "  time_total_s: 925.4726872444153\n",
      "  timers:\n",
      "    learn_throughput: 676.089\n",
      "    learn_time_ms: 5916.377\n",
      "    load_throughput: 8023153.364\n",
      "    load_time_ms: 0.499\n",
      "    sample_throughput: 306.15\n",
      "    sample_time_ms: 13065.505\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641872138\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 304000\n",
      "  training_iteration: 76\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:35:39 (running for 00:15:43.34)<br>Memory usage on this node: 7.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         923.654</td><td style=\"text-align: right;\">304000</td><td style=\"text-align: right;\">  19.2884</td><td style=\"text-align: right;\">            125.006 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         925.473</td><td style=\"text-align: right;\">304000</td><td style=\"text-align: right;\">-111.89  </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            464.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:35:44 (running for 00:15:48.39)<br>Memory usage on this node: 7.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         923.654</td><td style=\"text-align: right;\">304000</td><td style=\"text-align: right;\">  19.2884</td><td style=\"text-align: right;\">            125.006 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         925.473</td><td style=\"text-align: right;\">304000</td><td style=\"text-align: right;\">-111.89  </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            464.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 308000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-35-49\n",
      "  done: false\n",
      "  episode_len_mean: 1530.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 143.89167623123646\n",
      "  episode_reward_mean: 22.5329739485303\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 293\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.048281192779541\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013514633290469646\n",
      "          model: {}\n",
      "          policy_loss: -0.016295114532113075\n",
      "          total_loss: 1.7561777830123901\n",
      "          vf_explained_var: 0.710033118724823\n",
      "          vf_loss: 1.7656311988830566\n",
      "    num_agent_steps_sampled: 308000\n",
      "    num_agent_steps_trained: 308000\n",
      "    num_steps_sampled: 308000\n",
      "    num_steps_trained: 308000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.85294117647059\n",
      "    ram_util_percent: 33.323529411764696\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12320455707077115\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49370857170872356\n",
      "    mean_inference_ms: 2.4951615026033047\n",
      "    mean_raw_obs_processing_ms: 0.10976651798987092\n",
      "  time_since_restore: 936.1401641368866\n",
      "  time_this_iter_s: 12.486605167388916\n",
      "  time_total_s: 936.1401641368866\n",
      "  timers:\n",
      "    learn_throughput: 667.304\n",
      "    learn_time_ms: 5994.268\n",
      "    load_throughput: 40117685.318\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 307.848\n",
      "    sample_time_ms: 12993.407\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641872149\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 308000\n",
      "  training_iteration: 77\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:35:50 (running for 00:15:53.98)<br>Memory usage on this node: 8.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         936.14 </td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  22.533</td><td style=\"text-align: right;\">            143.892 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         925.473</td><td style=\"text-align: right;\">304000</td><td style=\"text-align: right;\">-111.89 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            464.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 308000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-35-51\n",
      "  done: false\n",
      "  episode_len_mean: 479.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8986481800011\n",
      "  episode_reward_mean: -111.97098274639336\n",
      "  episode_reward_min: -187.2602008764396\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 568\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.646977999612734e-24\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659014701843262\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.7342452451885038e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003864200320094824\n",
      "          total_loss: 211.88397216796875\n",
      "          vf_explained_var: 0.00013583623513113707\n",
      "          vf_loss: 211.88011169433594\n",
      "    num_agent_steps_sampled: 308000\n",
      "    num_agent_steps_trained: 308000\n",
      "    num_steps_sampled: 308000\n",
      "    num_steps_trained: 308000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.30000000000001\n",
      "    ram_util_percent: 33.36111111111111\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12540901012191724\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4975882221207957\n",
      "    mean_inference_ms: 2.553810768752367\n",
      "    mean_raw_obs_processing_ms: 0.11577003766914207\n",
      "  time_since_restore: 938.1577610969543\n",
      "  time_this_iter_s: 12.685073852539062\n",
      "  time_total_s: 938.1577610969543\n",
      "  timers:\n",
      "    learn_throughput: 676.648\n",
      "    learn_time_ms: 5911.49\n",
      "    load_throughput: 10030020.924\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 306.709\n",
      "    sample_time_ms: 13041.66\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641872151\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 308000\n",
      "  training_iteration: 77\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:35:55 (running for 00:15:59.08)<br>Memory usage on this node: 8.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         936.14 </td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  22.533</td><td style=\"text-align: right;\">            143.892 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         938.158</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">-111.971</td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            479.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:36:00 (running for 00:16:04.14)<br>Memory usage on this node: 8.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         936.14 </td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  22.533</td><td style=\"text-align: right;\">            143.892 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         938.158</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">-111.971</td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            479.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 312000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-36-01\n",
      "  done: false\n",
      "  episode_len_mean: 1530.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 143.89167623123646\n",
      "  episode_reward_mean: 26.044278531670024\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 295\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.0860888957977295\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01343531720340252\n",
      "          model: {}\n",
      "          policy_loss: -0.022898618131875992\n",
      "          total_loss: 1.5779085159301758\n",
      "          vf_explained_var: 0.768007755279541\n",
      "          vf_loss: 1.5940057039260864\n",
      "    num_agent_steps_sampled: 312000\n",
      "    num_agent_steps_trained: 312000\n",
      "    num_steps_sampled: 312000\n",
      "    num_steps_trained: 312000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.73888888888889\n",
      "    ram_util_percent: 33.400000000000006\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12325169532589074\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49374322046844293\n",
      "    mean_inference_ms: 2.495542817797379\n",
      "    mean_raw_obs_processing_ms: 0.10976660380337804\n",
      "  time_since_restore: 948.795318365097\n",
      "  time_this_iter_s: 12.65515422821045\n",
      "  time_total_s: 948.795318365097\n",
      "  timers:\n",
      "    learn_throughput: 667.804\n",
      "    learn_time_ms: 5989.78\n",
      "    load_throughput: 40117685.318\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 308.247\n",
      "    sample_time_ms: 12976.602\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872161\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 312000\n",
      "  training_iteration: 78\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 312000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-36-03\n",
      "  done: false\n",
      "  episode_len_mean: 464.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8986481800011\n",
      "  episode_reward_mean: -111.45148660900291\n",
      "  episode_reward_min: -187.2602008764396\n",
      "  episodes_this_iter: 11\n",
      "  episodes_total: 579\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.323488999806367e-24\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659355163574219\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.1951673545572703e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.004234499763697386\n",
      "          total_loss: 854.3988037109375\n",
      "          vf_explained_var: 0.0007994842017069459\n",
      "          vf_loss: 854.3944702148438\n",
      "    num_agent_steps_sampled: 312000\n",
      "    num_agent_steps_trained: 312000\n",
      "    num_steps_sampled: 312000\n",
      "    num_steps_trained: 312000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.34444444444445\n",
      "    ram_util_percent: 33.41111111111111\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12550000559519323\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49836944252124793\n",
      "    mean_inference_ms: 2.555758298157597\n",
      "    mean_raw_obs_processing_ms: 0.1160142813430959\n",
      "  time_since_restore: 950.7929685115814\n",
      "  time_this_iter_s: 12.635207414627075\n",
      "  time_total_s: 950.7929685115814\n",
      "  timers:\n",
      "    learn_throughput: 676.705\n",
      "    learn_time_ms: 5910.991\n",
      "    load_throughput: 10028821.806\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 307.31\n",
      "    sample_time_ms: 13016.19\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641872163\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 312000\n",
      "  training_iteration: 78\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:36:05 (running for 00:16:09.71)<br>Memory usage on this node: 8.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         948.795</td><td style=\"text-align: right;\">312000</td><td style=\"text-align: right;\">  26.0443</td><td style=\"text-align: right;\">            143.892 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         950.793</td><td style=\"text-align: right;\">312000</td><td style=\"text-align: right;\">-111.451 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            464.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:36:11 (running for 00:16:14.76)<br>Memory usage on this node: 8.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         948.795</td><td style=\"text-align: right;\">312000</td><td style=\"text-align: right;\">  26.0443</td><td style=\"text-align: right;\">            143.892 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         950.793</td><td style=\"text-align: right;\">312000</td><td style=\"text-align: right;\">-111.451 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            464.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 316000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-36-14\n",
      "  done: false\n",
      "  episode_len_mean: 1530.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 143.89167623123646\n",
      "  episode_reward_mean: 32.3942863286771\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 299\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5062500238418579\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.0011234283447266\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020540466532111168\n",
      "          model: {}\n",
      "          policy_loss: -0.02282741665840149\n",
      "          total_loss: 2.3003809452056885\n",
      "          vf_explained_var: 0.7106379866600037\n",
      "          vf_loss: 2.312809705734253\n",
      "    num_agent_steps_sampled: 316000\n",
      "    num_agent_steps_trained: 316000\n",
      "    num_steps_sampled: 316000\n",
      "    num_steps_trained: 316000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.249999999999986\n",
      "    ram_util_percent: 33.47222222222222\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12335222048398062\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4937793787293763\n",
      "    mean_inference_ms: 2.4960897212449726\n",
      "    mean_raw_obs_processing_ms: 0.10975865223390002\n",
      "  time_since_restore: 961.3607122898102\n",
      "  time_this_iter_s: 12.565393924713135\n",
      "  time_total_s: 961.3607122898102\n",
      "  timers:\n",
      "    learn_throughput: 669.32\n",
      "    learn_time_ms: 5976.216\n",
      "    load_throughput: 0.0\n",
      "    load_time_ms: 0.0\n",
      "    sample_throughput: 307.989\n",
      "    sample_time_ms: 12987.465\n",
      "    update_time_ms: 2.493\n",
      "  timestamp: 1641872174\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 316000\n",
      "  training_iteration: 79\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:36:16 (running for 00:16:20.27)<br>Memory usage on this node: 8.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         961.361</td><td style=\"text-align: right;\">316000</td><td style=\"text-align: right;\">  32.3943</td><td style=\"text-align: right;\">            143.892 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         950.793</td><td style=\"text-align: right;\">312000</td><td style=\"text-align: right;\">-111.451 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            464.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 316000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-36-16\n",
      "  done: false\n",
      "  episode_len_mean: 465.31\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8986481800011\n",
      "  episode_reward_mean: -111.3463544697459\n",
      "  episode_reward_min: -187.2602008764396\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 589\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 6.617444999031835e-25\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.65887975692749\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.1207492295616248e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.004081756342202425\n",
      "          total_loss: 710.5689086914062\n",
      "          vf_explained_var: -0.00042246290831826627\n",
      "          vf_loss: 710.5647583007812\n",
      "    num_agent_steps_sampled: 316000\n",
      "    num_agent_steps_trained: 316000\n",
      "    num_steps_sampled: 316000\n",
      "    num_steps_trained: 316000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.72222222222222\n",
      "    ram_util_percent: 33.47777777777778\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12561679323129188\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49888098399996766\n",
      "    mean_inference_ms: 2.5578885225969503\n",
      "    mean_raw_obs_processing_ms: 0.11619493065843285\n",
      "  time_since_restore: 963.5269119739532\n",
      "  time_this_iter_s: 12.733943462371826\n",
      "  time_total_s: 963.5269119739532\n",
      "  timers:\n",
      "    learn_throughput: 674.622\n",
      "    learn_time_ms: 5929.243\n",
      "    load_throughput: 13370430.347\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 307.207\n",
      "    sample_time_ms: 13020.558\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641872176\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 316000\n",
      "  training_iteration: 79\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:36:21 (running for 00:16:25.52)<br>Memory usage on this node: 8.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         961.361</td><td style=\"text-align: right;\">316000</td><td style=\"text-align: right;\">  32.3943</td><td style=\"text-align: right;\">            143.892 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         963.527</td><td style=\"text-align: right;\">316000</td><td style=\"text-align: right;\">-111.346 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            465.31</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:36:26 (running for 00:16:30.56)<br>Memory usage on this node: 8.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         961.361</td><td style=\"text-align: right;\">316000</td><td style=\"text-align: right;\">  32.3943</td><td style=\"text-align: right;\">            143.892 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1530.04</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         963.527</td><td style=\"text-align: right;\">316000</td><td style=\"text-align: right;\">-111.346 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            465.31</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 320000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-36-27\n",
      "  done: false\n",
      "  episode_len_mean: 1545.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 143.89167623123646\n",
      "  episode_reward_mean: 36.07809950877955\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 301\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.118481397628784\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00900496169924736\n",
      "          model: {}\n",
      "          policy_loss: -0.023086102679371834\n",
      "          total_loss: 2.330519199371338\n",
      "          vf_explained_var: 0.6987542510032654\n",
      "          vf_loss: 2.346766948699951\n",
      "    num_agent_steps_sampled: 320000\n",
      "    num_agent_steps_trained: 320000\n",
      "    num_steps_sampled: 320000\n",
      "    num_steps_trained: 320000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.22777777777779\n",
      "    ram_util_percent: 33.53888888888889\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12341554570653912\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49388158823677647\n",
      "    mean_inference_ms: 2.4969144958892833\n",
      "    mean_raw_obs_processing_ms: 0.10977149301418271\n",
      "  time_since_restore: 973.9919304847717\n",
      "  time_this_iter_s: 12.631218194961548\n",
      "  time_total_s: 973.9919304847717\n",
      "  timers:\n",
      "    learn_throughput: 669.868\n",
      "    learn_time_ms: 5971.329\n",
      "    load_throughput: 40108094.669\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 308.677\n",
      "    sample_time_ms: 12958.515\n",
      "    update_time_ms: 2.493\n",
      "  timestamp: 1641872187\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 320000\n",
      "  training_iteration: 80\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 320000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-36-29\n",
      "  done: false\n",
      "  episode_len_mean: 462.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8986481800011\n",
      "  episode_reward_mean: -111.22315804705404\n",
      "  episode_reward_min: -187.2602008764396\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 599\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.3087224995159173e-25\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.658872127532959\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.8811564334318973e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.00436605466529727\n",
      "          total_loss: 796.5685424804688\n",
      "          vf_explained_var: -0.00016205663268920034\n",
      "          vf_loss: 796.5640869140625\n",
      "    num_agent_steps_sampled: 320000\n",
      "    num_agent_steps_trained: 320000\n",
      "    num_steps_sampled: 320000\n",
      "    num_steps_trained: 320000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.73529411764706\n",
      "    ram_util_percent: 33.529411764705884\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12567318253616377\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49946381772316384\n",
      "    mean_inference_ms: 2.5594714965082654\n",
      "    mean_raw_obs_processing_ms: 0.11638207299953503\n",
      "  time_since_restore: 976.1321985721588\n",
      "  time_this_iter_s: 12.605286598205566\n",
      "  time_total_s: 976.1321985721588\n",
      "  timers:\n",
      "    learn_throughput: 676.785\n",
      "    learn_time_ms: 5910.293\n",
      "    load_throughput: 13370430.347\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 307.44\n",
      "    sample_time_ms: 13010.686\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641872189\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 320000\n",
      "  training_iteration: 80\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:36:32 (running for 00:16:36.12)<br>Memory usage on this node: 8.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         973.992</td><td style=\"text-align: right;\">320000</td><td style=\"text-align: right;\">  36.0781</td><td style=\"text-align: right;\">            143.892 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1545.58</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         976.132</td><td style=\"text-align: right;\">320000</td><td style=\"text-align: right;\">-111.223 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            462.9 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:36:37 (running for 00:16:41.17)<br>Memory usage on this node: 8.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         973.992</td><td style=\"text-align: right;\">320000</td><td style=\"text-align: right;\">  36.0781</td><td style=\"text-align: right;\">            143.892 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1545.58</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         976.132</td><td style=\"text-align: right;\">320000</td><td style=\"text-align: right;\">-111.223 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            462.9 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 324000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-36-39\n",
      "  done: false\n",
      "  episode_len_mean: 1545.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 143.89167623123646\n",
      "  episode_reward_mean: 38.962911128429226\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 303\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.108513355255127\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01118655689060688\n",
      "          model: {}\n",
      "          policy_loss: -0.02199038490653038\n",
      "          total_loss: 1.9931800365447998\n",
      "          vf_explained_var: 0.7609918117523193\n",
      "          vf_loss: 2.0066757202148438\n",
      "    num_agent_steps_sampled: 324000\n",
      "    num_agent_steps_trained: 324000\n",
      "    num_steps_sampled: 324000\n",
      "    num_steps_trained: 324000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.39444444444444\n",
      "    ram_util_percent: 33.56666666666667\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12347179728188942\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49392879967434394\n",
      "    mean_inference_ms: 2.4974311285644593\n",
      "    mean_raw_obs_processing_ms: 0.10977451560374198\n",
      "  time_since_restore: 986.5234155654907\n",
      "  time_this_iter_s: 12.531485080718994\n",
      "  time_total_s: 986.5234155654907\n",
      "  timers:\n",
      "    learn_throughput: 671.011\n",
      "    learn_time_ms: 5961.157\n",
      "    load_throughput: 20056444.71\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 309.699\n",
      "    sample_time_ms: 12915.781\n",
      "    update_time_ms: 2.493\n",
      "  timestamp: 1641872199\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 324000\n",
      "  training_iteration: 81\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 324000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-36-42\n",
      "  done: false\n",
      "  episode_len_mean: 404.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8986481800011\n",
      "  episode_reward_mean: -109.64202400564689\n",
      "  episode_reward_min: -187.2602008764396\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 620\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.6543612497579586e-25\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.658962249755859\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.235537349155493e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.005516763776540756\n",
      "          total_loss: 1691.1639404296875\n",
      "          vf_explained_var: -0.00018690350407268852\n",
      "          vf_loss: 1691.1585693359375\n",
      "    num_agent_steps_sampled: 324000\n",
      "    num_agent_steps_trained: 324000\n",
      "    num_steps_sampled: 324000\n",
      "    num_steps_trained: 324000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.09444444444445\n",
      "    ram_util_percent: 33.56666666666667\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12589540043489378\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5001047990038798\n",
      "    mean_inference_ms: 2.5636879953809055\n",
      "    mean_raw_obs_processing_ms: 0.116653118693853\n",
      "  time_since_restore: 988.779375076294\n",
      "  time_this_iter_s: 12.647176504135132\n",
      "  time_total_s: 988.779375076294\n",
      "  timers:\n",
      "    learn_throughput: 677.861\n",
      "    learn_time_ms: 5900.918\n",
      "    load_throughput: 13370430.347\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 308.536\n",
      "    sample_time_ms: 12964.454\n",
      "    update_time_ms: 1.696\n",
      "  timestamp: 1641872202\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 324000\n",
      "  training_iteration: 81\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:36:43 (running for 00:16:46.78)<br>Memory usage on this node: 8.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         986.523</td><td style=\"text-align: right;\">324000</td><td style=\"text-align: right;\">  38.9629</td><td style=\"text-align: right;\">            143.892 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1545.58</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         988.779</td><td style=\"text-align: right;\">324000</td><td style=\"text-align: right;\">-109.642 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            404.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:36:48 (running for 00:16:51.83)<br>Memory usage on this node: 8.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         986.523</td><td style=\"text-align: right;\">324000</td><td style=\"text-align: right;\">  38.9629</td><td style=\"text-align: right;\">            143.892 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1545.58</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         988.779</td><td style=\"text-align: right;\">324000</td><td style=\"text-align: right;\">-109.642 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            404.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 328000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-36-52\n",
      "  done: false\n",
      "  episode_len_mean: 1545.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 148.2650292445943\n",
      "  episode_reward_mean: 42.142181634325034\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 305\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.7997528314590454\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010909873992204666\n",
      "          model: {}\n",
      "          policy_loss: -0.017533164471387863\n",
      "          total_loss: 2.6869473457336426\n",
      "          vf_explained_var: 0.598791241645813\n",
      "          vf_loss: 2.6961958408355713\n",
      "    num_agent_steps_sampled: 328000\n",
      "    num_agent_steps_trained: 328000\n",
      "    num_steps_sampled: 328000\n",
      "    num_steps_trained: 328000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.935294117647054\n",
      "    ram_util_percent: 33.629411764705885\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12352506210497005\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4939760560982835\n",
      "    mean_inference_ms: 2.497948920493442\n",
      "    mean_raw_obs_processing_ms: 0.10977615682918547\n",
      "  time_since_restore: 998.9940638542175\n",
      "  time_this_iter_s: 12.470648288726807\n",
      "  time_total_s: 998.9940638542175\n",
      "  timers:\n",
      "    learn_throughput: 677.872\n",
      "    learn_time_ms: 5900.818\n",
      "    load_throughput: 20056444.71\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 311.714\n",
      "    sample_time_ms: 12832.284\n",
      "    update_time_ms: 2.493\n",
      "  timestamp: 1641872212\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 328000\n",
      "  training_iteration: 82\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:36:53 (running for 00:16:56.97)<br>Memory usage on this node: 8.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         998.994</td><td style=\"text-align: right;\">328000</td><td style=\"text-align: right;\">  42.1422</td><td style=\"text-align: right;\">            148.265 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1545.58</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         988.779</td><td style=\"text-align: right;\">324000</td><td style=\"text-align: right;\">-109.642 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            404.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 328000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-36-54\n",
      "  done: false\n",
      "  episode_len_mean: 389.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8986481800011\n",
      "  episode_reward_mean: -109.51608442311904\n",
      "  episode_reward_min: -187.2602008764396\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 626\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8.271806248789793e-26\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.660100936889648\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.078952488522191e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.002875451697036624\n",
      "          total_loss: 377.1127624511719\n",
      "          vf_explained_var: -0.0004081740917172283\n",
      "          vf_loss: 377.10992431640625\n",
      "    num_agent_steps_sampled: 328000\n",
      "    num_agent_steps_trained: 328000\n",
      "    num_steps_sampled: 328000\n",
      "    num_steps_trained: 328000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.80555555555556\n",
      "    ram_util_percent: 33.63888888888889\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12591069246809422\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.50032982297073\n",
      "    mean_inference_ms: 2.5642326490482192\n",
      "    mean_raw_obs_processing_ms: 0.11673170212879397\n",
      "  time_since_restore: 1001.4125871658325\n",
      "  time_this_iter_s: 12.633212089538574\n",
      "  time_total_s: 1001.4125871658325\n",
      "  timers:\n",
      "    learn_throughput: 684.7\n",
      "    learn_time_ms: 5841.976\n",
      "    load_throughput: 10027622.975\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 310.989\n",
      "    sample_time_ms: 12862.2\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641872214\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 328000\n",
      "  training_iteration: 82\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:36:58 (running for 00:17:02.46)<br>Memory usage on this node: 8.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         998.994</td><td style=\"text-align: right;\">328000</td><td style=\"text-align: right;\">  42.1422</td><td style=\"text-align: right;\">            148.265 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1545.58</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">        1001.41 </td><td style=\"text-align: right;\">328000</td><td style=\"text-align: right;\">-109.516 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            389.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:37:03 (running for 00:17:07.52)<br>Memory usage on this node: 8.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         998.994</td><td style=\"text-align: right;\">328000</td><td style=\"text-align: right;\">  42.1422</td><td style=\"text-align: right;\">            148.265 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1545.58</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">        1001.41 </td><td style=\"text-align: right;\">328000</td><td style=\"text-align: right;\">-109.516 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            389.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 332000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-37-04\n",
      "  done: false\n",
      "  episode_len_mean: 1560.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 152.95285268506734\n",
      "  episode_reward_mean: 49.54036101351354\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 309\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.7602814435958862\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01304665207862854\n",
      "          model: {}\n",
      "          policy_loss: -0.03051016665995121\n",
      "          total_loss: 2.6448724269866943\n",
      "          vf_explained_var: 0.6928172707557678\n",
      "          vf_loss: 2.665475368499756\n",
      "    num_agent_steps_sampled: 332000\n",
      "    num_agent_steps_trained: 332000\n",
      "    num_steps_sampled: 332000\n",
      "    num_steps_trained: 332000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.9388888888889\n",
      "    ram_util_percent: 33.71666666666667\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12364755351759824\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4941018751731139\n",
      "    mean_inference_ms: 2.49939490627901\n",
      "    mean_raw_obs_processing_ms: 0.10980276890620715\n",
      "  time_since_restore: 1011.6342573165894\n",
      "  time_this_iter_s: 12.640193462371826\n",
      "  time_total_s: 1011.6342573165894\n",
      "  timers:\n",
      "    learn_throughput: 684.536\n",
      "    learn_time_ms: 5843.372\n",
      "    load_throughput: 20056444.71\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 315.259\n",
      "    sample_time_ms: 12687.971\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641872224\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 332000\n",
      "  training_iteration: 83\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 332000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-37-07\n",
      "  done: false\n",
      "  episode_len_mean: 434.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8986481800011\n",
      "  episode_reward_mean: -110.12919180862838\n",
      "  episode_reward_min: -187.2602008764396\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 631\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.1359031243948966e-26\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.660057544708252\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.590541328117979e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.004105375148355961\n",
      "          total_loss: 275.7419738769531\n",
      "          vf_explained_var: 0.0006004786700941622\n",
      "          vf_loss: 275.7378845214844\n",
      "    num_agent_steps_sampled: 332000\n",
      "    num_agent_steps_trained: 332000\n",
      "    num_steps_sampled: 332000\n",
      "    num_steps_trained: 332000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.41666666666666\n",
      "    ram_util_percent: 33.72777777777779\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12595273876324176\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5004068093450266\n",
      "    mean_inference_ms: 2.5649536159711612\n",
      "    mean_raw_obs_processing_ms: 0.11675876693371456\n",
      "  time_since_restore: 1014.1614909172058\n",
      "  time_this_iter_s: 12.748903751373291\n",
      "  time_total_s: 1014.1614909172058\n",
      "  timers:\n",
      "    learn_throughput: 689.183\n",
      "    learn_time_ms: 5803.977\n",
      "    load_throughput: 10027622.975\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 314.098\n",
      "    sample_time_ms: 12734.897\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641872227\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 332000\n",
      "  training_iteration: 83\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:37:09 (running for 00:17:13.22)<br>Memory usage on this node: 8.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         1011.63</td><td style=\"text-align: right;\">332000</td><td style=\"text-align: right;\">  49.5404</td><td style=\"text-align: right;\">            152.953 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1560.93</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         1014.16</td><td style=\"text-align: right;\">332000</td><td style=\"text-align: right;\">-110.129 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            434.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:37:14 (running for 00:17:18.29)<br>Memory usage on this node: 8.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         1011.63</td><td style=\"text-align: right;\">332000</td><td style=\"text-align: right;\">  49.5404</td><td style=\"text-align: right;\">            152.953 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1560.93</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         1014.16</td><td style=\"text-align: right;\">332000</td><td style=\"text-align: right;\">-110.129 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            434.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 336000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-37-17\n",
      "  done: false\n",
      "  episode_len_mean: 1560.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 152.95285268506734\n",
      "  episode_reward_mean: 52.28843034973354\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 311\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 2.0405397415161133\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010635343380272388\n",
      "          model: {}\n",
      "          policy_loss: -0.024421725422143936\n",
      "          total_loss: 2.301806688308716\n",
      "          vf_explained_var: 0.7209156155586243\n",
      "          vf_loss: 2.3181519508361816\n",
      "    num_agent_steps_sampled: 336000\n",
      "    num_agent_steps_trained: 336000\n",
      "    num_steps_sampled: 336000\n",
      "    num_steps_trained: 336000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.92777777777778\n",
      "    ram_util_percent: 33.78333333333333\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1236962438191821\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49410443146417193\n",
      "    mean_inference_ms: 2.4995921500557623\n",
      "    mean_raw_obs_processing_ms: 0.10979702153378852\n",
      "  time_since_restore: 1024.2415397167206\n",
      "  time_this_iter_s: 12.607282400131226\n",
      "  time_total_s: 1024.2415397167206\n",
      "  timers:\n",
      "    learn_throughput: 684.233\n",
      "    learn_time_ms: 5845.965\n",
      "    load_throughput: 20056444.71\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 317.171\n",
      "    sample_time_ms: 12611.475\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872237\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 336000\n",
      "  training_iteration: 84\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 336000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-37-20\n",
      "  done: false\n",
      "  episode_len_mean: 466.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8986481800011\n",
      "  episode_reward_mean: -110.42500945710427\n",
      "  episode_reward_min: -187.2602008764396\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 636\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.0679515621974483e-26\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.660464763641357\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.376382267106237e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0030905005987733603\n",
      "          total_loss: 336.97027587890625\n",
      "          vf_explained_var: 0.001124720205552876\n",
      "          vf_loss: 336.9671630859375\n",
      "    num_agent_steps_sampled: 336000\n",
      "    num_agent_steps_trained: 336000\n",
      "    num_steps_sampled: 336000\n",
      "    num_steps_trained: 336000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.066666666666656\n",
      "    ram_util_percent: 33.78888888888888\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.125978097905709\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5004918657209659\n",
      "    mean_inference_ms: 2.565558387344526\n",
      "    mean_raw_obs_processing_ms: 0.11677259972827062\n",
      "  time_since_restore: 1026.685994386673\n",
      "  time_this_iter_s: 12.524503469467163\n",
      "  time_total_s: 1026.685994386673\n",
      "  timers:\n",
      "    learn_throughput: 689.123\n",
      "    learn_time_ms: 5804.476\n",
      "    load_throughput: 8021618.934\n",
      "    load_time_ms: 0.499\n",
      "    sample_throughput: 315.524\n",
      "    sample_time_ms: 12677.335\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641872240\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 336000\n",
      "  training_iteration: 84\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:37:20 (running for 00:17:23.75)<br>Memory usage on this node: 8.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         1024.24</td><td style=\"text-align: right;\">336000</td><td style=\"text-align: right;\">  52.2884</td><td style=\"text-align: right;\">            152.953 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1560.93</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         1026.69</td><td style=\"text-align: right;\">336000</td><td style=\"text-align: right;\">-110.425 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            466.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:37:25 (running for 00:17:28.80)<br>Memory usage on this node: 8.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         1024.24</td><td style=\"text-align: right;\">336000</td><td style=\"text-align: right;\">  52.2884</td><td style=\"text-align: right;\">            152.953 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1560.93</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         1026.69</td><td style=\"text-align: right;\">336000</td><td style=\"text-align: right;\">-110.425 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            466.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:37:30 (running for 00:17:33.87)<br>Memory usage on this node: 8.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         1024.24</td><td style=\"text-align: right;\">336000</td><td style=\"text-align: right;\">  52.2884</td><td style=\"text-align: right;\">            152.953 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1560.93</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         1026.69</td><td style=\"text-align: right;\">336000</td><td style=\"text-align: right;\">-110.425 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -187.26 </td><td style=\"text-align: right;\">            466.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 340000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-37-30\n",
      "  done: false\n",
      "  episode_len_mean: 1560.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 152.95285268506734\n",
      "  episode_reward_mean: 55.37343613719545\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 313\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.8151925802230835\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012008422054350376\n",
      "          model: {}\n",
      "          policy_loss: -0.01848008669912815\n",
      "          total_loss: 1.9446871280670166\n",
      "          vf_explained_var: 0.7326329946517944\n",
      "          vf_loss: 1.95404851436615\n",
      "    num_agent_steps_sampled: 340000\n",
      "    num_agent_steps_trained: 340000\n",
      "    num_steps_sampled: 340000\n",
      "    num_steps_trained: 340000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.7388888888889\n",
      "    ram_util_percent: 33.86666666666666\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12375166923192017\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49412220728517026\n",
      "    mean_inference_ms: 2.500083090090484\n",
      "    mean_raw_obs_processing_ms: 0.1098056429899157\n",
      "  time_since_restore: 1036.8647792339325\n",
      "  time_this_iter_s: 12.623239517211914\n",
      "  time_total_s: 1036.8647792339325\n",
      "  timers:\n",
      "    learn_throughput: 685.39\n",
      "    learn_time_ms: 5836.091\n",
      "    load_throughput: 13369364.89\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 317.256\n",
      "    sample_time_ms: 12608.1\n",
      "    update_time_ms: 2.293\n",
      "  timestamp: 1641872250\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 340000\n",
      "  training_iteration: 85\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 340000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-37-32\n",
      "  done: false\n",
      "  episode_len_mean: 410.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8986481800011\n",
      "  episode_reward_mean: -109.34706936076219\n",
      "  episode_reward_min: -127.64954703456766\n",
      "  episodes_this_iter: 15\n",
      "  episodes_total: 651\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0339757810987241e-26\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659250259399414\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.057702050388798e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.004724731203168631\n",
      "          total_loss: 1188.2567138671875\n",
      "          vf_explained_var: -0.00033719834755174816\n",
      "          vf_loss: 1188.2520751953125\n",
      "    num_agent_steps_sampled: 340000\n",
      "    num_agent_steps_trained: 340000\n",
      "    num_steps_sampled: 340000\n",
      "    num_steps_trained: 340000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.82777777777778\n",
      "    ram_util_percent: 33.900000000000006\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12598623996728597\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5006205244262656\n",
      "    mean_inference_ms: 2.566774936858185\n",
      "    mean_raw_obs_processing_ms: 0.11683465281825837\n",
      "  time_since_restore: 1039.334166765213\n",
      "  time_this_iter_s: 12.648172378540039\n",
      "  time_total_s: 1039.334166765213\n",
      "  timers:\n",
      "    learn_throughput: 689.668\n",
      "    learn_time_ms: 5799.888\n",
      "    load_throughput: 8021618.934\n",
      "    load_time_ms: 0.499\n",
      "    sample_throughput: 315.348\n",
      "    sample_time_ms: 12684.393\n",
      "    update_time_ms: 2.095\n",
      "  timestamp: 1641872252\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 340000\n",
      "  training_iteration: 85\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:37:35 (running for 00:17:39.45)<br>Memory usage on this node: 8.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         1036.86</td><td style=\"text-align: right;\">340000</td><td style=\"text-align: right;\">  55.3734</td><td style=\"text-align: right;\">            152.953 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1560.93</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         1039.33</td><td style=\"text-align: right;\">340000</td><td style=\"text-align: right;\">-109.347 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -127.65 </td><td style=\"text-align: right;\">            410.98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:37:40 (running for 00:17:44.49)<br>Memory usage on this node: 8.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         1036.86</td><td style=\"text-align: right;\">340000</td><td style=\"text-align: right;\">  55.3734</td><td style=\"text-align: right;\">            152.953 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1560.93</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         1039.33</td><td style=\"text-align: right;\">340000</td><td style=\"text-align: right;\">-109.347 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -127.65 </td><td style=\"text-align: right;\">            410.98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 344000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-37-42\n",
      "  done: false\n",
      "  episode_len_mean: 1560.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 152.95285268506734\n",
      "  episode_reward_mean: 58.639313022488196\n",
      "  episode_reward_min: -124.31250914849838\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 315\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.8491441011428833\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013757707551121712\n",
      "          model: {}\n",
      "          policy_loss: -0.01907161809504032\n",
      "          total_loss: 1.8767749071121216\n",
      "          vf_explained_var: 0.7768481373786926\n",
      "          vf_loss: 1.8853992223739624\n",
      "    num_agent_steps_sampled: 344000\n",
      "    num_agent_steps_trained: 344000\n",
      "    num_steps_sampled: 344000\n",
      "    num_steps_trained: 344000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.42222222222223\n",
      "    ram_util_percent: 33.95555555555555\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12381812989607795\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4941783556157621\n",
      "    mean_inference_ms: 2.5009510367083774\n",
      "    mean_raw_obs_processing_ms: 0.10982413990577099\n",
      "  time_since_restore: 1049.4112243652344\n",
      "  time_this_iter_s: 12.54644513130188\n",
      "  time_total_s: 1049.4112243652344\n",
      "  timers:\n",
      "    learn_throughput: 683.498\n",
      "    learn_time_ms: 5852.248\n",
      "    load_throughput: 13369364.89\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 317.824\n",
      "    sample_time_ms: 12585.583\n",
      "    update_time_ms: 2.293\n",
      "  timestamp: 1641872262\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 344000\n",
      "  training_iteration: 86\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 344000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-37-45\n",
      "  done: false\n",
      "  episode_len_mean: 426.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8986481800011\n",
      "  episode_reward_mean: -109.08729741838009\n",
      "  episode_reward_min: -127.64954703456766\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 655\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 5.169878905493621e-27\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.660244941711426\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.8731375917013793e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.002927258610725403\n",
      "          total_loss: 181.34332275390625\n",
      "          vf_explained_var: 0.0003681871748995036\n",
      "          vf_loss: 181.34039306640625\n",
      "    num_agent_steps_sampled: 344000\n",
      "    num_agent_steps_trained: 344000\n",
      "    num_steps_sampled: 344000\n",
      "    num_steps_trained: 344000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.75\n",
      "    ram_util_percent: 33.944444444444436\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12598309728791843\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5006988895945166\n",
      "    mean_inference_ms: 2.5669807153661384\n",
      "    mean_raw_obs_processing_ms: 0.11685986480166323\n",
      "  time_since_restore: 1052.0152506828308\n",
      "  time_this_iter_s: 12.681083917617798\n",
      "  time_total_s: 1052.0152506828308\n",
      "  timers:\n",
      "    learn_throughput: 689.265\n",
      "    learn_time_ms: 5803.279\n",
      "    load_throughput: 8020085.09\n",
      "    load_time_ms: 0.499\n",
      "    sample_throughput: 315.549\n",
      "    sample_time_ms: 12676.302\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641872265\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 344000\n",
      "  training_iteration: 86\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:37:46 (running for 00:17:50.12)<br>Memory usage on this node: 8.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         1049.41</td><td style=\"text-align: right;\">344000</td><td style=\"text-align: right;\">  58.6393</td><td style=\"text-align: right;\">            152.953 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1560.93</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         1052.02</td><td style=\"text-align: right;\">344000</td><td style=\"text-align: right;\">-109.087 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -127.65 </td><td style=\"text-align: right;\">            426.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:37:51 (running for 00:17:55.17)<br>Memory usage on this node: 8.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         1049.41</td><td style=\"text-align: right;\">344000</td><td style=\"text-align: right;\">  58.6393</td><td style=\"text-align: right;\">            152.953 </td><td style=\"text-align: right;\">            -124.313</td><td style=\"text-align: right;\">           1560.93</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         1052.02</td><td style=\"text-align: right;\">344000</td><td style=\"text-align: right;\">-109.087 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">            -127.65 </td><td style=\"text-align: right;\">            426.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 348000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-37-55\n",
      "  done: false\n",
      "  episode_len_mean: 1566.48\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 152.95285268506734\n",
      "  episode_reward_mean: 65.29839508361567\n",
      "  episode_reward_min: -117.55958731637523\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 319\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.9345703125\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011912589892745018\n",
      "          model: {}\n",
      "          policy_loss: -0.0166670773178339\n",
      "          total_loss: 3.394709348678589\n",
      "          vf_explained_var: 0.6915444731712341\n",
      "          vf_loss: 3.4023303985595703\n",
      "    num_agent_steps_sampled: 348000\n",
      "    num_agent_steps_trained: 348000\n",
      "    num_steps_sampled: 348000\n",
      "    num_steps_trained: 348000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.12222222222223\n",
      "    ram_util_percent: 34.00555555555556\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12391346597670935\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49422339590808906\n",
      "    mean_inference_ms: 2.501727701611141\n",
      "    mean_raw_obs_processing_ms: 0.10983737718199746\n",
      "  time_since_restore: 1062.0603947639465\n",
      "  time_this_iter_s: 12.649170398712158\n",
      "  time_total_s: 1062.0603947639465\n",
      "  timers:\n",
      "    learn_throughput: 681.396\n",
      "    learn_time_ms: 5870.3\n",
      "    load_throughput: 13369364.89\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 317.47\n",
      "    sample_time_ms: 12599.608\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872275\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 348000\n",
      "  training_iteration: 87\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:37:56 (running for 00:18:00.17)<br>Memory usage on this node: 8.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         1062.06</td><td style=\"text-align: right;\">348000</td><td style=\"text-align: right;\">  65.2984</td><td style=\"text-align: right;\">            152.953 </td><td style=\"text-align: right;\">             -117.56</td><td style=\"text-align: right;\">           1566.48</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         1052.02</td><td style=\"text-align: right;\">344000</td><td style=\"text-align: right;\">-109.087 </td><td style=\"text-align: right;\">            -94.8986</td><td style=\"text-align: right;\">             -127.65</td><td style=\"text-align: right;\">            426.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 348000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-37-58\n",
      "  done: false\n",
      "  episode_len_mean: 397.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -97.1480684861963\n",
      "  episode_reward_mean: -109.45706310750492\n",
      "  episode_reward_min: -130.00708930930557\n",
      "  episodes_this_iter: 13\n",
      "  episodes_total: 668\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.5849394527468104e-27\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.6589131355285645\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.504211463223328e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.004186709877103567\n",
      "          total_loss: 954.4474487304688\n",
      "          vf_explained_var: -0.00045241962652653456\n",
      "          vf_loss: 954.4432983398438\n",
      "    num_agent_steps_sampled: 348000\n",
      "    num_agent_steps_trained: 348000\n",
      "    num_steps_sampled: 348000\n",
      "    num_steps_trained: 348000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.794444444444444\n",
      "    ram_util_percent: 34.06111111111111\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1260000751902963\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5008628310728444\n",
      "    mean_inference_ms: 2.567790102849742\n",
      "    mean_raw_obs_processing_ms: 0.11691212248001007\n",
      "  time_since_restore: 1064.6943411827087\n",
      "  time_this_iter_s: 12.67909049987793\n",
      "  time_total_s: 1064.6943411827087\n",
      "  timers:\n",
      "    learn_throughput: 688.485\n",
      "    learn_time_ms: 5809.862\n",
      "    load_throughput: 8020085.09\n",
      "    load_time_ms: 0.499\n",
      "    sample_throughput: 315.64\n",
      "    sample_time_ms: 12672.645\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641872278\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 348000\n",
      "  training_iteration: 87\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:38:02 (running for 00:18:05.87)<br>Memory usage on this node: 8.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         1062.06</td><td style=\"text-align: right;\">348000</td><td style=\"text-align: right;\">  65.2984</td><td style=\"text-align: right;\">            152.953 </td><td style=\"text-align: right;\">            -117.56 </td><td style=\"text-align: right;\">           1566.48</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         1064.69</td><td style=\"text-align: right;\">348000</td><td style=\"text-align: right;\">-109.457 </td><td style=\"text-align: right;\">            -97.1481</td><td style=\"text-align: right;\">            -130.007</td><td style=\"text-align: right;\">            397.4 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:38:07 (running for 00:18:10.92)<br>Memory usage on this node: 8.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         1062.06</td><td style=\"text-align: right;\">348000</td><td style=\"text-align: right;\">  65.2984</td><td style=\"text-align: right;\">            152.953 </td><td style=\"text-align: right;\">            -117.56 </td><td style=\"text-align: right;\">           1566.48</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         1064.69</td><td style=\"text-align: right;\">348000</td><td style=\"text-align: right;\">-109.457 </td><td style=\"text-align: right;\">            -97.1481</td><td style=\"text-align: right;\">            -130.007</td><td style=\"text-align: right;\">            397.4 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 352000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-38-08\n",
      "  done: false\n",
      "  episode_len_mean: 1566.48\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 152.95285268506734\n",
      "  episode_reward_mean: 68.3344748979939\n",
      "  episode_reward_min: -117.55958731637523\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 321\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593749761581421\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.9979466199874878\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02141728065907955\n",
      "          model: {}\n",
      "          policy_loss: -0.027233615517616272\n",
      "          total_loss: 2.0009262561798096\n",
      "          vf_explained_var: 0.7025635838508606\n",
      "          vf_loss: 2.0118961334228516\n",
      "    num_agent_steps_sampled: 352000\n",
      "    num_agent_steps_trained: 352000\n",
      "    num_steps_sampled: 352000\n",
      "    num_steps_trained: 352000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.19411764705882\n",
      "    ram_util_percent: 34.129411764705885\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12397417063036656\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4942719842128215\n",
      "    mean_inference_ms: 2.5023159658099745\n",
      "    mean_raw_obs_processing_ms: 0.10985235472536858\n",
      "  time_since_restore: 1074.661691904068\n",
      "  time_this_iter_s: 12.60129714012146\n",
      "  time_total_s: 1074.661691904068\n",
      "  timers:\n",
      "    learn_throughput: 680.183\n",
      "    learn_time_ms: 5880.772\n",
      "    load_throughput: 13369364.89\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 317.412\n",
      "    sample_time_ms: 12601.91\n",
      "    update_time_ms: 2.293\n",
      "  timestamp: 1641872288\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 352000\n",
      "  training_iteration: 88\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 352000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-38-10\n",
      "  done: false\n",
      "  episode_len_mean: 396.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8514519629124\n",
      "  episode_reward_mean: -109.22619047398959\n",
      "  episode_reward_min: -130.00708930930557\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 678\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2924697263734052e-27\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659340858459473\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.04199992026588e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0035834822338074446\n",
      "          total_loss: 702.3370971679688\n",
      "          vf_explained_var: -0.0006123122875578701\n",
      "          vf_loss: 702.3335571289062\n",
      "    num_agent_steps_sampled: 352000\n",
      "    num_agent_steps_trained: 352000\n",
      "    num_steps_sampled: 352000\n",
      "    num_steps_trained: 352000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.870588235294115\n",
      "    ram_util_percent: 34.16470588235295\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12605686750527922\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5008751668827055\n",
      "    mean_inference_ms: 2.568544875816989\n",
      "    mean_raw_obs_processing_ms: 0.11689435170207765\n",
      "  time_since_restore: 1077.352487564087\n",
      "  time_this_iter_s: 12.658146381378174\n",
      "  time_total_s: 1077.352487564087\n",
      "  timers:\n",
      "    learn_throughput: 686.458\n",
      "    learn_time_ms: 5827.016\n",
      "    load_throughput: 8020851.939\n",
      "    load_time_ms: 0.499\n",
      "    sample_throughput: 315.86\n",
      "    sample_time_ms: 12663.83\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641872290\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 352000\n",
      "  training_iteration: 88\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:38:12 (running for 00:18:16.52)<br>Memory usage on this node: 8.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         1074.66</td><td style=\"text-align: right;\">352000</td><td style=\"text-align: right;\">  68.3345</td><td style=\"text-align: right;\">            152.953 </td><td style=\"text-align: right;\">            -117.56 </td><td style=\"text-align: right;\">           1566.48</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         1077.35</td><td style=\"text-align: right;\">352000</td><td style=\"text-align: right;\">-109.226 </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">            -130.007</td><td style=\"text-align: right;\">            396.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:38:17 (running for 00:18:21.59)<br>Memory usage on this node: 8.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         1074.66</td><td style=\"text-align: right;\">352000</td><td style=\"text-align: right;\">  68.3345</td><td style=\"text-align: right;\">            152.953 </td><td style=\"text-align: right;\">            -117.56 </td><td style=\"text-align: right;\">           1566.48</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         1077.35</td><td style=\"text-align: right;\">352000</td><td style=\"text-align: right;\">-109.226 </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">            -130.007</td><td style=\"text-align: right;\">            396.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 356000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-38-20\n",
      "  done: false\n",
      "  episode_len_mean: 1581.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 152.95285268506734\n",
      "  episode_reward_mean: 72.29393385837507\n",
      "  episode_reward_min: -108.78314121822392\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 323\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.695480465888977\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0075154174119234085\n",
      "          model: {}\n",
      "          policy_loss: -0.023732639849185944\n",
      "          total_loss: 2.276064872741699\n",
      "          vf_explained_var: 0.663478672504425\n",
      "          vf_loss: 2.2912368774414062\n",
      "    num_agent_steps_sampled: 356000\n",
      "    num_agent_steps_trained: 356000\n",
      "    num_steps_sampled: 356000\n",
      "    num_steps_trained: 356000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.83333333333333\n",
      "    ram_util_percent: 34.211111111111116\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12403635576198387\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49433250507096393\n",
      "    mean_inference_ms: 2.502952448390771\n",
      "    mean_raw_obs_processing_ms: 0.10986816120982658\n",
      "  time_since_restore: 1087.4993579387665\n",
      "  time_this_iter_s: 12.837666034698486\n",
      "  time_total_s: 1087.4993579387665\n",
      "  timers:\n",
      "    learn_throughput: 679.307\n",
      "    learn_time_ms: 5888.352\n",
      "    load_throughput: 10027622.975\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 316.635\n",
      "    sample_time_ms: 12632.828\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641872300\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 356000\n",
      "  training_iteration: 89\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:38:22 (running for 00:18:26.67)<br>Memory usage on this node: 8.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         1087.5 </td><td style=\"text-align: right;\">356000</td><td style=\"text-align: right;\">  72.2939</td><td style=\"text-align: right;\">            152.953 </td><td style=\"text-align: right;\">            -108.783</td><td style=\"text-align: right;\">           1581.89</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         1077.35</td><td style=\"text-align: right;\">352000</td><td style=\"text-align: right;\">-109.226 </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">            -130.007</td><td style=\"text-align: right;\">            396.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 356000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-38-23\n",
      "  done: false\n",
      "  episode_len_mean: 410.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8514519629124\n",
      "  episode_reward_mean: -109.1144291540937\n",
      "  episode_reward_min: -130.00708930930557\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 683\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 6.462348631867026e-28\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.6598286628723145\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.2072844413069106e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003204521257430315\n",
      "          total_loss: 212.73355102539062\n",
      "          vf_explained_var: -0.000636212294921279\n",
      "          vf_loss: 212.7303466796875\n",
      "    num_agent_steps_sampled: 356000\n",
      "    num_agent_steps_trained: 356000\n",
      "    num_steps_sampled: 356000\n",
      "    num_steps_trained: 356000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.82222222222224\n",
      "    ram_util_percent: 34.18333333333334\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12606221604142487\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5009676531688326\n",
      "    mean_inference_ms: 2.568676932126489\n",
      "    mean_raw_obs_processing_ms: 0.11690482393713097\n",
      "  time_since_restore: 1089.9557800292969\n",
      "  time_this_iter_s: 12.603292465209961\n",
      "  time_total_s: 1089.9557800292969\n",
      "  timers:\n",
      "    learn_throughput: 687.399\n",
      "    learn_time_ms: 5819.037\n",
      "    load_throughput: 8020851.939\n",
      "    load_time_ms: 0.499\n",
      "    sample_throughput: 315.561\n",
      "    sample_time_ms: 12675.848\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641872303\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 356000\n",
      "  training_iteration: 89\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:38:28 (running for 00:18:32.18)<br>Memory usage on this node: 8.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         1087.5 </td><td style=\"text-align: right;\">356000</td><td style=\"text-align: right;\">  72.2939</td><td style=\"text-align: right;\">            152.953 </td><td style=\"text-align: right;\">            -108.783</td><td style=\"text-align: right;\">           1581.89</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         1089.96</td><td style=\"text-align: right;\">356000</td><td style=\"text-align: right;\">-109.114 </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">            -130.007</td><td style=\"text-align: right;\">            410.8 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:38:33 (running for 00:18:37.22)<br>Memory usage on this node: 8.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         1087.5 </td><td style=\"text-align: right;\">356000</td><td style=\"text-align: right;\">  72.2939</td><td style=\"text-align: right;\">            152.953 </td><td style=\"text-align: right;\">            -108.783</td><td style=\"text-align: right;\">           1581.89</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         1089.96</td><td style=\"text-align: right;\">356000</td><td style=\"text-align: right;\">-109.114 </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">            -130.007</td><td style=\"text-align: right;\">            410.8 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 360000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-38-33\n",
      "  done: false\n",
      "  episode_len_mean: 1581.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 153.01527409017703\n",
      "  episode_reward_mean: 75.7311089498598\n",
      "  episode_reward_min: -108.78314121822392\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 325\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.9216161966323853\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009212618693709373\n",
      "          model: {}\n",
      "          policy_loss: -0.021446889266371727\n",
      "          total_loss: 2.0800719261169434\n",
      "          vf_explained_var: 0.6935735940933228\n",
      "          vf_loss: 2.0910251140594482\n",
      "    num_agent_steps_sampled: 360000\n",
      "    num_agent_steps_trained: 360000\n",
      "    num_steps_sampled: 360000\n",
      "    num_steps_trained: 360000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.58888888888888\n",
      "    ram_util_percent: 34.177777777777784\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12409877215688883\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49440439950242365\n",
      "    mean_inference_ms: 2.5036228671173917\n",
      "    mean_raw_obs_processing_ms: 0.10988794861180706\n",
      "  time_since_restore: 1100.0916805267334\n",
      "  time_this_iter_s: 12.592322587966919\n",
      "  time_total_s: 1100.0916805267334\n",
      "  timers:\n",
      "    learn_throughput: 678.939\n",
      "    learn_time_ms: 5891.543\n",
      "    load_throughput: 13370430.347\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 316.627\n",
      "    sample_time_ms: 12633.162\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872313\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 360000\n",
      "  training_iteration: 90\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 360000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-38-36\n",
      "  done: false\n",
      "  episode_len_mean: 424.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8514519629124\n",
      "  episode_reward_mean: -109.65769473192242\n",
      "  episode_reward_min: -130.00708930930557\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 690\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.231174315933513e-28\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659420013427734\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.194609234924428e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.002904305001720786\n",
      "          total_loss: 355.1133117675781\n",
      "          vf_explained_var: 0.0018897246336564422\n",
      "          vf_loss: 355.11041259765625\n",
      "    num_agent_steps_sampled: 360000\n",
      "    num_agent_steps_trained: 360000\n",
      "    num_steps_sampled: 360000\n",
      "    num_steps_trained: 360000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.150000000000006\n",
      "    ram_util_percent: 34.19444444444445\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1261070102881789\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5009674655501722\n",
      "    mean_inference_ms: 2.569289618473198\n",
      "    mean_raw_obs_processing_ms: 0.11686923088849004\n",
      "  time_since_restore: 1102.5590722560883\n",
      "  time_this_iter_s: 12.603292226791382\n",
      "  time_total_s: 1102.5590722560883\n",
      "  timers:\n",
      "    learn_throughput: 686.799\n",
      "    learn_time_ms: 5824.124\n",
      "    load_throughput: 6684149.801\n",
      "    load_time_ms: 0.598\n",
      "    sample_throughput: 315.896\n",
      "    sample_time_ms: 12662.397\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872316\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 360000\n",
      "  training_iteration: 90\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:38:39 (running for 00:18:42.78)<br>Memory usage on this node: 8.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         1100.09</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  75.7311</td><td style=\"text-align: right;\">            153.015 </td><td style=\"text-align: right;\">            -108.783</td><td style=\"text-align: right;\">           1581.89</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         1102.56</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">-109.658 </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">            -130.007</td><td style=\"text-align: right;\">            424.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:38:44 (running for 00:18:47.83)<br>Memory usage on this node: 8.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         1100.09</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  75.7311</td><td style=\"text-align: right;\">            153.015 </td><td style=\"text-align: right;\">            -108.783</td><td style=\"text-align: right;\">           1581.89</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         1102.56</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">-109.658 </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">            -130.007</td><td style=\"text-align: right;\">            424.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 364000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-38-46\n",
      "  done: false\n",
      "  episode_len_mean: 1581.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 153.01527409017703\n",
      "  episode_reward_mean: 81.67456447048342\n",
      "  episode_reward_min: -108.78314121822392\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 329\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.9942290782928467\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0077837733551859856\n",
      "          model: {}\n",
      "          policy_loss: -0.016556911170482635\n",
      "          total_loss: 2.5972583293914795\n",
      "          vf_explained_var: 0.7184063792228699\n",
      "          vf_loss: 2.6049492359161377\n",
      "    num_agent_steps_sampled: 364000\n",
      "    num_agent_steps_trained: 364000\n",
      "    num_steps_sampled: 364000\n",
      "    num_steps_trained: 364000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.772222222222226\n",
      "    ram_util_percent: 34.20555555555556\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12422353198019824\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49456060433179966\n",
      "    mean_inference_ms: 2.505032988820484\n",
      "    mean_raw_obs_processing_ms: 0.10992741658563161\n",
      "  time_since_restore: 1112.6471018791199\n",
      "  time_this_iter_s: 12.555421352386475\n",
      "  time_total_s: 1112.6471018791199\n",
      "  timers:\n",
      "    learn_throughput: 679.146\n",
      "    learn_time_ms: 5889.748\n",
      "    load_throughput: 20054047.334\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 316.436\n",
      "    sample_time_ms: 12640.801\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872326\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 364000\n",
      "  training_iteration: 91\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 364000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-38-48\n",
      "  done: false\n",
      "  episode_len_mean: 425.34\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8514519629124\n",
      "  episode_reward_mean: -109.94686073701554\n",
      "  episode_reward_min: -130.00708930930557\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 700\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.6155871579667565e-28\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.65941047668457\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.6708880795922596e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003453080775216222\n",
      "          total_loss: 697.1781005859375\n",
      "          vf_explained_var: 0.001097051310352981\n",
      "          vf_loss: 697.1746215820312\n",
      "    num_agent_steps_sampled: 364000\n",
      "    num_agent_steps_trained: 364000\n",
      "    num_steps_sampled: 364000\n",
      "    num_steps_trained: 364000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.00555555555555\n",
      "    ram_util_percent: 34.177777777777784\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1261146607395987\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5011368638354141\n",
      "    mean_inference_ms: 2.5695492477001607\n",
      "    mean_raw_obs_processing_ms: 0.11687633422529288\n",
      "  time_since_restore: 1115.1294527053833\n",
      "  time_this_iter_s: 12.570380449295044\n",
      "  time_total_s: 1115.1294527053833\n",
      "  timers:\n",
      "    learn_throughput: 687.163\n",
      "    learn_time_ms: 5821.032\n",
      "    load_throughput: 6684416.112\n",
      "    load_time_ms: 0.598\n",
      "    sample_throughput: 315.893\n",
      "    sample_time_ms: 12662.53\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641872328\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 364000\n",
      "  training_iteration: 91\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:38:49 (running for 00:18:53.36)<br>Memory usage on this node: 8.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         1112.65</td><td style=\"text-align: right;\">364000</td><td style=\"text-align: right;\">  81.6746</td><td style=\"text-align: right;\">            153.015 </td><td style=\"text-align: right;\">            -108.783</td><td style=\"text-align: right;\">           1581.89</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         1115.13</td><td style=\"text-align: right;\">364000</td><td style=\"text-align: right;\">-109.947 </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">            -130.007</td><td style=\"text-align: right;\">            425.34</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:38:54 (running for 00:18:58.41)<br>Memory usage on this node: 8.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         1112.65</td><td style=\"text-align: right;\">364000</td><td style=\"text-align: right;\">  81.6746</td><td style=\"text-align: right;\">            153.015 </td><td style=\"text-align: right;\">            -108.783</td><td style=\"text-align: right;\">           1581.89</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         1115.13</td><td style=\"text-align: right;\">364000</td><td style=\"text-align: right;\">-109.947 </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">            -130.007</td><td style=\"text-align: right;\">            425.34</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 368000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-38-58\n",
      "  done: false\n",
      "  episode_len_mean: 1589.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 153.01527409017703\n",
      "  episode_reward_mean: 85.7306250209366\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 331\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.7224987745285034\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007892022840678692\n",
      "          model: {}\n",
      "          policy_loss: -0.016967957839369774\n",
      "          total_loss: 2.460320472717285\n",
      "          vf_explained_var: 0.7767284512519836\n",
      "          vf_loss: 2.46829891204834\n",
      "    num_agent_steps_sampled: 368000\n",
      "    num_agent_steps_trained: 368000\n",
      "    num_steps_sampled: 368000\n",
      "    num_steps_trained: 368000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.87222222222223\n",
      "    ram_util_percent: 34.21666666666667\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12428461611545764\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4946548406967255\n",
      "    mean_inference_ms: 2.5057811556155496\n",
      "    mean_raw_obs_processing_ms: 0.10994789891295849\n",
      "  time_since_restore: 1125.1396911144257\n",
      "  time_this_iter_s: 12.492589235305786\n",
      "  time_total_s: 1125.1396911144257\n",
      "  timers:\n",
      "    learn_throughput: 678.882\n",
      "    learn_time_ms: 5892.042\n",
      "    load_throughput: 20054047.334\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 316.482\n",
      "    sample_time_ms: 12638.939\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872338\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 368000\n",
      "  training_iteration: 92\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:39:00 (running for 00:19:04.38)<br>Memory usage on this node: 8.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         1125.14</td><td style=\"text-align: right;\">368000</td><td style=\"text-align: right;\">  85.7306</td><td style=\"text-align: right;\">            153.015 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1589.61</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         1115.13</td><td style=\"text-align: right;\">364000</td><td style=\"text-align: right;\">-109.947 </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            425.34</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 368000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-39-01\n",
      "  done: false\n",
      "  episode_len_mean: 456.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8514519629124\n",
      "  episode_reward_mean: -110.04976573435663\n",
      "  episode_reward_min: -130.00708930930557\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 707\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 8.077935789833782e-29\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.660212993621826\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 5.209302571529406e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003567424137145281\n",
      "          total_loss: 485.2429504394531\n",
      "          vf_explained_var: 4.2467476305318996e-05\n",
      "          vf_loss: 485.2393798828125\n",
      "    num_agent_steps_sampled: 368000\n",
      "    num_agent_steps_trained: 368000\n",
      "    num_steps_sampled: 368000\n",
      "    num_steps_trained: 368000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.300000000000004\n",
      "    ram_util_percent: 34.22777777777779\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12609341415947073\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5013427829305449\n",
      "    mean_inference_ms: 2.5694880731074092\n",
      "    mean_raw_obs_processing_ms: 0.11688687240792747\n",
      "  time_since_restore: 1127.8494341373444\n",
      "  time_this_iter_s: 12.71998143196106\n",
      "  time_total_s: 1127.8494341373444\n",
      "  timers:\n",
      "    learn_throughput: 685.73\n",
      "    learn_time_ms: 5833.199\n",
      "    load_throughput: 8021235.418\n",
      "    load_time_ms: 0.499\n",
      "    sample_throughput: 316.066\n",
      "    sample_time_ms: 12655.604\n",
      "    update_time_ms: 2.095\n",
      "  timestamp: 1641872341\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 368000\n",
      "  training_iteration: 92\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:39:06 (running for 00:19:10.15)<br>Memory usage on this node: 8.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         1125.14</td><td style=\"text-align: right;\">368000</td><td style=\"text-align: right;\">  85.7306</td><td style=\"text-align: right;\">            153.015 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1589.61</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         1127.85</td><td style=\"text-align: right;\">368000</td><td style=\"text-align: right;\">-110.05  </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            456.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 372000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-39-11\n",
      "  done: false\n",
      "  episode_len_mean: 1589.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 155.8275204934882\n",
      "  episode_reward_mean: 88.2646849103358\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 333\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.406010627746582\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011904560029506683\n",
      "          model: {}\n",
      "          policy_loss: -0.01205834373831749\n",
      "          total_loss: 2.650683879852295\n",
      "          vf_explained_var: 0.8044224977493286\n",
      "          vf_loss: 2.649182081222534\n",
      "    num_agent_steps_sampled: 372000\n",
      "    num_agent_steps_trained: 372000\n",
      "    num_steps_sampled: 372000\n",
      "    num_steps_trained: 372000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.8470588235294\n",
      "    ram_util_percent: 34.252941176470586\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12434612231895606\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4947495310558028\n",
      "    mean_inference_ms: 2.5065483365377794\n",
      "    mean_raw_obs_processing_ms: 0.10996905126014139\n",
      "  time_since_restore: 1137.729020357132\n",
      "  time_this_iter_s: 12.589329242706299\n",
      "  time_total_s: 1137.729020357132\n",
      "  timers:\n",
      "    learn_throughput: 678.767\n",
      "    learn_time_ms: 5893.039\n",
      "    load_throughput: 20054047.334\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 316.591\n",
      "    sample_time_ms: 12634.602\n",
      "    update_time_ms: 2.394\n",
      "  timestamp: 1641872351\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 372000\n",
      "  training_iteration: 93\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:39:12 (running for 00:19:15.99)<br>Memory usage on this node: 8.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         1137.73</td><td style=\"text-align: right;\">372000</td><td style=\"text-align: right;\">  88.2647</td><td style=\"text-align: right;\">            155.828 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1589.61</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         1127.85</td><td style=\"text-align: right;\">368000</td><td style=\"text-align: right;\">-110.05  </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            456.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 372000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-39-14\n",
      "  done: false\n",
      "  episode_len_mean: 487.28\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8514519629124\n",
      "  episode_reward_mean: -110.43901205982601\n",
      "  episode_reward_min: -130.00708930930557\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 711\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.038967894916891e-29\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659121990203857\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.720258009958343e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0035170703195035458\n",
      "          total_loss: 115.14611053466797\n",
      "          vf_explained_var: 0.0012652795994654298\n",
      "          vf_loss: 115.14259338378906\n",
      "    num_agent_steps_sampled: 372000\n",
      "    num_agent_steps_trained: 372000\n",
      "    num_steps_sampled: 372000\n",
      "    num_steps_trained: 372000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.38333333333334\n",
      "    ram_util_percent: 34.26111111111111\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12608115258475588\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5014555154124186\n",
      "    mean_inference_ms: 2.569470532016166\n",
      "    mean_raw_obs_processing_ms: 0.11689454893790446\n",
      "  time_since_restore: 1140.5035910606384\n",
      "  time_this_iter_s: 12.654156923294067\n",
      "  time_total_s: 1140.5035910606384\n",
      "  timers:\n",
      "    learn_throughput: 685.554\n",
      "    learn_time_ms: 5834.695\n",
      "    load_throughput: 6683883.511\n",
      "    load_time_ms: 0.598\n",
      "    sample_throughput: 316.035\n",
      "    sample_time_ms: 12656.814\n",
      "    update_time_ms: 2.095\n",
      "  timestamp: 1641872354\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 372000\n",
      "  training_iteration: 93\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:39:18 (running for 00:19:21.81)<br>Memory usage on this node: 8.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         1137.73</td><td style=\"text-align: right;\">372000</td><td style=\"text-align: right;\">  88.2647</td><td style=\"text-align: right;\">            155.828 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1589.61</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         1140.5 </td><td style=\"text-align: right;\">372000</td><td style=\"text-align: right;\">-110.439 </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            487.28</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:39:23 (running for 00:19:26.86)<br>Memory usage on this node: 8.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         1137.73</td><td style=\"text-align: right;\">372000</td><td style=\"text-align: right;\">  88.2647</td><td style=\"text-align: right;\">            155.828 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1589.61</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         1140.5 </td><td style=\"text-align: right;\">372000</td><td style=\"text-align: right;\">-110.439 </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            487.28</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 376000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-39-24\n",
      "  done: false\n",
      "  episode_len_mean: 1589.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 163.13559083859153\n",
      "  episode_reward_mean: 91.46533919615833\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 335\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.7163032293319702\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011216291226446629\n",
      "          model: {}\n",
      "          policy_loss: -0.017305651679635048\n",
      "          total_loss: 2.6208481788635254\n",
      "          vf_explained_var: 0.7055878043174744\n",
      "          vf_loss: 2.625378131866455\n",
      "    num_agent_steps_sampled: 376000\n",
      "    num_agent_steps_trained: 376000\n",
      "    num_steps_sampled: 376000\n",
      "    num_steps_trained: 376000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 67.7421052631579\n",
      "    ram_util_percent: 34.3\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12441203552298613\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4948487230821901\n",
      "    mean_inference_ms: 2.5073447565918845\n",
      "    mean_raw_obs_processing_ms: 0.10999150721333939\n",
      "  time_since_restore: 1150.8289861679077\n",
      "  time_this_iter_s: 13.099965810775757\n",
      "  time_total_s: 1150.8289861679077\n",
      "  timers:\n",
      "    learn_throughput: 674.169\n",
      "    learn_time_ms: 5933.232\n",
      "    load_throughput: 20054047.334\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 316.378\n",
      "    sample_time_ms: 12643.093\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872364\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 376000\n",
      "  training_iteration: 94\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 376000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-39-27\n",
      "  done: false\n",
      "  episode_len_mean: 518.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8514519629124\n",
      "  episode_reward_mean: -110.5365656851824\n",
      "  episode_reward_min: -130.00708930930557\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 715\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.0194839474584456e-29\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.658385276794434\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.7265668361687858e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0033562963362783194\n",
      "          total_loss: 205.03269958496094\n",
      "          vf_explained_var: -3.519269739626907e-05\n",
      "          vf_loss: 205.02932739257812\n",
      "    num_agent_steps_sampled: 376000\n",
      "    num_agent_steps_trained: 376000\n",
      "    num_steps_sampled: 376000\n",
      "    num_steps_trained: 376000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.20526315789475\n",
      "    ram_util_percent: 34.31052631578947\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12611629938194768\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5014376629564229\n",
      "    mean_inference_ms: 2.5699112434787095\n",
      "    mean_raw_obs_processing_ms: 0.11685936572582692\n",
      "  time_since_restore: 1153.830946445465\n",
      "  time_this_iter_s: 13.32735538482666\n",
      "  time_total_s: 1153.830946445465\n",
      "  timers:\n",
      "    learn_throughput: 679.941\n",
      "    learn_time_ms: 5882.866\n",
      "    load_throughput: 6683350.994\n",
      "    load_time_ms: 0.599\n",
      "    sample_throughput: 315.213\n",
      "    sample_time_ms: 12689.843\n",
      "    update_time_ms: 2.095\n",
      "  timestamp: 1641872367\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 376000\n",
      "  training_iteration: 94\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:39:28 (running for 00:19:32.13)<br>Memory usage on this node: 8.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         1150.83</td><td style=\"text-align: right;\">376000</td><td style=\"text-align: right;\">  91.4653</td><td style=\"text-align: right;\">            163.136 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1589.61</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         1153.83</td><td style=\"text-align: right;\">376000</td><td style=\"text-align: right;\">-110.537 </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            518.2 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:39:33 (running for 00:19:37.19)<br>Memory usage on this node: 8.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         1150.83</td><td style=\"text-align: right;\">376000</td><td style=\"text-align: right;\">  91.4653</td><td style=\"text-align: right;\">            163.136 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1589.61</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         1153.83</td><td style=\"text-align: right;\">376000</td><td style=\"text-align: right;\">-110.537 </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            518.2 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 380000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-39-37\n",
      "  done: false\n",
      "  episode_len_mean: 1589.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 163.13559083859153\n",
      "  episode_reward_mean: 97.27242557875958\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 339\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.452219009399414\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008226481266319752\n",
      "          model: {}\n",
      "          policy_loss: -0.015754569321870804\n",
      "          total_loss: 2.915722608566284\n",
      "          vf_explained_var: 0.7069216966629028\n",
      "          vf_loss: 2.922106981277466\n",
      "    num_agent_steps_sampled: 380000\n",
      "    num_agent_steps_trained: 380000\n",
      "    num_steps_sampled: 380000\n",
      "    num_steps_trained: 380000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.77894736842104\n",
      "    ram_util_percent: 34.431578947368415\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12455139307558837\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49507794116676307\n",
      "    mean_inference_ms: 2.5090635546066067\n",
      "    mean_raw_obs_processing_ms: 0.11004467145844131\n",
      "  time_since_restore: 1164.207206249237\n",
      "  time_this_iter_s: 13.378220081329346\n",
      "  time_total_s: 1164.207206249237\n",
      "  timers:\n",
      "    learn_throughput: 669.264\n",
      "    learn_time_ms: 5976.715\n",
      "    load_throughput: 40117685.318\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 314.575\n",
      "    sample_time_ms: 12715.563\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872377\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 380000\n",
      "  training_iteration: 95\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:39:38 (running for 00:19:42.51)<br>Memory usage on this node: 8.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         1164.21</td><td style=\"text-align: right;\">380000</td><td style=\"text-align: right;\">  97.2724</td><td style=\"text-align: right;\">            163.136 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1589.61</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         1153.83</td><td style=\"text-align: right;\">376000</td><td style=\"text-align: right;\">-110.537 </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            518.2 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 380000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-39-40\n",
      "  done: false\n",
      "  episode_len_mean: 548.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8514519629124\n",
      "  episode_reward_mean: -110.50031198585066\n",
      "  episode_reward_min: -130.00708930930557\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 718\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0097419737292228e-29\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659261703491211\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.897124258855911e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0034981549251824617\n",
      "          total_loss: 126.16777801513672\n",
      "          vf_explained_var: 0.0004613650089595467\n",
      "          vf_loss: 126.1642837524414\n",
      "    num_agent_steps_sampled: 380000\n",
      "    num_agent_steps_trained: 380000\n",
      "    num_steps_sampled: 380000\n",
      "    num_steps_trained: 380000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.88947368421053\n",
      "    ram_util_percent: 34.44210526315789\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12612954565078288\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5014807692046857\n",
      "    mean_inference_ms: 2.570180750915341\n",
      "    mean_raw_obs_processing_ms: 0.1168454831852756\n",
      "  time_since_restore: 1167.3787143230438\n",
      "  time_this_iter_s: 13.547767877578735\n",
      "  time_total_s: 1167.3787143230438\n",
      "  timers:\n",
      "    learn_throughput: 674.747\n",
      "    learn_time_ms: 5928.145\n",
      "    load_throughput: 6683350.994\n",
      "    load_time_ms: 0.599\n",
      "    sample_throughput: 312.931\n",
      "    sample_time_ms: 12782.384\n",
      "    update_time_ms: 2.095\n",
      "  timestamp: 1641872380\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 380000\n",
      "  training_iteration: 95\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:39:44 (running for 00:19:47.73)<br>Memory usage on this node: 8.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         1164.21</td><td style=\"text-align: right;\">380000</td><td style=\"text-align: right;\">  97.2724</td><td style=\"text-align: right;\">            163.136 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1589.61</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         1167.38</td><td style=\"text-align: right;\">380000</td><td style=\"text-align: right;\">-110.5   </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            548.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:39:49 (running for 00:19:52.79)<br>Memory usage on this node: 9.3/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         1164.21</td><td style=\"text-align: right;\">380000</td><td style=\"text-align: right;\">  97.2724</td><td style=\"text-align: right;\">            163.136 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1589.61</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         1167.38</td><td style=\"text-align: right;\">380000</td><td style=\"text-align: right;\">-110.5   </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            548.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 384000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-39-51\n",
      "  done: false\n",
      "  episode_len_mean: 1589.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 163.13559083859153\n",
      "  episode_reward_mean: 99.92966619117863\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 341\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.363255262374878\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008198278024792671\n",
      "          model: {}\n",
      "          policy_loss: -0.022670799866318703\n",
      "          total_loss: 2.674921751022339\n",
      "          vf_explained_var: 0.7478581666946411\n",
      "          vf_loss: 2.6882541179656982\n",
      "    num_agent_steps_sampled: 384000\n",
      "    num_agent_steps_trained: 384000\n",
      "    num_steps_sampled: 384000\n",
      "    num_steps_trained: 384000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.3578947368421\n",
      "    ram_util_percent: 35.1578947368421\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12462273024024124\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4952008142395192\n",
      "    mean_inference_ms: 2.5099842875876486\n",
      "    mean_raw_obs_processing_ms: 0.1100757375211304\n",
      "  time_since_restore: 1177.8098278045654\n",
      "  time_this_iter_s: 13.60262155532837\n",
      "  time_total_s: 1177.8098278045654\n",
      "  timers:\n",
      "    learn_throughput: 662.104\n",
      "    learn_time_ms: 6041.343\n",
      "    load_throughput: 40117685.318\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 312.506\n",
      "    sample_time_ms: 12799.742\n",
      "    update_time_ms: 2.394\n",
      "  timestamp: 1641872391\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 384000\n",
      "  training_iteration: 96\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:39:54 (running for 00:19:58.16)<br>Memory usage on this node: 8.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         1177.81</td><td style=\"text-align: right;\">384000</td><td style=\"text-align: right;\">  99.9297</td><td style=\"text-align: right;\">            163.136 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1589.61</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         1167.38</td><td style=\"text-align: right;\">380000</td><td style=\"text-align: right;\">-110.5   </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            548.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 384000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-39-54\n",
      "  done: false\n",
      "  episode_len_mean: 501.17\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8514519629124\n",
      "  episode_reward_mean: -109.79081574434817\n",
      "  episode_reward_min: -130.00708930930557\n",
      "  episodes_this_iter: 15\n",
      "  episodes_total: 733\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 5.048709868646114e-30\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659641742706299\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.1272083472467784e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.004217193927615881\n",
      "          total_loss: 1037.8970947265625\n",
      "          vf_explained_var: 0.00016192153270822018\n",
      "          vf_loss: 1037.892822265625\n",
      "    num_agent_steps_sampled: 384000\n",
      "    num_agent_steps_trained: 384000\n",
      "    num_steps_sampled: 384000\n",
      "    num_steps_trained: 384000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.83157894736841\n",
      "    ram_util_percent: 35.699999999999996\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12620743546686478\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5017302933675174\n",
      "    mean_inference_ms: 2.57172376483602\n",
      "    mean_raw_obs_processing_ms: 0.11681992081279148\n",
      "  time_since_restore: 1181.2137143611908\n",
      "  time_this_iter_s: 13.835000038146973\n",
      "  time_total_s: 1181.2137143611908\n",
      "  timers:\n",
      "    learn_throughput: 666.65\n",
      "    learn_time_ms: 6000.153\n",
      "    load_throughput: 8020085.09\n",
      "    load_time_ms: 0.499\n",
      "    sample_throughput: 310.753\n",
      "    sample_time_ms: 12871.958\n",
      "    update_time_ms: 2.095\n",
      "  timestamp: 1641872394\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 384000\n",
      "  training_iteration: 96\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:39:59 (running for 00:20:03.61)<br>Memory usage on this node: 8.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         1177.81</td><td style=\"text-align: right;\">384000</td><td style=\"text-align: right;\">  99.9297</td><td style=\"text-align: right;\">            163.136 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1589.61</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         1181.21</td><td style=\"text-align: right;\">384000</td><td style=\"text-align: right;\">-109.791 </td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            501.17</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 388000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-40-04\n",
      "  done: false\n",
      "  episode_len_mean: 1589.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 166.15866728565484\n",
      "  episode_reward_mean: 102.68174431101733\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 343\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2904661893844604\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009309056214988232\n",
      "          model: {}\n",
      "          policy_loss: -0.02138456329703331\n",
      "          total_loss: 3.5630524158477783\n",
      "          vf_explained_var: 0.7741244435310364\n",
      "          vf_loss: 3.573833465576172\n",
      "    num_agent_steps_sampled: 388000\n",
      "    num_agent_steps_trained: 388000\n",
      "    num_steps_sampled: 388000\n",
      "    num_steps_trained: 388000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.80000000000001\n",
      "    ram_util_percent: 37.31666666666666\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12469621032436462\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4953336495364484\n",
      "    mean_inference_ms: 2.5109415031028\n",
      "    mean_raw_obs_processing_ms: 0.11011017241149221\n",
      "  time_since_restore: 1190.8948318958282\n",
      "  time_this_iter_s: 13.085004091262817\n",
      "  time_total_s: 1190.8948318958282\n",
      "  timers:\n",
      "    learn_throughput: 661.864\n",
      "    learn_time_ms: 6043.537\n",
      "    load_throughput: 20054047.334\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 309.933\n",
      "    sample_time_ms: 12906.03\n",
      "    update_time_ms: 2.393\n",
      "  timestamp: 1641872404\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 388000\n",
      "  training_iteration: 97\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:40:05 (running for 00:20:09.24)<br>Memory usage on this node: 8.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         1190.89</td><td style=\"text-align: right;\">388000</td><td style=\"text-align: right;\"> 102.682</td><td style=\"text-align: right;\">            166.159 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1589.61</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         1181.21</td><td style=\"text-align: right;\">384000</td><td style=\"text-align: right;\">-109.791</td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            501.17</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 388000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-40-07\n",
      "  done: false\n",
      "  episode_len_mean: 516.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8514519629124\n",
      "  episode_reward_mean: -109.89647910047563\n",
      "  episode_reward_min: -130.00708930930557\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 736\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.524354934323057e-30\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.658997058868408\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.8698378312365094e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0016011405969038606\n",
      "          total_loss: 133.4419708251953\n",
      "          vf_explained_var: -6.208060949575156e-05\n",
      "          vf_loss: 133.4403533935547\n",
      "    num_agent_steps_sampled: 388000\n",
      "    num_agent_steps_trained: 388000\n",
      "    num_steps_sampled: 388000\n",
      "    num_steps_trained: 388000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.19473684210527\n",
      "    ram_util_percent: 37.38947368421052\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12620740225291055\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5018463678288932\n",
      "    mean_inference_ms: 2.5718887675339372\n",
      "    mean_raw_obs_processing_ms: 0.1168395608765312\n",
      "  time_since_restore: 1194.356563091278\n",
      "  time_this_iter_s: 13.14284873008728\n",
      "  time_total_s: 1194.356563091278\n",
      "  timers:\n",
      "    learn_throughput: 666.749\n",
      "    learn_time_ms: 5999.255\n",
      "    load_throughput: 8020085.09\n",
      "    load_time_ms: 0.499\n",
      "    sample_throughput: 307.894\n",
      "    sample_time_ms: 12991.475\n",
      "    update_time_ms: 2.095\n",
      "  timestamp: 1641872407\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 388000\n",
      "  training_iteration: 97\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:40:11 (running for 00:20:14.76)<br>Memory usage on this node: 8.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         1190.89</td><td style=\"text-align: right;\">388000</td><td style=\"text-align: right;\"> 102.682</td><td style=\"text-align: right;\">            166.159 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1589.61</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         1194.36</td><td style=\"text-align: right;\">388000</td><td style=\"text-align: right;\">-109.896</td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            516.61</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:40:16 (running for 00:20:19.82)<br>Memory usage on this node: 8.9/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         1190.89</td><td style=\"text-align: right;\">388000</td><td style=\"text-align: right;\"> 102.682</td><td style=\"text-align: right;\">            166.159 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1589.61</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         1194.36</td><td style=\"text-align: right;\">388000</td><td style=\"text-align: right;\">-109.896</td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            516.61</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 392000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-40-16\n",
      "  done: false\n",
      "  episode_len_mean: 1589.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 171.60408604289543\n",
      "  episode_reward_mean: 105.39848430804491\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 345\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.377575159072876\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009688394144177437\n",
      "          model: {}\n",
      "          policy_loss: -0.02340083383023739\n",
      "          total_loss: 2.1285579204559326\n",
      "          vf_explained_var: 0.788147509098053\n",
      "          vf_loss: 2.140923261642456\n",
      "    num_agent_steps_sampled: 392000\n",
      "    num_agent_steps_trained: 392000\n",
      "    num_steps_sampled: 392000\n",
      "    num_steps_trained: 392000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.73888888888889\n",
      "    ram_util_percent: 37.455555555555556\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12476742202594114\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4954688553424587\n",
      "    mean_inference_ms: 2.5119156349717837\n",
      "    mean_raw_obs_processing_ms: 0.11014470588548443\n",
      "  time_since_restore: 1203.155042886734\n",
      "  time_this_iter_s: 12.260210990905762\n",
      "  time_total_s: 1203.155042886734\n",
      "  timers:\n",
      "    learn_throughput: 663.605\n",
      "    learn_time_ms: 6027.679\n",
      "    load_throughput: 13374693.878\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 310.315\n",
      "    sample_time_ms: 12890.138\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872416\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 392000\n",
      "  training_iteration: 98\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 392000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-40-20\n",
      "  done: false\n",
      "  episode_len_mean: 531.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8514519629124\n",
      "  episode_reward_mean: -109.72614166550103\n",
      "  episode_reward_min: -130.00708930930557\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 744\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2621774671615285e-30\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.658658027648926\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.4866713488336245e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003507862100377679\n",
      "          total_loss: 600.0928344726562\n",
      "          vf_explained_var: 0.00032450319849886\n",
      "          vf_loss: 600.0892944335938\n",
      "    num_agent_steps_sampled: 392000\n",
      "    num_agent_steps_trained: 392000\n",
      "    num_steps_sampled: 392000\n",
      "    num_steps_trained: 392000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.04705882352941\n",
      "    ram_util_percent: 37.44117647058823\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12621251448644566\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5021968673428399\n",
      "    mean_inference_ms: 2.572057604889547\n",
      "    mean_raw_obs_processing_ms: 0.11688629243686276\n",
      "  time_since_restore: 1206.7065320014954\n",
      "  time_this_iter_s: 12.349968910217285\n",
      "  time_total_s: 1206.7065320014954\n",
      "  timers:\n",
      "    learn_throughput: 666.749\n",
      "    learn_time_ms: 5999.255\n",
      "    load_throughput: 10024028.201\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 308.643\n",
      "    sample_time_ms: 12959.953\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641872420\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 392000\n",
      "  training_iteration: 98\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:40:21 (running for 00:20:25.11)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         1203.16</td><td style=\"text-align: right;\">392000</td><td style=\"text-align: right;\"> 105.398</td><td style=\"text-align: right;\">            171.604 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1589.61</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         1206.71</td><td style=\"text-align: right;\">392000</td><td style=\"text-align: right;\">-109.726</td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            531.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:40:26 (running for 00:20:30.17)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         1203.16</td><td style=\"text-align: right;\">392000</td><td style=\"text-align: right;\"> 105.398</td><td style=\"text-align: right;\">            171.604 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1589.61</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         1206.71</td><td style=\"text-align: right;\">392000</td><td style=\"text-align: right;\">-109.726</td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            531.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 396000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-40-29\n",
      "  done: false\n",
      "  episode_len_mean: 1588.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 171.60408604289543\n",
      "  episode_reward_mean: 108.82678436277554\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 349\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.7161215543746948\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0055700610391795635\n",
      "          model: {}\n",
      "          policy_loss: -0.022420860826969147\n",
      "          total_loss: 84.85203552246094\n",
      "          vf_explained_var: 0.540005624294281\n",
      "          vf_loss: 84.86811065673828\n",
      "    num_agent_steps_sampled: 396000\n",
      "    num_agent_steps_trained: 396000\n",
      "    num_steps_sampled: 396000\n",
      "    num_steps_trained: 396000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.07058823529412\n",
      "    ram_util_percent: 37.60588235294118\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12491290132061113\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4957402860192983\n",
      "    mean_inference_ms: 2.513892971580798\n",
      "    mean_raw_obs_processing_ms: 0.11021551884031554\n",
      "  time_since_restore: 1215.5798127651215\n",
      "  time_this_iter_s: 12.424769878387451\n",
      "  time_total_s: 1215.5798127651215\n",
      "  timers:\n",
      "    learn_throughput: 664.782\n",
      "    learn_time_ms: 6017.008\n",
      "    load_throughput: 20063640.277\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 311.418\n",
      "    sample_time_ms: 12844.486\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872429\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 396000\n",
      "  training_iteration: 99\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:40:32 (running for 00:20:36.02)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         1215.58</td><td style=\"text-align: right;\">396000</td><td style=\"text-align: right;\"> 108.827</td><td style=\"text-align: right;\">            171.604 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         1206.71</td><td style=\"text-align: right;\">392000</td><td style=\"text-align: right;\">-109.726</td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            531.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 396000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-40-32\n",
      "  done: false\n",
      "  episode_len_mean: 532.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8514519629124\n",
      "  episode_reward_mean: -110.2183099925359\n",
      "  episode_reward_min: -130.00708930930557\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 752\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 6.3108873358076425e-31\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.658331394195557\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.2468781562802178e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0030857704114168882\n",
      "          total_loss: 499.81927490234375\n",
      "          vf_explained_var: -0.0006769589963369071\n",
      "          vf_loss: 499.8161926269531\n",
      "    num_agent_steps_sampled: 396000\n",
      "    num_agent_steps_trained: 396000\n",
      "    num_steps_sampled: 396000\n",
      "    num_steps_trained: 396000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.87777777777777\n",
      "    ram_util_percent: 37.655555555555566\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12621550237273524\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.502510497586216\n",
      "    mean_inference_ms: 2.572178498849096\n",
      "    mean_raw_obs_processing_ms: 0.11694031022462942\n",
      "  time_since_restore: 1219.1582291126251\n",
      "  time_this_iter_s: 12.45169711112976\n",
      "  time_total_s: 1219.1582291126251\n",
      "  timers:\n",
      "    learn_throughput: 666.118\n",
      "    learn_time_ms: 6004.94\n",
      "    load_throughput: 8017785.424\n",
      "    load_time_ms: 0.499\n",
      "    sample_throughput: 309.151\n",
      "    sample_time_ms: 12938.649\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641872432\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 396000\n",
      "  training_iteration: 99\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:40:37 (running for 00:20:41.63)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         1215.58</td><td style=\"text-align: right;\">396000</td><td style=\"text-align: right;\"> 108.827</td><td style=\"text-align: right;\">            171.604 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         1219.16</td><td style=\"text-align: right;\">396000</td><td style=\"text-align: right;\">-110.218</td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            532.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 400000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-40-41\n",
      "  done: false\n",
      "  episode_len_mean: 1588.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 175.50134324223671\n",
      "  episode_reward_mean: 111.12944906047613\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 351\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.4090988636016846\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009699253365397453\n",
      "          model: {}\n",
      "          policy_loss: -0.02410813979804516\n",
      "          total_loss: 2.640293598175049\n",
      "          vf_explained_var: 0.6088830232620239\n",
      "          vf_loss: 2.6533539295196533\n",
      "    num_agent_steps_sampled: 400000\n",
      "    num_agent_steps_trained: 400000\n",
      "    num_steps_sampled: 400000\n",
      "    num_steps_trained: 400000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.64117647058824\n",
      "    ram_util_percent: 37.670588235294126\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12498363551206887\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4958714195814484\n",
      "    mean_inference_ms: 2.5148831743016276\n",
      "    mean_raw_obs_processing_ms: 0.11025017886046552\n",
      "  time_since_restore: 1227.8011274337769\n",
      "  time_this_iter_s: 12.221314668655396\n",
      "  time_total_s: 1227.8011274337769\n",
      "  timers:\n",
      "    learn_throughput: 665.51\n",
      "    learn_time_ms: 6010.425\n",
      "    load_throughput: 20063640.277\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 312.425\n",
      "    sample_time_ms: 12803.07\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641872441\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 400000\n",
      "  training_iteration: 100\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:40:43 (running for 00:20:47.25)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         1227.8 </td><td style=\"text-align: right;\">400000</td><td style=\"text-align: right;\"> 111.129</td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         1219.16</td><td style=\"text-align: right;\">396000</td><td style=\"text-align: right;\">-110.218</td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            532.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 400000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-40-45\n",
      "  done: false\n",
      "  episode_len_mean: 547.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8514519629124\n",
      "  episode_reward_mean: -110.8028755259071\n",
      "  episode_reward_min: -130.00708930930557\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 758\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.1554436679038213e-31\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659543991088867\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.9499244053331495e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0034158097114413977\n",
      "          total_loss: 349.70147705078125\n",
      "          vf_explained_var: 0.0007704033050686121\n",
      "          vf_loss: 349.69805908203125\n",
      "    num_agent_steps_sampled: 400000\n",
      "    num_agent_steps_trained: 400000\n",
      "    num_steps_sampled: 400000\n",
      "    num_steps_trained: 400000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.911764705882355\n",
      "    ram_util_percent: 37.65882352941178\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12623710797407375\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5026094778623341\n",
      "    mean_inference_ms: 2.5724762537467467\n",
      "    mean_raw_obs_processing_ms: 0.11695645898614034\n",
      "  time_since_restore: 1231.5002210140228\n",
      "  time_this_iter_s: 12.341991901397705\n",
      "  time_total_s: 1231.5002210140228\n",
      "  timers:\n",
      "    learn_throughput: 666.583\n",
      "    learn_time_ms: 6000.751\n",
      "    load_throughput: 10021034.524\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 309.523\n",
      "    sample_time_ms: 12923.106\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641872445\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 400000\n",
      "  training_iteration: 100\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:40:49 (running for 00:20:52.97)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">          1227.8</td><td style=\"text-align: right;\">400000</td><td style=\"text-align: right;\"> 111.129</td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">          1231.5</td><td style=\"text-align: right;\">400000</td><td style=\"text-align: right;\">-110.803</td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            547.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 404000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-40-53\n",
      "  done: false\n",
      "  episode_len_mean: 1588.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 175.50134324223671\n",
      "  episode_reward_mean: 113.37994870108\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 353\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.4507046937942505\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008841080591082573\n",
      "          model: {}\n",
      "          policy_loss: -0.013764502480626106\n",
      "          total_loss: 2.345942497253418\n",
      "          vf_explained_var: 0.7545257210731506\n",
      "          vf_loss: 2.3496367931365967\n",
      "    num_agent_steps_sampled: 404000\n",
      "    num_agent_steps_trained: 404000\n",
      "    num_steps_sampled: 404000\n",
      "    num_steps_trained: 404000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.07222222222222\n",
      "    ram_util_percent: 37.66666666666667\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1250538443308452\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49599572758054833\n",
      "    mean_inference_ms: 2.5158514551191904\n",
      "    mean_raw_obs_processing_ms: 0.11028270600859556\n",
      "  time_since_restore: 1240.0623359680176\n",
      "  time_this_iter_s: 12.261208534240723\n",
      "  time_total_s: 1240.0623359680176\n",
      "  timers:\n",
      "    learn_throughput: 665.93\n",
      "    learn_time_ms: 6006.636\n",
      "    load_throughput: 20063640.277\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 313.217\n",
      "    sample_time_ms: 12770.706\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641872453\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 404000\n",
      "  training_iteration: 101\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:40:54 (running for 00:20:58.53)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         1240.06</td><td style=\"text-align: right;\">404000</td><td style=\"text-align: right;\"> 113.38 </td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         1231.5 </td><td style=\"text-align: right;\">400000</td><td style=\"text-align: right;\">-110.803</td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            547.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 404000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-40-57\n",
      "  done: false\n",
      "  episode_len_mean: 562.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8514519629124\n",
      "  episode_reward_mean: -110.67246525688492\n",
      "  episode_reward_min: -130.00708930930557\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 762\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5777218339519106e-31\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.660579204559326\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.646605992140394e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.002832022262737155\n",
      "          total_loss: 150.95068359375\n",
      "          vf_explained_var: -0.000367959204595536\n",
      "          vf_loss: 150.94784545898438\n",
      "    num_agent_steps_sampled: 404000\n",
      "    num_agent_steps_trained: 404000\n",
      "    num_steps_sampled: 404000\n",
      "    num_steps_trained: 404000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.811764705882354\n",
      "    ram_util_percent: 37.694117647058825\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12624939750202488\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5026651269125582\n",
      "    mean_inference_ms: 2.572640110891099\n",
      "    mean_raw_obs_processing_ms: 0.1169560402809203\n",
      "  time_since_restore: 1243.6985964775085\n",
      "  time_this_iter_s: 12.198375463485718\n",
      "  time_total_s: 1243.6985964775085\n",
      "  timers:\n",
      "    learn_throughput: 667.005\n",
      "    learn_time_ms: 5996.961\n",
      "    load_throughput: 10021034.524\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 310.433\n",
      "    sample_time_ms: 12885.24\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641872457\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 404000\n",
      "  training_iteration: 101\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:41:00 (running for 00:21:04.18)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         1240.06</td><td style=\"text-align: right;\">404000</td><td style=\"text-align: right;\"> 113.38 </td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         1243.7 </td><td style=\"text-align: right;\">404000</td><td style=\"text-align: right;\">-110.672</td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            562.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:41:05 (running for 00:21:09.24)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         1240.06</td><td style=\"text-align: right;\">404000</td><td style=\"text-align: right;\"> 113.38 </td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         1243.7 </td><td style=\"text-align: right;\">404000</td><td style=\"text-align: right;\">-110.672</td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -130.007 </td><td style=\"text-align: right;\">            562.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 408000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-41-05\n",
      "  done: false\n",
      "  episode_len_mean: 1588.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 175.50134324223671\n",
      "  episode_reward_mean: 115.6497657172036\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 355\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.314666986465454\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008687617257237434\n",
      "          model: {}\n",
      "          policy_loss: -0.02584126964211464\n",
      "          total_loss: 3.9518113136291504\n",
      "          vf_explained_var: 0.7134891748428345\n",
      "          vf_loss: 3.967756748199463\n",
      "    num_agent_steps_sampled: 408000\n",
      "    num_agent_steps_trained: 408000\n",
      "    num_steps_sampled: 408000\n",
      "    num_steps_trained: 408000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.50588235294117\n",
      "    ram_util_percent: 37.77647058823529\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12511895712030405\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4961027266000126\n",
      "    mean_inference_ms: 2.5167597555025436\n",
      "    mean_raw_obs_processing_ms: 0.11031605878714629\n",
      "  time_since_restore: 1252.2427594661713\n",
      "  time_this_iter_s: 12.180423498153687\n",
      "  time_total_s: 1252.2427594661713\n",
      "  timers:\n",
      "    learn_throughput: 666.683\n",
      "    learn_time_ms: 5999.854\n",
      "    load_throughput: 20063640.277\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 313.891\n",
      "    sample_time_ms: 12743.284\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641872465\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 408000\n",
      "  training_iteration: 102\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 408000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-41-09\n",
      "  done: false\n",
      "  episode_len_mean: 592.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8514519629124\n",
      "  episode_reward_mean: -110.34468869410048\n",
      "  episode_reward_min: -126.93009018911908\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 766\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 7.888609169759553e-32\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659754276275635\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.9088308767532e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0037564353551715612\n",
      "          total_loss: 211.0908203125\n",
      "          vf_explained_var: -0.0002799883368425071\n",
      "          vf_loss: 211.08706665039062\n",
      "    num_agent_steps_sampled: 408000\n",
      "    num_agent_steps_trained: 408000\n",
      "    num_steps_sampled: 408000\n",
      "    num_steps_trained: 408000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.25555555555556\n",
      "    ram_util_percent: 37.79999999999999\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1262659500377749\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5026872059222434\n",
      "    mean_inference_ms: 2.572862456031146\n",
      "    mean_raw_obs_processing_ms: 0.11694027423370038\n",
      "  time_since_restore: 1255.9907228946686\n",
      "  time_this_iter_s: 12.292126417160034\n",
      "  time_total_s: 1255.9907228946686\n",
      "  timers:\n",
      "    learn_throughput: 668.728\n",
      "    learn_time_ms: 5981.502\n",
      "    load_throughput: 10021034.524\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 311.221\n",
      "    sample_time_ms: 12852.587\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641872469\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 408000\n",
      "  training_iteration: 102\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:41:10 (running for 00:21:14.48)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         1252.24</td><td style=\"text-align: right;\">408000</td><td style=\"text-align: right;\"> 115.65 </td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         1255.99</td><td style=\"text-align: right;\">408000</td><td style=\"text-align: right;\">-110.345</td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -126.93  </td><td style=\"text-align: right;\">            592.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:41:15 (running for 00:21:19.52)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         1252.24</td><td style=\"text-align: right;\">408000</td><td style=\"text-align: right;\"> 115.65 </td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         1255.99</td><td style=\"text-align: right;\">408000</td><td style=\"text-align: right;\">-110.345</td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -126.93  </td><td style=\"text-align: right;\">            592.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 412000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-41-18\n",
      "  done: false\n",
      "  episode_len_mean: 1588.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 175.50134324223671\n",
      "  episode_reward_mean: 119.90874580280146\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 359\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.7170093059539795\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00652113975957036\n",
      "          model: {}\n",
      "          policy_loss: -0.02192678116261959\n",
      "          total_loss: 4.037185192108154\n",
      "          vf_explained_var: 0.5399156808853149\n",
      "          vf_loss: 4.0516839027404785\n",
      "    num_agent_steps_sampled: 412000\n",
      "    num_agent_steps_trained: 412000\n",
      "    num_steps_sampled: 412000\n",
      "    num_steps_trained: 412000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.917647058823526\n",
      "    ram_util_percent: 37.829411764705874\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12523766918127158\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49628209835448955\n",
      "    mean_inference_ms: 2.518436235583601\n",
      "    mean_raw_obs_processing_ms: 0.11037209098916037\n",
      "  time_since_restore: 1264.4102172851562\n",
      "  time_this_iter_s: 12.167457818984985\n",
      "  time_total_s: 1264.4102172851562\n",
      "  timers:\n",
      "    learn_throughput: 667.715\n",
      "    learn_time_ms: 5990.578\n",
      "    load_throughput: 20063640.277\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 314.865\n",
      "    sample_time_ms: 12703.874\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641872478\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 412000\n",
      "  training_iteration: 103\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:41:21 (running for 00:21:24.95)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         1264.41</td><td style=\"text-align: right;\">412000</td><td style=\"text-align: right;\"> 119.909</td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         1255.99</td><td style=\"text-align: right;\">408000</td><td style=\"text-align: right;\">-110.345</td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -126.93  </td><td style=\"text-align: right;\">            592.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 412000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-41-22\n",
      "  done: false\n",
      "  episode_len_mean: 623.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -94.8514519629124\n",
      "  episode_reward_mean: -110.42185244431657\n",
      "  episode_reward_min: -126.93009018911908\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 772\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.9443045848797766e-32\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659461975097656\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 4.0878074969441514e-07\n",
      "          model: {}\n",
      "          policy_loss: -0.035324130207300186\n",
      "          total_loss: 255.7049102783203\n",
      "          vf_explained_var: 0.0002549152122810483\n",
      "          vf_loss: 255.740234375\n",
      "    num_agent_steps_sampled: 412000\n",
      "    num_agent_steps_trained: 412000\n",
      "    num_steps_sampled: 412000\n",
      "    num_steps_trained: 412000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.652941176470584\n",
      "    ram_util_percent: 37.87058823529411\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12624845122834732\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.502857879598189\n",
      "    mean_inference_ms: 2.5726698116635767\n",
      "    mean_raw_obs_processing_ms: 0.11697146311539854\n",
      "  time_since_restore: 1268.2409613132477\n",
      "  time_this_iter_s: 12.250238418579102\n",
      "  time_total_s: 1268.2409613132477\n",
      "  timers:\n",
      "    learn_throughput: 669.834\n",
      "    learn_time_ms: 5971.629\n",
      "    load_throughput: 10024627.151\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 312.328\n",
      "    sample_time_ms: 12807.042\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641872482\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 412000\n",
      "  training_iteration: 103\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:41:27 (running for 00:21:30.79)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         1264.41</td><td style=\"text-align: right;\">412000</td><td style=\"text-align: right;\"> 119.909</td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         1268.24</td><td style=\"text-align: right;\">412000</td><td style=\"text-align: right;\">-110.422</td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -126.93  </td><td style=\"text-align: right;\">            623.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 416000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-41-30\n",
      "  done: false\n",
      "  episode_len_mean: 1588.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 175.50134324223671\n",
      "  episode_reward_mean: 121.66837345199788\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 361\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.4710346460342407\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013843913562595844\n",
      "          model: {}\n",
      "          policy_loss: -0.017541108652949333\n",
      "          total_loss: 3.4678900241851807\n",
      "          vf_explained_var: 0.7295745015144348\n",
      "          vf_loss: 3.4696619510650635\n",
      "    num_agent_steps_sampled: 416000\n",
      "    num_agent_steps_trained: 416000\n",
      "    num_steps_sampled: 416000\n",
      "    num_steps_trained: 416000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.417647058823526\n",
      "    ram_util_percent: 37.8470588235294\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1252839283003923\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49634081474326697\n",
      "    mean_inference_ms: 2.5191295212513256\n",
      "    mean_raw_obs_processing_ms: 0.11039549520001475\n",
      "  time_since_restore: 1276.5886461734772\n",
      "  time_this_iter_s: 12.178428888320923\n",
      "  time_total_s: 1276.5886461734772\n",
      "  timers:\n",
      "    learn_throughput: 673.241\n",
      "    learn_time_ms: 5941.41\n",
      "    load_throughput: 20063640.277\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 316.152\n",
      "    sample_time_ms: 12652.155\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641872490\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 416000\n",
      "  training_iteration: 104\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:41:32 (running for 00:21:36.13)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         1276.59</td><td style=\"text-align: right;\">416000</td><td style=\"text-align: right;\"> 121.668</td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         1268.24</td><td style=\"text-align: right;\">412000</td><td style=\"text-align: right;\">-110.422</td><td style=\"text-align: right;\">            -94.8515</td><td style=\"text-align: right;\">           -126.93  </td><td style=\"text-align: right;\">            623.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 416000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-41-34\n",
      "  done: false\n",
      "  episode_len_mean: 639.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -99.80101821980625\n",
      "  episode_reward_mean: -110.77242055028327\n",
      "  episode_reward_min: -126.93009018911908\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 782\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.9721522924398883e-32\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659666061401367\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.612702812461066e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.00402740016579628\n",
      "          total_loss: 617.9295654296875\n",
      "          vf_explained_var: 0.0010035984450951219\n",
      "          vf_loss: 617.925537109375\n",
      "    num_agent_steps_sampled: 416000\n",
      "    num_agent_steps_trained: 416000\n",
      "    num_steps_sampled: 416000\n",
      "    num_steps_trained: 416000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.45882352941176\n",
      "    ram_util_percent: 37.83529411764705\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1262341752590977\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5030358685106314\n",
      "    mean_inference_ms: 2.572382594020866\n",
      "    mean_raw_obs_processing_ms: 0.1170046440078696\n",
      "  time_since_restore: 1280.5011720657349\n",
      "  time_this_iter_s: 12.260210752487183\n",
      "  time_total_s: 1280.5011720657349\n",
      "  timers:\n",
      "    learn_throughput: 674.373\n",
      "    learn_time_ms: 5931.436\n",
      "    load_throughput: 13368299.602\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 314.199\n",
      "    sample_time_ms: 12730.77\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641872494\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 416000\n",
      "  training_iteration: 104\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:41:38 (running for 00:21:42.06)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         1276.59</td><td style=\"text-align: right;\">416000</td><td style=\"text-align: right;\"> 121.668</td><td style=\"text-align: right;\">             175.501</td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         1280.5 </td><td style=\"text-align: right;\">416000</td><td style=\"text-align: right;\">-110.772</td><td style=\"text-align: right;\">             -99.801</td><td style=\"text-align: right;\">           -126.93  </td><td style=\"text-align: right;\">            639.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 420000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-41-42\n",
      "  done: false\n",
      "  episode_len_mean: 1588.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 175.50134324223671\n",
      "  episode_reward_mean: 123.19287095611702\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 363\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.4847606420516968\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007755092810839415\n",
      "          model: {}\n",
      "          policy_loss: -0.020545730367302895\n",
      "          total_loss: 2.5723633766174316\n",
      "          vf_explained_var: 0.7581648826599121\n",
      "          vf_loss: 2.584075689315796\n",
      "    num_agent_steps_sampled: 420000\n",
      "    num_agent_steps_trained: 420000\n",
      "    num_steps_sampled: 420000\n",
      "    num_steps_trained: 420000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.252941176470586\n",
      "    ram_util_percent: 37.87647058823529\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12532762661451352\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4963859018814772\n",
      "    mean_inference_ms: 2.5197526104348817\n",
      "    mean_raw_obs_processing_ms: 0.11041517880685486\n",
      "  time_since_restore: 1288.5646159648895\n",
      "  time_this_iter_s: 11.975969791412354\n",
      "  time_total_s: 1288.5646159648895\n",
      "  timers:\n",
      "    learn_throughput: 680.217\n",
      "    learn_time_ms: 5880.473\n",
      "    load_throughput: 20063640.277\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 319.407\n",
      "    sample_time_ms: 12523.201\n",
      "    update_time_ms: 1.994\n",
      "  timestamp: 1641872502\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 105\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:41:43 (running for 00:21:47.14)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         1288.56</td><td style=\"text-align: right;\">420000</td><td style=\"text-align: right;\"> 123.193</td><td style=\"text-align: right;\">             175.501</td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         1280.5 </td><td style=\"text-align: right;\">416000</td><td style=\"text-align: right;\">-110.772</td><td style=\"text-align: right;\">             -99.801</td><td style=\"text-align: right;\">           -126.93  </td><td style=\"text-align: right;\">            639.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 420000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-41-46\n",
      "  done: false\n",
      "  episode_len_mean: 640.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -99.80101821980625\n",
      "  episode_reward_mean: -110.54999807402339\n",
      "  episode_reward_min: -126.93009018911908\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 787\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 9.860761462199441e-33\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659496307373047\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.8242507710274367e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0018104204209521413\n",
      "          total_loss: 194.2996063232422\n",
      "          vf_explained_var: 0.0005404258263297379\n",
      "          vf_loss: 194.2978057861328\n",
      "    num_agent_steps_sampled: 420000\n",
      "    num_agent_steps_trained: 420000\n",
      "    num_steps_sampled: 420000\n",
      "    num_steps_trained: 420000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.870588235294115\n",
      "    ram_util_percent: 37.89411764705882\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12622287383097677\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5031114685253036\n",
      "    mean_inference_ms: 2.5721144870410177\n",
      "    mean_raw_obs_processing_ms: 0.11702257355902208\n",
      "  time_since_restore: 1292.6237514019012\n",
      "  time_this_iter_s: 12.122579336166382\n",
      "  time_total_s: 1292.6237514019012\n",
      "  timers:\n",
      "    learn_throughput: 680.714\n",
      "    learn_time_ms: 5876.184\n",
      "    load_throughput: 13368299.602\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 317.39\n",
      "    sample_time_ms: 12602.792\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641872506\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 105\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:41:48 (running for 00:21:52.18)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         1288.56</td><td style=\"text-align: right;\">420000</td><td style=\"text-align: right;\"> 123.193</td><td style=\"text-align: right;\">             175.501</td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         1292.62</td><td style=\"text-align: right;\">420000</td><td style=\"text-align: right;\">-110.55 </td><td style=\"text-align: right;\">             -99.801</td><td style=\"text-align: right;\">           -126.93  </td><td style=\"text-align: right;\">            640.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:41:53 (running for 00:21:57.24)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         1288.56</td><td style=\"text-align: right;\">420000</td><td style=\"text-align: right;\"> 123.193</td><td style=\"text-align: right;\">             175.501</td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         1292.62</td><td style=\"text-align: right;\">420000</td><td style=\"text-align: right;\">-110.55 </td><td style=\"text-align: right;\">             -99.801</td><td style=\"text-align: right;\">           -126.93  </td><td style=\"text-align: right;\">            640.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 424000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-41-54\n",
      "  done: false\n",
      "  episode_len_mean: 1588.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 175.50134324223671\n",
      "  episode_reward_mean: 124.79600538431879\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 365\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3711916208267212\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009160215966403484\n",
      "          model: {}\n",
      "          policy_loss: -0.017432190477848053\n",
      "          total_loss: 3.3246471881866455\n",
      "          vf_explained_var: 0.7125597596168518\n",
      "          vf_loss: 3.3316450119018555\n",
      "    num_agent_steps_sampled: 424000\n",
      "    num_agent_steps_trained: 424000\n",
      "    num_steps_sampled: 424000\n",
      "    num_steps_trained: 424000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.59999999999999\n",
      "    ram_util_percent: 37.88235294117647\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12536302760379867\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49641798432149764\n",
      "    mean_inference_ms: 2.5203172909863496\n",
      "    mean_raw_obs_processing_ms: 0.11043085057920371\n",
      "  time_since_restore: 1300.6562774181366\n",
      "  time_this_iter_s: 12.09166145324707\n",
      "  time_total_s: 1300.6562774181366\n",
      "  timers:\n",
      "    learn_throughput: 689.514\n",
      "    learn_time_ms: 5801.185\n",
      "    load_throughput: 20063640.277\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 322.813\n",
      "    sample_time_ms: 12391.085\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641872514\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 424000\n",
      "  training_iteration: 106\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:41:58 (running for 00:22:02.29)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         1300.66</td><td style=\"text-align: right;\">424000</td><td style=\"text-align: right;\"> 124.796</td><td style=\"text-align: right;\">             175.501</td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         1292.62</td><td style=\"text-align: right;\">420000</td><td style=\"text-align: right;\">-110.55 </td><td style=\"text-align: right;\">             -99.801</td><td style=\"text-align: right;\">           -126.93  </td><td style=\"text-align: right;\">            640.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 424000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-41-58\n",
      "  done: false\n",
      "  episode_len_mean: 594.06\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -99.40891600069031\n",
      "  episode_reward_mean: -109.9396260349939\n",
      "  episode_reward_min: -126.93009018911908\n",
      "  episodes_this_iter: 15\n",
      "  episodes_total: 802\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.930380731099721e-33\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.659892559051514\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.098577678883885e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.004530382342636585\n",
      "          total_loss: 1254.3548583984375\n",
      "          vf_explained_var: -8.220486779464409e-05\n",
      "          vf_loss: 1254.3502197265625\n",
      "    num_agent_steps_sampled: 424000\n",
      "    num_agent_steps_trained: 424000\n",
      "    num_steps_sampled: 424000\n",
      "    num_steps_trained: 424000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.616666666666674\n",
      "    ram_util_percent: 37.877777777777766\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12628721847003907\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.502935872140913\n",
      "    mean_inference_ms: 2.5722517954274395\n",
      "    mean_raw_obs_processing_ms: 0.1169760252986525\n",
      "  time_since_restore: 1304.980702161789\n",
      "  time_this_iter_s: 12.356950759887695\n",
      "  time_total_s: 1304.980702161789\n",
      "  timers:\n",
      "    learn_throughput: 688.248\n",
      "    learn_time_ms: 5811.856\n",
      "    load_throughput: 13368299.602\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 320.946\n",
      "    sample_time_ms: 12463.142\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641872518\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 424000\n",
      "  training_iteration: 106\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:42:03 (running for 00:22:07.61)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         1300.66</td><td style=\"text-align: right;\">424000</td><td style=\"text-align: right;\"> 124.796</td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         1304.98</td><td style=\"text-align: right;\">424000</td><td style=\"text-align: right;\">-109.94 </td><td style=\"text-align: right;\">            -99.4089</td><td style=\"text-align: right;\">           -126.93  </td><td style=\"text-align: right;\">            594.06</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 428000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-42-06\n",
      "  done: false\n",
      "  episode_len_mean: 1588.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 175.50134324223671\n",
      "  episode_reward_mean: 128.47885491966846\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 369\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.1587311029434204\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00919347070157528\n",
      "          model: {}\n",
      "          policy_loss: -0.017535272985696793\n",
      "          total_loss: 2.991722822189331\n",
      "          vf_explained_var: 0.7019264698028564\n",
      "          vf_loss: 2.998785972595215\n",
      "    num_agent_steps_sampled: 428000\n",
      "    num_agent_steps_trained: 428000\n",
      "    num_steps_sampled: 428000\n",
      "    num_steps_trained: 428000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.9470588235294\n",
      "    ram_util_percent: 37.88823529411765\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12541848678510412\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4964371362188932\n",
      "    mean_inference_ms: 2.5212577379698873\n",
      "    mean_raw_obs_processing_ms: 0.11045683038629203\n",
      "  time_since_restore: 1312.7339758872986\n",
      "  time_this_iter_s: 12.077698469161987\n",
      "  time_total_s: 1312.7339758872986\n",
      "  timers:\n",
      "    learn_throughput: 690.559\n",
      "    learn_time_ms: 5792.408\n",
      "    load_throughput: 40156093.825\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 327.346\n",
      "    sample_time_ms: 12219.469\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641872526\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 428000\n",
      "  training_iteration: 107\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:42:09 (running for 00:22:13.38)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         1312.73</td><td style=\"text-align: right;\">428000</td><td style=\"text-align: right;\"> 128.479</td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         1304.98</td><td style=\"text-align: right;\">424000</td><td style=\"text-align: right;\">-109.94 </td><td style=\"text-align: right;\">            -99.4089</td><td style=\"text-align: right;\">           -126.93  </td><td style=\"text-align: right;\">            594.06</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 428000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-42-10\n",
      "  done: false\n",
      "  episode_len_mean: 502.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -99.40891600069031\n",
      "  episode_reward_mean: -109.40639026401601\n",
      "  episode_reward_min: -124.37499354399368\n",
      "  episodes_this_iter: 15\n",
      "  episodes_total: 817\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.4651903655498604e-33\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.66049861907959\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.6065540598428925e-07\n",
      "          model: {}\n",
      "          policy_loss: -0.00884964969009161\n",
      "          total_loss: 1157.589599609375\n",
      "          vf_explained_var: 0.0011537420796230435\n",
      "          vf_loss: 1157.598388671875\n",
      "    num_agent_steps_sampled: 428000\n",
      "    num_agent_steps_trained: 428000\n",
      "    num_steps_sampled: 428000\n",
      "    num_steps_trained: 428000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.33529411764706\n",
      "    ram_util_percent: 37.88235294117647\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12624737686176835\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.503047604944212\n",
      "    mean_inference_ms: 2.5709628842349317\n",
      "    mean_raw_obs_processing_ms: 0.11703760095775191\n",
      "  time_since_restore: 1317.0673768520355\n",
      "  time_this_iter_s: 12.086674690246582\n",
      "  time_total_s: 1317.0673768520355\n",
      "  timers:\n",
      "    learn_throughput: 690.286\n",
      "    learn_time_ms: 5794.702\n",
      "    load_throughput: 13368299.602\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 324.933\n",
      "    sample_time_ms: 12310.237\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641872530\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 428000\n",
      "  training_iteration: 107\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:42:14 (running for 00:22:18.70)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         1312.73</td><td style=\"text-align: right;\">428000</td><td style=\"text-align: right;\"> 128.479</td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         1317.07</td><td style=\"text-align: right;\">428000</td><td style=\"text-align: right;\">-109.406</td><td style=\"text-align: right;\">            -99.4089</td><td style=\"text-align: right;\">           -124.375 </td><td style=\"text-align: right;\">            502.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 432000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-42-18\n",
      "  done: false\n",
      "  episode_len_mean: 1588.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 175.50134324223671\n",
      "  episode_reward_mean: 130.2991702358344\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 371\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.236232042312622\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009387176483869553\n",
      "          model: {}\n",
      "          policy_loss: -0.020391492173075676\n",
      "          total_loss: 2.290874481201172\n",
      "          vf_explained_var: 0.7486622333526611\n",
      "          vf_loss: 2.3005733489990234\n",
      "    num_agent_steps_sampled: 432000\n",
      "    num_agent_steps_trained: 432000\n",
      "    num_steps_sampled: 432000\n",
      "    num_steps_trained: 432000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.56470588235294\n",
      "    ram_util_percent: 37.870588235294115\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12544271287630798\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4964350400481863\n",
      "    mean_inference_ms: 2.5216719003350225\n",
      "    mean_raw_obs_processing_ms: 0.11047003565875455\n",
      "  time_since_restore: 1324.758816242218\n",
      "  time_this_iter_s: 12.024840354919434\n",
      "  time_total_s: 1324.758816242218\n",
      "  timers:\n",
      "    learn_throughput: 690.416\n",
      "    learn_time_ms: 5793.605\n",
      "    load_throughput: 0.0\n",
      "    load_time_ms: 0.0\n",
      "    sample_throughput: 328.251\n",
      "    sample_time_ms: 12185.785\n",
      "    update_time_ms: 1.695\n",
      "  timestamp: 1641872538\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 432000\n",
      "  training_iteration: 108\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:42:20 (running for 00:22:24.41)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         1324.76</td><td style=\"text-align: right;\">432000</td><td style=\"text-align: right;\"> 130.299</td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         1317.07</td><td style=\"text-align: right;\">428000</td><td style=\"text-align: right;\">-109.406</td><td style=\"text-align: right;\">            -99.4089</td><td style=\"text-align: right;\">           -124.375 </td><td style=\"text-align: right;\">            502.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 432000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-42-23\n",
      "  done: false\n",
      "  episode_len_mean: 503.16\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -98.558116856557\n",
      "  episode_reward_mean: -109.3189866581899\n",
      "  episode_reward_min: -124.37499354399368\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 825\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2325951827749302e-33\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663006782531738\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.6941458486362535e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0032657801639288664\n",
      "          total_loss: 461.11444091796875\n",
      "          vf_explained_var: 0.0006610288983210921\n",
      "          vf_loss: 461.1112365722656\n",
      "    num_agent_steps_sampled: 432000\n",
      "    num_agent_steps_trained: 432000\n",
      "    num_steps_sampled: 432000\n",
      "    num_steps_trained: 432000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.05294117647058\n",
      "    ram_util_percent: 37.8470588235294\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12618199784776762\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5030664380690806\n",
      "    mean_inference_ms: 2.5696557322166296\n",
      "    mean_raw_obs_processing_ms: 0.11705967918318587\n",
      "  time_since_restore: 1329.2697422504425\n",
      "  time_this_iter_s: 12.202365398406982\n",
      "  time_total_s: 1329.2697422504425\n",
      "  timers:\n",
      "    learn_throughput: 691.178\n",
      "    learn_time_ms: 5787.222\n",
      "    load_throughput: 13368299.602\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 325.575\n",
      "    sample_time_ms: 12285.973\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641872543\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 432000\n",
      "  training_iteration: 108\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:42:26 (running for 00:22:29.92)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         1324.76</td><td style=\"text-align: right;\">432000</td><td style=\"text-align: right;\"> 130.299</td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         1329.27</td><td style=\"text-align: right;\">432000</td><td style=\"text-align: right;\">-109.319</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -124.375 </td><td style=\"text-align: right;\">            503.16</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 436000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-42-30\n",
      "  done: false\n",
      "  episode_len_mean: 1588.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 175.50134324223671\n",
      "  episode_reward_mean: 131.7927846738383\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 373\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.4070773124694824\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00882292166352272\n",
      "          model: {}\n",
      "          policy_loss: -0.018439821898937225\n",
      "          total_loss: 2.7200374603271484\n",
      "          vf_explained_var: 0.7546628713607788\n",
      "          vf_loss: 2.7284271717071533\n",
      "    num_agent_steps_sampled: 436000\n",
      "    num_agent_steps_trained: 436000\n",
      "    num_steps_sampled: 436000\n",
      "    num_steps_trained: 436000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.370588235294115\n",
      "    ram_util_percent: 37.85882352941176\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12546205104650165\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4964246919802534\n",
      "    mean_inference_ms: 2.5220609263494804\n",
      "    mean_raw_obs_processing_ms: 0.11048365161986058\n",
      "  time_since_restore: 1336.7118482589722\n",
      "  time_this_iter_s: 11.95303201675415\n",
      "  time_total_s: 1336.7118482589722\n",
      "  timers:\n",
      "    learn_throughput: 690.405\n",
      "    learn_time_ms: 5793.705\n",
      "    load_throughput: 0.0\n",
      "    load_time_ms: 0.0\n",
      "    sample_throughput: 329.536\n",
      "    sample_time_ms: 12138.284\n",
      "    update_time_ms: 1.696\n",
      "  timestamp: 1641872550\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 436000\n",
      "  training_iteration: 109\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:42:31 (running for 00:22:35.37)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         1336.71</td><td style=\"text-align: right;\">436000</td><td style=\"text-align: right;\"> 131.793</td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         1329.27</td><td style=\"text-align: right;\">432000</td><td style=\"text-align: right;\">-109.319</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -124.375 </td><td style=\"text-align: right;\">            503.16</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 436000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-42-35\n",
      "  done: false\n",
      "  episode_len_mean: 549.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -98.558116856557\n",
      "  episode_reward_mean: -109.58922947794963\n",
      "  episode_reward_min: -124.37499354399368\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 829\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 6.162975913874651e-34\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.662779331207275\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.8269820145633275e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0035284366458654404\n",
      "          total_loss: 132.67054748535156\n",
      "          vf_explained_var: 0.0011754274601116776\n",
      "          vf_loss: 132.66702270507812\n",
      "    num_agent_steps_sampled: 436000\n",
      "    num_agent_steps_trained: 436000\n",
      "    num_steps_sampled: 436000\n",
      "    num_steps_trained: 436000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.07777777777778\n",
      "    ram_util_percent: 37.88333333333333\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12614066740162314\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5030851275329656\n",
      "    mean_inference_ms: 2.568896292645316\n",
      "    mean_raw_obs_processing_ms: 0.11706728807369539\n",
      "  time_since_restore: 1341.5289542675018\n",
      "  time_this_iter_s: 12.259212017059326\n",
      "  time_total_s: 1341.5289542675018\n",
      "  timers:\n",
      "    learn_throughput: 690.904\n",
      "    learn_time_ms: 5789.516\n",
      "    load_throughput: 20063640.277\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 326.332\n",
      "    sample_time_ms: 12257.469\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641872555\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 436000\n",
      "  training_iteration: 109\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:42:37 (running for 00:22:41.20)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         1336.71</td><td style=\"text-align: right;\">436000</td><td style=\"text-align: right;\"> 131.793</td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         1341.53</td><td style=\"text-align: right;\">436000</td><td style=\"text-align: right;\">-109.589</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -124.375 </td><td style=\"text-align: right;\">            549.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:42:42 (running for 00:22:46.26)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         1336.71</td><td style=\"text-align: right;\">436000</td><td style=\"text-align: right;\"> 131.793</td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         1341.53</td><td style=\"text-align: right;\">436000</td><td style=\"text-align: right;\">-109.589</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -124.375 </td><td style=\"text-align: right;\">            549.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 440000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-42-42\n",
      "  done: false\n",
      "  episode_len_mean: 1588.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 175.50134324223671\n",
      "  episode_reward_mean: 133.3862134808574\n",
      "  episode_reward_min: -77.15919584544807\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 375\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.9774604439735413\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012087118811905384\n",
      "          model: {}\n",
      "          policy_loss: -0.026000190526247025\n",
      "          total_loss: 2.2290542125701904\n",
      "          vf_explained_var: 0.7502945065498352\n",
      "          vf_loss: 2.241286516189575\n",
      "    num_agent_steps_sampled: 440000\n",
      "    num_agent_steps_trained: 440000\n",
      "    num_steps_sampled: 440000\n",
      "    num_steps_trained: 440000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.27058823529413\n",
      "    ram_util_percent: 37.91176470588235\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12547694715625884\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49640283256659584\n",
      "    mean_inference_ms: 2.5223816219258963\n",
      "    mean_raw_obs_processing_ms: 0.11049468789575254\n",
      "  time_since_restore: 1348.8773112297058\n",
      "  time_this_iter_s: 12.165462970733643\n",
      "  time_total_s: 1348.8773112297058\n",
      "  timers:\n",
      "    learn_throughput: 689.502\n",
      "    learn_time_ms: 5801.284\n",
      "    load_throughput: 0.0\n",
      "    load_time_ms: 0.0\n",
      "    sample_throughput: 329.893\n",
      "    sample_time_ms: 12125.139\n",
      "    update_time_ms: 1.596\n",
      "  timestamp: 1641872562\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 440000\n",
      "  training_iteration: 110\n",
      "  trial_id: 59aed_00000\n",
      "  \n",
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 440000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-42-47\n",
      "  done: false\n",
      "  episode_len_mean: 504.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -98.558116856557\n",
      "  episode_reward_mean: -109.37172939864222\n",
      "  episode_reward_min: -124.37499354399368\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 838\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.0814879569373254e-34\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.662627220153809\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.519743358992855e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0033729486167430878\n",
      "          total_loss: 603.6669311523438\n",
      "          vf_explained_var: 0.0008708576206117868\n",
      "          vf_loss: 603.66357421875\n",
      "    num_agent_steps_sampled: 440000\n",
      "    num_agent_steps_trained: 440000\n",
      "    num_steps_sampled: 440000\n",
      "    num_steps_trained: 440000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.23529411764706\n",
      "    ram_util_percent: 37.9\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12616925604582951\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5027028438552482\n",
      "    mean_inference_ms: 2.5680605360449293\n",
      "    mean_raw_obs_processing_ms: 0.1169472378825071\n",
      "  time_since_restore: 1353.6465463638306\n",
      "  time_this_iter_s: 12.117592096328735\n",
      "  time_total_s: 1353.6465463638306\n",
      "  timers:\n",
      "    learn_throughput: 690.535\n",
      "    learn_time_ms: 5792.608\n",
      "    load_throughput: 20063640.277\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 326.938\n",
      "    sample_time_ms: 12234.74\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641872567\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 440000\n",
      "  training_iteration: 110\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:42:47 (running for 00:22:51.33)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         1348.88</td><td style=\"text-align: right;\">440000</td><td style=\"text-align: right;\"> 133.386</td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         1353.65</td><td style=\"text-align: right;\">440000</td><td style=\"text-align: right;\">-109.372</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -124.375 </td><td style=\"text-align: right;\">            504.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:42:52 (running for 00:22:56.39)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         1348.88</td><td style=\"text-align: right;\">440000</td><td style=\"text-align: right;\"> 133.386</td><td style=\"text-align: right;\">            175.501 </td><td style=\"text-align: right;\">            -77.1592</td><td style=\"text-align: right;\">           1588.9 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         1353.65</td><td style=\"text-align: right;\">440000</td><td style=\"text-align: right;\">-109.372</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -124.375 </td><td style=\"text-align: right;\">            504.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 444000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-42-54\n",
      "  done: false\n",
      "  episode_len_mean: 1599.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 185.9017285160145\n",
      "  episode_reward_mean: 138.59594401186544\n",
      "  episode_reward_min: 48.52960730327402\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 379\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.046233892440796\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008032063022255898\n",
      "          model: {}\n",
      "          policy_loss: -0.018424106761813164\n",
      "          total_loss: 3.197356700897217\n",
      "          vf_explained_var: 0.7165828943252563\n",
      "          vf_loss: 3.206631660461426\n",
      "    num_agent_steps_sampled: 444000\n",
      "    num_agent_steps_trained: 444000\n",
      "    num_steps_sampled: 444000\n",
      "    num_steps_trained: 444000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.93529411764706\n",
      "    ram_util_percent: 37.90588235294118\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1254861830246685\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49632916557760864\n",
      "    mean_inference_ms: 2.5228862485608907\n",
      "    mean_raw_obs_processing_ms: 0.1105111941823306\n",
      "  time_since_restore: 1360.9929084777832\n",
      "  time_this_iter_s: 12.115597248077393\n",
      "  time_total_s: 1360.9929084777832\n",
      "  timers:\n",
      "    learn_throughput: 689.206\n",
      "    learn_time_ms: 5803.778\n",
      "    load_throughput: 0.0\n",
      "    load_time_ms: 0.0\n",
      "    sample_throughput: 330.166\n",
      "    sample_time_ms: 12115.127\n",
      "    update_time_ms: 1.596\n",
      "  timestamp: 1641872574\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 444000\n",
      "  training_iteration: 111\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:42:57 (running for 00:23:01.71)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         1360.99</td><td style=\"text-align: right;\">444000</td><td style=\"text-align: right;\"> 138.596</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">             48.5296</td><td style=\"text-align: right;\">           1599.29</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         1353.65</td><td style=\"text-align: right;\">440000</td><td style=\"text-align: right;\">-109.372</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -124.375 </td><td style=\"text-align: right;\">            504.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 444000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-42-59\n",
      "  done: false\n",
      "  episode_len_mean: 520.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -98.558116856557\n",
      "  episode_reward_mean: -109.33916500550662\n",
      "  episode_reward_min: -124.37499354399368\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 841\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5407439784686627e-34\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.662923812866211\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.1922480780413025e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003614990506321192\n",
      "          total_loss: 129.14596557617188\n",
      "          vf_explained_var: -0.00021108465443830937\n",
      "          vf_loss: 129.14234924316406\n",
      "    num_agent_steps_sampled: 444000\n",
      "    num_agent_steps_trained: 444000\n",
      "    num_steps_sampled: 444000\n",
      "    num_steps_trained: 444000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.182352941176475\n",
      "    ram_util_percent: 37.95294117647058\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12615609537455527\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5026201327375981\n",
      "    mean_inference_ms: 2.5675915300200303\n",
      "    mean_raw_obs_processing_ms: 0.1169181652069774\n",
      "  time_since_restore: 1365.8289647102356\n",
      "  time_this_iter_s: 12.18241834640503\n",
      "  time_total_s: 1365.8289647102356\n",
      "  timers:\n",
      "    learn_throughput: 689.514\n",
      "    learn_time_ms: 5801.185\n",
      "    load_throughput: 40146484.805\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 327.118\n",
      "    sample_time_ms: 12228.02\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641872579\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 444000\n",
      "  training_iteration: 111\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:43:03 (running for 00:23:07.58)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         1360.99</td><td style=\"text-align: right;\">444000</td><td style=\"text-align: right;\"> 138.596</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">             48.5296</td><td style=\"text-align: right;\">           1599.29</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         1365.83</td><td style=\"text-align: right;\">444000</td><td style=\"text-align: right;\">-109.339</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -124.375 </td><td style=\"text-align: right;\">            520.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 448000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-43-07\n",
      "  done: false\n",
      "  episode_len_mean: 1599.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 185.9017285160145\n",
      "  episode_reward_mean: 139.68422678530422\n",
      "  episode_reward_min: 48.52960730327402\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 381\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2180259227752686\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.007485717535018921\n",
      "          model: {}\n",
      "          policy_loss: -0.017461463809013367\n",
      "          total_loss: 2.0465476512908936\n",
      "          vf_explained_var: 0.759381890296936\n",
      "          vf_loss: 2.0554826259613037\n",
      "    num_agent_steps_sampled: 448000\n",
      "    num_agent_steps_trained: 448000\n",
      "    num_steps_sampled: 448000\n",
      "    num_steps_trained: 448000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.847058823529416\n",
      "    ram_util_percent: 37.97647058823529\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12548834558211874\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4962653139583697\n",
      "    mean_inference_ms: 2.523024436140822\n",
      "    mean_raw_obs_processing_ms: 0.1105129868464657\n",
      "  time_since_restore: 1373.0935456752777\n",
      "  time_this_iter_s: 12.100637197494507\n",
      "  time_total_s: 1373.0935456752777\n",
      "  timers:\n",
      "    learn_throughput: 686.411\n",
      "    learn_time_ms: 5827.414\n",
      "    load_throughput: 40136880.383\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 331.001\n",
      "    sample_time_ms: 12084.557\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641872587\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 448000\n",
      "  training_iteration: 112\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:43:09 (running for 00:23:12.82)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         1373.09</td><td style=\"text-align: right;\">448000</td><td style=\"text-align: right;\"> 139.684</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">             48.5296</td><td style=\"text-align: right;\">           1599.29</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         1365.83</td><td style=\"text-align: right;\">444000</td><td style=\"text-align: right;\">-109.339</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -124.375 </td><td style=\"text-align: right;\">            520.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 448000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-43-12\n",
      "  done: false\n",
      "  episode_len_mean: 536.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -98.558116856557\n",
      "  episode_reward_mean: -109.52254789347415\n",
      "  episode_reward_min: -126.53207238545704\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 845\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 7.703719892343314e-35\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663268566131592\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 5.015627948523615e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003040458308532834\n",
      "          total_loss: 264.1528015136719\n",
      "          vf_explained_var: -0.00035011389991268516\n",
      "          vf_loss: 264.1497497558594\n",
      "    num_agent_steps_sampled: 448000\n",
      "    num_agent_steps_trained: 448000\n",
      "    num_steps_sampled: 448000\n",
      "    num_steps_trained: 448000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.9\n",
      "    ram_util_percent: 37.95882352941177\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12613889461890462\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5024979932862652\n",
      "    mean_inference_ms: 2.566930644584549\n",
      "    mean_raw_obs_processing_ms: 0.11688168638483583\n",
      "  time_since_restore: 1378.0801994800568\n",
      "  time_this_iter_s: 12.251234769821167\n",
      "  time_total_s: 1378.0801994800568\n",
      "  timers:\n",
      "    learn_throughput: 688.024\n",
      "    learn_time_ms: 5813.752\n",
      "    load_throughput: 40146484.805\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 327.299\n",
      "    sample_time_ms: 12221.237\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641872592\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 448000\n",
      "  training_iteration: 112\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:43:14 (running for 00:23:17.83)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         1373.09</td><td style=\"text-align: right;\">448000</td><td style=\"text-align: right;\"> 139.684</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">             48.5296</td><td style=\"text-align: right;\">           1599.29</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         1378.08</td><td style=\"text-align: right;\">448000</td><td style=\"text-align: right;\">-109.523</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -126.532 </td><td style=\"text-align: right;\">            536.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 452000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-43-19\n",
      "  done: false\n",
      "  episode_len_mean: 1599.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 185.9017285160145\n",
      "  episode_reward_mean: 140.8168415310554\n",
      "  episode_reward_min: 48.52960730327402\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 383\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.0816420316696167\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009084321558475494\n",
      "          model: {}\n",
      "          policy_loss: -0.022573499009013176\n",
      "          total_loss: 1.9841843843460083\n",
      "          vf_explained_var: 0.7891797423362732\n",
      "          vf_loss: 1.9964103698730469\n",
      "    num_agent_steps_sampled: 452000\n",
      "    num_agent_steps_trained: 452000\n",
      "    num_steps_sampled: 452000\n",
      "    num_steps_trained: 452000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.21111111111111\n",
      "    ram_util_percent: 37.94444444444444\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12548375822683805\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49617482311322\n",
      "    mean_inference_ms: 2.5230407265657395\n",
      "    mean_raw_obs_processing_ms: 0.11050586330700947\n",
      "  time_since_restore: 1385.170247077942\n",
      "  time_this_iter_s: 12.076701402664185\n",
      "  time_total_s: 1385.170247077942\n",
      "  timers:\n",
      "    learn_throughput: 685.168\n",
      "    learn_time_ms: 5837.986\n",
      "    load_throughput: 20061241.181\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 330.901\n",
      "    sample_time_ms: 12088.208\n",
      "    update_time_ms: 1.696\n",
      "  timestamp: 1641872599\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 452000\n",
      "  training_iteration: 113\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:43:19 (running for 00:23:22.90)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         1385.17</td><td style=\"text-align: right;\">452000</td><td style=\"text-align: right;\"> 140.817</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">             48.5296</td><td style=\"text-align: right;\">           1599.29</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         1378.08</td><td style=\"text-align: right;\">448000</td><td style=\"text-align: right;\">-109.523</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -126.532 </td><td style=\"text-align: right;\">            536.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 452000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-43-24\n",
      "  done: false\n",
      "  episode_len_mean: 490.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -98.558116856557\n",
      "  episode_reward_mean: -108.88727572530198\n",
      "  episode_reward_min: -126.53207238545704\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 861\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.851859946171657e-35\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.664492130279541\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 5.554833251153468e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.004826822783797979\n",
      "          total_loss: 1281.5965576171875\n",
      "          vf_explained_var: -0.0004198512760922313\n",
      "          vf_loss: 1281.591796875\n",
      "    num_agent_steps_sampled: 452000\n",
      "    num_agent_steps_trained: 452000\n",
      "    num_steps_sampled: 452000\n",
      "    num_steps_trained: 452000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.05882352941176\n",
      "    ram_util_percent: 37.970588235294116\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.126067446557852\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5020668684285959\n",
      "    mean_inference_ms: 2.564240331813073\n",
      "    mean_raw_obs_processing_ms: 0.1167247863133466\n",
      "  time_since_restore: 1390.1858236789703\n",
      "  time_this_iter_s: 12.105624198913574\n",
      "  time_total_s: 1390.1858236789703\n",
      "  timers:\n",
      "    learn_throughput: 688.709\n",
      "    learn_time_ms: 5807.967\n",
      "    load_throughput: 0.0\n",
      "    load_time_ms: 0.0\n",
      "    sample_throughput: 327.195\n",
      "    sample_time_ms: 12225.131\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641872604\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 452000\n",
      "  training_iteration: 113\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:43:24 (running for 00:23:27.94)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         1385.17</td><td style=\"text-align: right;\">452000</td><td style=\"text-align: right;\"> 140.817</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">             48.5296</td><td style=\"text-align: right;\">           1599.29</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         1390.19</td><td style=\"text-align: right;\">452000</td><td style=\"text-align: right;\">-108.887</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -126.532 </td><td style=\"text-align: right;\">            490.9 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:43:29 (running for 00:23:32.99)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         1385.17</td><td style=\"text-align: right;\">452000</td><td style=\"text-align: right;\"> 140.817</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">             48.5296</td><td style=\"text-align: right;\">           1599.29</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         1390.19</td><td style=\"text-align: right;\">452000</td><td style=\"text-align: right;\">-108.887</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -126.532 </td><td style=\"text-align: right;\">            490.9 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 456000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-43-31\n",
      "  done: false\n",
      "  episode_len_mean: 1599.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 185.9017285160145\n",
      "  episode_reward_mean: 142.26380557327818\n",
      "  episode_reward_min: 48.52960730327402\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 385\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.4053512811660767\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0101793697103858\n",
      "          model: {}\n",
      "          policy_loss: -0.021127918735146523\n",
      "          total_loss: 3.672407388687134\n",
      "          vf_explained_var: 0.7026983499526978\n",
      "          vf_loss: 3.6819403171539307\n",
      "    num_agent_steps_sampled: 456000\n",
      "    num_agent_steps_trained: 456000\n",
      "    num_steps_sampled: 456000\n",
      "    num_steps_trained: 456000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.35625\n",
      "    ram_util_percent: 37.96875\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12547380663752838\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4960743393231439\n",
      "    mean_inference_ms: 2.5229946291182768\n",
      "    mean_raw_obs_processing_ms: 0.11049631580535571\n",
      "  time_since_restore: 1397.1492094993591\n",
      "  time_this_iter_s: 11.978962421417236\n",
      "  time_total_s: 1397.1492094993591\n",
      "  timers:\n",
      "    learn_throughput: 685.203\n",
      "    learn_time_ms: 5837.687\n",
      "    load_throughput: 20061241.181\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 331.183\n",
      "    sample_time_ms: 12077.902\n",
      "    update_time_ms: 1.696\n",
      "  timestamp: 1641872611\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 456000\n",
      "  training_iteration: 114\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:43:35 (running for 00:23:38.94)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         1397.15</td><td style=\"text-align: right;\">456000</td><td style=\"text-align: right;\"> 142.264</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">             48.5296</td><td style=\"text-align: right;\">           1599.29</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         1390.19</td><td style=\"text-align: right;\">452000</td><td style=\"text-align: right;\">-108.887</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -126.532 </td><td style=\"text-align: right;\">            490.9 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 456000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-43-36\n",
      "  done: false\n",
      "  episode_len_mean: 491.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -98.558116856557\n",
      "  episode_reward_mean: -109.10164954742106\n",
      "  episode_reward_min: -126.53207238545704\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 865\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.9259299730858284e-35\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.664258003234863\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.4190955489066255e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.002821945585310459\n",
      "          total_loss: 275.5991516113281\n",
      "          vf_explained_var: -0.00015215962775982916\n",
      "          vf_loss: 275.5963134765625\n",
      "    num_agent_steps_sampled: 456000\n",
      "    num_agent_steps_trained: 456000\n",
      "    num_steps_sampled: 456000\n",
      "    num_steps_trained: 456000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.1235294117647\n",
      "    ram_util_percent: 37.98823529411764\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12606737599078982\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5019023213974156\n",
      "    mean_inference_ms: 2.5637709356773994\n",
      "    mean_raw_obs_processing_ms: 0.11666648671852776\n",
      "  time_since_restore: 1402.4031500816345\n",
      "  time_this_iter_s: 12.217326402664185\n",
      "  time_total_s: 1402.4031500816345\n",
      "  timers:\n",
      "    learn_throughput: 688.319\n",
      "    learn_time_ms: 5811.258\n",
      "    load_throughput: 40117685.318\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 327.559\n",
      "    sample_time_ms: 12211.534\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641872616\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 456000\n",
      "  training_iteration: 114\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:43:40 (running for 00:23:44.22)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         1397.15</td><td style=\"text-align: right;\">456000</td><td style=\"text-align: right;\"> 142.264</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">             48.5296</td><td style=\"text-align: right;\">           1599.29</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         1402.4 </td><td style=\"text-align: right;\">456000</td><td style=\"text-align: right;\">-109.102</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -126.532 </td><td style=\"text-align: right;\">            491.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 460000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-43-43\n",
      "  done: false\n",
      "  episode_len_mean: 1599.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 185.9017285160145\n",
      "  episode_reward_mean: 144.8338232496399\n",
      "  episode_reward_min: 48.52960730327402\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 389\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2170053720474243\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008514945395290852\n",
      "          model: {}\n",
      "          policy_loss: -0.01877565309405327\n",
      "          total_loss: 3.1639184951782227\n",
      "          vf_explained_var: 0.6749914884567261\n",
      "          vf_loss: 3.17299485206604\n",
      "    num_agent_steps_sampled: 460000\n",
      "    num_agent_steps_trained: 460000\n",
      "    num_steps_sampled: 460000\n",
      "    num_steps_trained: 460000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.79999999999999\n",
      "    ram_util_percent: 37.98333333333333\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.125452308863068\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49585226751339023\n",
      "    mean_inference_ms: 2.5228236528453154\n",
      "    mean_raw_obs_processing_ms: 0.11047488907689047\n",
      "  time_since_restore: 1409.20596408844\n",
      "  time_this_iter_s: 12.05675458908081\n",
      "  time_total_s: 1409.20596408844\n",
      "  timers:\n",
      "    learn_throughput: 683.591\n",
      "    learn_time_ms: 5851.45\n",
      "    load_throughput: 13373627.74\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 331.366\n",
      "    sample_time_ms: 12071.258\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641872623\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 460000\n",
      "  training_iteration: 115\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:43:46 (running for 00:23:50.00)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         1409.21</td><td style=\"text-align: right;\">460000</td><td style=\"text-align: right;\"> 144.834</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">             48.5296</td><td style=\"text-align: right;\">           1599.29</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         1402.4 </td><td style=\"text-align: right;\">456000</td><td style=\"text-align: right;\">-109.102</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -126.532 </td><td style=\"text-align: right;\">            491.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 460000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-43-48\n",
      "  done: false\n",
      "  episode_len_mean: 444.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -98.558116856557\n",
      "  episode_reward_mean: -109.8791303637909\n",
      "  episode_reward_min: -131.3264333027297\n",
      "  episodes_this_iter: 11\n",
      "  episodes_total: 876\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 9.629649865429142e-36\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663385391235352\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.6235280497767235e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0040568090043962\n",
      "          total_loss: 968.7517700195312\n",
      "          vf_explained_var: 0.0008391999290324748\n",
      "          vf_loss: 968.7477416992188\n",
      "    num_agent_steps_sampled: 460000\n",
      "    num_agent_steps_trained: 460000\n",
      "    num_steps_sampled: 460000\n",
      "    num_steps_trained: 460000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.94444444444444\n",
      "    ram_util_percent: 37.988888888888894\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1260083937359201\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.501655465128387\n",
      "    mean_inference_ms: 2.561941655490798\n",
      "    mean_raw_obs_processing_ms: 0.11657709869118975\n",
      "  time_since_restore: 1414.5646250247955\n",
      "  time_this_iter_s: 12.16147494316101\n",
      "  time_total_s: 1414.5646250247955\n",
      "  timers:\n",
      "    learn_throughput: 686.364\n",
      "    learn_time_ms: 5827.814\n",
      "    load_throughput: 40117685.318\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 327.805\n",
      "    sample_time_ms: 12202.381\n",
      "    update_time_ms: 1.994\n",
      "  timestamp: 1641872628\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 460000\n",
      "  training_iteration: 115\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:43:51 (running for 00:23:55.40)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         1409.21</td><td style=\"text-align: right;\">460000</td><td style=\"text-align: right;\"> 144.834</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">             48.5296</td><td style=\"text-align: right;\">           1599.29</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         1414.56</td><td style=\"text-align: right;\">460000</td><td style=\"text-align: right;\">-109.879</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">            444.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 464000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-43-55\n",
      "  done: false\n",
      "  episode_len_mean: 1599.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 185.9017285160145\n",
      "  episode_reward_mean: 145.63755709694018\n",
      "  episode_reward_min: 48.52960730327402\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 391\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.1883951425552368\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009233365766704082\n",
      "          model: {}\n",
      "          policy_loss: -0.019146107137203217\n",
      "          total_loss: 2.8789010047912598\n",
      "          vf_explained_var: 0.7753587365150452\n",
      "          vf_loss: 2.8875298500061035\n",
      "    num_agent_steps_sampled: 464000\n",
      "    num_agent_steps_trained: 464000\n",
      "    num_steps_sampled: 464000\n",
      "    num_steps_trained: 464000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.758823529411764\n",
      "    ram_util_percent: 38.0\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12543846979933349\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4957325542367616\n",
      "    mean_inference_ms: 2.522701194359683\n",
      "    mean_raw_obs_processing_ms: 0.11046498614068946\n",
      "  time_since_restore: 1421.374419927597\n",
      "  time_this_iter_s: 12.168455839157104\n",
      "  time_total_s: 1421.374419927597\n",
      "  timers:\n",
      "    learn_throughput: 682.277\n",
      "    learn_time_ms: 5862.72\n",
      "    load_throughput: 13373627.74\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 331.111\n",
      "    sample_time_ms: 12080.557\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641872635\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 464000\n",
      "  training_iteration: 116\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:43:57 (running for 00:24:01.20)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         1421.37</td><td style=\"text-align: right;\">464000</td><td style=\"text-align: right;\"> 145.638</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">             48.5296</td><td style=\"text-align: right;\">           1599.29</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         1414.56</td><td style=\"text-align: right;\">460000</td><td style=\"text-align: right;\">-109.879</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">            444.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 464000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-44-00\n",
      "  done: false\n",
      "  episode_len_mean: 474.51\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -98.558116856557\n",
      "  episode_reward_mean: -109.98908883305735\n",
      "  episode_reward_min: -131.3264333027297\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 881\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 4.814824932714571e-36\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663819789886475\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 2.1599673516448092e-07\n",
      "          model: {}\n",
      "          policy_loss: -0.051335785537958145\n",
      "          total_loss: 139.0712127685547\n",
      "          vf_explained_var: 0.00086643872782588\n",
      "          vf_loss: 139.12255859375\n",
      "    num_agent_steps_sampled: 464000\n",
      "    num_agent_steps_trained: 464000\n",
      "    num_steps_sampled: 464000\n",
      "    num_steps_trained: 464000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.35882352941176\n",
      "    ram_util_percent: 38.01176470588236\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1259905901373077\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5014946319661892\n",
      "    mean_inference_ms: 2.561218728330272\n",
      "    mean_raw_obs_processing_ms: 0.11651423937492691\n",
      "  time_since_restore: 1426.662270784378\n",
      "  time_this_iter_s: 12.09764575958252\n",
      "  time_total_s: 1426.662270784378\n",
      "  timers:\n",
      "    learn_throughput: 687.128\n",
      "    learn_time_ms: 5821.332\n",
      "    load_throughput: 40117685.318\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 327.861\n",
      "    sample_time_ms: 12200.281\n",
      "    update_time_ms: 2.094\n",
      "  timestamp: 1641872640\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 464000\n",
      "  training_iteration: 116\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:44:02 (running for 00:24:06.50)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         1421.37</td><td style=\"text-align: right;\">464000</td><td style=\"text-align: right;\"> 145.638</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">             48.5296</td><td style=\"text-align: right;\">           1599.29</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         1426.66</td><td style=\"text-align: right;\">464000</td><td style=\"text-align: right;\">-109.989</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">            474.51</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 468000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-44-07\n",
      "  done: false\n",
      "  episode_len_mean: 1599.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 185.9017285160145\n",
      "  episode_reward_mean: 146.3385482739432\n",
      "  episode_reward_min: 48.52960730327402\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 393\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.148239254951477\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008815743029117584\n",
      "          model: {}\n",
      "          policy_loss: -0.01605607196688652\n",
      "          total_loss: 2.9991557598114014\n",
      "          vf_explained_var: 0.764350950717926\n",
      "          vf_loss: 3.0051701068878174\n",
      "    num_agent_steps_sampled: 468000\n",
      "    num_agent_steps_trained: 468000\n",
      "    num_steps_sampled: 468000\n",
      "    num_steps_trained: 468000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.54117647058824\n",
      "    ram_util_percent: 38.05294117647059\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1254226541291363\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4956052505589676\n",
      "    mean_inference_ms: 2.52254586106961\n",
      "    mean_raw_obs_processing_ms: 0.11045417315238534\n",
      "  time_since_restore: 1433.4261872768402\n",
      "  time_this_iter_s: 12.051767349243164\n",
      "  time_total_s: 1433.4261872768402\n",
      "  timers:\n",
      "    learn_throughput: 682.695\n",
      "    learn_time_ms: 5859.13\n",
      "    load_throughput: 10029421.33\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 330.745\n",
      "    sample_time_ms: 12093.912\n",
      "    update_time_ms: 1.795\n",
      "  timestamp: 1641872647\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 468000\n",
      "  training_iteration: 117\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:44:08 (running for 00:24:12.26)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         1433.43</td><td style=\"text-align: right;\">468000</td><td style=\"text-align: right;\"> 146.339</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">             48.5296</td><td style=\"text-align: right;\">           1599.29</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         1426.66</td><td style=\"text-align: right;\">464000</td><td style=\"text-align: right;\">-109.989</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">            474.51</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 468000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-44-12\n",
      "  done: false\n",
      "  episode_len_mean: 474.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -98.558116856557\n",
      "  episode_reward_mean: -109.94755489664632\n",
      "  episode_reward_min: -131.3264333027297\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 887\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.4074124663572855e-36\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663987636566162\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.6824093285758863e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0037614235188812017\n",
      "          total_loss: 422.0059814453125\n",
      "          vf_explained_var: 0.0010824169730767608\n",
      "          vf_loss: 422.0022277832031\n",
      "    num_agent_steps_sampled: 468000\n",
      "    num_agent_steps_trained: 468000\n",
      "    num_steps_sampled: 468000\n",
      "    num_steps_trained: 468000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.33529411764706\n",
      "    ram_util_percent: 38.029411764705884\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1259754468167502\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5012779715319867\n",
      "    mean_inference_ms: 2.560386170244871\n",
      "    mean_raw_obs_processing_ms: 0.11642459036195195\n",
      "  time_since_restore: 1438.7260067462921\n",
      "  time_this_iter_s: 12.063735961914062\n",
      "  time_total_s: 1438.7260067462921\n",
      "  timers:\n",
      "    learn_throughput: 685.308\n",
      "    learn_time_ms: 5836.79\n",
      "    load_throughput: 40117685.318\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 328.524\n",
      "    sample_time_ms: 12175.653\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872652\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 468000\n",
      "  training_iteration: 117\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:44:13 (running for 00:24:17.59)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         1433.43</td><td style=\"text-align: right;\">468000</td><td style=\"text-align: right;\"> 146.339</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">             48.5296</td><td style=\"text-align: right;\">           1599.29</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         1438.73</td><td style=\"text-align: right;\">468000</td><td style=\"text-align: right;\">-109.948</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">            474.61</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:44:18 (running for 00:24:22.64)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         1433.43</td><td style=\"text-align: right;\">468000</td><td style=\"text-align: right;\"> 146.339</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">             48.5296</td><td style=\"text-align: right;\">           1599.29</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         1438.73</td><td style=\"text-align: right;\">468000</td><td style=\"text-align: right;\">-109.948</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">            474.61</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 472000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-44-19\n",
      "  done: false\n",
      "  episode_len_mean: 1599.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 185.9017285160145\n",
      "  episode_reward_mean: 147.35752686260324\n",
      "  episode_reward_min: 48.52960730327402\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 395\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3631043434143066\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008011055178940296\n",
      "          model: {}\n",
      "          policy_loss: -0.019693726673722267\n",
      "          total_loss: 1.7069041728973389\n",
      "          vf_explained_var: 0.7520724534988403\n",
      "          vf_loss: 1.7174729108810425\n",
      "    num_agent_steps_sampled: 472000\n",
      "    num_agent_steps_trained: 472000\n",
      "    num_steps_sampled: 472000\n",
      "    num_steps_trained: 472000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.42941176470589\n",
      "    ram_util_percent: 38.03529411764706\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12540520705907995\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4954715887213535\n",
      "    mean_inference_ms: 2.5223401314619722\n",
      "    mean_raw_obs_processing_ms: 0.1104391352701261\n",
      "  time_since_restore: 1445.4909195899963\n",
      "  time_this_iter_s: 12.064732313156128\n",
      "  time_total_s: 1445.4909195899963\n",
      "  timers:\n",
      "    learn_throughput: 680.991\n",
      "    learn_time_ms: 5873.79\n",
      "    load_throughput: 10029421.33\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 331.14\n",
      "    sample_time_ms: 12079.467\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641872659\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 472000\n",
      "  training_iteration: 118\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:44:24 (running for 00:24:28.40)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         1445.49</td><td style=\"text-align: right;\">472000</td><td style=\"text-align: right;\"> 147.358</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">             48.5296</td><td style=\"text-align: right;\">           1599.29</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         1438.73</td><td style=\"text-align: right;\">468000</td><td style=\"text-align: right;\">-109.948</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">            474.61</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 472000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-44-25\n",
      "  done: false\n",
      "  episode_len_mean: 489.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -98.558116856557\n",
      "  episode_reward_mean: -110.43473185442242\n",
      "  episode_reward_min: -131.3264333027297\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 895\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2037062331786428e-36\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.663837909698486\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 9.816015023034197e-08\n",
      "          model: {}\n",
      "          policy_loss: 0.0032947200816124678\n",
      "          total_loss: 603.6016235351562\n",
      "          vf_explained_var: 0.00105851364787668\n",
      "          vf_loss: 603.5983276367188\n",
      "    num_agent_steps_sampled: 472000\n",
      "    num_agent_steps_trained: 472000\n",
      "    num_steps_sampled: 472000\n",
      "    num_steps_trained: 472000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.682352941176475\n",
      "    ram_util_percent: 38.07058823529412\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12587170685970983\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5012621434475257\n",
      "    mean_inference_ms: 2.5585430264852707\n",
      "    mean_raw_obs_processing_ms: 0.11638983687105568\n",
      "  time_since_restore: 1450.997187614441\n",
      "  time_this_iter_s: 12.271180868148804\n",
      "  time_total_s: 1450.997187614441\n",
      "  timers:\n",
      "    learn_throughput: 684.279\n",
      "    learn_time_ms: 5845.567\n",
      "    load_throughput: 40117685.318\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 328.151\n",
      "    sample_time_ms: 12189.516\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641872665\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 472000\n",
      "  training_iteration: 118\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:44:30 (running for 00:24:33.93)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         1445.49</td><td style=\"text-align: right;\">472000</td><td style=\"text-align: right;\"> 147.358</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">             48.5296</td><td style=\"text-align: right;\">           1599.29</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         1451   </td><td style=\"text-align: right;\">472000</td><td style=\"text-align: right;\">-110.435</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">            489.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 476000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-44-31\n",
      "  done: false\n",
      "  episode_len_mean: 1587.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 185.9017285160145\n",
      "  episode_reward_mean: 146.3425402815684\n",
      "  episode_reward_min: -70.77250116858819\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 399\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.4487642049789429\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00886575412005186\n",
      "          model: {}\n",
      "          policy_loss: -0.02440173178911209\n",
      "          total_loss: 111.27244567871094\n",
      "          vf_explained_var: 0.5171427130699158\n",
      "          vf_loss: 111.28675079345703\n",
      "    num_agent_steps_sampled: 476000\n",
      "    num_agent_steps_trained: 476000\n",
      "    num_steps_sampled: 476000\n",
      "    num_steps_trained: 476000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.42941176470588\n",
      "    ram_util_percent: 38.11176470588236\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12536511563551878\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4951937151411019\n",
      "    mean_inference_ms: 2.5218482449444966\n",
      "    mean_raw_obs_processing_ms: 0.11040540654979894\n",
      "  time_since_restore: 1457.5696165561676\n",
      "  time_this_iter_s: 12.078696966171265\n",
      "  time_total_s: 1457.5696165561676\n",
      "  timers:\n",
      "    learn_throughput: 679.71\n",
      "    learn_time_ms: 5884.861\n",
      "    load_throughput: 10029421.33\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 330.712\n",
      "    sample_time_ms: 12095.1\n",
      "    update_time_ms: 1.895\n",
      "  timestamp: 1641872671\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 476000\n",
      "  training_iteration: 119\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:44:35 (running for 00:24:39.47)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         1457.57</td><td style=\"text-align: right;\">476000</td><td style=\"text-align: right;\"> 146.343</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">            -70.7725</td><td style=\"text-align: right;\">           1587.6 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         1451   </td><td style=\"text-align: right;\">472000</td><td style=\"text-align: right;\">-110.435</td><td style=\"text-align: right;\">            -98.5581</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">            489.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 476000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-44-37\n",
      "  done: false\n",
      "  episode_len_mean: 490.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.25344585032698\n",
      "  episode_reward_mean: -110.5333509873894\n",
      "  episode_reward_min: -131.3264333027297\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 903\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 6.018531165893214e-37\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.664249897003174\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.3909428275837854e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0034440639428794384\n",
      "          total_loss: 555.5433959960938\n",
      "          vf_explained_var: 0.0005868365406058729\n",
      "          vf_loss: 555.5399780273438\n",
      "    num_agent_steps_sampled: 476000\n",
      "    num_agent_steps_trained: 476000\n",
      "    num_steps_sampled: 476000\n",
      "    num_steps_trained: 476000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.629411764705885\n",
      "    ram_util_percent: 38.11176470588235\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1257915737358928\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.501111122826853\n",
      "    mean_inference_ms: 2.5569427243204386\n",
      "    mean_raw_obs_processing_ms: 0.11631510790949416\n",
      "  time_since_restore: 1463.201547384262\n",
      "  time_this_iter_s: 12.204359769821167\n",
      "  time_total_s: 1463.201547384262\n",
      "  timers:\n",
      "    learn_throughput: 683.533\n",
      "    learn_time_ms: 5851.95\n",
      "    load_throughput: 40117685.318\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 328.252\n",
      "    sample_time_ms: 12185.758\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872677\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 476000\n",
      "  training_iteration: 119\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:44:41 (running for 00:24:45.14)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         1457.57</td><td style=\"text-align: right;\">476000</td><td style=\"text-align: right;\"> 146.343</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">            -70.7725</td><td style=\"text-align: right;\">            1587.6</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         1463.2 </td><td style=\"text-align: right;\">476000</td><td style=\"text-align: right;\">-110.533</td><td style=\"text-align: right;\">            -96.2534</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">             490.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 480000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-44-43\n",
      "  done: false\n",
      "  episode_len_mean: 1587.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 185.9017285160145\n",
      "  episode_reward_mean: 148.04750203458053\n",
      "  episode_reward_min: -70.77250116858819\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 402\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2429490089416504\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008551510982215405\n",
      "          model: {}\n",
      "          policy_loss: -0.021232767030596733\n",
      "          total_loss: 4.8867950439453125\n",
      "          vf_explained_var: 0.6018888354301453\n",
      "          vf_loss: 4.898287296295166\n",
      "    num_agent_steps_sampled: 480000\n",
      "    num_agent_steps_trained: 480000\n",
      "    num_steps_sampled: 480000\n",
      "    num_steps_trained: 480000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.629411764705885\n",
      "    ram_util_percent: 37.98235294117647\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12533330898759304\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.494996194316091\n",
      "    mean_inference_ms: 2.521704739321622\n",
      "    mean_raw_obs_processing_ms: 0.11038120814836411\n",
      "  time_since_restore: 1469.7231123447418\n",
      "  time_this_iter_s: 12.153495788574219\n",
      "  time_total_s: 1469.7231123447418\n",
      "  timers:\n",
      "    learn_throughput: 677.586\n",
      "    learn_time_ms: 5903.311\n",
      "    load_throughput: 10029421.33\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 330.931\n",
      "    sample_time_ms: 12087.096\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641872683\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 480000\n",
      "  training_iteration: 120\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:44:46 (running for 00:24:50.64)<br>Memory usage on this node: 9.0/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         1469.72</td><td style=\"text-align: right;\">480000</td><td style=\"text-align: right;\"> 148.048</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">            -70.7725</td><td style=\"text-align: right;\">            1587.6</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         1463.2 </td><td style=\"text-align: right;\">476000</td><td style=\"text-align: right;\">-110.533</td><td style=\"text-align: right;\">            -96.2534</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">             490.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 480000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-44-50\n",
      "  done: false\n",
      "  episode_len_mean: 522.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -96.25344585032698\n",
      "  episode_reward_mean: -111.21701982141992\n",
      "  episode_reward_min: -131.3264333027297\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 911\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.009265582946607e-37\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.664888858795166\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.2608279575943016e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0032332923728972673\n",
      "          total_loss: 499.016845703125\n",
      "          vf_explained_var: 0.001718840328976512\n",
      "          vf_loss: 499.0135803222656\n",
      "    num_agent_steps_sampled: 480000\n",
      "    num_agent_steps_trained: 480000\n",
      "    num_steps_sampled: 480000\n",
      "    num_steps_trained: 480000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 65.32631578947368\n",
      "    ram_util_percent: 37.91578947368421\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1257491710090677\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5008417892694804\n",
      "    mean_inference_ms: 2.5557087259438203\n",
      "    mean_raw_obs_processing_ms: 0.11619923470631083\n",
      "  time_since_restore: 1476.0691339969635\n",
      "  time_this_iter_s: 12.867586612701416\n",
      "  time_total_s: 1476.0691339969635\n",
      "  timers:\n",
      "    learn_throughput: 676.728\n",
      "    learn_time_ms: 5910.792\n",
      "    load_throughput: 20051650.532\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 327.678\n",
      "    sample_time_ms: 12207.124\n",
      "    update_time_ms: 2.393\n",
      "  timestamp: 1641872690\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 480000\n",
      "  training_iteration: 120\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:44:52 (running for 00:24:56.00)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         1469.72</td><td style=\"text-align: right;\">480000</td><td style=\"text-align: right;\"> 148.048</td><td style=\"text-align: right;\">            185.902 </td><td style=\"text-align: right;\">            -70.7725</td><td style=\"text-align: right;\">           1587.6 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         1476.07</td><td style=\"text-align: right;\">480000</td><td style=\"text-align: right;\">-111.217</td><td style=\"text-align: right;\">            -96.2534</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">            522.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 484000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-44-56\n",
      "  done: false\n",
      "  episode_len_mean: 1587.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 193.48823881678285\n",
      "  episode_reward_mean: 149.04692171125154\n",
      "  episode_reward_min: -70.77250116858819\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 404\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.0484025478363037\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012451311573386192\n",
      "          model: {}\n",
      "          policy_loss: -0.019931359216570854\n",
      "          total_loss: 1.8923825025558472\n",
      "          vf_explained_var: 0.7454385161399841\n",
      "          vf_loss: 1.8981308937072754\n",
      "    num_agent_steps_sampled: 484000\n",
      "    num_agent_steps_trained: 484000\n",
      "    num_steps_sampled: 484000\n",
      "    num_steps_trained: 484000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 67.31052631578947\n",
      "    ram_util_percent: 37.97894736842105\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12530988069208818\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4948594906615385\n",
      "    mean_inference_ms: 2.5214138766951826\n",
      "    mean_raw_obs_processing_ms: 0.11036033554967872\n",
      "  time_since_restore: 1482.8230769634247\n",
      "  time_this_iter_s: 13.099964618682861\n",
      "  time_total_s: 1482.8230769634247\n",
      "  timers:\n",
      "    learn_throughput: 672.947\n",
      "    learn_time_ms: 5944.002\n",
      "    load_throughput: 8024688.382\n",
      "    load_time_ms: 0.498\n",
      "    sample_throughput: 328.844\n",
      "    sample_time_ms: 12163.82\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641872696\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 484000\n",
      "  training_iteration: 121\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:44:58 (running for 00:25:01.76)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         1482.82</td><td style=\"text-align: right;\">484000</td><td style=\"text-align: right;\"> 149.047</td><td style=\"text-align: right;\">            193.488 </td><td style=\"text-align: right;\">            -70.7725</td><td style=\"text-align: right;\">           1587.6 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         1476.07</td><td style=\"text-align: right;\">480000</td><td style=\"text-align: right;\">-111.217</td><td style=\"text-align: right;\">            -96.2534</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">            522.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:45:03 (running for 00:25:06.83)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         1482.82</td><td style=\"text-align: right;\">484000</td><td style=\"text-align: right;\"> 149.047</td><td style=\"text-align: right;\">            193.488 </td><td style=\"text-align: right;\">            -70.7725</td><td style=\"text-align: right;\">           1587.6 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         1476.07</td><td style=\"text-align: right;\">480000</td><td style=\"text-align: right;\">-111.217</td><td style=\"text-align: right;\">            -96.2534</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">            522.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 484000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-45-03\n",
      "  done: false\n",
      "  episode_len_mean: 536.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -93.09124282326412\n",
      "  episode_reward_mean: -110.9667489681948\n",
      "  episode_reward_min: -131.3264333027297\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 918\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5046327914733034e-37\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.665346622467041\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 5.671526537298632e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003125108778476715\n",
      "          total_loss: 479.27947998046875\n",
      "          vf_explained_var: 0.0012471057707443833\n",
      "          vf_loss: 479.2763366699219\n",
      "    num_agent_steps_sampled: 484000\n",
      "    num_agent_steps_trained: 484000\n",
      "    num_steps_sampled: 484000\n",
      "    num_steps_trained: 484000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.92222222222222\n",
      "    ram_util_percent: 38.055555555555564\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12573417703356993\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5005476229980522\n",
      "    mean_inference_ms: 2.554815296451694\n",
      "    mean_raw_obs_processing_ms: 0.11607697189540293\n",
      "  time_since_restore: 1489.249882698059\n",
      "  time_this_iter_s: 13.180748701095581\n",
      "  time_total_s: 1489.249882698059\n",
      "  timers:\n",
      "    learn_throughput: 669.733\n",
      "    learn_time_ms: 5972.527\n",
      "    load_throughput: 20051650.532\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 325.11\n",
      "    sample_time_ms: 12303.541\n",
      "    update_time_ms: 3.49\n",
      "  timestamp: 1641872703\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 484000\n",
      "  training_iteration: 121\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:45:08 (running for 00:25:12.24)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         1482.82</td><td style=\"text-align: right;\">484000</td><td style=\"text-align: right;\"> 149.047</td><td style=\"text-align: right;\">            193.488 </td><td style=\"text-align: right;\">            -70.7725</td><td style=\"text-align: right;\">            1587.6</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         1489.25</td><td style=\"text-align: right;\">484000</td><td style=\"text-align: right;\">-110.967</td><td style=\"text-align: right;\">            -93.0912</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">             536  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 488000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-45-10\n",
      "  done: false\n",
      "  episode_len_mean: 1587.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 193.48823881678285\n",
      "  episode_reward_mean: 149.87641504128226\n",
      "  episode_reward_min: -70.77250116858819\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 406\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.976650595664978\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.00971759483218193\n",
      "          model: {}\n",
      "          policy_loss: -0.02355644479393959\n",
      "          total_loss: 3.748577356338501\n",
      "          vf_explained_var: 0.6898476481437683\n",
      "          vf_loss: 3.7610650062561035\n",
      "    num_agent_steps_sampled: 488000\n",
      "    num_agent_steps_trained: 488000\n",
      "    num_steps_sampled: 488000\n",
      "    num_steps_trained: 488000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.69444444444444\n",
      "    ram_util_percent: 38.166666666666664\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12528654460651734\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4947281360189404\n",
      "    mean_inference_ms: 2.5211299375277845\n",
      "    mean_raw_obs_processing_ms: 0.11034090216528342\n",
      "  time_since_restore: 1496.061671257019\n",
      "  time_this_iter_s: 13.23859429359436\n",
      "  time_total_s: 1496.061671257019\n",
      "  timers:\n",
      "    learn_throughput: 668.829\n",
      "    learn_time_ms: 5980.604\n",
      "    load_throughput: 8023153.364\n",
      "    load_time_ms: 0.499\n",
      "    sample_throughput: 325.636\n",
      "    sample_time_ms: 12283.636\n",
      "    update_time_ms: 2.194\n",
      "  timestamp: 1641872710\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 488000\n",
      "  training_iteration: 122\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:45:14 (running for 00:25:18.06)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         1496.06</td><td style=\"text-align: right;\">488000</td><td style=\"text-align: right;\"> 149.876</td><td style=\"text-align: right;\">            193.488 </td><td style=\"text-align: right;\">            -70.7725</td><td style=\"text-align: right;\">            1587.6</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         1489.25</td><td style=\"text-align: right;\">484000</td><td style=\"text-align: right;\">-110.967</td><td style=\"text-align: right;\">            -93.0912</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">             536  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 488000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-45-16\n",
      "  done: false\n",
      "  episode_len_mean: 566.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -93.09124282326412\n",
      "  episode_reward_mean: -111.02948766500211\n",
      "  episode_reward_min: -131.3264333027297\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 923\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 7.523163957366517e-38\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.666390419006348\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 3.815751199454098e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003242584178224206\n",
      "          total_loss: 219.8684844970703\n",
      "          vf_explained_var: 5.35573999513872e-05\n",
      "          vf_loss: 219.86524963378906\n",
      "    num_agent_steps_sampled: 488000\n",
      "    num_agent_steps_trained: 488000\n",
      "    num_steps_sampled: 488000\n",
      "    num_steps_trained: 488000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 67.13157894736842\n",
      "    ram_util_percent: 38.231578947368426\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12570062793215966\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5004314587748446\n",
      "    mean_inference_ms: 2.5540372721051363\n",
      "    mean_raw_obs_processing_ms: 0.11602416913787504\n",
      "  time_since_restore: 1502.4535698890686\n",
      "  time_this_iter_s: 13.203687191009521\n",
      "  time_total_s: 1502.4535698890686\n",
      "  timers:\n",
      "    learn_throughput: 665.014\n",
      "    learn_time_ms: 6014.914\n",
      "    load_throughput: 20051650.532\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 322.097\n",
      "    sample_time_ms: 12418.61\n",
      "    update_time_ms: 3.59\n",
      "  timestamp: 1641872716\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 488000\n",
      "  training_iteration: 122\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:45:19 (running for 00:25:23.45)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         1496.06</td><td style=\"text-align: right;\">488000</td><td style=\"text-align: right;\"> 149.876</td><td style=\"text-align: right;\">            193.488 </td><td style=\"text-align: right;\">            -70.7725</td><td style=\"text-align: right;\">           1587.6 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         1502.45</td><td style=\"text-align: right;\">488000</td><td style=\"text-align: right;\">-111.029</td><td style=\"text-align: right;\">            -93.0912</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">            566.94</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 492000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-45-23\n",
      "  done: false\n",
      "  episode_len_mean: 1587.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 193.48823881678285\n",
      "  episode_reward_mean: 150.91414097832794\n",
      "  episode_reward_min: -70.77250116858819\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 409\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.158888339996338\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0104502709582448\n",
      "          model: {}\n",
      "          policy_loss: -0.019322706386446953\n",
      "          total_loss: 4.606490612030029\n",
      "          vf_explained_var: 0.6095301508903503\n",
      "          vf_loss: 4.6139092445373535\n",
      "    num_agent_steps_sampled: 492000\n",
      "    num_agent_steps_trained: 492000\n",
      "    num_steps_sampled: 492000\n",
      "    num_steps_trained: 492000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.97222222222223\n",
      "    ram_util_percent: 38.22777777777778\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1252459574153526\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4945147213870423\n",
      "    mean_inference_ms: 2.5203901038126526\n",
      "    mean_raw_obs_processing_ms: 0.11030618567890073\n",
      "  time_since_restore: 1508.7756671905518\n",
      "  time_this_iter_s: 12.713995933532715\n",
      "  time_total_s: 1508.7756671905518\n",
      "  timers:\n",
      "    learn_throughput: 666.019\n",
      "    learn_time_ms: 6005.837\n",
      "    load_throughput: 10029421.33\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 323.612\n",
      "    sample_time_ms: 12360.485\n",
      "    update_time_ms: 2.294\n",
      "  timestamp: 1641872723\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 492000\n",
      "  training_iteration: 123\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:45:25 (running for 00:25:28.79)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         1508.78</td><td style=\"text-align: right;\">492000</td><td style=\"text-align: right;\"> 150.914</td><td style=\"text-align: right;\">            193.488 </td><td style=\"text-align: right;\">            -70.7725</td><td style=\"text-align: right;\">           1587.6 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         1502.45</td><td style=\"text-align: right;\">488000</td><td style=\"text-align: right;\">-111.029</td><td style=\"text-align: right;\">            -93.0912</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">            566.94</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 492000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-45-29\n",
      "  done: false\n",
      "  episode_len_mean: 582.37\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -93.09124282326412\n",
      "  episode_reward_mean: -111.06215902014213\n",
      "  episode_reward_min: -131.3264333027297\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 926\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 3.7615819786832586e-38\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.666541576385498\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.147922645827748e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003120379289612174\n",
      "          total_loss: 159.91139221191406\n",
      "          vf_explained_var: 0.00027685562963597476\n",
      "          vf_loss: 159.90826416015625\n",
      "    num_agent_steps_sampled: 492000\n",
      "    num_agent_steps_trained: 492000\n",
      "    num_steps_sampled: 492000\n",
      "    num_steps_trained: 492000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.13529411764706\n",
      "    ram_util_percent: 38.14705882352942\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12569169166178998\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5003320198009337\n",
      "    mean_inference_ms: 2.553632182877136\n",
      "    mean_raw_obs_processing_ms: 0.11597658011704123\n",
      "  time_since_restore: 1514.8384473323822\n",
      "  time_this_iter_s: 12.384877443313599\n",
      "  time_total_s: 1514.8384473323822\n",
      "  timers:\n",
      "    learn_throughput: 662.236\n",
      "    learn_time_ms: 6040.146\n",
      "    load_throughput: 20051650.532\n",
      "    load_time_ms: 0.199\n",
      "    sample_throughput: 320.902\n",
      "    sample_time_ms: 12464.874\n",
      "    update_time_ms: 3.59\n",
      "  timestamp: 1641872729\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 492000\n",
      "  training_iteration: 123\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:45:30 (running for 00:25:33.84)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         1508.78</td><td style=\"text-align: right;\">492000</td><td style=\"text-align: right;\"> 150.914</td><td style=\"text-align: right;\">            193.488 </td><td style=\"text-align: right;\">            -70.7725</td><td style=\"text-align: right;\">           1587.6 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         1514.84</td><td style=\"text-align: right;\">492000</td><td style=\"text-align: right;\">-111.062</td><td style=\"text-align: right;\">            -93.0912</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">            582.37</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:45:35 (running for 00:25:38.91)<br>Memory usage on this node: 9.1/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         1508.78</td><td style=\"text-align: right;\">492000</td><td style=\"text-align: right;\"> 150.914</td><td style=\"text-align: right;\">            193.488 </td><td style=\"text-align: right;\">            -70.7725</td><td style=\"text-align: right;\">           1587.6 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         1514.84</td><td style=\"text-align: right;\">492000</td><td style=\"text-align: right;\">-111.062</td><td style=\"text-align: right;\">            -93.0912</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">            582.37</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 496000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-45-35\n",
      "  done: false\n",
      "  episode_len_mean: 1587.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 196.20007441539863\n",
      "  episode_reward_mean: 152.72600538075497\n",
      "  episode_reward_min: -70.77250116858819\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 412\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.7348470091819763\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012889046221971512\n",
      "          model: {}\n",
      "          policy_loss: -0.02050907164812088\n",
      "          total_loss: 3.066880702972412\n",
      "          vf_explained_var: 0.7865637540817261\n",
      "          vf_loss: 3.0727081298828125\n",
      "    num_agent_steps_sampled: 496000\n",
      "    num_agent_steps_trained: 496000\n",
      "    num_steps_sampled: 496000\n",
      "    num_steps_trained: 496000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.42941176470588\n",
      "    ram_util_percent: 38.188235294117646\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12521161843221035\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4943331012105964\n",
      "    mean_inference_ms: 2.5201997287493314\n",
      "    mean_raw_obs_processing_ms: 0.11027384907088326\n",
      "  time_since_restore: 1520.9501066207886\n",
      "  time_this_iter_s: 12.174439430236816\n",
      "  time_total_s: 1520.9501066207886\n",
      "  timers:\n",
      "    learn_throughput: 664.298\n",
      "    learn_time_ms: 6021.396\n",
      "    load_throughput: 10029421.33\n",
      "    load_time_ms: 0.399\n",
      "    sample_throughput: 322.841\n",
      "    sample_time_ms: 12389.987\n",
      "    update_time_ms: 2.394\n",
      "  timestamp: 1641872735\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 496000\n",
      "  training_iteration: 124\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:45:40 (running for 00:25:44.01)<br>Memory usage on this node: 9.3/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">         1520.95</td><td style=\"text-align: right;\">496000</td><td style=\"text-align: right;\"> 152.726</td><td style=\"text-align: right;\">            196.2   </td><td style=\"text-align: right;\">            -70.7725</td><td style=\"text-align: right;\">           1587.6 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         1514.84</td><td style=\"text-align: right;\">492000</td><td style=\"text-align: right;\">-111.062</td><td style=\"text-align: right;\">            -93.0912</td><td style=\"text-align: right;\">           -131.326 </td><td style=\"text-align: right;\">            582.37</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 496000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-45-42\n",
      "  done: false\n",
      "  episode_len_mean: 581.48\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -93.09124282326412\n",
      "  episode_reward_mean: -112.23322399808735\n",
      "  episode_reward_min: -238.47585568164712\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 935\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.8807909893416293e-38\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.667300701141357\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 4.180939754405699e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.0038500980008393526\n",
      "          total_loss: 600.4487915039062\n",
      "          vf_explained_var: 0.0005482322885654867\n",
      "          vf_loss: 600.4449462890625\n",
      "    num_agent_steps_sampled: 496000\n",
      "    num_agent_steps_trained: 496000\n",
      "    num_steps_sampled: 496000\n",
      "    num_steps_trained: 496000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.30555555555556\n",
      "    ram_util_percent: 38.422222222222224\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1256003913550137\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5002298020831675\n",
      "    mean_inference_ms: 2.5520008077340104\n",
      "    mean_raw_obs_processing_ms: 0.1159338129976199\n",
      "  time_since_restore: 1527.7698628902435\n",
      "  time_this_iter_s: 12.931415557861328\n",
      "  time_total_s: 1527.7698628902435\n",
      "  timers:\n",
      "    learn_throughput: 655.997\n",
      "    learn_time_ms: 6097.593\n",
      "    load_throughput: 40088927.121\n",
      "    load_time_ms: 0.1\n",
      "    sample_throughput: 319.896\n",
      "    sample_time_ms: 12504.055\n",
      "    update_time_ms: 3.59\n",
      "  timestamp: 1641872742\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 496000\n",
      "  training_iteration: 124\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:45:46 (running for 00:25:49.84)<br>Memory usage on this node: 9.3/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 6.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>RUNNING </td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">         1520.95</td><td style=\"text-align: right;\">496000</td><td style=\"text-align: right;\"> 152.726</td><td style=\"text-align: right;\">            196.2   </td><td style=\"text-align: right;\">            -70.7725</td><td style=\"text-align: right;\">           1587.6 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">         1527.77</td><td style=\"text-align: right;\">496000</td><td style=\"text-align: right;\">-112.233</td><td style=\"text-align: right;\">            -93.0912</td><td style=\"text-align: right;\">           -238.476 </td><td style=\"text-align: right;\">            581.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00000:\n",
      "  agent_timesteps_total: 500000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-45-48\n",
      "  done: true\n",
      "  episode_len_mean: 1587.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 196.20007441539863\n",
      "  episode_reward_mean: 153.45067648359728\n",
      "  episode_reward_min: -70.77250116858819\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 414\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.139062523841858\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.0671825408935547\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01213842537254095\n",
      "          model: {}\n",
      "          policy_loss: -0.01928684115409851\n",
      "          total_loss: 2.5726094245910645\n",
      "          vf_explained_var: 0.7618371248245239\n",
      "          vf_loss: 2.5780699253082275\n",
      "    num_agent_steps_sampled: 500000\n",
      "    num_agent_steps_trained: 500000\n",
      "    num_steps_sampled: 500000\n",
      "    num_steps_trained: 500000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.82631578947368\n",
      "    ram_util_percent: 38.900000000000006\n",
      "  pid: 14984\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12518400829059953\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4942068248083011\n",
      "    mean_inference_ms: 2.5198840600970267\n",
      "    mean_raw_obs_processing_ms: 0.11024707265675478\n",
      "  time_since_restore: 1534.4250679016113\n",
      "  time_this_iter_s: 13.474961280822754\n",
      "  time_total_s: 1534.4250679016113\n",
      "  timers:\n",
      "    learn_throughput: 656.802\n",
      "    learn_time_ms: 6090.112\n",
      "    load_throughput: 13372561.773\n",
      "    load_time_ms: 0.299\n",
      "    sample_throughput: 320.539\n",
      "    sample_time_ms: 12478.968\n",
      "    update_time_ms: 2.394\n",
      "  timestamp: 1641872748\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 500000\n",
      "  training_iteration: 125\n",
      "  trial_id: 59aed_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:45:51 (running for 00:25:55.54)<br>Memory usage on this node: 8.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>RUNNING   </td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">         1527.77</td><td style=\"text-align: right;\">496000</td><td style=\"text-align: right;\">-112.233</td><td style=\"text-align: right;\">            -93.0912</td><td style=\"text-align: right;\">           -238.476 </td><td style=\"text-align: right;\">            581.48</td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>TERMINATED</td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         1534.43</td><td style=\"text-align: right;\">500000</td><td style=\"text-align: right;\"> 153.451</td><td style=\"text-align: right;\">            196.2   </td><td style=\"text-align: right;\">            -70.7725</td><td style=\"text-align: right;\">           1587.6 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_59aed_00001:\n",
      "  agent_timesteps_total: 500000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_21-45-53\n",
      "  done: true\n",
      "  episode_len_mean: 581.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -93.09124282326412\n",
      "  episode_reward_mean: -111.92518470832314\n",
      "  episode_reward_min: -238.47585568164712\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 939\n",
      "  experiment_id: df00180b7d954073a5e90382e5a24c5a\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.0\n",
      "          cur_lr: 5.000000058430487e-08\n",
      "          entropy: 5.667382717132568\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 1.7188935430567653e-07\n",
      "          model: {}\n",
      "          policy_loss: 0.003136329585686326\n",
      "          total_loss: 136.68453979492188\n",
      "          vf_explained_var: -0.00047622379497624934\n",
      "          vf_loss: 136.681396484375\n",
      "    num_agent_steps_sampled: 500000\n",
      "    num_agent_steps_trained: 500000\n",
      "    num_steps_sampled: 500000\n",
      "    num_steps_trained: 500000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.329411764705874\n",
      "    ram_util_percent: 37.682352941176475\n",
      "  pid: 16012\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12557965778506777\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5001560740337605\n",
      "    mean_inference_ms: 2.551435364558597\n",
      "    mean_raw_obs_processing_ms: 0.11589909500694423\n",
      "  time_since_restore: 1539.549358844757\n",
      "  time_this_iter_s: 11.77949595451355\n",
      "  time_total_s: 1539.549358844757\n",
      "  timers:\n",
      "    learn_throughput: 665.886\n",
      "    learn_time_ms: 6007.035\n",
      "    load_throughput: 20049254.302\n",
      "    load_time_ms: 0.2\n",
      "    sample_throughput: 317.098\n",
      "    sample_time_ms: 12614.385\n",
      "    update_time_ms: 3.59\n",
      "  timestamp: 1641872753\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 500000\n",
      "  training_iteration: 125\n",
      "  trial_id: 59aed_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 21:45:53 (running for 00:25:57.67)<br>Memory usage on this node: 8.2/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/1 GPUs, 0.0/10.44 GiB heap, 0.0/5.22 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO<br>Number of trials: 2/2 (2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00000</td><td>TERMINATED</td><td>127.0.0.1:14984</td><td style=\"text-align: right;\">5e-05</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         1534.43</td><td style=\"text-align: right;\">500000</td><td style=\"text-align: right;\"> 153.451</td><td style=\"text-align: right;\">            196.2   </td><td style=\"text-align: right;\">            -70.7725</td><td style=\"text-align: right;\">           1587.6 </td></tr>\n",
       "<tr><td>PPO_BipedalWalker-v3_59aed_00001</td><td>TERMINATED</td><td>127.0.0.1:16012</td><td style=\"text-align: right;\">5e-08</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         1539.55</td><td style=\"text-align: right;\">500000</td><td style=\"text-align: right;\">-111.925</td><td style=\"text-align: right;\">            -93.0912</td><td style=\"text-align: right;\">           -238.476 </td><td style=\"text-align: right;\">            581.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 21:45:54,279\tINFO tune.py:626 -- Total run time: 1558.06 seconds (1557.63 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "analysis = tune.run(\n",
    "    'PPO',\n",
    "    config=config,\n",
    "    stop=stop,\n",
    "    checkpoint_at_end=True,\n",
    "    checkpoint_freq=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_lr=5e-05 1_lr=5e-08\n"
     ]
    }
   ],
   "source": [
    "trials = analysis.trials\n",
    "\n",
    "print(trials[0].experiment_tag, trials[1].experiment_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best checkpoint 0_lr=5e-05: C:\\Users\\user\\ray_results\\PPO\\PPO_BipedalWalker-v3_59aed_00000_0_lr=5e-05_2022-01-10_21-19-56\\checkpoint_000125\\checkpoint-125\n"
     ]
    }
   ],
   "source": [
    "trial = trials[0]\n",
    "best_checkpoint = analysis.get_best_checkpoint(trial, metric='episode_reward_mean', mode='max')\n",
    "print(f\"Found best checkpoint {trial.experiment_tag}: {best_checkpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " pid=9340)\u001b[0m 2022-01-10 22:03:48,986\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      "2022-01-10 22:03:50,595\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      "2022-01-10 22:03:51,566\tWARNING util.py:57 -- Install gputil for GPU system monitoring.\n",
      "2022-01-10 22:03:51,628\tINFO trainable.py:467 -- Restored on 127.0.0.1 from checkpoint: C:\\Users\\user\\ray_results\\PPO\\PPO_BipedalWalker-v3_59aed_00000_0_lr=5e-05_2022-01-10_21-19-56\\checkpoint_000125\\checkpoint-125\n",
      "2022-01-10 22:03:51,629\tINFO trainable.py:475 -- Current state after restoring: {'_iteration': 125, '_timesteps_total': 0, '_time_total': 1534.4250679016113, '_episodes_total': 414}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PPO"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['lr'] = 5e-05\n",
    "new_trainer = PPOTrainer(config=config)\n",
    "\n",
    "new_trainer.restore('C:\\\\Users\\\\user\\\\ray_results\\\\PPO\\\\PPO_BipedalWalker-v3_59aed_00000_0_lr=5e-05_2022-01-10_21-19-56\\\\checkpoint_000125\\\\checkpoint-125')\n",
    "new_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 21:55:26,451\tWARNING deprecation.py:45 -- DeprecationWarning: `compute_action` has been deprecated. Use `compute_single_action` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.7473704e-03 -1.9652160e-05  1.5287405e-03 -1.5999869e-02\n",
      "  9.1881022e-02 -2.0174221e-03  8.6031389e-01  2.8935287e-03\n",
      "  1.0000000e+00  3.2286901e-02 -2.0172792e-03  8.5386354e-01\n",
      "  1.4267368e-03  1.0000000e+00  4.4081420e-01  4.4582030e-01\n",
      "  4.6142298e-01  4.8955038e-01  5.3410304e-01  6.0246128e-01\n",
      "  7.0914918e-01  8.8593221e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-0.00123087  0.0072964  -0.01467363 -0.0133914   0.4532907   0.71732265\n",
      "  0.07284689 -1.0001532   1.          0.3549167   0.68547946  0.07684553\n",
      " -1.0011859   1.          0.44630772  0.4513762   0.46717334  0.49565127\n",
      "  0.54075915  0.60996926  0.71798676  0.89697284  1.          1.        ]\n",
      "[ 0.00783661  0.01807019 -0.0048142  -0.04313451  0.5312864   0.9999997\n",
      " -0.0413115  -1.          0.          0.35546896  0.02566755 -0.04081035\n",
      " -1.0000001   0.          0.44430223  0.44934794  0.46507406  0.49342406\n",
      "  0.53832924  0.6072284   0.7147605   0.8929423   1.          1.        ]\n",
      "[ 0.02943771  0.04291969  0.01180127 -0.05921927  0.60965985  1.0000004\n",
      " -0.15181565 -0.99999994  0.          0.28509304 -0.82258284 -0.13860321\n",
      " -0.89175385  0.          0.44155216  0.44656664  0.46219543  0.49036995\n",
      "  0.53499717  0.60346985  0.7103364   0.8874153   1.          1.        ]\n",
      "[ 0.042495    0.02592327  0.00874524 -0.06436388  0.6885913   1.0000075\n",
      " -0.26459968 -0.99999976  0.          0.20385893 -1.0000033  -0.01421261\n",
      "  0.9999962   0.          0.43853897  0.44351923  0.4590414   0.48702362\n",
      "  0.53134626  0.5993517   0.705489    0.8813595   1.          1.        ]\n",
      "[ 0.05593196  0.02673621  0.01066962 -0.08375178  0.76761156  0.9999972\n",
      " -0.37836838 -1.          0.          0.12315588 -0.9999987   0.08736527\n",
      "  0.7621358   1.          0.43462768  0.43956354  0.45494723  0.4826799\n",
      "  0.5266073   0.5940062   0.69919676  0.87349874  1.          1.        ]\n",
      "[ 0.07778539  0.04359378  0.01473102 -0.10716888  0.84704816  0.9999998\n",
      " -0.48932552 -1.          0.          0.0909171  -0.513626   -0.04427862\n",
      " -1.0000001   1.          0.42967382  0.4345534   0.44976178  0.47717834\n",
      "  0.520605    0.5872357   0.6912274   0.8635427   1.          1.        ]\n",
      "[ 0.10547066  0.05506832  0.02278432 -0.12483024  0.9260365   0.99999976\n",
      " -0.54305196 -0.52304834  0.          0.00580233 -0.99999976 -0.15439332\n",
      " -0.9999997   0.          0.4238773   0.42869106  0.44369423  0.47074094\n",
      "  0.5135818   0.5793136   0.68190235  0.851893    1.          1.        ]\n",
      "[ 0.12401108  0.03686832  0.02605067 -0.1294099   1.0058657   1.0000001\n",
      " -0.65610814 -0.99999994  0.         -0.08187179 -1.0789899  -0.02961886\n",
      "  1.0000006   0.          0.41783938  0.42258456  0.43737406  0.46403548\n",
      "  0.50626606  0.57106155  0.672189    0.8397582   1.          1.        ]\n",
      "[ 0.13229273  0.01649844  0.01053611 -0.13937175  1.0817544   0.9999999\n",
      " -0.63490796  0.          0.         -0.13509957 -0.6459509   0.05108273\n",
      "  0.16535622  1.          0.41136658  0.41603827  0.43059865  0.45684707\n",
      "  0.49842346  0.5622152   0.66177607  0.82674944  1.          1.        ]\n",
      "[ 0.165373    0.06628162  0.05240704 -0.0834344   1.0540178  -0.30515146\n",
      " -0.5114286   1.0000001   0.         -0.15311317 -0.4019484   0.01621228\n",
      " -0.20070209  1.          0.4075988   0.4122277   0.4266547   0.4526627\n",
      "  0.49385828  0.5570657   0.6557147   0.8191771   1.          1.        ]\n",
      "[ 1.6524622e-01 -4.1195002e-04  3.7447318e-02 -9.0466172e-02\n",
      "  1.1136959e+00  8.3207005e-01 -3.8161623e-01  9.9999982e-01\n",
      "  0.0000000e+00 -1.4004453e-01  1.5657787e-01 -2.4719954e-02\n",
      " -3.1900239e-01  1.0000000e+00  4.0336117e-01  4.0794194e-01\n",
      "  4.2221895e-01  4.4795656e-01  4.8872387e-01  5.5127418e-01\n",
      "  6.4889753e-01  8.1066048e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 1.9036679e-01  5.0110158e-02  6.0502704e-02 -1.0755994e-01\n",
      "  1.1086278e+00  5.9604645e-08 -2.3204243e-01  1.1913486e+00\n",
      "  0.0000000e+00 -1.8755235e-01 -5.5184960e-01 -1.3860762e-01\n",
      " -9.9999982e-01  1.0000000e+00  3.9840123e-01  4.0292567e-01\n",
      "  4.1702715e-01  4.4244826e-01  4.8271427e-01  5.4449540e-01\n",
      "  6.4091837e-01  8.0069220e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.22387074  0.06690007  0.07304109 -0.12670921  1.0907792  -0.18024231\n",
      " -0.10689282  1.0000001   0.         -0.2720044  -1.0000001  -0.23924649\n",
      " -0.912949    0.          0.39256036  0.3970185   0.4109132   0.43596163\n",
      "  0.4756373   0.53651273  0.631522    0.7889534   1.          1.        ]\n",
      "[ 0.24989206  0.05173196  0.08463258 -0.16769153  1.1694694   0.9999998\n",
      " -0.21597815 -0.9846604   0.         -0.35782492 -0.9999998  -0.34841943\n",
      " -0.9999997   0.          0.38475907  0.3891286   0.40274718  0.42729783\n",
      "  0.46618497  0.52585065  0.6189718   0.77327466  1.          1.        ]\n",
      "[ 0.2880852   0.06530613  0.07538763 -0.16733108  1.1349186   0.\n",
      " -0.12363267  0.39148507  0.         -0.4496498  -1.0000001  -0.4548515\n",
      " -1.0000001   0.          0.37735903  0.38164452  0.39500117  0.41907966\n",
      "  0.4572189   0.51573706  0.6070672   0.75840235  1.          1.        ]\n",
      "[ 0.31849545  0.06087218  0.09076579 -0.16585332  1.1347439   0.\n",
      " -0.13313818 -0.08711231  0.         -0.55381167 -1.296519   -0.33072412\n",
      "  0.99999934  0.          0.36966136  0.37385944  0.38694364  0.41053092\n",
      "  0.44789216  0.5052166   0.59468377  0.74293184  1.          1.        ]\n",
      "[ 3.5101485e-01  6.5057948e-02  9.3890391e-02 -1.7884377e-01\n",
      "  1.1325144e+00  2.9802322e-08 -2.4963617e-01 -9.9999970e-01\n",
      "  0.0000000e+00 -6.3799387e-01 -1.0438567e+00 -2.0870328e-01\n",
      "  1.0000001e+00  0.0000000e+00  3.6136967e-01  3.6547357e-01\n",
      "  3.7826428e-01  4.0132251e-01  4.3784574e-01  4.9388435e-01\n",
      "  5.8134472e-01  7.2626752e-01  9.9675506e-01  1.0000000e+00]\n",
      "[ 0.38067845  0.05933422  0.08993505 -0.19588275  1.1322792   0.\n",
      " -0.3298713  -0.67949295  0.         -0.71895117 -0.99999994 -0.08556318\n",
      "  1.0000001   0.          0.35226786  0.3562684   0.36873695  0.39121443\n",
      "  0.42681772  0.4814449   0.5667024   0.70797503  0.9717863   1.        ]\n",
      "[ 4.0042022e-01  3.9491799e-02  7.0461288e-02 -2.1250965e-01\n",
      "  1.1288677e+00 -1.4901161e-08 -2.0493555e-01  9.9999982e-01\n",
      "  0.0000000e+00 -7.9560667e-01 -9.3949711e-01  3.9888024e-02\n",
      "  9.9999994e-01  0.0000000e+00  3.4235290e-01  3.4624082e-01\n",
      "  3.5835844e-01  3.8020325e-01  4.1480446e-01  4.6789411e-01\n",
      "  5.5075192e-01  6.8804830e-01  9.4459271e-01  1.0000000e+00]\n",
      "[ 4.0661344e-01  1.2407242e-02  5.5367801e-02 -2.1767591e-01\n",
      "  1.1249036e+00  2.3096800e-07 -8.0004930e-02  1.0000001e+00\n",
      "  0.0000000e+00 -8.1102091e-01 -1.6981502e-01  6.7847252e-02\n",
      " -8.6443585e-01  1.0000000e+00  3.3215907e-01  3.3593124e-01\n",
      "  3.4768805e-01  3.6888242e-01  4.0245333e-01  4.5396221e-01\n",
      "  5.3435290e-01  6.6756111e-01  9.1663814e-01  1.0000000e+00]\n",
      "[ 4.1792554e-01  2.2768524e-02  5.7203785e-02 -2.4472271e-01\n",
      "  1.1231852e+00 -2.5331974e-07  4.4284940e-02  9.9999994e-01\n",
      "  0.0000000e+00 -8.0069453e-01  0.0000000e+00 -2.9012561e-02\n",
      " -9.9999982e-01  1.0000000e+00  3.2070085e-01  3.2434291e-01\n",
      "  3.3569413e-01  3.5615739e-01  3.8857025e-01  4.3830225e-01\n",
      "  5.1591974e-01  6.4453280e-01  8.8503933e-01  1.0000000e+00]\n",
      "[ 4.2838928e-01  2.0837739e-02  5.7991315e-02 -2.6207775e-01\n",
      "  1.1202650e+00  1.3411045e-07  1.6947216e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.0276603e-01  0.0000000e+00 -1.4462900e-01\n",
      " -1.0000000e+00  0.0000000e+00  3.0844289e-01  3.1194574e-01\n",
      "  3.2286310e-01  3.4254417e-01  3.7371814e-01  4.2154926e-01\n",
      "  4.9620005e-01  6.1989719e-01  8.5121095e-01  1.0000000e+00]\n",
      "[ 4.3781170e-01  1.8727666e-02  5.8599111e-02 -2.7922046e-01\n",
      "  1.1174425e+00  7.4505806e-08  2.9467708e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.0507070e-01  0.0000000e+00 -2.6091218e-01\n",
      " -1.0000000e+00  0.0000000e+00  2.9537973e-01  2.9873422e-01\n",
      "  3.0918920e-01  3.2803676e-01  3.5789046e-01  4.0369582e-01\n",
      "  4.7518501e-01  5.9364337e-01  8.1516051e-01  1.0000000e+00]\n",
      "[ 4.4082627e-01  6.0015335e-03  6.3334711e-02 -2.8311327e-01\n",
      "  1.1144394e+00  8.5681677e-08  4.1916764e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.0530733e-01  0.0000000e+00 -2.4202478e-01\n",
      "  1.5445577e-01  0.0000000e+00  2.8211764e-01  2.8532150e-01\n",
      "  2.9530710e-01  3.1330842e-01  3.4182173e-01  3.8557050e-01\n",
      "  4.5384994e-01  5.6698966e-01  7.7856106e-01  1.0000000e+00]\n",
      "[ 4.39560056e-01 -2.75562028e-03  6.77262768e-02 -2.90285230e-01\n",
      "  1.11318302e+00 -7.26431608e-08  5.42796969e-01  9.99999940e-01\n",
      "  0.00000000e+00 -8.07969153e-01  3.72529030e-09 -2.62117505e-01\n",
      "  1.14818895e-02  0.00000000e+00  2.68503547e-01  2.71552801e-01\n",
      "  2.81056523e-01  2.98189163e-01  3.25326502e-01  3.66964132e-01\n",
      "  4.31948602e-01  5.39628565e-01  7.40990222e-01  1.00000000e+00]\n",
      "[ 4.2868555e-01 -2.4681417e-02  1.1175228e-01 -7.1080849e-02\n",
      "  1.0692058e+00 -4.8787397e-01  6.6874063e-01  1.0004742e+00\n",
      "  0.0000000e+00 -8.2221287e-01  1.0728836e-05 -2.4316525e-01\n",
      "  1.0284403e-01  0.0000000e+00  2.6557985e-01  2.6859590e-01\n",
      "  2.7799615e-01  2.9494223e-01  3.2178408e-01  3.6296830e-01\n",
      "  4.2724517e-01  5.3375262e-01  7.3292166e-01  1.0000000e+00]\n",
      "[ 4.0260258e-01 -5.2380957e-02  1.3154987e-01  1.0020894e-02\n",
      "  1.0292774e+00 -4.8882559e-01  7.9077017e-01  9.9976873e-01\n",
      "  0.0000000e+00 -8.2098514e-01 -6.3776970e-06 -2.0274615e-01\n",
      "  2.1825825e-01  1.0000000e+00  2.6597968e-01  2.6900029e-01\n",
      "  2.7841467e-01  2.9538625e-01  3.2226852e-01  3.6351475e-01\n",
      "  4.2788839e-01  5.3455621e-01  7.3402506e-01  1.0000000e+00]\n",
      "[ 0.3549099  -0.09562015  0.15666449  0.00528906  1.0486552   0.25279325\n",
      "  0.91200984  1.0000004   0.         -0.7809252   0.418234   -0.20401669\n",
      "  0.12849236  1.          0.26610368  0.2691257   0.27854446  0.29552397\n",
      "  0.32241875  0.36368424  0.4280879   0.5348054   0.7343673   1.        ]\n",
      "[ 0.30369887 -0.10247311  0.1852377   0.00735011  1.1279864   1.0007025\n",
      "  0.82334566 -0.75005084  0.         -0.74900216  0.39467114 -0.18115473\n",
      "  0.19120802  1.          0.2662784   0.2693024   0.27872732  0.29571798\n",
      "  0.32263044  0.36392298  0.42836893  0.53515655  0.73484945  1.        ]\n",
      "[ 0.25538465 -0.09669055  0.21717255  0.01832559  1.1276922   0.\n",
      "  0.9438695   1.          0.         -0.74908817 -0.00155246 -0.11331272\n",
      "  0.55750054  1.          0.2669627   0.26999447  0.27944365  0.29647797\n",
      "  0.32345957  0.36485824  0.42946982  0.53653187  0.73673797  1.        ]\n",
      "[ 2.2662790e-01 -5.7706010e-02  2.5046656e-01  2.7922798e-02\n",
      "  1.1262997e+00 -2.5629997e-06  8.2792079e-01 -1.0000006e+00\n",
      "  0.0000000e+00 -8.0268794e-01 -6.5343893e-01  1.3520896e-02\n",
      "  9.9997264e-01  0.0000000e+00  2.6813161e-01  2.7117667e-01\n",
      "  2.8066722e-01  2.9777610e-01  3.2487586e-01  3.6645579e-01\n",
      "  4.3135026e-01  5.3888106e-01  7.3996377e-01  1.0000000e+00]\n",
      "[ 1.8407716e-01 -8.5438557e-02  2.6478672e-01  3.8663901e-02\n",
      "  1.1233262e+00 -4.1723251e-07  7.1565878e-01 -1.0000001e+00\n",
      "  0.0000000e+00 -8.0358475e-01  0.0000000e+00  8.6336493e-02\n",
      "  5.8289576e-01  0.0000000e+00  2.6976919e-01  2.7283284e-01\n",
      "  2.8238136e-01  2.9959473e-01  3.2685998e-01  3.6869389e-01\n",
      "  4.3398467e-01  5.4217225e-01  7.4448299e-01  1.0000000e+00]\n",
      "[ 0.1177478  -0.13303337  0.28452796  0.04195176  1.0979383  -0.30782145\n",
      "  0.8385502   0.99999994  0.         -0.77566314  0.35788292  0.15246719\n",
      "  0.5326925   0.          0.2714615   0.27454436  0.28415275  0.30147412\n",
      "  0.32891044  0.37100673  0.4367071   0.54557335  0.74915326  1.        ]\n",
      "[ 0.03672147 -0.16226332  0.3085212   0.03535526  1.1632231   0.84816456\n",
      "  0.8701918   0.5151989   1.         -0.73487014  0.5126791   0.22219276\n",
      "  0.56410027  0.          0.27278936  0.2758873   0.2855427   0.3029488\n",
      "  0.33051932  0.37282154  0.43884328  0.54824203  0.7528178   1.        ]\n",
      "[-0.02778049 -0.12988037  0.29356757  0.0803346   1.134808    0.\n",
      "  1.0128334   0.99003476  1.         -0.7284998   0.08602244  0.3364225\n",
      "  0.9199355   0.          0.2764689   0.27960864  0.2893943   0.30703518\n",
      "  0.33497757  0.37785038  0.44476268  0.55563706  0.76297224  1.        ]\n",
      "[-3.0012261e-02 -4.1924074e-02  1.8573947e-01  1.5279616e-01\n",
      "  1.1478257e+00  1.5017033e-02  9.7107506e-01  1.0283986e-03\n",
      "  1.0000000e+00 -7.8020930e-01 -3.7255794e-01  4.6657890e-01\n",
      "  9.9877757e-01  0.0000000e+00  2.8417346e-01  2.8740069e-01\n",
      "  2.9745904e-01  3.1559154e-01  3.4431261e-01  3.8838020e-01\n",
      "  4.5715719e-01  5.7112139e-01  7.8423452e-01  1.0000000e+00]\n",
      "[-0.03911675 -0.03044356  0.16935226  0.161346    1.1392614  -0.0049172\n",
      "  0.93514943 -0.08544817  1.         -0.82011247 -0.4029017   0.5919114\n",
      "  1.002053    0.          0.2918765   0.2951912   0.3055222   0.3241462\n",
      "  0.35364583  0.39890796  0.46954927  0.5866027   0.80549264  1.        ]\n",
      "[-3.8115196e-02  1.7833642e-03  1.5550765e-01  1.6553271e-01\n",
      "  1.1348962e+00 -6.5192580e-09  8.9870143e-01 -4.0516415e-01\n",
      "  1.0000000e+00 -7.6879543e-01  6.5753436e-01  4.7568756e-01\n",
      " -9.9999994e-01  0.0000000e+00  2.9963353e-01  3.0303633e-01\n",
      "  3.1364188e-01  3.3276087e-01  3.6304447e-01  4.0950951e-01\n",
      "  4.8202822e-01  6.0219246e-01  8.2679391e-01  1.0000000e+00]\n",
      "[-0.02404182  0.0283006   0.15141185  0.17230669  1.1349084   0.\n",
      "  0.81829125 -0.6735523   1.         -0.69019777  0.9999997   0.36186188\n",
      " -1.          0.          0.30772558  0.31122026  0.32211226  0.34174755\n",
      "  0.37284902  0.4205689   0.49504608  0.6184556   0.848941    1.        ]\n",
      "[ 0.00636311  0.06097516  0.150304    0.1673676   1.1339831  -0.00281334\n",
      "  0.6999539  -1.0009922   1.         -0.61141557  1.000588    0.24707788\n",
      " -0.99944836  0.          0.31564185  0.31922644  0.33039862  0.35053906\n",
      "  0.3824406   0.43138808  0.5077812   0.63436544  0.8706066   1.        ]\n",
      "[ 0.04193072  0.07116474  0.1489459   0.15252003  1.1256666  -0.09376791\n",
      "  0.5835091  -0.99999994  1.         -0.53571314  1.0000005   0.14575225\n",
      " -0.9999991   0.          0.3228366   0.32650292  0.33792976  0.35852927\n",
      "  0.39115798  0.44122118  0.5193556   0.64882517  0.89032406  1.        ]\n",
      "[ 0.08627806  0.08876014  0.14993353  0.14325093  1.0772396  -0.58148503\n",
      "  0.5407012  -0.01863337  1.         -0.45857754  0.99999946  0.00587285\n",
      " -1.3452736   1.          0.32963806  0.3333816   0.34504917  0.36608267\n",
      "  0.3993988   0.45051673  0.5302973   0.6624945   0.9124193   1.        ]\n",
      "[ 0.11740499  0.06260744  0.14545038  0.11301981  1.0817392   0.12627384\n",
      "  0.40139687 -1.          0.         -0.37944496  1.0000002  -0.08899772\n",
      " -1.0083088   1.          0.3349846   0.33878887  0.35064566  0.37202033\n",
      "  0.40587682  0.45782384  0.5388984   0.67323977  0.92991215  1.        ]\n",
      "[ 0.15696539  0.07918868  0.1448166   0.10455867  1.000343   -0.9999995\n",
      "  0.52390915  1.          0.         -0.319791    0.7540005  -0.20485008\n",
      " -0.99999994  1.          0.33998942  0.34385052  0.3558845   0.3775785\n",
      "  0.4119408   0.46466395  0.54694974  0.6832983   0.94632953  1.        ]\n",
      "[ 0.20262058  0.09127481  0.15767732  0.08391798  0.9192995  -1.\n",
      "  0.64316314  0.97505146  0.         -0.30575687  0.18332034 -0.25468612\n",
      " -0.4601151   0.          0.34405646  0.34796375  0.36014166  0.38209516\n",
      "  0.41686854  0.47022235  0.5534925   0.69147205  0.9598561   1.        ]\n",
      "[ 0.2577266   0.11013006  0.18371846  0.06963342  0.83846796 -1.\n",
      "  0.754981    0.91724366  0.         -0.3818355  -0.92920303 -0.21421266\n",
      " -0.04219925  1.          0.34748843  0.35143468  0.36373407  0.38590658\n",
      "  0.42102683  0.47491285  0.5590136   0.6983695   0.97016615  1.        ]\n",
      "[ 0.31239593  0.10941148  0.19956228  0.05378739  0.8285281  -0.11513829\n",
      "  0.6387574  -0.9999998   0.         -0.48594975 -1.3003616  -0.10438323\n",
      "  0.586442    1.          0.35008016  0.35405585  0.36644697  0.38878486\n",
      "  0.42416704  0.47845498  0.563183    0.7035783   0.9776751   1.        ]\n",
      "[ 0.3561687   0.08751734  0.21376841  0.04814891  0.85291827  0.32529384\n",
      "  0.52266777 -0.99999994  0.         -0.58044255 -1.183527   -0.03132904\n",
      "  0.61416924  1.          0.35245812  0.3564608   0.36893612  0.3914257\n",
      "  0.42704824  0.48170492  0.5670085   0.7083574   0.984591    1.        ]\n",
      "[ 0.38685685  0.06099944  0.20582235  0.01417264  0.92975914  0.9999998\n",
      "  0.41368717 -1.0000001   0.         -0.64955044 -0.8471276  -0.03728902\n",
      " -0.08169702  1.          0.35318804  0.357199    0.36970016  0.39223632\n",
      "  0.42793262  0.4827025   0.5681827   0.7098244   0.9868365   1.        ]\n",
      "[ 0.41981936  0.06556599  0.21127495 -0.01264885  1.006423    1.0000001\n",
      "  0.3503942  -0.62492603  0.         -0.7324286  -1.         -0.09659171\n",
      " -0.54520196  0.          0.3526668   0.35667187  0.36915454  0.39165747\n",
      "  0.42730108  0.48199013  0.5673442   0.7087768   0.98554397  1.        ]\n",
      "[ 0.45678374  0.07355423  0.21639659 -0.03138195  1.0832001   1.0000014\n",
      "  0.242859   -0.99999994  0.         -0.81626725 -1.0000005  -0.18139791\n",
      " -0.77006215  0.          0.35128278  0.3552721   0.36770582  0.39012042\n",
      "  0.42562416  0.48009858  0.56511766  0.70599526  0.9818129   1.        ]\n",
      "[ 0.48256433  0.05121646  0.19679098 -0.04051488  1.1608341   1.0000002\n",
      "  0.13309026 -0.99999994  0.         -0.82128054  0.         -0.35939515\n",
      " -1.5504794   0.          0.34944806  0.35341656  0.36578533  0.38808286\n",
      "  0.42340115  0.47759107  0.5621661   0.7023079   0.9767891   1.        ]\n",
      "[ 5.2382070e-01  7.4912637e-02  1.9309182e-01 -3.0577518e-02\n",
      "  1.1349111e+00  5.9604645e-08  1.0032481e-01 -6.2111616e-01\n",
      "  0.0000000e+00 -8.2643324e-01  0.0000000e+00 -4.7379613e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.4834781e-01  3.5230383e-01\n",
      "  3.6463365e-01  3.8686097e-01  4.2206806e-01  4.7608736e-01\n",
      "  5.6039613e-01  7.0009667e-01  9.7383660e-01  1.0000000e+00]\n",
      "[ 5.5041635e-01  5.3107876e-02  1.8438788e-01 -5.1893428e-02\n",
      "  1.1320221e+00 -8.9406967e-08  1.9704860e-01  7.6394492e-01\n",
      "  0.0000000e+00 -8.2745248e-01  0.0000000e+00 -5.7601273e-01\n",
      " -8.6514091e-01  0.0000000e+00  3.4598693e-01  3.4991613e-01\n",
      "  3.6216238e-01  3.8423908e-01  4.1920757e-01  4.7286075e-01\n",
      "  5.5659813e-01  6.9535184e-01  9.6731085e-01  1.0000000e+00]\n",
      "[ 5.7005173e-01  3.9119203e-02  1.9244023e-01 -5.4107048e-02\n",
      "  1.1285410e+00  2.3841858e-07  3.2339537e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.2910633e-01  0.0000000e+00 -5.0062394e-01\n",
      "  6.1232275e-01  0.0000000e+00  3.4350571e-01  3.4740674e-01\n",
      "  3.5956517e-01  3.8148353e-01  4.1620123e-01  4.6946967e-01\n",
      "  5.5260652e-01  6.9036520e-01  9.6045226e-01  1.0000000e+00]\n",
      "[ 5.8741021e-01  3.4534112e-02  1.9575100e-01 -6.6569276e-02\n",
      "  1.1255529e+00 -1.7881393e-07  4.4918966e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3260465e-01  0.0000000e+00 -3.7665391e-01\n",
      "  1.0000004e+00  0.0000000e+00  3.4043145e-01  3.4429756e-01\n",
      "  3.5634717e-01  3.7806937e-01  4.1247639e-01  4.6526808e-01\n",
      "  5.4766089e-01  6.8418664e-01  9.5191783e-01  1.0000000e+00]\n",
      "[ 6.0495585e-01  3.5452560e-02  1.9676869e-01 -8.1547461e-02\n",
      "  1.1242306e+00 -7.4505806e-08  5.4719698e-01  7.8216505e-01\n",
      "  0.0000000e+00 -8.3490789e-01  0.0000000e+00 -2.5335228e-01\n",
      "  1.0000002e+00  0.0000000e+00  3.3665267e-01  3.4047586e-01\n",
      "  3.5239172e-01  3.7387282e-01  4.0789789e-01  4.6010360e-01\n",
      "  5.4158187e-01  6.7659217e-01  9.4138932e-01  1.0000000e+00]\n",
      "[ 6.2739074e-01  4.6148948e-02  1.9661769e-01 -9.2592508e-02\n",
      "  1.1246767e+00  2.9802322e-08  5.4915750e-01  9.0522766e-03\n",
      "  0.0000000e+00 -8.3490741e-01  0.0000000e+00 -1.3271356e-01\n",
      "  9.9999970e-01  0.0000000e+00  3.3235693e-01  3.3613133e-01\n",
      "  3.4789515e-01  3.6910215e-01  4.0269306e-01  4.5423260e-01\n",
      "  5.3467119e-01  6.6795874e-01  9.2939538e-01  1.0000000e+00]\n",
      "[ 0.65385854  0.05424757  0.19473657 -0.1048089   1.124906    0.\n",
      "  0.4801252  -0.5882918   0.         -0.83490777  0.         -0.2723688\n",
      " -1.258905    1.          0.32749006  0.3312092   0.34280077  0.3636972\n",
      "  0.39679623  0.44758105  0.5268417   0.6581775   0.9157826   1.        ]\n",
      "[ 0.67674994  0.04686331  0.1918048  -0.14069933  1.1172678  -0.10399912\n",
      "  0.54379     0.522627    0.         -0.83325166  0.         -0.26224434\n",
      " -0.9999997   1.          0.32074708  0.32438964  0.33574253  0.3562087\n",
      "  0.38862625  0.4383654   0.51599413  0.6446257   0.8968561   1.        ]\n",
      "[ 6.9302052e-01  3.2538529e-02  1.9454816e-01 -1.5484163e-01\n",
      "  1.1151671e+00  2.9802322e-08  6.4798796e-01  8.4249187e-01\n",
      "  0.0000000e+00 -8.3360207e-01  0.0000000e+00 -3.1281066e-01\n",
      " -4.3064377e-01  0.0000000e+00  3.1352317e-01  3.1708372e-01\n",
      "  3.2818088e-01  3.4818614e-01  3.7987354e-01  4.2849249e-01\n",
      "  5.0437284e-01  6.3010740e-01  8.7657130e-01  1.0000000e+00]\n",
      "[ 7.0411217e-01  2.1904523e-02  1.9665980e-01 -1.6225313e-01\n",
      "  1.1139811e+00  1.6391277e-07  7.7067912e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3464795e-01  0.0000000e+00 -3.7188470e-01\n",
      " -8.6098772e-01  1.0000000e+00  3.0595174e-01  3.0942628e-01\n",
      "  3.2025549e-01  3.3977762e-01  3.7069979e-01  4.1814461e-01\n",
      "  4.9219248e-01  6.1489058e-01  8.5530591e-01  1.0000000e+00]\n",
      "[ 7.0844096e-01  9.4212033e-03  1.9351974e-01 -1.7412806e-01\n",
      "  1.1145349e+00  4.4703484e-08  8.9110172e-01  9.9999994e-01\n",
      "  0.0000000e+00 -8.3490759e-01  0.0000000e+00 -3.7494135e-01\n",
      " -3.6196503e-01  1.0000000e+00  2.9769734e-01  3.0107814e-01\n",
      "  3.1161517e-01  3.3061060e-01  3.6069852e-01  4.0686330e-01\n",
      "  4.7891340e-01  5.9830117e-01  8.3056647e-01  1.0000000e+00]\n",
      "[ 7.0384634e-01 -9.1727646e-03  1.9010466e-01 -1.7647681e-01\n",
      "  1.1145010e+00  1.8626451e-08  1.0108304e+00  1.0000000e+00\n",
      "  0.0000000e+00 -8.3490759e-01  0.0000000e+00 -4.1083753e-01\n",
      " -2.9562548e-01  1.0000000e+00  2.8941914e-01  2.9270595e-01\n",
      "  3.0294997e-01  3.2141718e-01  3.5066843e-01  3.9554948e-01\n",
      "  4.6559605e-01  5.8166397e-01  8.0541962e-01  1.0000000e+00]\n",
      "[ 6.9670814e-01 -1.5422923e-02  1.7680790e-01 -1.6849342e-01\n",
      "  1.1349373e+00  1.6391277e-07  9.3490899e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3491498e-01  0.0000000e+00 -4.4218493e-01\n",
      " -2.5406066e-01  1.0000000e+00  2.8145057e-01  2.8464687e-01\n",
      "  2.9460883e-01  3.1256759e-01  3.4101349e-01  3.8465884e-01\n",
      "  4.5277682e-01  5.6564903e-01  7.8118283e-01  1.0000000e+00]\n",
      "[ 6.8633848e-01 -2.0748641e-02  1.6243964e-01 -1.6097809e-01\n",
      "  1.1339407e+00  6.4864755e-05  8.1784773e-01 -9.9999410e-01\n",
      "  0.0000000e+00 -8.3490759e-01 -2.2649765e-06 -4.7040212e-01\n",
      " -2.3638050e-01  1.0000000e+00  2.7388924e-01  2.7699968e-01\n",
      "  2.8669402e-01  3.0417031e-01  3.3185196e-01  3.7432477e-01\n",
      "  4.4061270e-01  5.5045259e-01  7.5816512e-01  1.0000000e+00]\n",
      "[ 6.6667867e-01 -3.9469648e-02  1.6850227e-01 -3.2586340e-02\n",
      "  1.1313487e+00 -8.8171661e-04  7.1520483e-01 -8.9941192e-01\n",
      "  0.0000000e+00 -8.3503276e-01  1.3366342e-04 -4.6536958e-01\n",
      "  1.6439562e-01  1.0000000e+00  2.7248877e-01  2.7558330e-01\n",
      "  2.8522807e-01  3.0261499e-01  3.3015510e-01  3.7241074e-01\n",
      "  4.3835974e-01  5.4763794e-01  7.5456345e-01  1.0000000e+00]\n",
      "[ 6.4231217e-01 -4.8841611e-02  1.9322306e-01  3.5495074e-03\n",
      "  1.0817640e+00 -6.0593438e-01  8.3788514e-01  1.0000013e+00\n",
      "  0.0000000e+00 -8.3499652e-01  2.9802322e-07 -4.4141924e-01\n",
      "  2.0350648e-01  0.0000000e+00  2.7268887e-01  2.7578565e-01\n",
      "  2.8543752e-01  3.0283722e-01  3.3039755e-01  3.7268421e-01\n",
      "  4.3868163e-01  5.4804009e-01  7.5611752e-01  1.0000000e+00]\n",
      "[ 6.0906559e-01 -6.6074617e-02  2.0319058e-01  5.0895765e-02\n",
      "  1.0392891e+00 -5.3227544e-01  9.5843780e-01  1.0000014e+00\n",
      "  0.0000000e+00 -8.3490735e-01  2.6822090e-07 -3.9466226e-01\n",
      "  2.7531490e-01  1.0000000e+00  2.7498975e-01  2.7811268e-01\n",
      "  2.8784597e-01  3.0539247e-01  3.3318537e-01  3.7582883e-01\n",
      "  4.4238314e-01  5.5266434e-01  7.6433069e-01  1.0000000e+00]\n",
      "[ 5.6977171e-01 -7.8530088e-02  2.3194538e-01  4.0851146e-02\n",
      "  1.0891387e+00  6.3168293e-01  8.4020615e-01 -1.0000001e+00\n",
      "  0.0000000e+00 -8.2984662e-01 -3.5762787e-07 -3.3908033e-01\n",
      "  4.1133639e-01  1.0000000e+00  2.7678612e-01  2.7992946e-01\n",
      "  2.8972632e-01  3.0738744e-01  3.3536190e-01  3.7828392e-01\n",
      "  4.4527298e-01  5.5627459e-01  7.7109015e-01  1.0000000e+00]\n",
      "[ 5.2148098e-01 -9.6605636e-02  2.5610551e-01  4.4923380e-02\n",
      "  1.0914426e+00  3.1836689e-02  9.6059084e-01  9.9999970e-01\n",
      "  0.0000000e+00 -8.2960397e-01 -3.5762787e-07 -2.7716899e-01\n",
      "  5.1229137e-01  0.0000000e+00  2.7875200e-01  2.8191766e-01\n",
      "  2.9178411e-01  3.0957067e-01  3.3774382e-01  3.8097069e-01\n",
      "  4.4843554e-01  5.6022555e-01  7.7850062e-01  1.0000000e+00]\n",
      "[ 0.47020236 -0.10253562  0.28089985  0.04696233  1.1359789   0.4583115\n",
      "  0.9349066   0.          0.         -0.8298932   0.         -0.2089647\n",
      "  0.56760836  0.          0.2807549   0.2839433   0.29388064  0.31179503\n",
      "  0.3401706   0.38370806  0.45165765  0.5642509   0.7857808   1.        ]\n",
      "[ 4.2423940e-01 -9.2548534e-02  2.9968688e-01  6.1654072e-02\n",
      "  1.1349185e+00  1.7881393e-07  9.3490767e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3041602e-01  0.0000000e+00 -1.3916135e-01\n",
      "  5.7132393e-01  0.0000000e+00  2.8350550e-01  2.8672513e-01\n",
      "  2.9675984e-01  3.1484973e-01  3.4350330e-01  3.8746729e-01\n",
      "  4.5608261e-01  5.6977898e-01  7.9383254e-01  1.0000000e+00]\n",
      "[ 0.3784434  -0.09171879  0.32324654  0.07100525  1.1339961   0.\n",
      "  0.8705766  -0.55435926  0.         -0.8306195   0.         -0.0648185\n",
      "  0.60577875  0.          0.28668088  0.28993657  0.30008367  0.31837618\n",
      "  0.34735066  0.3918071   0.46119094  0.5761607   0.80310744  1.        ]\n",
      "[ 3.2688141e-01 -1.0331860e-01  3.5129452e-01  7.6683603e-02\n",
      "  1.1327072e+00 -2.3841858e-07  8.1553376e-01 -4.8632005e-01\n",
      "  0.0000000e+00 -8.3119398e-01  0.0000000e+00  2.1788120e-02\n",
      "  7.0034075e-01  0.0000000e+00  2.9009131e-01  2.9338574e-01\n",
      "  3.0365354e-01  3.2216367e-01  3.5148284e-01  3.9646813e-01\n",
      "  4.6667737e-01  5.8301485e-01  8.1307274e-01  1.0000000e+00]\n",
      "[ 0.25925016 -0.13545491  0.3811549   0.07589312  1.1209421  -0.14226836\n",
      "  0.93660474  0.9999998   0.         -0.8320218   0.          0.13486803\n",
      "  0.90813947  0.          0.29338747  0.29671934  0.3071038   0.32582423\n",
      "  0.35547656  0.40097302  0.47198     0.58963877  0.82274127  1.        ]\n",
      "[ 1.9215102e-01 -1.3454001e-01  4.0032437e-01  9.1013044e-02\n",
      "  1.1029863e+00 -2.3006785e-01  9.3490660e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3353239e-01 -5.9604645e-08  2.5621170e-01\n",
      "  9.7924805e-01  0.0000000e+00  2.9735938e-01  3.0073634e-01\n",
      "  3.1126142e-01  3.3023527e-01  3.6028904e-01  4.0640143e-01\n",
      "  4.7836971e-01  5.9751767e-01  8.3194089e-01  1.0000000e+00]\n",
      "[ 0.12054721 -0.14341444  0.40209106  0.07187473  1.0946401  -0.10207033\n",
      "  0.9349067   0.          0.         -0.831071    0.04579747  0.38090003\n",
      "  1.0001154   0.          0.3004162   0.30382788  0.31446114  0.33363006\n",
      "  0.36399278  0.41057917  0.4832873   0.6035659   0.837878    1.        ]\n",
      "[ 0.04337018 -0.15456058  0.40120977  0.05909886  1.1148086   0.2847001\n",
      "  0.82139754 -1.0000001   0.         -0.8203583   0.1391002   0.5037377\n",
      "  0.9999997   0.          0.30285183  0.30629116  0.31701064  0.33633497\n",
      "  0.36694384  0.41390795  0.48720556  0.60837156  0.8423002   1.        ]\n",
      "[-0.02642952 -0.14037588  0.40755653  0.05781226  1.048056   -0.8160783\n",
      "  1.0446541   2.5634353   1.         -0.81486034  0.09714884  0.6288269\n",
      "  1.0000001   0.          0.30517945  0.30864522  0.31944707  0.33891994\n",
      "  0.36976406  0.4170891   0.49095008  0.6129599   0.84642833  1.        ]\n",
      "[-0.12005947 -0.18233837  0.3215605   0.07038385  1.1737313   1.0284069\n",
      "  0.9348956   0.          1.         -0.7745799   0.42354506  0.7443635\n",
      "  0.9999997   0.          0.30821213  0.31171235  0.32262155  0.3422879\n",
      "  0.37343854  0.4212339   0.4958288   0.61897695  0.8527004   1.        ]\n",
      "[-1.2392289e-01 -4.7877178e-02  2.3648806e-01  1.6240381e-01\n",
      "  1.1469648e+00  1.4392853e-02  9.5154381e-01 -1.4136235e-04\n",
      "  1.0000000e+00 -8.1329936e-01 -2.1499842e-01  8.6860663e-01\n",
      "  9.9886280e-01  0.0000000e+00  3.1653985e-01  3.2013464e-01\n",
      "  3.3133861e-01  3.5153633e-01  3.8352865e-01  4.3261540e-01\n",
      "  5.0922585e-01  6.3784295e-01  8.7408817e-01  1.0000000e+00]\n",
      "[-0.13161294 -0.01800085  0.22459897  0.17249665  1.1356238  -0.00581534\n",
      "  0.93494457 -0.25292525  1.         -0.74200624  0.9191764   0.75178605\n",
      " -0.9992447   0.          0.32463154  0.32831824  0.33980858  0.36052263\n",
      "  0.39333278  0.4436743   0.52224314  0.65631455  0.89545345  1.        ]\n",
      "[-1.2004619e-01  2.3172917e-02  2.2471797e-01  1.7253265e-01\n",
      "  1.1349065e+00 -1.4901161e-08  8.5912210e-01 -6.4695597e-01\n",
      "  1.0000000e+00 -6.7181873e-01  8.9482117e-01  6.3661110e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.3272582e-01  3.3650443e-01\n",
      "  3.4828129e-01  3.6951181e-01  4.0314004e-01  4.5473677e-01\n",
      "  5.3526461e-01  6.7479253e-01  9.1682529e-01  1.0000000e+00]\n",
      "[-9.1641001e-02  5.6961332e-02  2.2251935e-01  1.7327520e-01\n",
      "  1.1343781e+00 -3.2788515e-04  7.4083185e-01 -1.0001138e+00\n",
      "  1.0000000e+00 -5.9349734e-01  1.0000684e+00  5.2349395e-01\n",
      " -9.9992889e-01  0.0000000e+00  3.4089941e-01  3.4477085e-01\n",
      "  3.5683700e-01  3.7858906e-01  4.1304338e-01  4.6590763e-01\n",
      "  5.4838419e-01  6.9313455e-01  9.3893278e-01  1.0000000e+00]\n",
      "[-0.05505481  0.07327317  0.22283477  0.15846689  1.1226541  -0.13505\n",
      "  0.6236416  -1.          1.         -0.5238815   0.9020333   0.4133379\n",
      " -1.          0.          0.3483986   0.35235518  0.3646868   0.38691738\n",
      "  0.4221296   0.47615677  0.560379    0.70860773  0.95962834  1.        ]\n",
      "[-0.02513797  0.05992407  0.22189237  0.14444445  1.1120179  -0.1129564\n",
      "  0.5068585  -1.          0.         -0.4561883   0.8634132   0.2982968\n",
      " -1.0000004   1.          0.35524136  0.35927567  0.37184948  0.39451668\n",
      "  0.43042052  0.48550877  0.57132155  0.7227382   0.9785123   1.        ]\n",
      "[ 0.02567053  0.10154189  0.2346669   0.13189201  1.0309395  -0.99999964\n",
      "  0.4948473   0.20618953  1.         -0.43394724  0.3109675   0.18919241\n",
      " -0.9999998   0.          0.3615584   0.36566445  0.37846184  0.4015321\n",
      "  0.4380744   0.4941423   0.58141935  0.7358016   0.99584395  1.        ]\n",
      "[ 0.07701406  0.10297288  0.22720262  0.11601836  0.9978129  -0.43269056\n",
      "  0.35584795 -0.99999976  1.         -0.3946211   0.51213557  0.07750481\n",
      " -1.0000001   0.          0.3671601   0.37132978  0.38432544  0.40775314\n",
      "  0.44486162  0.50179815  0.5903715   0.7473964   1.          1.        ]\n",
      "[ 0.11865841  0.08344     0.21935594  0.09410605  0.9868824  -0.11307159\n",
      "  0.23835504 -1.0000001   1.         -0.33348468  0.77259314 -0.03794122\n",
      " -1.          0.          0.37168464  0.3759057   0.3890615   0.4127779\n",
      "  0.45034367  0.50798184  0.59759736  0.75609934  1.          1.        ]\n",
      "[ 0.15337907  0.06940635  0.21430469  0.06954363  1.0031468   0.21446264\n",
      "  0.12205976 -1.0000001   0.         -0.26605964  0.8727899  -0.14372873\n",
      " -1.          0.          0.37500763  0.3792664   0.39253983  0.4164683\n",
      "  0.45436984  0.51252335  0.6032171   0.761635    1.          1.        ]\n",
      "[ 0.2004252   0.09410256  0.22225997  0.05498831  0.9589869  -0.5410721\n",
      "  0.17785323  0.4525038   0.         -0.24708134  0.24739832 -0.26052403\n",
      " -0.9999998   0.          0.377729    0.3820187   0.39538845  0.41949052\n",
      "  0.45766714  0.5162427   0.6084372   0.7660386   1.          1.        ]\n",
      "[ 0.2539053   0.10686187  0.24037866  0.01915229  0.96803457  0.12564039\n",
      "  0.12174422 -0.49745587  0.         -0.28934595 -0.5050769  -0.37599766\n",
      " -1.0000001   0.          0.37879393  0.3830957   0.39650315  0.4206732\n",
      "  0.45895743  0.5176981   0.6108677   0.7673268   1.          1.        ]\n",
      "[ 0.30354625  0.09880645  0.250495   -0.01710907  1.0412873   0.95937365\n",
      "  0.01660037 -1.0000001   0.         -0.3742711  -0.9999997  -0.4880358\n",
      " -0.99999994  0.          0.3781275   0.3824217   0.39580557  0.41993308\n",
      "  0.45814997  0.5167873   0.6103651   0.7653778   1.          1.        ]\n",
      "[ 0.35400534  0.10055316  0.27404866 -0.02152089  1.1182575   1.0000005\n",
      " -0.08822346 -0.99999994  0.         -0.5114453  -1.702975   -0.36201715\n",
      "  1.0000002   0.          0.37723994  0.3815241   0.3948765   0.4189474\n",
      "  0.45707458  0.51557064  0.6095427   0.7629539   1.          1.        ]\n",
      "[ 4.1748145e-01  1.2680498e-01  2.5728989e-01 -3.5634749e-02\n",
      "  1.1174438e+00  5.9604645e-08 -1.5268087e-01 -5.7331347e-01\n",
      "  0.0000000e+00 -5.9467179e-01 -1.0000000e+00 -4.7663879e-01\n",
      " -1.0000004e+00  0.0000000e+00  3.7575275e-01  3.8001999e-01\n",
      "  3.9331979e-01  4.1729578e-01  4.5527267e-01  5.1351458e-01\n",
      "  6.0764438e-01  7.5947642e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 4.8296377e-01  1.3082491e-01  2.6157683e-01 -5.1659759e-02\n",
      "  1.1159354e+00 -5.9604645e-08 -2.6758468e-01 -1.0000001e+00\n",
      "  0.0000000e+00 -6.7771411e-01 -9.9999988e-01 -5.9238803e-01\n",
      " -9.9999982e-01  0.0000000e+00  3.7351426e-01  3.7775609e-01\n",
      "  3.9097667e-01  4.1480982e-01  4.5256045e-01  5.1043385e-01\n",
      "  6.0446942e-01  7.5459874e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 5.4542243e-01  1.2478907e-01  2.5818476e-01 -6.8810292e-02\n",
      "  1.1151748e+00 -5.9604645e-08 -3.3646536e-01 -6.0581017e-01\n",
      "  0.0000000e+00 -7.6086390e-01 -9.9999988e-01 -7.0855105e-01\n",
      " -9.9999982e-01  0.0000000e+00  3.7045521e-01  3.7466228e-01\n",
      "  3.8777459e-01  4.1141257e-01  4.4885400e-01  5.0623482e-01\n",
      "  5.9988064e-01  7.4821341e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 5.97053885e-01  1.00796245e-01  2.47328535e-01 -7.65817463e-02\n",
      "  1.10737646e+00 -1.19209290e-07 -2.08399653e-01  9.99999583e-01\n",
      "  0.00000000e+00 -8.55391204e-01 -1.00000000e+00 -6.34908557e-01\n",
      "  1.98682155e-08  0.00000000e+00  3.67200971e-01  3.71371090e-01\n",
      "  3.84368211e-01  4.07798529e-01  4.44911093e-01  5.01769960e-01\n",
      "  5.94950676e-01  7.41474926e-01  1.00000000e+00  1.00000000e+00]\n",
      "[ 6.2733078e-01  6.8695128e-02  2.3226078e-01 -7.4567683e-02\n",
      "  1.1060677e+00  5.9604645e-08 -6.6435933e-02  1.0903424e+00\n",
      "  0.0000000e+00 -8.3491284e-01  0.0000000e+00 -5.7890213e-01\n",
      "  6.0509878e-01  0.0000000e+00  3.6383855e-01  3.6797050e-01\n",
      "  3.8084859e-01  4.0406439e-01  4.4083709e-01  4.9716073e-01\n",
      "  5.8976495e-01  7.3461556e-01  9.9782991e-01  1.0000000e+00]\n",
      "[ 6.6337627e-01  7.1984716e-02  2.3093583e-01 -1.0187390e-01\n",
      "  1.1009283e+00 -2.3841858e-07  6.1952889e-02  9.9999994e-01\n",
      "  0.0000000e+00 -8.3486891e-01  0.0000000e+00 -6.1271262e-01\n",
      " -2.8892168e-01  0.0000000e+00  3.5915095e-01  3.6322966e-01\n",
      "  3.7594184e-01  3.9885852e-01  4.3515745e-01  4.9074423e-01\n",
      "  5.8232313e-01  7.2529089e-01  9.8394990e-01  1.0000000e+00]\n",
      "[ 6.94138765e-01  6.28834367e-02  2.39512682e-01 -1.05604656e-01\n",
      "  1.09773374e+00  1.78813934e-07  1.90460622e-01  1.00000012e+00\n",
      "  0.00000000e+00 -8.34908009e-01  0.00000000e+00 -4.91811275e-01\n",
      "  9.99999821e-01  0.00000000e+00  3.54281843e-01  3.58305246e-01\n",
      "  3.70845079e-01  3.93451065e-01  4.29257900e-01  4.84079391e-01\n",
      "  5.74591994e-01  7.15606749e-01  9.70810354e-01  1.00000000e+00]\n",
      "[ 0.7168014   0.04647754  0.24413684 -0.12967184  1.1208656   0.35047325\n",
      "  0.3222257   1.          0.         -0.8349078   0.         -0.37136436\n",
      "  1.0000004   0.          0.34826627  0.35222137  0.3645483   0.38677043\n",
      "  0.42196926  0.47585085  0.5649134   0.7037849   0.954667    1.        ]\n",
      "[ 7.4403334e-01  5.5749640e-02  2.4227071e-01 -1.3928403e-01\n",
      "  1.1179198e+00  2.0861626e-07  4.4996846e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3490735e-01  0.0000000e+00 -2.5066543e-01\n",
      "  9.9999970e-01  0.0000000e+00  3.4179607e-01  3.4567767e-01\n",
      "  3.5777560e-01  3.7958488e-01  4.1412979e-01  4.6700281e-01\n",
      "  5.5444950e-01  6.9112992e-01  9.3734157e-01  1.0000000e+00]\n",
      "[ 7.7308768e-01  5.9463810e-02  2.4344742e-01 -1.5336470e-01\n",
      "  1.1169641e+00 -5.9604645e-08  5.2450335e-01  5.8742976e-01\n",
      "  0.0000000e+00 -8.3490771e-01  0.0000000e+00 -3.3295858e-01\n",
      " -1.6011939e+00  1.0000000e+00  3.3465433e-01  3.3845484e-01\n",
      "  3.5029998e-01  3.7165356e-01  4.0547666e-01  4.5723912e-01\n",
      "  5.4283780e-01  6.7723089e-01  9.1826183e-01  1.0000000e+00]\n",
      "[ 8.0176681e-01  6.1206773e-02  2.4013710e-01 -1.8130836e-01\n",
      "  1.1185515e+00 -8.9406967e-08  5.8211648e-01  4.5850563e-01\n",
      "  0.0000000e+00 -8.3490837e-01  0.0000000e+00 -3.3161068e-01\n",
      " -8.8625461e-01  0.0000000e+00  3.2603970e-01  3.2974237e-01\n",
      "  3.4128261e-01  3.6208650e-01  3.9503893e-01  4.4546789e-01\n",
      "  5.2869403e-01  6.6061938e-01  8.9534432e-01  1.0000000e+00]\n",
      "[ 0.8321689   0.06094699  0.24139555 -0.19508778  1.1176605   0.\n",
      "  0.6307775   0.3860518   0.         -0.8349069   0.         -0.41536057\n",
      " -0.70545334  0.          0.31695095  0.3205504   0.33176893  0.3519929\n",
      "  0.38402674  0.43304992  0.51374537  0.64312345  0.8711843   1.        ]\n",
      "[ 0.8637951   0.06352949  0.23906493 -0.19590975  1.1175091   0.\n",
      "  0.60447466 -0.2269448   0.         -0.83490753  0.         -0.49718916\n",
      " -1.076729    1.          0.3078174   0.31131312  0.32220837  0.34184954\n",
      "  0.37296027  0.42057124  0.49871278  0.6255527   0.8469124   1.        ]\n",
      "[ 0.8990507   0.07095639  0.23424739 -0.2161075   1.1175231   0.\n",
      "  0.5208553  -0.70852727  0.         -0.83075625  0.08790219 -0.5370343\n",
      " -0.8665659   1.          0.2976513   0.30103156  0.31156698  0.3305595\n",
      "  0.36064273  0.40668526  0.48190156  0.60608447  0.8195808   1.        ]\n",
      "[ 0.9180937   0.03812358  0.22794072 -0.2390245   1.1062477  -0.10887137\n",
      "  0.64455724  0.99999994  0.         -0.7982059   0.41319263 -0.646253\n",
      " -0.9235472   1.          0.28646657  0.28971982  0.29985934  0.31813818\n",
      "  0.34709102  0.39141122  0.4633331   0.58474725  0.7887143   1.        ]\n",
      "[ 9.3996722e-01  4.3408956e-02  2.5101236e-01 -2.5027740e-01\n",
      "  1.1047456e+00  1.7881393e-07  7.6793683e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.1923205e-01 -2.5637934e-01 -7.2240853e-01\n",
      " -9.1461015e-01  1.0000000e+00  2.7478921e-01  2.7790987e-01\n",
      "  2.8763607e-01  3.0516979e-01  3.3294240e-01  3.7546277e-01\n",
      "  4.4398287e-01  5.6181383e-01  7.5648826e-01  1.0000000e+00]\n",
      "[ 9.5216054e-01  2.4523161e-02  2.4436830e-01 -2.5110659e-01\n",
      "  1.1045361e+00 -1.4901161e-08  9.0701771e-01  1.1526304e+00\n",
      "  0.0000000e+00 -8.3298588e-01  0.0000000e+00 -7.3989201e-01\n",
      " -1.0218001e-01  1.0000000e+00  2.6299286e-01  2.6597956e-01\n",
      "  2.7528819e-01  2.9206923e-01  3.1864959e-01  3.5935262e-01\n",
      "  4.2441800e-01  5.3784710e-01  7.2393382e-01  1.0000000e+00]\n",
      "[ 9.1919428e-01 -3.0568279e-02  1.2917177e-01 -1.8454874e-02\n",
      "  1.1104529e+00 -6.7416430e-03  9.2185700e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3104354e-01  2.8067827e-04 -7.0823097e-01\n",
      "  1.2718071e-01  1.0000000e+00  2.6470608e-01  2.6771221e-01\n",
      "  2.7708152e-01  2.9397187e-01  3.2072538e-01  3.6167330e-01\n",
      "  4.2769223e-01  5.4143411e-01  7.2866178e-01  1.0000000e+00]\n",
      "[ 8.9237219e-01 -3.4392335e-02  1.2906924e-01  2.1931862e-02\n",
      "  1.1144242e+00 -2.7659982e-03  9.2899656e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3305424e-01  9.7841024e-05 -6.7741895e-01\n",
      "  1.4330021e-01  0.0000000e+00  2.6699936e-01  2.7003154e-01\n",
      "  2.7948204e-01  2.9651868e-01  3.2350400e-01  3.6478466e-01\n",
      "  4.3196338e-01  5.4620826e-01  7.3499060e-01  1.0000000e+00]\n",
      "[ 8.7013543e-01 -3.7503179e-02  1.4222579e-01  2.9995484e-02\n",
      "  1.1166233e+00  6.2449276e-04  9.3081558e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3437097e-01 -2.6121736e-05 -6.4269149e-01\n",
      "  1.5940985e-01  1.0000000e+00  2.6870811e-01  2.7175969e-01\n",
      "  2.8127065e-01  2.9841635e-01  3.2557437e-01  3.6709782e-01\n",
      "  4.3526223e-01  5.4928583e-01  7.3970622e-01  1.0000000e+00]\n",
      "[ 8.4950846e-01 -4.0932313e-02  1.5581547e-01  3.2424737e-02\n",
      "  1.1167560e+00  4.8130751e-05  9.3092620e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490777e-01  5.9604645e-08 -6.2455642e-01\n",
      "  1.8355958e-01  0.0000000e+00  2.7018896e-01  2.7325737e-01\n",
      "  2.8282073e-01  3.0006093e-01  3.2736859e-01  3.6909890e-01\n",
      "  4.3820107e-01  5.5157173e-01  7.4379289e-01  1.0000000e+00]\n",
      "[ 8.2713306e-01 -4.4750471e-02  1.7092539e-01  3.6238998e-02\n",
      "  1.1166825e+00  2.1338463e-05  9.3106389e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3483660e-01 -8.6426735e-07 -5.9967315e-01\n",
      "  2.0648624e-01  0.0000000e+00  2.7184746e-01  2.7493471e-01\n",
      "  2.8455678e-01  3.0190277e-01  3.2937807e-01  3.7134051e-01\n",
      "  4.4148338e-01  5.5414218e-01  7.4836987e-01  1.0000000e+00]\n",
      "[ 8.0300295e-01 -4.8270203e-02  1.8473478e-01  3.8350824e-02\n",
      "  1.1165887e+00  3.3378601e-06  9.2859328e-01 -2.2127369e-02\n",
      "  0.0000000e+00 -8.3478379e-01 -5.0663948e-07 -5.7213938e-01\n",
      "  2.2642791e-01  0.0000000e+00  2.7359983e-01  2.7670699e-01\n",
      "  2.8639108e-01  3.0384889e-01  3.3150131e-01  3.7370855e-01\n",
      "  4.4496220e-01  5.5684602e-01  7.5320590e-01  1.0000000e+00]\n",
      "[ 7.7684700e-01 -5.2329000e-02  2.0060810e-01  4.0725574e-02\n",
      "  1.1164865e+00  2.6702881e-05  9.2880476e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3473992e-01 -1.1920929e-06 -5.4169059e-01\n",
      "  2.4989201e-01  0.0000000e+00  2.7545744e-01  2.7858567e-01\n",
      "  2.8833553e-01  3.0591187e-01  3.3374804e-01  3.7621823e-01\n",
      "  4.4866237e-01  5.5969834e-01  7.5833237e-01  1.0000000e+00]\n",
      "[ 7.4850833e-01 -5.6698266e-02  2.1736421e-01  4.4101510e-02\n",
      "  1.1163701e+00  4.6849251e-05  9.2905200e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3469993e-01 -1.9371510e-06 -5.0780702e-01\n",
      "  2.7777049e-01  0.0000000e+00  2.7746597e-01  2.8061703e-01\n",
      "  2.9043797e-01  3.0814248e-01  3.3615518e-01  3.7893170e-01\n",
      "  4.5266420e-01  5.6278116e-01  7.6348948e-01  1.0000000e+00]\n",
      "[ 7.1810031e-01 -6.0841970e-02  2.3372273e-01  4.5828804e-02\n",
      "  1.1162281e+00 -1.6492605e-04  9.2932510e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3465040e-01  5.4538250e-06 -4.7075844e-01\n",
      "  3.0407298e-01  0.0000000e+00  2.7954790e-01  2.8272259e-01\n",
      "  2.9261723e-01  3.1045458e-01  3.3864951e-01  3.8174346e-01\n",
      "  4.5621815e-01  5.6595224e-01  7.6849580e-01  1.0000000e+00]\n",
      "[ 6.8633795e-01 -6.3554756e-02  2.4317196e-01  5.0937403e-02\n",
      "  1.1158224e+00  7.7486038e-07  8.8499618e-01 -3.7666225e-01\n",
      "  0.0000000e+00 -8.3463055e-01 -8.9406967e-08 -4.3019152e-01\n",
      "  3.3265349e-01  0.0000000e+00  2.8186265e-01  2.8506362e-01\n",
      "  2.9504019e-01  3.1302524e-01  3.4142449e-01  3.8556862e-01\n",
      "  4.6011198e-01  5.6952661e-01  7.7409273e-01  1.0000000e+00]\n",
      "[ 6.5151393e-01 -6.9720387e-02  2.6583016e-01  5.4594744e-02\n",
      "  1.1153835e+00 -7.1525574e-07  8.5557377e-01 -2.5386962e-01\n",
      "  0.0000000e+00 -8.3463007e-01  8.9406967e-08 -3.8464665e-01\n",
      "  3.7340161e-01  0.0000000e+00  2.8433841e-01  2.8756753e-01\n",
      "  2.9763171e-01  3.1577474e-01  3.4439185e-01  3.8968602e-01\n",
      "  4.6427962e-01  5.7333255e-01  7.8006810e-01  1.0000000e+00]\n",
      "[ 6.1431003e-01 -7.4485451e-02  2.8162390e-01  6.0026251e-02\n",
      "  1.1144572e+00  5.9604645e-07  8.0145049e-01 -4.6857071e-01\n",
      "  0.0000000e+00 -8.3469516e-01 -8.9406967e-08 -3.3393884e-01\n",
      "  4.1485071e-01  0.0000000e+00  2.8705782e-01  2.9031780e-01\n",
      "  3.0047825e-01  3.1879479e-01  3.4765232e-01  3.9418605e-01\n",
      "  4.6885213e-01  5.7777101e-01  7.8665072e-01  1.0000000e+00]\n",
      "[ 0.56783634 -0.09311659  0.30799448  0.06121064  1.0975056  -0.21121657\n",
      "  0.89755464  0.79216594  0.         -0.83490855  0.         -0.27181363\n",
      "  0.5102169   0.          0.28979823  0.29308933  0.30334678  0.3218323\n",
      "  0.35093534  0.39877683  0.47347307  0.5829055   0.7932367   1.        ]\n",
      "[ 0.51781267 -0.10009637  0.33614838  0.06027867  1.1477046   0.6430634\n",
      "  0.78069854 -1.          0.         -0.83490837  0.         -0.20302331\n",
      "  0.5614188   0.          0.29247892  0.29580045  0.3061528   0.32477432\n",
      "  0.3541434   0.4033404   0.4780104   0.5879009   0.80107176  1.        ]\n",
      "[ 0.46029234 -0.1170621   0.3604842   0.06639346  1.1349076   0.\n",
      "  0.929132    0.9999997   0.         -0.834908    0.         -0.12058878\n",
      "  0.67820925  0.          0.29549086  0.2988466   0.30930555  0.32808158\n",
      "  0.35774973  0.40842924  0.483096    0.593528    0.8131048   1.        ]\n",
      "[ 4.08117235e-01 -1.04471721e-01  3.61675769e-01  8.54954645e-02\n",
      "  1.13274455e+00  3.95536423e-04  8.15719843e-01 -9.99963701e-01\n",
      "  0.00000000e+00 -8.34908545e-01 -1.31726265e-05 -3.68492603e-02\n",
      "  6.84767425e-01  0.00000000e+00  2.99324989e-01  3.02724272e-01\n",
      "  3.13318908e-01  3.32300514e-01  3.63152891e-01  4.14527118e-01\n",
      "  4.88037318e-01  6.00768864e-01  8.27832222e-01  1.00000000e+00]\n",
      "[ 3.4967661e-01 -1.1698270e-01  3.8757178e-01  9.1316022e-02\n",
      "  1.1291363e+00 -2.5284290e-04  7.0610046e-01 -1.0000252e+00\n",
      "  0.0000000e+00 -8.3490759e-01  8.4638596e-06  5.9954166e-02\n",
      "  7.9036790e-01  0.0000000e+00  3.0339855e-01  3.0684412e-01\n",
      "  3.1757799e-01  3.3678260e-01  3.6899233e-01  4.2031276e-01\n",
      "  4.9327984e-01  6.0845947e-01  8.4349853e-01  1.0000000e+00]\n",
      "[ 2.7549130e-01 -1.4828983e-01  4.1674244e-01  9.1646694e-02\n",
      "  1.0996897e+00 -3.5478961e-01  8.3021581e-01  1.0000015e+00\n",
      "  0.0000000e+00 -8.3490807e-01 -2.9802322e-07  1.8355650e-01\n",
      "  1.0020416e+00  0.0000000e+00  3.0740425e-01  3.1089529e-01\n",
      "  3.2173103e-01  3.4118676e-01  3.7480164e-01  4.2601719e-01\n",
      "  4.9835083e-01  6.1646360e-01  8.5380948e-01  1.0000000e+00]\n",
      "[ 2.0060787e-01 -1.4963377e-01  4.2769247e-01  7.2595447e-02\n",
      "  1.1395344e+00  5.3020269e-01  7.1730578e-01 -9.9999857e-01\n",
      "  0.0000000e+00 -8.3490664e-01 -3.6358833e-06  3.1103110e-01\n",
      "  1.0298404e+00  0.0000000e+00  3.1050605e-01  3.1403232e-01\n",
      "  3.2493782e-01  3.4458748e-01  3.7949690e-01  4.3047899e-01\n",
      "  5.0203043e-01  6.2269747e-01  8.6038387e-01  1.0000000e+00]\n",
      "[ 1.3278888e-01 -1.3579500e-01  4.2907348e-01  6.8712652e-02\n",
      "  1.1337891e+00  1.0061264e-04  6.1334217e-01 -9.9999005e-01\n",
      "  0.0000000e+00 -8.3490705e-01 -3.2782555e-06  4.3304712e-01\n",
      "  9.9953508e-01  0.0000000e+00  3.1344047e-01  3.1700006e-01\n",
      "  3.2796943e-01  3.4849420e-01  3.8398501e-01  4.3471047e-01\n",
      "  5.0545347e-01  6.2859493e-01  8.6653215e-01  1.0000000e+00]\n",
      "[ 5.9196614e-02 -1.4757152e-01  4.3156922e-01  5.4866727e-02\n",
      "  1.1271431e+00 -4.1723251e-07  5.3912276e-01  1.4409808e+00\n",
      "  1.0000000e+00 -8.2842374e-01  9.4599366e-02  5.5673999e-01\n",
      "  9.9999982e-01  0.0000000e+00  3.1568593e-01  3.1924528e-01\n",
      "  3.3028024e-01  3.5178807e-01  3.8734561e-01  4.3799260e-01\n",
      "  5.0839210e-01  6.3310778e-01  8.7093621e-01  1.0000000e+00]\n",
      "[ 2.3854753e-02 -7.0337623e-02  2.6666296e-01  1.8835795e-01\n",
      "  1.1313034e+00  1.7866582e-02  5.4081541e-01  1.2752743e-01\n",
      "  1.0000000e+00 -8.2899582e-01 -4.5612454e-04  6.6629869e-01\n",
      "  8.9577407e-01  0.0000000e+00  3.2438290e-01  3.2801527e-01\n",
      "  3.3935341e-01  3.6212704e-01  3.9805421e-01  4.4896978e-01\n",
      "  5.2198607e-01  6.5017450e-01  8.9284217e-01  1.0000000e+00]\n",
      "[ 6.3211937e-03 -3.4862567e-02  2.5513530e-01  1.9353867e-01\n",
      "  1.1311429e+00 -4.0233135e-07  5.0633913e-01 -2.9237118e-01\n",
      "  1.0000000e+00 -7.4921387e-01  1.0000033e+00  5.4794896e-01\n",
      " -9.9999452e-01  0.0000000e+00  3.3337921e-01  3.3708888e-01\n",
      "  3.4874064e-01  3.7278652e-01  4.0912357e-01  4.6020579e-01\n",
      "  5.3606141e-01  6.6724008e-01  9.1627151e-01  1.0000000e+00]\n",
      "[ 1.1057418e-02  9.6548311e-03  2.5713047e-01  1.9401719e-01\n",
      "  1.1295452e+00  1.4901161e-08  4.0130520e-01 -8.9914346e-01\n",
      "  1.0000000e+00 -6.7247498e-01  9.7162855e-01  4.3182707e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.4246573e-01  3.4625354e-01\n",
      "  3.5846883e-01  3.8355082e-01  4.2030349e-01  4.7155699e-01\n",
      "  5.5027854e-01  6.8447852e-01  9.3993747e-01  1.0000000e+00]\n",
      "[ 0.01750667  0.01293916  0.2567157   0.17733206  1.127891   -0.00197419\n",
      "  0.28558397 -1.0005988   1.         -0.596607    0.97923225  0.32144982\n",
      " -1.0000516   0.          0.35075474  0.354612    0.36768222  0.3934089\n",
      "  0.43051064  0.48186594  0.5632334   0.7001735   0.9622172   1.        ]\n",
      "[ 0.03013617  0.02532362  0.2600074   0.1593967   1.1116211  -0.16426459\n",
      "  0.17081523 -1.0000001   1.         -0.53345233  0.8031731   0.20516926\n",
      " -1.          0.          0.3582427   0.36216664  0.37605575  0.40226752\n",
      "  0.43974933  0.49113068  0.5752467   0.7160656   0.98289895  1.        ]\n",
      "[ 0.04114416  0.02195043  0.25878868  0.13948436  1.1030401  -0.09035952\n",
      "  0.05526876 -1.          0.         -0.4706302   0.81151056  0.09381229\n",
      " -1.0000001   0.          0.36476478  0.36876014  0.38341823  0.40965766\n",
      "  0.4477714   0.499189    0.5857733   0.73181975  1.          1.        ]\n",
      "[ 5.7673760e-02  3.3059888e-02  2.6509777e-01  1.1207148e-01\n",
      "  1.1004636e+00 -1.4901161e-08 -6.0685873e-02 -1.0000001e+00\n",
      "  0.0000000e+00 -4.4250855e-01  3.6581478e-01 -2.3277998e-02\n",
      " -1.0000001e+00  0.0000000e+00  3.7004486e-01  3.7409809e-01\n",
      "  3.8947076e-01  4.1566440e-01  4.5350406e-01  5.0620323e-01\n",
      "  5.9430265e-01  7.4481362e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 7.6181754e-02  3.6973976e-02  2.6749915e-01  9.2179969e-02\n",
      "  1.0984555e+00  2.9802322e-08 -1.7711425e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -4.2685157e-01  2.1333162e-01 -1.3978589e-01\n",
      " -1.0000000e+00  0.0000000e+00  3.7440136e-01  3.7850231e-01\n",
      "  3.9454609e-01  4.2064163e-01  4.5815018e-01  5.1196927e-01\n",
      "  6.0134649e-01  7.5574702e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.0940602   0.03565859  0.26450565  0.06479312  1.1101751   0.1434439\n",
      " -0.14483666  0.25945812  0.         -0.4618382  -0.39281443 -0.2531377\n",
      " -0.9999998   0.          0.3774702   0.38185334  0.39824873  0.42418072\n",
      "  0.4612921   0.51599765  0.6063184   0.76378065  1.          1.        ]\n",
      "[ 1.1031444e-01  3.2550361e-02  2.8102538e-01  6.3149191e-02\n",
      "  1.1081307e+00  5.9604645e-08 -6.8635941e-02  6.1181289e-01\n",
      "  0.0000000e+00 -5.4242587e-01 -1.0000000e+00 -1.3093889e-01\n",
      "  9.9999970e-01  0.0000000e+00  3.8045099e-01  3.8533956e-01\n",
      "  4.0188462e-01  4.2762864e-01  4.6430328e-01  5.1990020e-01\n",
      "  6.1115086e-01  7.6924354e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 1.2696354e-01  3.3332899e-02  2.8148770e-01  4.5404844e-02\n",
      "  1.1072069e+00 -1.4901161e-08 -6.6332817e-03  5.0174332e-01\n",
      "  0.0000000e+00 -6.2323982e-01 -1.0000000e+00 -7.1947575e-03\n",
      "  1.0000000e+00  0.0000000e+00  3.8259864e-01  3.8797772e-01\n",
      "  4.0463609e-01  4.3014705e-01  4.6633732e-01  5.2267748e-01\n",
      "  6.1431998e-01  7.7273840e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 1.4693026e-01  3.9966058e-02  2.8606448e-01  2.9848915e-02\n",
      "  1.1077254e+00  2.9802322e-08 -3.2063603e-02 -2.1260519e-01\n",
      "  0.0000000e+00 -6.9874758e-01 -9.3036693e-01  1.1681050e-01\n",
      "  1.0000000e+00  0.0000000e+00  3.8402870e-01  3.8989195e-01\n",
      "  4.0635687e-01  4.3186665e-01  4.6752298e-01  5.2448392e-01\n",
      "  6.1628568e-01  7.7486897e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.17092314  0.04799733  0.27321538  0.00839629  1.1053143   0.\n",
      " -0.14832449 -0.99999994  0.         -0.70827657 -0.0951779   0.00159049\n",
      " -0.9999997   0.          0.38447225  0.3907803   0.40693378  0.4324798\n",
      "  0.467575    0.524964    0.61672     0.7751618   1.          1.        ]\n",
      "[ 0.18712087  0.03237269  0.2591968  -0.00837676  1.098291   -0.07798081\n",
      " -0.08248258  0.5359475   0.         -0.7223382  -0.14663304 -0.11382318\n",
      " -1.0000001   0.          0.3841065   0.39082244  0.4066554   0.4319382\n",
      "  0.4667018   0.5243569   0.6159005   0.7739526   1.          1.        ]\n",
      "[ 0.20180075  0.02933335  0.2742159  -0.02702796  1.1006484   0.06920542\n",
      "  0.04318488  0.99999994  0.         -0.8033227  -0.9999998  -0.0378722\n",
      "  0.5948401   0.          0.3828516   0.38998327  0.40544978  0.43014163\n",
      "  0.46476066  0.52264166  0.6136752   0.77103335  1.          1.        ]\n",
      "[ 0.20666698  0.00933057  0.25730273 -0.00290119  1.0176327  -0.9481627\n",
      "  0.326276    2.2314405   0.         -0.8068277   0.          0.08783168\n",
      "  0.9999997   0.          0.38306072  0.39022815  0.40537965  0.42954752\n",
      "  0.46442783  0.52244174  0.6131653   0.77019745  1.          1.        ]\n",
      "[ 0.18423134 -0.04493435  0.2510101  -0.03438996  1.0503659   0.4433102\n",
      "  0.45158625  1.          0.         -0.7588998   0.646714    0.21499634\n",
      "  0.9999998   0.          0.38171968  0.38886198  0.40365693  0.42725876\n",
      "  0.4622408   0.5200932   0.6102019   0.7664049   1.          1.        ]\n",
      "[ 0.16778097 -0.03298303  0.259743   -0.05615988  1.1291864   1.0000002\n",
      "  0.33619374 -0.9999998   0.         -0.71832794  0.556495    0.3425688\n",
      "  1.0000002   0.          0.37938356  0.38648218  0.4008788   0.42386287\n",
      "  0.45883942  0.51636744  0.60565215  0.7606902   1.          1.        ]\n",
      "[ 0.16262282 -0.01022714  0.25937068 -0.06025374  1.129521    0.\n",
      "  0.35221863  0.1333592   0.         -0.6926049   0.36197388  0.4692406\n",
      "  1.0000001   0.          0.3768967   0.38389018  0.3979447   0.42030928\n",
      "  0.4552609   0.5124392   0.6008725   0.7546994   1.          1.        ]\n",
      "[ 1.70246989e-01  1.52941095e-02  2.69045234e-01 -7.72167668e-02\n",
      "  1.12745464e+00  1.49011612e-08  2.36551881e-01 -9.99999762e-01\n",
      "  0.00000000e+00 -6.88141525e-01  8.48319307e-02  3.87626350e-01\n",
      " -1.12714159e+00  1.00000000e+00  3.73675883e-01  3.80305171e-01\n",
      "  3.94228429e-01  4.15929437e-01  4.50780123e-01  5.07489145e-01\n",
      "  5.94912946e-01  7.47276366e-01  1.00000000e+00  1.00000000e+00]\n",
      "[ 1.7699127e-01  1.4116752e-02  2.6288232e-01 -9.7849652e-02\n",
      "  1.1263682e+00 -5.2154064e-08  1.2079370e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -6.2516701e-01  5.6600457e-01  3.3038580e-01\n",
      " -1.0000000e+00  1.0000000e+00  3.6939961e-01  3.7566087e-01\n",
      "  3.8941410e-01  4.1043136e-01  4.4505009e-01  5.0111300e-01\n",
      "  5.8732909e-01  7.3789942e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.18048085  0.00700169  0.2559555  -0.12252069  1.1051737  -0.23283875\n",
      "  0.24447024  0.99999946  0.         -0.6114891   0.18945235  0.2139225\n",
      " -0.9999998   1.          0.3640392   0.36992437  0.38346758  0.40377364\n",
      "  0.43802926  0.4932652   0.5780652   0.7264985   1.          1.        ]\n",
      "[ 1.9188714e-01  2.2720005e-02  2.6887479e-01 -1.5591070e-01\n",
      "  1.1036057e+00 -1.4901161e-08  3.5320264e-01  8.7335539e-01\n",
      "  0.0000000e+00 -6.5543145e-01 -4.9697191e-01  1.0336602e-01\n",
      " -9.9999982e-01  0.0000000e+00  3.5714540e-01  3.6261898e-01\n",
      "  3.7585378e-01  3.9540946e-01  4.2913696e-01  4.8329490e-01\n",
      "  5.6635678e-01  7.1213526e-01  9.8868334e-01  1.0000000e+00]\n",
      "[ 2.1767065e-01  5.1569212e-02  2.8125992e-01 -1.7185363e-01\n",
      "  1.1033695e+00  2.9802322e-08  2.8385526e-01 -5.8967376e-01\n",
      "  0.0000000e+00 -7.2098035e-01 -7.6465094e-01 -7.0755482e-03\n",
      " -9.9999994e-01  0.0000000e+00  3.4957060e-01  3.5461044e-01\n",
      "  3.6716628e-01  3.8626993e-01  4.1940141e-01  4.7237113e-01\n",
      "  5.5354440e-01  6.9642985e-01  9.6753448e-01  1.0000000e+00]\n",
      "[ 2.49423578e-01  6.35218397e-02  2.85902709e-01 -1.91432998e-01\n",
      "  1.10183060e+00 -3.27825546e-07  1.67505383e-01 -1.00000012e+00\n",
      "  0.00000000e+00 -8.06006968e-01 -9.99999762e-01 -1.16056204e-01\n",
      " -9.99999702e-01  0.00000000e+00  3.41100544e-01  3.45690161e-01\n",
      "  3.57542664e-01  3.76145631e-01  4.08581138e-01  4.60215271e-01\n",
      "  5.39316654e-01  6.79012299e-01  9.43926811e-01  1.00000000e+00]\n",
      "[ 2.6618204e-01  3.3463210e-02  2.6688635e-01 -1.9203724e-01\n",
      "  1.0999129e+00  1.9371510e-07  5.1407635e-02 -1.0000001e+00\n",
      "  0.0000000e+00 -8.0937785e-01  0.0000000e+00 -2.6076174e-01\n",
      " -1.2554865e+00  0.0000000e+00  3.3242694e-01  3.3670193e-01\n",
      "  3.4788445e-01  3.6598489e-01  3.9769581e-01  4.4797537e-01\n",
      "  5.2501220e-01  6.6151744e-01  9.1529393e-01  1.0000000e+00]\n",
      "[ 0.27905065  0.02570111  0.2538675  -0.19173561  1.0410048  -0.7296778\n",
      "  0.13425171  0.6748318   0.         -0.79752964  0.16609907 -0.37851214\n",
      " -0.99999994  0.          0.32355314  0.327714    0.3382513   0.35585052\n",
      "  0.38682193  0.43574134  0.5107285   0.6440586   0.8865686   1.        ]\n",
      "[ 0.29434663  0.03054134  0.2622238  -0.21515404  0.9835073  -0.697576\n",
      "  0.1758737  -0.07608005  1.         -0.82804805 -0.36451632 -0.4475819\n",
      " -0.59334105  0.          0.3135929   0.3176257   0.32748234  0.34452125\n",
      "  0.37463623  0.42201898  0.49473158  0.6245246   0.8541607   1.        ]\n",
      "[ 0.2924069  -0.00262421  0.25263986 -0.22285664  1.1245131   0.9296415\n",
      " -0.00830472 -1.1403222   1.         -0.8275531   0.         -0.39573193\n",
      "  0.43636796  0.          0.30313754  0.30703586  0.31622866  0.33268204\n",
      "  0.36186743  0.40762553  0.4779808   0.60409194  0.8199499   1.        ]\n",
      "[ 3.2886761e-01  7.3008291e-02  1.6776082e-01 -1.2714767e-01\n",
      "  1.1255455e+00  6.5991282e-04 -8.5369349e-02 -6.4679343e-01\n",
      "  1.0000000e+00 -8.1235516e-01  2.5795466e-01 -2.6729012e-01\n",
      "  1.0000430e+00  0.0000000e+00  2.9732010e-01  3.0114365e-01\n",
      "  3.0991498e-01  3.2603985e-01  3.5473949e-01  3.9960554e-01\n",
      "  4.6861807e-01  5.9264863e-01  8.0298787e-01  1.0000000e+00]\n",
      "[ 3.4530056e-01  3.2951597e-02  1.4067636e-01 -1.3697797e-01\n",
      "  1.1217242e+00  2.9802322e-08  4.0251434e-02  1.0000004e+00\n",
      "  1.0000000e+00 -7.5614744e-01  7.9898250e-01 -1.3318431e-01\n",
      "  1.0000005e+00  0.0000000e+00  2.9095304e-01  2.9469469e-01\n",
      "  3.0308351e-01  3.1885672e-01  3.4697333e-01  3.9084506e-01\n",
      "  4.5843503e-01  5.8023679e-01  7.8529835e-01  1.0000000e+00]\n",
      "[ 3.5618123e-01  2.1841882e-02  1.3370809e-01 -1.5187304e-01\n",
      "  1.1193643e+00  2.6822090e-07  1.6508508e-01  1.0000001e+00\n",
      "  0.0000000e+00 -6.8577468e-01  9.9999982e-01 -2.9122782e-01\n",
      " -7.5767428e-01  1.0000000e+00  2.8384754e-01  2.8749779e-01\n",
      "  2.9550272e-01  3.1090981e-01  3.3832565e-01  3.8107798e-01\n",
      "  4.4710612e-01  5.6644696e-01  7.6557618e-01  1.0000000e+00]\n",
      "[ 3.6951593e-01  2.6832864e-02  1.6651647e-01 -1.4433224e-01\n",
      "  1.1173226e+00 -2.9802322e-07  2.8950804e-01  9.9999994e-01\n",
      "  0.0000000e+00 -7.6223296e-01 -4.2923969e-01 -2.4154115e-01\n",
      " -4.2065430e-01  1.0000000e+00  2.7702600e-01  2.8057519e-01\n",
      "  2.8815040e-01  3.0324990e-01  3.2999030e-01  3.7168491e-01\n",
      "  4.3616906e-01  5.5310166e-01  7.4660927e-01  1.0000000e+00]\n",
      "[ 3.8398361e-01  2.8907757e-02  1.8476985e-01 -1.5584093e-01\n",
      "  1.1143467e+00 -1.3411045e-07  4.1499627e-01  9.9999994e-01\n",
      "  0.0000000e+00 -8.4341604e-01 -1.0000000e+00 -1.5550029e-01\n",
      "  5.4576778e-01  1.0000000e+00  2.6980442e-01  2.7298278e-01\n",
      "  2.8035298e-01  2.9513505e-01  3.2115987e-01  3.6173794e-01\n",
      "  4.2457929e-01  5.3767037e-01  7.2652394e-01  1.0000000e+00]\n",
      "[ 3.9161822e-01  1.5948251e-02  1.6602862e-01 -1.6263701e-01\n",
      "  1.1138642e+00 -7.4505806e-09  4.8946238e-01  5.9875304e-01\n",
      "  0.0000000e+00 -8.3490777e-01  0.0000000e+00 -2.5781476e-01\n",
      " -5.3096718e-01  0.0000000e+00  2.6227841e-01  2.6512003e-01\n",
      "  2.7227798e-01  2.8669912e-01  3.1198007e-01  3.5138285e-01\n",
      "  4.1254270e-01  5.2136838e-01  7.0561445e-01  1.0000000e+00]\n",
      "[ 3.6020848e-01 -5.8854703e-02  1.6671176e-01 -6.0396515e-02\n",
      "  1.1113018e+00 -2.9001534e-03  6.1669350e-01  9.9987882e-01\n",
      "  0.0000000e+00 -8.3621985e-01  1.4296174e-04 -1.3920033e-01\n",
      "  3.6053756e-01  1.0000000e+00  2.5996262e-01  2.6247481e-01\n",
      "  2.6956132e-01  2.8400797e-01  3.0905160e-01  3.4814572e-01\n",
      "  4.0864938e-01  5.1677436e-01  6.9907790e-01  1.0000000e+00]\n",
      "[ 3.2902804e-01 -6.0046960e-02  2.0412914e-01 -4.2706605e-02\n",
      "  1.1100502e+00  1.2245774e-04  7.4104154e-01  1.0000130e+00\n",
      "  0.0000000e+00 -8.3492500e-01 -4.6491623e-06 -1.7613244e-01\n",
      "  2.5355414e-01  0.0000000e+00  2.5817907e-01  2.6029703e-01\n",
      "  2.6732472e-01  2.8187600e-01  3.0673164e-01  3.4562099e-01\n",
      "  4.0553293e-01  5.1349884e-01  6.9397986e-01  1.0000000e+00]\n",
      "[ 0.2913862  -0.07408473  0.20524816 -0.04514975  1.1078899   0.\n",
      "  0.865258    1.          0.         -0.8358717   0.07351932 -0.0693934\n",
      "  0.3523611   1.          0.2563533   0.25806907  0.2650366   0.27969414\n",
      "  0.30435738  0.34303674  0.40234384  0.5101432   0.6887616   1.        ]\n",
      "[ 2.5919998e-01 -6.3147068e-02  2.2969267e-01 -3.0416192e-02\n",
      "  1.1068970e+00  5.0991774e-05  8.2155943e-01 -3.8891473e-01\n",
      "  0.0000000e+00 -8.3492553e-01 -8.1360340e-06 -1.0941410e-01\n",
      "  3.0438474e-01  1.0000000e+00  2.5506777e-01  2.5634316e-01\n",
      "  2.6326412e-01  2.7809152e-01  3.0261347e-01  3.4118184e-01\n",
      "  3.9996645e-01  5.0807458e-01  6.8501616e-01  1.0000000e+00]\n",
      "[ 0.21909086 -0.08019123  0.2637501   0.01938897  1.034504   -0.90379655\n",
      "  0.9429089   0.9999998   0.         -0.8349065   0.         -0.00874662\n",
      "  0.83097583  0.          0.25568384  0.25666347  0.26359308  0.27878234\n",
      "  0.3033652   0.3421864   0.4008257   0.50920725  0.68704456  1.        ]\n",
      "[ 0.17294441 -0.09239218  0.29402938  0.01638288  1.0317304  -0.01192397\n",
      "  0.981117    1.3224255   1.         -0.8349074   0.          0.06399816\n",
      "  0.59536386  1.          0.255792    0.256772    0.2638245   0.27927834\n",
      "  0.30405164  0.34296635  0.40139514  0.5096409   0.6886195   1.        ]\n",
      "[ 0.10540044 -0.13288544  0.2874998   0.01982442  1.103839    0.81545645\n",
      "  0.93490314  0.          1.         -0.80702937  0.31050563  0.12835306\n",
      "  0.55119556  0.          0.25607327  0.2570544   0.26445308  0.27994373\n",
      "  0.30492064  0.34394658  0.4022126   0.51038843  0.6905988   1.        ]\n",
      "[ 8.8926367e-02 -3.2828309e-02  1.7374729e-01  1.1106224e-01\n",
      "  1.1065807e+00  3.4420133e-02  9.3490636e-01  7.2818100e-03\n",
      "  1.0000000e+00 -8.0725622e-01 -6.9023669e-04  1.7937016e-01\n",
      "  4.2089376e-01  0.0000000e+00  2.6094073e-01  2.6194048e-01\n",
      "  2.6973522e-01  2.8553528e-01  3.1114507e-01  3.5085854e-01\n",
      "  4.1006356e-01  5.1971805e-01  7.0477605e-01  1.0000000e+00]\n",
      "[ 7.2396502e-02 -3.3084441e-02  1.3381863e-01  1.4272965e-01\n",
      "  1.1058656e+00 -1.3134867e-02  9.3438148e-01 -4.9794716e-04\n",
      "  1.0000000e+00 -8.0746746e-01  2.0126998e-04  2.3791629e-01\n",
      "  4.8411587e-01  0.0000000e+00  2.6735887e-01  2.6838320e-01\n",
      "  2.7658704e-01  2.9278845e-01  3.1917435e-01  3.5960716e-01\n",
      "  4.2176276e-01  5.3194702e-01  7.2441447e-01  1.0000000e+00]\n",
      "[ 0.0552166  -0.03438058  0.13446218  0.15626484  1.1058923   0.\n",
      "  0.9297147  -0.0390537   1.         -0.80781317  0.          0.3015219\n",
      "  0.52354866  0.          0.27440515  0.27545652  0.2840945   0.3007357\n",
      "  0.32796592  0.36919767  0.43482068  0.5453633   0.7505321   1.        ]\n",
      "[ 4.2658988e-02 -2.5122926e-02  1.3516364e-01  1.6595662e-01\n",
      "  1.1058605e+00  1.4901161e-08  9.1220951e-01 -1.4673485e-01\n",
      "  1.0000000e+00 -8.0820441e-01  0.0000000e+00  3.6069298e-01\n",
      "  4.8574471e-01  0.0000000e+00  2.8192240e-01  2.8300256e-01\n",
      "  2.9209352e-01  3.0920327e-01  3.3732891e-01  3.7941930e-01\n",
      "  4.4870019e-01  5.5967295e-01  7.7827770e-01  1.0000000e+00]\n",
      "[ 0.02977394 -0.02577247  0.1358387   0.17902403  1.1058093   0.\n",
      "  0.8912621  -0.17577513  1.         -0.8086003   0.          0.42422622\n",
      "  0.52195925  0.          0.2900496   0.29116088  0.30072916  0.31845084\n",
      "  0.34743214  0.3904584   0.46364436  0.57580787  0.8054961   1.        ]\n",
      "[ 0.01668832 -0.02617031  0.13663755  0.19181368  1.1057351   0.\n",
      "  0.8663854  -0.20902474  1.         -0.8090212   0.          0.49220407\n",
      "  0.5585509   0.          0.29877335  0.30012065  0.3099877   0.32837516\n",
      "  0.35825962  0.4022972   0.47963068  0.5931088   0.82805866  1.        ]\n",
      "[ 1.33826099e-02 -6.52404176e-03  1.24008395e-01  1.92235202e-01\n",
      "  1.10571575e+00 -2.60770321e-08  8.18797290e-01 -3.98649305e-01\n",
      "  1.00000000e+00 -7.34418213e-01  9.42426741e-01  3.74791682e-01\n",
      " -1.00000000e+00  0.00000000e+00  3.07560056e-01  3.09132606e-01\n",
      "  3.19295943e-01  3.38346422e-01  3.69138360e-01  4.14205015e-01\n",
      "  4.95235354e-01  6.10506058e-01  8.50761533e-01  1.00000000e+00]\n",
      "[ 3.2184191e-02  3.7721414e-02  1.2607199e-01  1.8916595e-01\n",
      "  1.1051936e+00 -2.9802322e-08  7.2138107e-01 -8.2269531e-01\n",
      "  1.0000000e+00 -6.6677445e-01  8.6139816e-01  2.5994986e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.1627059e-01  3.1806910e-01\n",
      "  3.2852626e-01  3.4823519e-01  3.7971634e-01  4.2601219e-01\n",
      "  5.0870889e-01  6.2775707e-01  8.7327135e-01  1.0000000e+00]\n",
      "[ 5.0195862e-02  3.6051556e-02  1.2334456e-01  1.7495862e-01\n",
      "  1.1041698e+00 -8.7916851e-07  6.0470712e-01 -9.9999994e-01\n",
      "  0.0000000e+00 -5.8961004e-01  1.0000007e+00  1.5225768e-01\n",
      " -9.9999905e-01  0.0000000e+00  3.2428876e-01  3.2630414e-01\n",
      "  3.3703202e-01  3.5735115e-01  3.8941172e-01  4.3778577e-01\n",
      "  5.2111614e-01  6.4384329e-01  8.9104986e-01  1.0000000e+00]\n",
      "[ 0.09538823  0.09041095  0.13583554  0.15608154  1.0816774  -0.2593808\n",
      "  0.4890594  -0.9999998   1.         -0.5676757   0.28606147  0.0357523\n",
      " -1.0000001   0.          0.3315385   0.33377644  0.34475     0.36563298\n",
      "  0.39820144  0.44893706  0.53234875  0.65883076  0.90627605  1.        ]\n",
      "[ 0.12761407  0.064437    0.12498204  0.1431614   1.0774858  -0.03872809\n",
      "  0.3729924  -1.          1.         -0.5018784   0.8491116  -0.07319558\n",
      " -1.0000002   0.          0.33812058  0.3405632   0.35175988  0.37315604\n",
      "  0.40618402  0.45907262  0.5425483   0.6724451   0.9200915   1.        ]\n",
      "[ 0.15753722  0.05993868  0.12154862  0.12622747  1.0725398  -0.03863895\n",
      "  0.25661457 -1.          0.         -0.42292786  1.0000001  -0.18773925\n",
      " -1.          0.          0.34391463  0.34655005  0.3579757   0.37979716\n",
      "  0.413222    0.46804854  0.5515336   0.68446344  0.93221134  1.        ]\n",
      "[ 0.18383045  0.05257174  0.10971478  0.11548771  1.0124989  -0.7428462\n",
      "  0.37943983  0.9999998   0.         -0.33880597  1.0771067  -0.2924087\n",
      " -1.          0.          0.34918866  0.3519992   0.36367297  0.38584173\n",
      "  0.41962805  0.47621748  0.5597122   0.69540226  0.9432447   1.        ]\n",
      "[ 0.21923065  0.07081509  0.11826269  0.09746966  0.93125755 -0.99999976\n",
      "  0.50214547  1.0000001   0.         -0.2807436   0.73341095 -0.39287424\n",
      " -0.87218714  0.          0.35366416  0.3566512   0.36854678  0.39101267\n",
      "  0.42508888  0.48326856  0.5666677   0.70475996  0.9524858   1.        ]\n",
      "[ 0.26425093  0.08986702  0.14872283  0.08573892  0.8502623  -1.0000005\n",
      "  0.62505436  0.99999994  0.         -0.32592374 -0.5246045  -0.26505792\n",
      "  0.9999998   0.          0.35758308  0.36077657  0.37288743  0.3956179\n",
      "  0.42991653  0.48966473  0.57299906  0.7134126   0.96034074  1.        ]\n",
      "[ 0.3235923   0.11864721  0.16379322  0.06407905  0.8027219  -0.5653486\n",
      "  0.5093139  -0.99999976  0.         -0.40733808 -1.         -0.1428703\n",
      "  0.99999994  0.          0.3605465   0.36392584  0.37622148  0.39915517\n",
      "  0.43358558  0.4947048   0.5778816   0.7217089   0.9660271   1.        ]\n",
      "[ 0.36360303  0.07991973  0.13710919  0.02372972  0.81431717  0.16434589\n",
      "  0.39368153 -1.          0.         -0.4008808   0.09612128 -0.25984156\n",
      " -0.9999997   0.          0.36171007  0.36510032  0.37749687  0.4004072\n",
      "  0.43492818  0.49683145  0.5796877   0.7252962   0.9676603   1.        ]\n",
      "[ 0.39758757  0.06764927  0.14147693 -0.00699845  0.8705583   0.72916734\n",
      "  0.28243965 -0.9999998   0.         -0.41903496 -0.19364336 -0.37485385\n",
      " -1.0000001   0.          0.36140707  0.36479446  0.3772396   0.40002993\n",
      "  0.4345184   0.4968549   0.57918286  0.7255151   0.966096    1.        ]\n",
      "[ 0.43094411  0.06638868  0.16161005 -0.01984396  0.9476412   1.0000008\n",
      "  0.17410785 -1.          0.         -0.4997489  -1.0000005  -0.3025174\n",
      "  0.58461547  0.          0.36049     0.3638688   0.3763481   0.39897156\n",
      "  0.43336877  0.49573773  0.5777068   0.7244395   0.96307814  1.        ]\n",
      "[ 0.45609498  0.04997623  0.15988724 -0.03559951  1.0234973   1.0000005\n",
      "  0.17863703 -0.06901487  0.         -0.58114374 -1.         -0.17882001\n",
      "  0.9999998   0.          0.35881236  0.36217543  0.37466     0.3970779\n",
      "  0.4313532   0.49336487  0.5750332   0.72158974  0.95842904  1.        ]\n",
      "[ 0.48042822  0.04833918  0.15869913 -0.04429216  1.1013982   1.0000004\n",
      "  0.06854892 -0.9999998   0.         -0.6237206  -0.50147945 -0.0810405\n",
      " -0.4069245   1.          0.356734    0.3600776   0.37255183  0.39474428\n",
      "  0.4291818   0.4904637   0.57172865  0.71780056  0.952925    1.        ]\n",
      "[ 5.2277011e-01  8.4691547e-02  1.6251965e-01 -5.8614694e-02\n",
      "  1.0997975e+00 -5.9604645e-08  1.1418867e-01  3.4502843e-01\n",
      "  0.0000000e+00 -7.0165426e-01 -9.9111891e-01 -8.7129951e-02\n",
      " -1.4071618e-01  1.0000000e+00  3.5401863e-01  3.5733679e-01\n",
      "  3.6977726e-01  3.9171055e-01  4.2620805e-01  4.8671982e-01\n",
      "  5.6742072e-01  7.1253711e-01  9.4604319e-01  1.0000000e+00]\n",
      "[ 0.5420684   0.03830149  0.1504023  -0.09027115  1.1768858   0.99999976\n",
      "  0.09442574 -0.24831478  0.         -0.70610803 -0.02731404 -0.2031517\n",
      " -1.          0.          0.34977812  0.35305652  0.36540237  0.38700378\n",
      "  0.42128202  0.480969    0.5607124   0.70367205  0.93593335  1.        ]\n",
      "[ 0.6028613   0.10904315  0.17303859 -0.09657294  1.1349149   0.\n",
      "  0.06274354 -0.8078906   0.         -0.796398   -0.99999976 -0.3120681\n",
      " -0.9999998   0.          0.3456879   0.34897673  0.3611901   0.38245827\n",
      "  0.41658148  0.4754048   0.5542384   0.69523734  0.9260672   1.        ]\n",
      "[ 6.5669882e-01  1.0760412e-01  1.7211613e-01 -1.1323734e-01\n",
      "  1.1337187e+00  5.9604645e-08 -3.2136679e-02 -8.2063264e-01\n",
      "  0.0000000e+00 -8.7986732e-01 -1.0000000e+00 -4.2651665e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.4043345e-01  3.4373143e-01\n",
      "  3.5576123e-01  3.7663198e-01  4.1042423e-01  4.6829709e-01\n",
      "  5.4592973e-01  6.8413037e-01  9.1366076e-01  1.0000000e+00]\n",
      "[ 6.8793821e-01  7.7765875e-02  1.4786705e-01 -1.1511775e-01\n",
      "  1.1349372e+00 -2.9802322e-08 -1.0801327e-01 -7.7001983e-01\n",
      "  0.0000000e+00 -8.3493465e-01  0.0000000e+00 -5.8389902e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.3519512e-01  3.3848685e-01\n",
      "  3.5033309e-01  3.7083539e-01  4.0417862e-01  4.6124774e-01\n",
      "  5.3765392e-01  6.7281210e-01  9.0153497e-01  1.0000000e+00]\n",
      "[ 7.1465182e-01  5.3883720e-02  1.3385542e-01 -1.3920452e-01\n",
      "  1.1311138e+00 -1.1920929e-07  1.9032896e-02  9.9999982e-01\n",
      "  0.0000000e+00 -8.3490688e-01  0.0000000e+00 -7.0292735e-01\n",
      " -1.0000000e+00  0.0000000e+00  3.2868522e-01  3.3195692e-01\n",
      "  3.4357461e-01  3.6364108e-01  3.9633164e-01  4.5251614e-01\n",
      "  5.2737516e-01  6.5855098e-01  8.8665849e-01  1.0000000e+00]\n",
      "[ 7.3644960e-01  4.4014387e-02  1.4256352e-01 -1.3948636e-01\n",
      "  1.1276432e+00  2.9802322e-07  1.4582664e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3490735e-01  0.0000000e+00 -6.3457966e-01\n",
      "  5.6575686e-01  0.0000000e+00  3.2214624e-01  3.2540140e-01\n",
      "  3.3678967e-01  3.5641193e-01  3.8847443e-01  4.4373715e-01\n",
      "  5.1704872e-01  6.4428306e-01  8.7161499e-01  1.0000000e+00]\n",
      "[ 7.5560063e-01  3.9456848e-02  1.4579871e-01 -1.5144771e-01\n",
      "  1.1247547e+00 -1.6391277e-07  2.7277029e-01  9.9999994e-01\n",
      "  0.0000000e+00 -8.3490890e-01  0.0000000e+00 -5.1435244e-01\n",
      "  1.0000005e+00  0.0000000e+00  3.1503913e-01  3.1827250e-01\n",
      "  3.2941127e-01  3.4855750e-01  3.7990826e-01  4.3420428e-01\n",
      "  5.0582683e-01  6.2961978e-01  8.5528934e-01  1.0000000e+00]\n",
      "[ 7.7322704e-01  3.6385477e-02  1.4653647e-01 -1.6778998e-01\n",
      "  1.1221611e+00 -1.7881393e-07  3.9939272e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3490866e-01  0.0000000e+00 -3.9406931e-01\n",
      "  1.0000004e+00  0.0000000e+00  3.0715773e-01  3.1036100e-01\n",
      "  3.2122290e-01  3.3985204e-01  3.7036714e-01  4.2364711e-01\n",
      "  4.9338531e-01  6.1389810e-01  8.3727682e-01  1.0000000e+00]\n",
      "[ 7.8947836e-01  3.3597585e-02  1.4733283e-01 -1.8414430e-01\n",
      "  1.1199620e+00  1.9371510e-07  5.2533364e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3490795e-01  0.0000000e+00 -4.9816489e-01\n",
      " -1.2939354e+00  1.0000000e+00  2.9850203e-01  3.0166680e-01\n",
      "  3.1222442e-01  3.3029541e-01  3.5985106e-01  4.1206548e-01\n",
      "  4.7972399e-01  5.9662104e-01  8.1757677e-01  1.0000000e+00]\n",
      "[ 8.0263883e-01  2.8594868e-02  1.4581886e-01 -2.0617165e-01\n",
      "  1.1200547e+00  8.9406967e-08  6.5178382e-01  1.0233377e+00\n",
      "  0.0000000e+00 -8.3490771e-01  0.0000000e+00 -4.7541475e-01\n",
      " -4.7780049e-01  1.0000000e+00  2.8859586e-01  2.9170766e-01\n",
      "  3.0191675e-01  3.1936499e-01  3.4775358e-01  3.9838183e-01\n",
      "  4.6409345e-01  5.7683033e-01  7.9516721e-01  1.0000000e+00]\n",
      "[ 8.0856729e-01  1.1915674e-02  1.4145367e-01 -2.1042927e-01\n",
      "  1.1187263e+00  2.9802322e-08  7.7455962e-01  9.9999994e-01\n",
      "  0.0000000e+00 -8.3490819e-01  0.0000000e+00 -5.3079057e-01\n",
      " -4.6275643e-01  1.0000000e+00  2.7869606e-01  2.8175363e-01\n",
      "  2.9161435e-01  3.0844265e-01  3.3565459e-01  3.8452137e-01\n",
      "  4.4868055e-01  5.5704969e-01  7.7279252e-01  1.0000000e+00]\n",
      "[ 8.0657262e-01 -3.9308826e-03  1.3793023e-01 -2.1401447e-01\n",
      "  1.1181283e+00  3.7252903e-09  8.9567745e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3490807e-01 -1.8626451e-09 -5.7745397e-01\n",
      "  1.6378678e-02  1.0000000e+00  2.6861340e-01  2.7161348e-01\n",
      "  2.8111932e-01  2.9732019e-01  3.2331684e-01  3.7038743e-01\n",
      "  4.3301779e-01  5.3689921e-01  7.4911499e-01  1.0000000e+00]\n",
      "[ 7.96231329e-01 -2.43728328e-02  1.11501545e-01 -3.76731977e-02\n",
      "  1.11101341e+00 -9.35085118e-03  1.02140296e+00  9.99093235e-01\n",
      "  0.00000000e+00 -8.34762394e-01  3.99142504e-04 -6.00236416e-01\n",
      "  1.01287447e-01  0.00000000e+00  2.67555267e-01  2.70589262e-01\n",
      "  2.80059278e-01  2.96122313e-01  3.22300345e-01  3.69222939e-01\n",
      "  4.31263924e-01  5.34863889e-01  7.46251881e-01  1.00000000e+00]\n",
      "[ 7.8353089e-01 -2.7743295e-02  9.2311643e-02  3.0709894e-02\n",
      "  1.1332929e+00 -1.6523898e-04  9.3490875e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3499527e-01  5.7071447e-06 -5.9287024e-01\n",
      "  3.1264850e-01  0.0000000e+00  2.6927075e-01  2.7232873e-01\n",
      "  2.8185961e-01  2.9794091e-01  3.2469270e-01  3.7196356e-01\n",
      "  4.3374437e-01  5.3832054e-01  7.5010258e-01  1.0000000e+00]\n",
      "[ 7.6326889e-01 -4.0132165e-02  9.2711210e-02  9.4424173e-02\n",
      "  1.1331465e+00 -3.6296248e-04  9.3490672e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3494180e-01  1.4781952e-05 -5.2741420e-01\n",
      "  1.6720758e-01  1.0000000e+00  2.7374038e-01  2.7684912e-01\n",
      "  2.8647569e-01  3.0278015e-01  3.3056027e-01  3.7853789e-01\n",
      "  4.4046882e-01  5.4730344e-01  7.5912708e-01  1.0000000e+00]\n",
      "[ 7.4464804e-01 -3.7190538e-02  1.1748461e-01  1.0974558e-01\n",
      "  1.1331699e+00 -1.2189150e-04  9.3490684e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3207387e-01  4.0084124e-06 -4.6918082e-01\n",
      "  4.6089089e-01  0.0000000e+00  2.7883944e-01  2.8200608e-01\n",
      "  2.9169071e-01  3.0829200e-01  3.3728161e-01  3.8509661e-01\n",
      "  4.4839987e-01  5.5755138e-01  7.6933873e-01  1.0000000e+00]\n",
      "[ 7.2536606e-01 -3.8550116e-02  1.2608825e-01  1.1551514e-01\n",
      "  1.1329246e+00  8.1956387e-07  8.8378406e-01 -4.3024436e-01\n",
      "  0.0000000e+00 -8.3202612e-01 -1.0430813e-07 -4.2911386e-01\n",
      "  3.5337004e-01  1.0000000e+00  2.8421038e-01  2.8743804e-01\n",
      "  2.9718208e-01  3.1409591e-01  3.4436688e-01  3.9200145e-01\n",
      "  4.5675188e-01  5.6834567e-01  7.8007799e-01  1.0000000e+00]\n",
      "[ 7.0175880e-01 -4.7308870e-02  1.4573516e-01  1.2042850e-01\n",
      "  1.0931337e+00 -4.9880448e-01  1.0035655e+00  9.9999875e-01\n",
      "  0.0000000e+00 -8.3206290e-01  2.0861626e-07 -3.8205957e-01\n",
      "  3.9915845e-01  0.0000000e+00  2.8980386e-01  2.9309502e-01\n",
      "  3.0289000e-01  3.2012868e-01  3.5178167e-01  3.9916930e-01\n",
      "  4.6543711e-01  5.7958728e-01  7.9115272e-01  1.0000000e+00]\n",
      "[ 6.73728168e-01 -5.61471991e-02  1.72551110e-01  1.17028266e-01\n",
      "  1.13683605e+00  5.55430412e-01  8.85110378e-01 -9.99999762e-01\n",
      "  0.00000000e+00 -8.32220197e-01  3.27825546e-07 -3.30120564e-01\n",
      "  4.32915777e-01  0.00000000e+00  2.95224965e-01  2.98577696e-01\n",
      "  3.08399081e-01  3.25951308e-01  3.59042645e-01  4.06068176e-01\n",
      "  4.73828167e-01  5.92388391e-01  8.01658630e-01  1.00000000e+00]\n",
      "[ 6.3965064e-01 -6.8293139e-02  1.9647834e-01  1.2406638e-01\n",
      "  1.1278522e+00 -1.1400637e-01  1.0047439e+00  9.9999636e-01\n",
      "  0.0000000e+00 -8.3237720e-01  6.5565109e-07 -2.6917911e-01\n",
      "  5.0284785e-01  0.0000000e+00  3.0095917e-01  3.0437702e-01\n",
      "  3.1421587e-01  3.3209914e-01  3.6675727e-01  4.1334352e-01\n",
      "  4.8269159e-01  6.0683304e-01  8.1266683e-01  1.0000000e+00]\n",
      "[ 6.1094117e-01 -6.4987414e-02  2.0517640e-01  1.3171899e-01\n",
      "  1.1351496e+00  9.8019838e-05  9.3492723e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3496588e-01 -3.2782555e-06 -2.0829666e-01\n",
      "  5.1706892e-01  0.0000000e+00  3.0713513e-01  3.1062311e-01\n",
      "  3.2048678e-01  3.3952346e-01  3.7504664e-01  4.2119190e-01\n",
      "  4.9224484e-01  6.2234378e-01  8.2445002e-01  1.0000000e+00]\n",
      "[ 5.7449859e-01 -7.2810523e-02  2.2321258e-01  1.3955483e-01\n",
      "  1.1348486e+00 -6.8545341e-07  9.2619431e-01 -7.8884661e-02\n",
      "  0.0000000e+00 -8.3490658e-01  8.9406967e-08 -1.3799047e-01\n",
      "  5.7760847e-01  0.0000000e+00  3.1357852e-01  3.1706867e-01\n",
      "  3.2702187e-01  3.4737429e-01  3.8371888e-01  4.2936474e-01\n",
      "  5.0220323e-01  6.3858318e-01  8.3666551e-01  1.0000000e+00]\n",
      "[ 5.3502846e-01 -7.8922085e-02  2.3125023e-01  1.4729559e-01\n",
      "  1.1341268e+00  8.6426735e-07  8.6091197e-01 -5.6177288e-01\n",
      "  0.0000000e+00 -8.3490735e-01 -1.1920929e-07 -6.0473442e-02\n",
      "  6.3615572e-01  0.0000000e+00  3.2037184e-01  3.2375145e-01\n",
      "  3.3391443e-01  3.5564402e-01  3.9172021e-01  4.3798679e-01\n",
      "  5.1310921e-01  6.5426856e-01  8.4957045e-01  1.0000000e+00]\n",
      "[ 4.8983115e-01 -9.0330407e-02  2.5422487e-01  1.5458168e-01\n",
      "  1.1332388e+00 -2.0861626e-06  8.1185675e-01 -4.3063167e-01\n",
      "  0.0000000e+00 -8.3490831e-01  2.9802322e-07  2.7902603e-02\n",
      "  7.2377539e-01  0.0000000e+00  3.2748175e-01  3.3073711e-01\n",
      "  3.4111938e-01  3.6432517e-01  3.9977428e-01  4.4734633e-01\n",
      "  5.2454710e-01  6.6738206e-01  8.6298674e-01  1.0000000e+00]\n",
      "[ 4.38370943e-01 -1.02805726e-01  2.74495274e-01  1.60965115e-01\n",
      "  1.13216805e+00 -2.02655792e-06  7.73218632e-01 -3.49022388e-01\n",
      "  0.00000000e+00 -8.34906518e-01  2.98023224e-07  1.28790736e-01\n",
      "  8.25005352e-01  0.00000000e+00  3.34860772e-01  3.37979615e-01\n",
      "  3.48589242e-01  3.73357922e-01  4.08118576e-01  4.57074225e-01\n",
      "  5.36417961e-01  6.80972517e-01  8.78660798e-01  1.00000000e+00]\n",
      "[ 3.8012785e-01 -1.1643907e-01  2.8248292e-01  1.7249155e-01\n",
      "  1.1283116e+00  4.6318769e-04  6.6456366e-01 -9.9995238e-01\n",
      "  0.0000000e+00 -8.3490819e-01 -1.5735626e-05  2.4552870e-01\n",
      "  9.5606065e-01  0.0000000e+00  3.4274334e-01  3.4572315e-01\n",
      "  3.5717717e-01  3.8298649e-01  4.1704538e-01  4.6747288e-01\n",
      "  5.4909885e-01  6.9550771e-01  8.9782339e-01  1.0000000e+00]\n",
      "[ 3.1687382e-01 -1.2649076e-01  2.8333530e-01  1.5891789e-01\n",
      "  1.0710853e+00 -6.9927615e-01  7.9046118e-01  1.0000188e+00\n",
      "  0.0000000e+00 -8.3490771e-01 -4.1723251e-06  3.7182099e-01\n",
      "  1.0307485e+00  0.0000000e+00  3.4994292e-01  3.5277739e-01\n",
      "  3.6543083e-01  3.9183652e-01  4.2516333e-01  4.7695175e-01\n",
      "  5.6068099e-01  7.0868909e-01  9.1525328e-01  1.0000000e+00]\n",
      "[ 2.58289605e-01 -1.17180884e-01  2.89409965e-01  1.41284898e-01\n",
      "  1.06091595e+00 -7.70837665e-02  6.82421029e-01 -9.99996960e-01\n",
      "  0.00000000e+00 -8.34906638e-01 -2.98023224e-07  4.92969453e-01\n",
      "  9.98977661e-01  0.00000000e+00  3.56162250e-01  3.59003782e-01\n",
      "  3.72822762e-01  3.99110973e-01  4.32307661e-01  4.85326827e-01\n",
      "  5.73298335e-01  7.17867196e-01  9.30598140e-01  1.00000000e+00]\n",
      "[ 0.19743675 -0.12171578  0.2939897   0.11923241  1.0599492   0.04461735\n",
      "  0.57523954 -1.          0.         -0.83490735  0.          0.61418426\n",
      "  1.0000001   0.          0.36128706  0.36416945  0.37910277  0.40455645\n",
      "  0.43824387  0.49233893  0.5840897   0.72524244  0.9452827   1.        ]\n",
      "[ 0.13852687 -0.11838642  0.28454587  0.11699612  0.9795253  -0.9608215\n",
      "  0.6510469   0.5338089   0.         -0.7789143   0.704678    0.6006905\n",
      " -0.11418293  0.          0.36631283  0.36923534  0.38525343  0.40989822\n",
      "  0.44431958  0.49948278  0.5946562   0.7324882   0.9597079   1.        ]\n",
      "[ 0.09797036 -0.08203259  0.29768232  0.09799135  0.8975394  -0.91365784\n",
      "  0.5585729  -0.9999998   0.         -0.7236679   0.7295249   0.4860332\n",
      " -1.0000001   0.          0.37044278  0.37369522  0.39048594  0.41425562\n",
      "  0.449325    0.50541526  0.60370183  0.7381529   0.97168696  1.        ]\n",
      "[ 0.06914718 -0.05766509  0.2399215   0.12203686  0.9036375   0.06190494\n",
      "  0.5785214   0.06673232  1.         -0.6777523   0.5952197   0.37016803\n",
      " -1.          0.          0.37586895  0.37986204  0.39692986  0.42005846\n",
      "  0.45587075  0.51305985  0.6147099   0.74629563  0.9871196   1.        ]\n",
      "[ 0.04557694 -0.04708282  0.242487    0.09794333  0.94910836  0.5677296\n",
      "  0.45450318 -1.0000001   1.         -0.64956766  0.37165552  0.25368118\n",
      " -0.99999994  0.          0.3801946   0.38491052  0.40220517  0.4246594\n",
      "  0.4610988   0.5192021   0.6214348   0.7525428   0.99931294  1.        ]\n",
      "[ 0.01435191 -0.06240283  0.23781918  0.07177337  1.0281619   0.9999998\n",
      "  0.33648807 -1.0000001   1.         -0.62478137  0.34516203  0.14027977\n",
      " -1.          0.          0.3832599   0.3886613   0.4058372   0.42788708\n",
      "  0.4648164   0.5236177   0.62609506  0.75662255  1.          1.        ]\n",
      "[-0.01538784 -0.05951059  0.24318472  0.05354362  1.1064432   1.0000002\n",
      "  0.2202183  -1.          0.         -0.6217987   0.05341673  0.07541221\n",
      " -0.5634537   0.          0.38547474  0.39155862  0.40801585  0.4301841\n",
      "  0.46751657  0.52687615  0.62943506  0.7592411   1.          1.        ]\n",
      "[-1.1413104e-02  7.9453345e-03  2.6267681e-01  3.4900326e-02\n",
      "  1.1045560e+00  3.7252903e-09  1.0502386e-01 -9.9999982e-01\n",
      "  0.0000000e+00 -6.9439620e-01 -8.2937676e-01 -2.9735684e-02\n",
      " -9.9999970e-01  0.0000000e+00  3.8690108e-01  3.9369881e-01\n",
      "  4.0936968e-01  4.3161148e-01  4.6927586e-01  5.2907431e-01\n",
      "  6.3154584e-01  7.6044405e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-6.1778487e-03  1.0557027e-02  2.6106048e-01  1.3506171e-02\n",
      "  1.1025989e+00 -6.7055225e-08 -1.0791659e-02 -1.0000000e+00\n",
      "  0.0000000e+00 -7.8134233e-01 -9.9999988e-01 -1.3300419e-01\n",
      " -9.9999970e-01  0.0000000e+00  3.8733065e-01  3.9481652e-01\n",
      "  4.0969282e-01  4.3210849e-01  4.6984091e-01  5.3054142e-01\n",
      "  6.3211232e-01  7.5997353e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-1.1764830e-02 -1.1012652e-02  2.7546349e-01  1.2869459e-02\n",
      "  1.0988541e+00  2.9802322e-08 -1.2523913e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -8.6960876e-01 -1.0974025e+00 -9.0970993e-03\n",
      "  1.0000004e+00  0.0000000e+00  3.8794020e-01  3.9590922e-01\n",
      "  4.0994585e-01  4.3256322e-01  4.7045937e-01  5.3234267e-01\n",
      "  6.3257837e-01  7.5933337e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-0.05825783 -0.08119547  0.24251418  0.01337607  1.1287451   0.30735487\n",
      "  0.00134826  0.99999934  0.         -0.83490855  0.          0.06044984\n",
      "  1.0000001   0.          0.38900346  0.3969943   0.41031224  0.43311232\n",
      "  0.4712153   0.53410107  0.63320184  0.7590272   1.          1.        ]\n",
      "[-0.08637188 -0.05580144  0.25307736  0.01183099  1.0878795  -0.4992356\n",
      "  0.12632108  1.0000001   0.         -0.8349077   0.          0.18113852\n",
      "  0.99999994  0.          0.38990885  0.3979183   0.41045997  0.43344077\n",
      "  0.47173992  0.5356417   0.63350356  0.75829643  1.          1.        ]\n",
      "[-0.12916352 -0.08557244  0.22943017 -0.02881278  1.165709    1.0000021\n",
      "  0.01012582 -0.9999998   0.         -0.7556661   0.99999905  0.06303513\n",
      " -1.0000014   0.          0.38881022  0.3967971   0.40860683  0.43162388\n",
      "  0.46988958  0.53421146  0.63080126  0.75439185  1.          1.        ]\n",
      "[-1.3447712e-01 -1.9857671e-02  2.4910295e-01 -4.9215302e-02\n",
      "  1.1349152e+00  5.9604645e-08 -5.8318138e-02 -2.2908656e-01\n",
      "  1.0000000e+00 -7.6717591e-01 -3.3351302e-02 -4.5779943e-02\n",
      " -9.9999982e-01  0.0000000e+00  3.8720024e-01  3.9468059e-01\n",
      "  4.0615559e-01  4.2918542e-01  4.6736971e-01  5.3204632e-01\n",
      "  6.2721032e-01  7.4942672e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-1.19960345e-01  2.01418027e-02  2.51342803e-01 -3.94088179e-02\n",
      "  1.13758647e+00  1.19075179e-04 -1.41409397e-01 -4.56121892e-01\n",
      "  0.00000000e+00 -8.29029441e-01 -7.10980594e-01 -4.63149548e-02\n",
      " -4.36036587e-02  0.00000000e+00  3.86169314e-01  3.92887861e-01\n",
      "  4.04310733e-01  4.27390754e-01  4.65556622e-01  5.30732214e-01\n",
      "  6.23950899e-01  7.45459437e-01  1.00000000e+00  1.00000000e+00]\n",
      "[-1.2228286e-01 -7.6561756e-03  2.0932183e-01  4.1523804e-03\n",
      "  1.1357113e+00 -1.0782480e-04 -1.6980886e-01 -1.9749157e-01\n",
      "  0.0000000e+00 -7.8573644e-01  5.7621527e-01 -1.6215777e-01\n",
      " -1.0000049e+00  0.0000000e+00  3.8683006e-01  3.9291978e-01\n",
      "  4.0434355e-01  4.2756689e-01  4.6588507e-01  5.3187615e-01\n",
      "  6.2335509e-01  7.4471140e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-1.15200296e-01  1.31951319e-02  2.08066985e-01 -2.55486779e-02\n",
      "  1.13515401e+00 -1.49011612e-08 -1.84965372e-01 -1.12623155e-01\n",
      "  0.00000000e+00 -8.05449903e-01 -2.03482598e-01 -2.77111650e-01\n",
      " -1.00000012e+00  0.00000000e+00  3.86068970e-01  3.91525894e-01\n",
      "  4.02909160e-01  4.26180631e-01  4.64494020e-01  5.30924857e-01\n",
      "  6.20751083e-01  7.41575360e-01  1.00000000e+00  1.00000000e+00]\n",
      "[-0.11176031  0.00688669  0.22270633  0.00897581  1.1247379  -0.12706278\n",
      " -0.20756686 -0.19098037  0.         -0.8076385   0.         -0.15426612\n",
      "  0.99999934  0.          0.38691115  0.3917003   0.40319633  0.42652172\n",
      "  0.4650125   0.5323468   0.62031597  0.7415692   1.          1.        ]\n",
      "[-1.0904336e-01  5.4394342e-03  1.7966190e-01 -5.0010122e-03\n",
      "  1.1248294e+00 -3.7252903e-09 -2.0665824e-01  8.2047461e-03\n",
      "  0.0000000e+00 -7.9736871e-01  1.5328632e-01 -2.7104962e-01\n",
      " -1.0000005e+00  0.0000000e+00  3.8701555e-01  3.9126268e-01\n",
      "  4.0285778e-01  4.2616358e-01  4.6473408e-01  5.3264701e-01\n",
      "  6.1914849e-01  7.4076283e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-1.1289173e-01 -7.6782638e-03  1.9429849e-01 -3.1245677e-04\n",
      "  1.1247513e+00  7.4505806e-09 -2.2483087e-01 -1.5248390e-01\n",
      "  0.0000000e+00 -8.1981951e-01 -2.5946394e-01 -1.4834070e-01\n",
      "  1.0000004e+00  0.0000000e+00  3.8734123e-01  3.9100319e-01\n",
      "  4.0271297e-01  4.2601043e-01  4.6469066e-01  5.3328532e-01\n",
      "  6.1818761e-01  7.4029332e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-1.1493635e-01 -4.0818937e-03  1.5476635e-01 -8.6542955e-03\n",
      "  1.1246965e+00 -1.8543936e-04 -2.4388587e-01 -1.5939012e-01\n",
      "  0.0000000e+00 -8.2228220e-01  6.1653554e-06 -2.6418900e-01\n",
      " -9.9997228e-01  0.0000000e+00  3.8720882e-01  3.9040229e-01\n",
      "  4.0218955e-01  4.2546117e-01  4.6418118e-01  5.3269702e-01\n",
      "  6.1686569e-01  7.3917687e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-1.2410850e-01 -1.8297266e-02  1.3921157e-01  2.2165740e-02\n",
      "  1.1247771e+00  2.1556020e-04 -2.4792671e-01 -3.3981070e-02\n",
      "  0.0000000e+00 -7.5963485e-01  7.9746819e-01 -3.8144612e-01\n",
      " -9.9998599e-01  0.0000000e+00  3.8846192e-01  3.9124215e-01\n",
      "  4.0314773e-01  4.2656520e-01  4.6538568e-01  5.3384495e-01\n",
      "  6.1762530e-01  7.4077266e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-1.24450758e-01 -5.88241790e-04  1.20439924e-01  6.38408363e-02\n",
      "  1.10623097e+00 -2.33489677e-01 -2.35477924e-01  1.02438688e-01\n",
      "  0.00000000e+00 -6.80287242e-01  1.00000000e+00 -4.97592092e-01\n",
      " -1.00000000e+00  0.00000000e+00  3.91658843e-01  3.94094944e-01\n",
      "  4.06177729e-01  4.29867566e-01  4.69046891e-01  5.37648559e-01\n",
      "  6.21285200e-01  7.46157944e-01  1.00000000e+00  1.00000000e+00]\n",
      "[-0.10785573  0.0332751   0.10526438  0.09780962  1.062237   -0.55084234\n",
      " -0.21056509  0.2036529   0.         -0.61951476  0.7653822  -0.61286473\n",
      " -0.9999998   0.          0.39633337  0.39863005  0.41093946  0.43500778\n",
      "  0.47529095  0.5436716   0.62736714  0.75471056  1.          1.        ]\n",
      "[-0.07887615  0.05793522  0.11676166  0.1453554   0.9929105  -0.865188\n",
      " -0.16796124  0.3440005   0.         -0.59312266  0.4048841  -0.48230743\n",
      "  0.9999995   0.          0.40309775  0.40543365  0.41805714  0.44266766\n",
      "  0.4844734   0.5526964   0.63661605  0.7675371   1.          1.        ]\n",
      "[-0.0510506   0.05563419  0.10700314  0.11901902  0.949677   -0.52401984\n",
      " -0.08444774  0.6810253   0.         -0.6267296  -0.39389378 -0.35976732\n",
      "  1.0000001   0.          0.40865532  0.4110234   0.4239119   0.44897467\n",
      "  0.4920671   0.56011397  0.6441814   0.77807623  1.          1.        ]\n",
      "[-0.01028448  0.0815212   0.10099866  0.13174114  0.8700984  -0.9946141\n",
      " -0.04310858  0.33547452  0.         -0.7080008  -1.0007007  -0.23762143\n",
      "  0.9997068   0.          0.41485718  0.41726124  0.43043348  0.45598903\n",
      "  0.5004555   0.56838644  0.65268147  0.7898355   1.          1.        ]\n",
      "[ 0.01103565  0.0426561   0.08039151  0.11665316  0.83283424 -0.43043384\n",
      "  0.07899147  0.98433     0.         -0.76396084 -0.68118215 -0.11455631\n",
      "  1.          0.          0.42030388  0.42273948  0.4361557   0.46213895\n",
      "  0.5077856   0.5756493   0.6601396   0.8007364   1.          1.        ]\n",
      "[ 0.06132945  0.10055587  0.08028331  0.08340927  0.7534285  -0.99999964\n",
      "  0.10711592  0.22783715  0.         -0.84437436 -0.95620966 -0.22662783\n",
      " -0.99999934  0.          0.42428505  0.42674375  0.44035134  0.4666601\n",
      "  0.51323646  0.5809637   0.6655178   0.8089183   1.          1.        ]\n",
      "[ 0.07631166  0.03412853  0.05499389  0.06121251  0.80013144  0.5683005\n",
      " -0.00750232 -1.          0.         -0.83490944  0.         -0.35593593\n",
      " -1.0000001   0.          0.4272003   0.42967588  0.44342008  0.46996376\n",
      "  0.5172027   0.58485353  0.6694737   0.8148968   1.          1.        ]\n",
      "[ 0.08375242  0.01477246  0.04698171  0.0403727   0.8785134   1.0000001\n",
      " -0.12147653 -1.0000001   0.         -0.82576936  0.13391256 -0.47393155\n",
      " -0.99999994  0.          0.42904916  0.43153545  0.44537538  0.47207698\n",
      "  0.51978284  0.58732444  0.67193705  0.8187211   1.          1.        ]\n",
      "[ 0.07886183 -0.00988005  0.03743979  0.03627402  0.9574866   1.\n",
      " -0.15771449 -0.34532583  0.         -0.7680494   0.7359002  -0.5916765\n",
      " -0.99999994  0.          0.43066633  0.43316197  0.44708368  0.47392142\n",
      "  0.5220254   0.5894848   0.67410165  0.822059    1.          1.        ]\n",
      "[ 0.07166552 -0.014728    0.0294129   0.01273933  1.0294406   0.9999998\n",
      " -0.02270114  0.99999976  0.         -0.7486018   0.27425247 -0.70806265\n",
      " -1.0000002   0.          0.43118578  0.43368444  0.44764444  0.4745379\n",
      "  0.52283204  0.5901839   0.674736    0.82317466  1.          1.        ]\n",
      "[ 0.07311368  0.00256191  0.06834564 -0.01496187  1.1015551   1.0000005\n",
      "  0.11438125  1.0000001   0.         -0.82937914 -1.0000002  -0.5828781\n",
      "  0.9999998   0.          0.43037677  0.4328946   0.44684657  0.4737282\n",
      "  0.5221152   0.5891273   0.673368    0.82170933  1.          1.        ]\n",
      "[ 7.3067300e-02 -3.6606455e-04  6.5607473e-02  2.4694293e-03\n",
      "  1.0938878e+00 -3.2596290e-08  3.3379972e-01  1.7246743e+00\n",
      "  0.0000000e+00 -8.3201128e-01  1.3969839e-09 -4.6015227e-01\n",
      "  1.0000001e+00  0.0000000e+00  4.3040630e-01  4.3296567e-01\n",
      "  4.4691995e-01  4.7384587e-01  5.2245718e-01  5.8918476e-01\n",
      "  6.7319548e-01  8.2192224e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.06458204 -0.01705636  0.04393756 -0.02520553  1.1730988   0.9999999\n",
      "  0.27153993 -0.5528506   0.         -0.7527888   1.0000001  -0.57778883\n",
      " -1.0000001   0.          0.4291203   0.43169606  0.44560942  0.47247455\n",
      "  0.5210158   0.58748716  0.6712333   0.8194406   1.          1.        ]\n",
      "[ 0.08238178  0.03002603  0.05249278 -0.03502711  1.1349075  -0.20306213\n",
      "  0.37176663  0.48657465  0.         -0.73607075  0.26044083 -0.69150233\n",
      " -1.0000001   0.          0.42765638  0.43025172  0.44411853  0.47091535\n",
      "  0.51938176  0.5855553   0.6689949   0.816619    1.          1.        ]\n",
      "[ 9.4982646e-02  2.3263682e-02  6.6153742e-02 -6.1760135e-02\n",
      "  1.1307508e+00 -2.6822090e-07  4.9665397e-01  9.9999982e-01\n",
      "  0.0000000e+00 -7.7656239e-01 -3.6309427e-01 -6.3490927e-01\n",
      "  0.0000000e+00  0.0000000e+00  4.2478272e-01  4.2739826e-01\n",
      "  4.4117308e-01  4.6781737e-01  5.1604038e-01  5.8175468e-01\n",
      "  6.6469502e-01  8.1101257e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 1.2202850e-01  5.4076310e-02  7.4820057e-02 -6.6966154e-02\n",
      "  1.0914667e+00 -4.8728994e-01  5.4462588e-01  3.9454475e-01\n",
      "  0.0000000e+00 -8.1373256e-01 -4.6499604e-01 -6.3478899e-01\n",
      " -9.9341078e-09  0.0000000e+00  4.2165524e-01  4.2428881e-01\n",
      "  4.3796343e-01  4.6443757e-01  5.1237470e-01  5.7761669e-01\n",
      "  6.6003579e-01  8.0489618e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.1502095   0.05625108  0.08811607 -0.06123081  1.0606391  -0.35540503\n",
      "  0.4295467  -0.9999997   0.         -0.8174986   0.         -0.51096463\n",
      "  0.9999997   0.          0.41877538  0.42143765  0.43502036  0.4613502\n",
      "  0.5090879   0.5738117   0.6556834   0.799309    1.          1.        ]\n",
      "[ 0.17208311  0.04358814  0.07946122 -0.07167763  0.979641   -1.0000006\n",
      "  0.5528338   1.0000001   0.         -0.817555    0.04955763 -0.38629925\n",
      "  1.          0.          0.4153833   0.4180647   0.43153873  0.45768353\n",
      "  0.50510883  0.5693235   0.6506323   0.7926735   1.          1.        ]\n",
      "[ 0.1797529   0.01525869  0.07849535 -0.113038    1.027617    0.61830944\n",
      "  0.43639094 -1.          0.         -0.8201423   0.         -0.26321244\n",
      "  1.0000001   0.          0.4100109   0.4126937   0.4259946   0.4518169\n",
      "  0.49859357  0.56220233  0.6427828   0.78205675  1.          1.        ]\n",
      "[ 0.18236898  0.00499455  0.07712594 -0.1343377   1.0947014   0.85665447\n",
      "  0.3221621  -1.          0.         -0.8236188   0.         -0.13846254\n",
      "  0.99999994  0.          0.40361375  0.40628874  0.41938323  0.44481176\n",
      "  0.49076587  0.5537186   0.6334851   0.7693797   1.          1.        ]\n",
      "[ 0.1972473   0.02966899  0.0724893  -0.12442644  1.0354285  -0.7269502\n",
      "  0.445351    1.0000001   0.         -0.826992    0.         -0.01310635\n",
      "  0.99999976  0.          0.39773226  0.40040034  0.41330504  0.4383717\n",
      "  0.48357055  0.5459188   0.6249359   0.7577252   1.          1.        ]\n",
      "[ 0.20638369  0.01824636  0.06447595 -0.12179956  0.95466346 -0.9999995\n",
      "  0.5688477   0.99999994  0.         -0.7823435   0.6355682   0.11866432\n",
      "  1.0000002   0.          0.39192966  0.39458677  0.4073041   0.43200958\n",
      "  0.4764414   0.53822196  0.6165228   0.74651605  1.          1.        ]\n",
      "[ 0.22527212  0.03778535  0.06957553 -0.13361096  0.8912165  -0.7466981\n",
      "  0.46001184 -0.985616    0.         -0.73615706  0.6673188   0.25363123\n",
      "  1.0000004   0.          0.38558015  0.38822433  0.4007366   0.42504585\n",
      "  0.46863338  0.52979916  0.60732156  0.734494    1.          1.        ]\n",
      "[ 0.23604393  0.0215914   0.05947525 -0.15977567  0.8525825  -0.44628605\n",
      "  0.34788775 -1.          0.         -0.66117114  1.          0.31134546\n",
      "  0.3727866   0.          0.37798792  0.38060218  0.3928688   0.41668954\n",
      "  0.45919102  0.5197215   0.5963651   0.72011644  0.99749047  1.        ]\n",
      "[ 0.23931372  0.00665432  0.03845032 -0.17785116  0.772386   -1.0000001\n",
      "  0.48544872  1.1687042   1.         -0.53401047  1.6467353   0.03968668\n",
      " -3.0246153   1.          0.3695082   0.37207213  0.3840638   0.40732166\n",
      "  0.44852027  0.5084584   0.5842062   0.7040557   0.97107655  1.        ]\n",
      "[ 0.2520601   0.02644595  0.0177941  -0.19342543  0.8403953   0.7270316\n",
      "  0.34803903 -1.001988    1.         -0.45845994  0.99152565 -0.10807467\n",
      " -1.5994533   1.          0.36026916  0.3627613   0.37445292  0.39708012\n",
      "  0.436769    0.49617922  0.5710426   0.6865541   0.9429298   1.        ]\n",
      "[ 0.25763395  0.01169607  0.02287279 -0.21234043  0.9189996   0.9871423\n",
      "  0.23228449 -1.          1.         -0.4017937   0.66405433 -0.15091419\n",
      " -1.0000001   1.          0.35009965  0.35251647  0.36387792  0.3858147\n",
      "  0.42386138  0.48266503  0.5565349   0.66729045  0.91199076  1.        ]\n",
      "[ 0.27111897  0.0268448   0.04190023 -0.2296326   0.9941614   0.96565205\n",
      "  0.118801   -1.0000001   0.         -0.4017277   0.00557739 -0.22083318\n",
      " -0.57838565  1.          0.33932155  0.3416697   0.35268155  0.373898\n",
      "  0.4102634   0.46834707  0.541104    0.64687574  0.8793286   1.        ]\n",
      "[ 0.2748554   0.00695301  0.02920708 -0.25253952  1.0552202   0.8575421\n",
      "  0.25528878  0.9999998   0.         -0.40413788  0.01108893 -0.33629334\n",
      " -0.9999998   1.          0.32744893  0.32971242  0.3403389   0.36075264\n",
      "  0.39521828  0.4525711   0.5241505   0.6261529   0.84694064  1.        ]\n",
      "[ 0.2858606   0.02173809  0.06280035 -0.26166746  1.1302581   0.98903656\n",
      "  0.29028302  0.20123608  0.         -0.48516148 -1.         -0.28502846\n",
      " -0.1508112   1.          0.31512237  0.3173171   0.32754406  0.347144\n",
      "  0.37973893  0.43620035  0.506454    0.60509604  0.81344634  1.        ]\n",
      "[ 0.31704512  0.06255137  0.09853314 -0.24120931  1.1301799   0.\n",
      "  0.31055224  0.1515301   0.         -0.56223047 -1.0938052  -0.25526214\n",
      "  0.11657941  1.          0.30376413  0.3059187   0.3157783   0.33465213\n",
      "  0.36564645  0.42094383  0.49003282  0.58554965  0.7826877   1.        ]\n",
      "[ 0.3469026   0.05976277  0.12513095 -0.23548204  1.129759    0.\n",
      "  0.31421024  0.02143759  0.         -0.6549338  -1.1584918  -0.22892523\n",
      "  0.21657749  1.          0.2926647   0.29479793  0.30429912  0.32248175\n",
      "  0.35200736  0.40524206  0.4738211   0.5663373   0.7524865   1.        ]\n",
      "[ 3.6747372e-01  4.1128770e-02  9.8791994e-02 -2.4679786e-01\n",
      "  1.1296990e+00 -2.9802322e-08  2.8874326e-01 -2.1618940e-01\n",
      "  0.0000000e+00 -6.5596116e-01  7.1874559e-03 -3.4498060e-01\n",
      " -1.0000000e+00  1.0000000e+00  2.8104204e-01  2.8313360e-01\n",
      "  2.9225886e-01  3.0969784e-01  3.3788252e-01  3.8863572e-01\n",
      "  4.5583642e-01  5.4633945e-01  7.2071892e-01  1.0000000e+00]\n",
      "[ 4.0366998e-01  7.2373129e-02  1.2140452e-01 -2.6701880e-01\n",
      "  1.1276374e+00 -2.9802322e-08  1.7252320e-01 -1.0000001e+00\n",
      "  0.0000000e+00 -7.2462600e-01 -8.3958077e-01 -3.7985611e-01\n",
      "  8.3610915e-02  1.0000000e+00  2.6849279e-01  2.7054775e-01\n",
      "  2.7926737e-01  2.9591206e-01  3.2284215e-01  3.7077695e-01\n",
      "  4.3642229e-01  5.2469510e-01  6.8646175e-01  1.0000000e+00]\n",
      "[ 0.4451863   0.07965211  0.17734492 -0.11156095  1.0606111  -0.7614714\n",
      "  0.29912072  1.0009149   0.         -0.8260781  -1.0202708  -0.25767314\n",
      "  0.7678326   1.          0.26369953  0.2658242   0.2743916   0.2908186\n",
      "  0.31728515  0.36466593  0.42904988  0.515909    0.67380464  1.        ]\n",
      "[ 0.45836186  0.02582716  0.16039886 -0.12187884  1.0464268  -0.13822776\n",
      "  0.4242019   1.0000001   0.         -0.8217556   0.         -0.27822113\n",
      " -0.10761318  1.          0.25792217  0.26009527  0.268478    0.2846061\n",
      "  0.3105073   0.3569978   0.42014557  0.5055193   0.6586599   1.        ]\n",
      "[ 0.43903014 -0.03491955  0.16084673 -0.11935233  1.0869223   0.52641505\n",
      "  0.55190396  1.0000004   0.         -0.8391302  -0.10028276 -0.26086712\n",
      "  0.15210927  1.          0.25220567  0.25441638  0.2626161   0.2784498\n",
      "  0.30379072  0.34941053  0.41131708  0.49520203  0.64417416  1.        ]\n",
      "[ 0.4051537  -0.05145613  0.19943109 -0.01354648  1.1257722   0.5722668\n",
      "  0.6949667   1.0000125   0.         -0.8392162   0.02163085 -0.22585607\n",
      "  0.23800707  1.          0.2536114   0.2558344   0.2640798   0.28013232\n",
      "  0.30608416  0.3523738   0.41336587  0.496619    0.64744204  1.        ]\n",
      "[ 3.8140661e-01 -3.7363525e-02  2.0125838e-01 -8.8768397e-03\n",
      "  1.1237290e+00  5.9604645e-08  8.2563484e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3782810e-01  0.0000000e+00 -1.6314924e-01\n",
      "  5.2030045e-01  1.0000000e+00  2.5414887e-01  2.5637662e-01\n",
      "  2.6471415e-01  2.8085059e-01  3.0754700e-01  3.5405791e-01\n",
      "  4.1406900e-01  4.9652639e-01  6.4903450e-01  1.0000000e+00]\n",
      "[ 3.5045972e-01 -5.8070712e-02  2.0662487e-01  2.0416565e-02\n",
      "  1.0972738e+00 -3.4483024e-01  9.4708192e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3490890e-01 -2.9802322e-08 -1.6392875e-01\n",
      "  4.3100324e-01  1.0000000e+00  2.5503883e-01  2.5727436e-01\n",
      "  2.6576149e-01  2.8196177e-01  3.0947050e-01  3.5622272e-01\n",
      "  4.1531673e-01  4.9701631e-01  6.5179574e-01  1.0000000e+00]\n",
      "[ 3.1632081e-01 -6.6440932e-02  2.3274186e-01  3.9251428e-02\n",
      "  1.1228491e+00  3.2981604e-01  8.3095932e-01 -9.9999970e-01\n",
      "  0.0000000e+00 -8.3517712e-01  2.9802322e-08 -1.4003801e-01\n",
      "  5.5852032e-01  1.0000000e+00  2.5677994e-01  2.5903073e-01\n",
      "  2.6771531e-01  2.8403467e-01  3.1258795e-01  3.5840946e-01\n",
      "  4.1736174e-01  4.9880782e-01  6.5694684e-01  1.0000000e+00]\n",
      "[ 0.27785304 -0.07680016  0.26135805  0.06888603  1.0634024  -0.7426628\n",
      "  0.95188534  1.          0.         -0.8349071   0.         -0.0504297\n",
      "  0.74371743  1.          0.2597177   0.26199424  0.27093804  0.2874539\n",
      "  0.31734702  0.3621712   0.42048925  0.502477    0.6654435   1.        ]\n",
      "[ 2.2783363e-01 -9.9889487e-02  2.9138133e-01  6.4248830e-02\n",
      "  1.0667853e+00 -2.3097873e-02  9.3490648e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490723e-01  1.1920929e-07  3.5774827e-02\n",
      "  7.0329565e-01  1.0000000e+00  2.6236078e-01  2.6466048e-01\n",
      "  2.7386862e-01  2.9056311e-01  3.2183963e-01  3.6552522e-01\n",
      "  4.2308304e-01  5.0550592e-01  6.7316979e-01  1.0000000e+00]\n",
      "[ 1.6874386e-01 -1.1810346e-01  3.1868926e-01  6.4894997e-02\n",
      "  1.1061734e+00  5.0948608e-01  8.1876731e-01 -1.0000033e+00\n",
      "  0.0000000e+00 -8.3490741e-01  1.2516975e-06  1.3899642e-01\n",
      "  8.3906263e-01  0.0000000e+00  2.6499453e-01  2.6744506e-01\n",
      "  2.7680501e-01  2.9436713e-01  3.2642582e-01  3.6885166e-01\n",
      "  4.2555362e-01  5.0838298e-01  6.8091142e-01  1.0000000e+00]\n",
      "[ 0.10150504 -0.13472693  0.34671566  0.07913791  1.0696627  -0.44906878\n",
      "  0.9613868   1.5779141   1.         -0.8281503   0.09320915  0.25100666\n",
      "  0.90708035  0.          0.2682297   0.2709057   0.28038678  0.2992936\n",
      "  0.33188882  0.3729622   0.428766    0.5121369   0.69025177  1.        ]\n",
      "[ 0.01700789 -0.16811335  0.3177839   0.09632297  1.1567669   0.9374007\n",
      "  0.93490434  0.          1.         -0.7997015   0.3529848   0.3641067\n",
      "  0.9156852   0.          0.27221325  0.2751051   0.28473315  0.30496866\n",
      "  0.33762848  0.3780861   0.43317375  0.5173187   0.7014856   1.        ]\n",
      "[ 4.6007326e-03 -4.7929913e-02  2.0669749e-01  1.8005611e-01\n",
      "  1.1418190e+00  1.5280724e-02  9.3527997e-01 -4.4681630e-04\n",
      "  0.0000000e+00 -8.3623338e-01 -2.8281125e-01  4.9222505e-01\n",
      "  9.9842095e-01  0.0000000e+00  2.8090546e-01  2.8400582e-01\n",
      "  2.9394537e-01  3.1569082e-01  3.4784916e-01  3.8953149e-01\n",
      "  4.4471228e-01  5.3351659e-01  7.2545594e-01  1.0000000e+00]\n",
      "[-1.5631175e-02 -4.7727510e-02  1.9926848e-01  1.9318926e-01\n",
      "  1.1381814e+00 -1.4062166e-02  9.3508422e-01 -6.7763128e-03\n",
      "  0.0000000e+00 -8.3516502e-01  2.0131469e-04  5.6951731e-01\n",
      "  7.2484511e-01  0.0000000e+00  2.8996736e-01  2.9326037e-01\n",
      "  3.0378211e-01  3.2679471e-01  3.5849392e-01  4.0031806e-01\n",
      "  4.5674005e-01  5.5044609e-01  7.5042397e-01  1.0000000e+00]\n",
      "[-2.1698188e-02 -1.1925893e-02  1.9827634e-01  1.9733872e-01\n",
      "  1.1349019e+00  2.2351742e-08  9.0185469e-01 -3.5632065e-01\n",
      "  0.0000000e+00 -8.3490723e-01  0.0000000e+00  6.0017854e-01\n",
      "  1.7561115e-01  1.0000000e+00  2.9919326e-01  3.0259106e-01\n",
      "  3.1418774e-01  3.3798862e-01  3.6922681e-01  4.1098678e-01\n",
      "  4.6883413e-01  5.6751585e-01  7.7935314e-01  1.0000000e+00]\n",
      "[-2.6446229e-02 -9.1116196e-03  1.8394060e-01  1.9251876e-01\n",
      "  1.1349069e+00  3.7252903e-09  8.5626411e-01 -3.8988853e-01\n",
      "  0.0000000e+00 -7.4948287e-01  9.9999994e-01  5.1377624e-01\n",
      " -1.0000000e+00  1.0000000e+00  3.0813083e-01  3.1163010e-01\n",
      "  3.2424366e-01  3.4880632e-01  3.7963483e-01  4.2136088e-01\n",
      "  4.8059589e-01  5.8407170e-01  8.0734378e-01  1.0000000e+00]\n",
      "[-0.02495554  0.00294493  0.19003789  0.18926524  1.0550089  -0.9999983\n",
      "  0.97628814  1.0000001   0.         -0.6902474   0.7445641   0.47665715\n",
      " -0.318595    0.          0.3169873   0.32058716  0.3342338   0.35953897\n",
      "  0.38993743  0.4316006   0.4922035   0.60147977  0.8355072   1.        ]\n",
      "[-0.00447768  0.04070015  0.20371653  0.1659279   1.0016797  -0.6549151\n",
      "  1.0288166   0.5450538   1.         -0.70411146 -0.16415751  0.50523686\n",
      "  0.2305312   1.          0.32480568  0.3284943   0.343147    0.36788765\n",
      "  0.39899194  0.4404908   0.50227535  0.61719286  0.8613536   1.        ]\n",
      "[ 0.01297545  0.03513667  0.17885952  0.16179568  1.0028415   0.22775945\n",
      "  0.8854753  -0.9999996   0.         -0.6487596   0.70149136  0.42229575\n",
      " -0.7181723   1.          0.3324777   0.33625346  0.35183334  0.37610385\n",
      "  0.4079028   0.44930983  0.51227045  0.63261175  0.88659924  1.        ]\n",
      "[ 0.0444756   0.06314413  0.18753092  0.14520718  1.0071765   0.05742651\n",
      "  0.7662606  -0.99999994  1.         -0.5985477   0.6346488   0.30495334\n",
      " -0.99999994  1.          0.33937946  0.34325317  0.359716    0.38346797\n",
      "  0.41514     0.45713508  0.5219553   0.6464827   0.91014254  1.        ]\n",
      "[ 0.07410479  0.05928833  0.18453728  0.13147107  1.006115   -0.00291041\n",
      "  0.6489598  -1.          0.         -0.5356472   0.8168483   0.19567871\n",
      " -1.          0.          0.34559172  0.35006368  0.36685312  0.39007977\n",
      "  0.42147595  0.46407405  0.5312196   0.65895754  0.93270683  1.        ]\n",
      "[ 0.11333609  0.07851095  0.18933655  0.11282059  0.99175495 -0.15966675\n",
      "  0.53216004 -1.          1.         -0.49350432  0.539345    0.07961714\n",
      " -0.99999994  0.          0.35099146  0.35605276  0.37312946  0.39579797\n",
      "  0.4268786   0.46997917  0.539225    0.66968775  0.9525389   1.        ]\n",
      "[ 0.1385906   0.05044263  0.17892282  0.09146642  1.0132016   0.28001168\n",
      "  0.41622728 -1.0000001   0.         -0.421646    0.9286574  -0.02849948\n",
      " -0.99999994  0.          0.3553099   0.36091277  0.37822255  0.40034187\n",
      "  0.43109348  0.47458166  0.5455796   0.6782622   0.96862113  1.        ]\n",
      "[ 0.1689567   0.06077283  0.18169734  0.07511423  1.017084    0.06932369\n",
      "  0.29970837 -1.          0.         -0.354892    0.84675354 -0.14382589\n",
      " -0.99999994  0.          0.35890076  0.36503273  0.38254014  0.40408736\n",
      "  0.4344792   0.4782737   0.5508099   0.685384    0.98028034  1.        ]\n",
      "[ 0.18692328  0.03576924  0.17588991  0.04463165  1.0731175   0.7133785\n",
      "  0.1854266  -1.0000001   0.         -0.28127316  0.94442725 -0.25213552\n",
      " -1.0000001   0.          0.36100477  0.36762092  0.38485062  0.40620962\n",
      "  0.43620044  0.48013887  0.5537561   0.6895393   0.98665565  1.        ]\n",
      "[ 0.2274925   0.08113194  0.19229653  0.03540833  1.0554245  -0.21091759\n",
      "  0.10944021 -0.64828175  0.         -0.25575477  0.32792836 -0.36930728\n",
      " -0.9999998   0.          0.36278513  0.36991274  0.38651186  0.40796307\n",
      "  0.4375033   0.48154286  0.5561799   0.6930452   0.99211735  1.        ]\n",
      "[ 0.26457518  0.0740964   0.19580115  0.00844293  1.0736594   0.24739122\n",
      " -0.00643659 -1.          0.         -0.24050312  0.20225632 -0.48553944\n",
      " -1.0000001   0.          0.3632892   0.37090805  0.38684574  0.40831548\n",
      "  0.4373497   0.48134732  0.5566305   0.69400287  0.99389195  1.        ]\n",
      "[ 0.3058386   0.08236385  0.22421807 -0.00210092  1.112119    0.4980712\n",
      " -0.12044287 -1.          0.         -0.32045254 -0.9830364  -0.36229372\n",
      "  1.0000002   0.          0.3633129   0.3714819   0.3866537   0.40811276\n",
      "  0.43654743  0.48043564  0.55629313  0.6939946   0.9943228   1.        ]\n",
      "[ 3.3562127e-01  5.9511695e-02  1.8326233e-01 -1.9006317e-02\n",
      "  1.1113931e+00  2.9802322e-08 -9.2907071e-02  2.0987396e-01\n",
      "  0.0000000e+00 -2.8486070e-01  4.5747229e-01 -4.7889471e-01\n",
      " -9.9999970e-01  0.0000000e+00  3.6264700e-01  3.7109974e-01\n",
      "  3.8563451e-01  4.0672264e-01  4.3495241e-01  4.7865939e-01\n",
      "  5.5473626e-01  6.9232833e-01  9.9226838e-01  1.0000000e+00]\n",
      "[ 0.37476438  0.0781514   0.20185019 -0.0336906   1.0930305  -0.17946857\n",
      "  0.03397197  0.9999998   0.         -0.33553368 -0.62849605 -0.4894483\n",
      " -0.11027481  0.          0.36167133  0.37010133  0.3839282   0.40448633\n",
      "  0.43256092  0.47600627  0.55233115  0.689369    0.988375    1.        ]\n",
      "[ 0.4071097   0.06435064  0.22798723 -0.06078187  1.170948    1.0000004\n",
      " -0.06142902 -0.88565785  0.         -0.41699973 -1.         -0.36626804\n",
      "  0.9999997   0.          0.35945922  0.36783767  0.38084334  0.4007764\n",
      "  0.4285935   0.47161925  0.54788935  0.6838016   0.9807554   1.        ]\n",
      "[ 4.5574814e-01  8.7199219e-02  2.1683794e-01 -7.4570604e-02\n",
      "  1.1349130e+00  5.9604645e-08  7.4825108e-02  6.6552401e-01\n",
      "  0.0000000e+00 -5.0347829e-01 -1.0000000e+00 -3.7150478e-01\n",
      " -9.4276153e-02  0.0000000e+00  3.5691476e-01  3.6523390e-01\n",
      "  3.7747127e-01  3.9681503e-01  4.2435715e-01  4.6693924e-01\n",
      "  5.4297709e-01  6.7765468e-01  9.7226262e-01  1.0000000e+00]\n",
      "[ 5.1430643e-01  1.1699792e-01  2.3005892e-01 -9.6792974e-02\n",
      "  1.1331915e+00  5.9604645e-08 -4.0464640e-02 -9.9999970e-01\n",
      "  0.0000000e+00 -5.8680928e-01 -1.0000000e+00 -4.8650229e-01\n",
      " -1.0000002e+00  0.0000000e+00  3.5308057e-01  3.6131033e-01\n",
      "  3.7270930e-01  3.9140019e-01  4.1855553e-01  4.6055076e-01\n",
      "  5.3593165e-01  6.6885751e-01  9.5995706e-01  1.0000000e+00]\n",
      "[ 0.5720049   0.11526885  0.23031017 -0.11363666  1.13167     0.\n",
      " -0.15591216 -1.          0.         -0.6702913  -0.9999999  -0.6016915\n",
      " -0.9999998   0.          0.34844851  0.35638428  0.36711976  0.385142\n",
      "  0.41184974  0.45317218  0.5276025   0.65846777  0.9453426   1.        ]\n",
      "[ 0.62130547  0.09856638  0.22746882 -0.12108749  1.1311171   0.\n",
      " -0.18985033 -0.3016601   0.         -0.7502728  -0.99999994 -0.6013198\n",
      "  0.          0.          0.34343025  0.3505787   0.36113927  0.37849241\n",
      "  0.40472668  0.4453344   0.5186628   0.6473212   0.9296253   1.        ]\n",
      "[ 6.6520768e-01  8.7777764e-02  2.2052456e-01 -1.4028321e-01\n",
      "  1.1270998e+00 -1.1920929e-07 -1.1338711e-01  5.8532077e-01\n",
      "  0.0000000e+00 -8.3035302e-01 -1.0000000e+00 -6.0024667e-01\n",
      "  1.9868216e-08  0.0000000e+00  3.3747581e-01  3.4385288e-01\n",
      "  3.5421085e-01  3.7089339e-01  3.9659148e-01  4.3638298e-01\n",
      "  5.0824267e-01  6.3433957e-01  9.1123420e-01  1.0000000e+00]\n",
      "[ 6.9029456e-01  5.0036963e-02  1.9972822e-01 -1.3534182e-01\n",
      "  1.1239781e+00  1.7881393e-07  1.2739658e-02  1.0000001e+00\n",
      "  0.0000000e+00 -8.3387494e-01  0.0000000e+00 -4.8047376e-01\n",
      "  9.6066117e-01  0.0000000e+00  3.3167452e-01  3.3734381e-01\n",
      "  3.4750572e-01  3.6356819e-01  3.8875070e-01  4.2775553e-01\n",
      "  4.9814099e-01  6.2175763e-01  8.9338583e-01  1.0000000e+00]\n",
      "[ 7.1292955e-01  4.6194218e-02  2.0046702e-01 -1.5174702e-01\n",
      "  1.1211312e+00 -2.6822090e-07  1.3971066e-01  9.9999982e-01\n",
      "  0.0000000e+00 -8.3490849e-01  0.0000000e+00 -3.5867369e-01\n",
      "  1.0000001e+00  0.0000000e+00  3.2509559e-01  3.3005133e-01\n",
      "  3.3999354e-01  3.5542032e-01  3.8003218e-01  4.1816223e-01\n",
      "  4.8678765e-01  6.0762292e-01  8.7328619e-01  1.0000000e+00]\n",
      "[ 7.3373759e-01  4.2809438e-02  2.0115568e-01 -1.6860388e-01\n",
      "  1.1182109e+00 -2.6822090e-07  2.6682019e-01  9.9999982e-01\n",
      "  0.0000000e+00 -8.3490813e-01  0.0000000e+00 -3.7356579e-01\n",
      " -1.3483604e+00  1.0000000e+00  3.1771722e-01  3.2195193e-01\n",
      "  3.3165020e-01  3.4642401e-01  3.7040836e-01  4.0757281e-01\n",
      "  4.7414589e-01  5.9188944e-01  8.4828973e-01  1.0000000e+00]\n",
      "[ 7.5379592e-01  4.1508812e-02  2.0003070e-01 -1.9467893e-01\n",
      "  1.1162648e+00 -1.4901161e-07  3.9310110e-01  9.9999994e-01\n",
      "  0.0000000e+00 -8.3490789e-01  0.0000000e+00 -3.8802719e-01\n",
      " -5.8547258e-01  1.0000000e+00  3.0899504e-01  3.1250167e-01\n",
      "  3.2191524e-01  3.3601141e-01  3.5927337e-01  3.9532062e-01\n",
      "  4.5951855e-01  5.7347709e-01  8.1853652e-01  1.0000000e+00]\n",
      "[ 7.7056915e-01  3.3573359e-02  2.0096120e-01 -2.0595793e-01\n",
      "  1.1135061e+00  1.7881393e-07  5.1885855e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3490825e-01  0.0000000e+00 -4.4937050e-01\n",
      " -5.1397938e-01  1.0000000e+00  2.9986700e-01  3.0263677e-01\n",
      "  3.1175318e-01  3.2515928e-01  3.4766933e-01  3.8255230e-01\n",
      "  4.4437307e-01  5.5424571e-01  7.8740185e-01  1.0000000e+00]\n",
      "[ 7.7887052e-01  1.6675636e-02  1.9713964e-01 -2.1121332e-01\n",
      "  1.1115541e+00  6.7055225e-08  6.4302814e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3490670e-01  0.0000000e+00 -5.0878847e-01\n",
      " -4.9668571e-01  1.0000000e+00  2.9046795e-01  2.9250914e-01\n",
      "  3.0125195e-01  3.1403872e-01  3.3577916e-01  3.6946914e-01\n",
      "  4.2882597e-01  5.3448856e-01  7.5534672e-01  1.0000000e+00]\n",
      "[ 7.8235924e-01  7.4815685e-03  2.0011599e-01 -2.1285859e-01\n",
      "  1.1104680e+00 -2.2351742e-08  7.6584053e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3490765e-01  3.7252903e-09 -6.2068152e-01\n",
      " -2.6564687e-01  0.0000000e+00  2.8038737e-01  2.8228971e-01\n",
      "  2.9048410e-01  3.0281383e-01  3.2377726e-01  3.5626304e-01\n",
      "  4.1313773e-01  5.1455474e-01  7.2448945e-01  1.0000000e+00]\n",
      "[ 7.6099879e-01 -3.8754925e-02  1.6722532e-01 -3.2033578e-02\n",
      "  1.1120768e+00 -8.1203729e-03  8.8599050e-01  9.9942464e-01\n",
      "  0.0000000e+00 -8.3491093e-01  3.1523407e-04 -5.5271351e-01\n",
      "  1.6158950e-01  0.0000000e+00  2.7863187e-01  2.8052229e-01\n",
      "  2.8830346e-01  3.0054063e-01  3.2133067e-01  3.5357097e-01\n",
      "  4.1039336e-01  5.1132345e-01  7.2026139e-01  1.0000000e+00]\n",
      "[ 7.4132568e-01 -3.8727500e-02  1.6840786e-01 -3.4645125e-02\n",
      "  1.1123161e+00 -1.4901161e-08  9.6544588e-01  6.6100407e-01\n",
      "  0.0000000e+00 -8.3490801e-01  0.0000000e+00 -5.2833366e-01\n",
      "  1.6136445e-01  1.0000000e+00  2.7680820e-01  2.7868626e-01\n",
      "  2.8604734e-01  2.9818872e-01  3.1879982e-01  3.5078621e-01\n",
      "  4.0754330e-01  5.0796044e-01  7.1583849e-01  1.0000000e+00]\n",
      "[ 7.2025746e-01 -4.1694943e-02  1.7042072e-01 -1.3419927e-02\n",
      "  1.1218779e+00  1.0949373e-04  9.3490553e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490753e-01 -3.6060810e-06 -5.2655590e-01\n",
      "  9.6621893e-02  1.0000000e+00  2.7594954e-01  2.7782178e-01\n",
      "  2.8476322e-01  2.9685012e-01  3.1734976e-01  3.4919065e-01\n",
      "  4.0617964e-01  5.0652766e-01  7.1449935e-01  1.0000000e+00]\n",
      "[ 0.69645786 -0.04759954  0.18508014  0.00400152  1.1217642   0.\n",
      "  0.92109966 -0.11683891  0.         -0.83423114  0.00753999 -0.5058341\n",
      "  0.17190535  1.          0.2759075   0.27777943  0.2842718   0.2963378\n",
      "  0.31677946  0.34881172  0.40607095  0.5067485   0.71586996  1.        ]\n",
      "[ 0.67019516 -0.05254644  0.20537627  0.0186274   1.1193771  -0.02835724\n",
      "  0.9213463   0.          0.         -0.8341842   0.         -0.47557485\n",
      "  0.2489417   1.          0.27652386  0.27839997  0.2843984   0.29646978\n",
      "  0.31689408  0.34958565  0.40712553  0.50831693  0.71984535  1.        ]\n",
      "[ 6.4070189e-01 -5.9011713e-02  2.2694080e-01  3.4663185e-02\n",
      "  1.1192427e+00  1.2278557e-05  9.2163110e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3417356e-01 -4.1723251e-07 -4.3493164e-01\n",
      "  3.3384714e-01  1.0000000e+00  2.7786058e-01  2.7974579e-01\n",
      "  2.8520289e-01  2.9730844e-01  3.1775990e-01  3.5130873e-01\n",
      "  4.0962359e-01  5.1135874e-01  7.2692299e-01  1.0000000e+00]\n",
      "[ 6.0866588e-01 -6.4101085e-02  2.4831516e-01  3.8399965e-02\n",
      "  1.1190839e+00 -5.9515238e-05  9.2196059e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3415502e-01  1.9669533e-06 -3.9397848e-01\n",
      "  3.3525959e-01  1.0000000e+00  2.7934229e-01  2.8097233e-01\n",
      "  2.8610265e-01  2.9823238e-01  3.1872895e-01  3.5321939e-01\n",
      "  4.1238746e-01  5.1472485e-01  7.3473114e-01  1.0000000e+00]\n",
      "[ 5.7365000e-01 -7.0065729e-02  2.6981574e-01  4.2425662e-02\n",
      "  1.1188992e+00 -6.6339970e-05  9.2234755e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3414632e-01  2.2053719e-06 -3.4771383e-01\n",
      "  3.7823179e-01  1.0000000e+00  2.8098023e-01  2.8196043e-01\n",
      "  2.8710881e-01  2.9924721e-01  3.1981358e-01  3.5533255e-01\n",
      "  4.1543552e-01  5.1843816e-01  7.4330986e-01  1.0000000e+00]\n",
      "[ 5.3540355e-01 -7.6533258e-02  2.9220462e-01  4.6741571e-02\n",
      "  1.1186883e+00  4.0233135e-06  9.2280614e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3416170e-01 -1.1920929e-07 -2.9540002e-01\n",
      "  4.2698428e-01  0.0000000e+00  2.8278559e-01  2.8306198e-01\n",
      "  2.8823048e-01  3.0037966e-01  3.2102385e-01  3.5766265e-01\n",
      "  4.1878709e-01  5.2252233e-01  7.5270700e-01  1.0000000e+00]\n",
      "[ 4.9359515e-01 -8.3664447e-02  3.1540853e-01  5.1337443e-02\n",
      "  1.1184437e+00  4.7087669e-06  9.2334616e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3421201e-01 -1.7881393e-07 -2.3613048e-01\n",
      "  4.8292029e-01  0.0000000e+00  2.8476804e-01  2.8428474e-01\n",
      "  2.8947559e-01  3.0163783e-01  3.2236847e-01  3.6022249e-01\n",
      "  4.2245898e-01  5.2780235e-01  7.6290071e-01  1.0000000e+00]\n",
      "[ 4.4941181e-01 -8.8595554e-02  3.2658041e-01  6.1346956e-02\n",
      "  1.1171989e+00  1.5497208e-06  8.4559119e-01 -6.7452288e-01\n",
      "  0.0000000e+00 -8.3474344e-01 -1.7881393e-07 -1.6807652e-01\n",
      "  5.4255342e-01  0.0000000e+00  2.8719172e-01  2.8591824e-01\n",
      "  2.9113889e-01  3.0332974e-01  3.2485250e-01  3.6336389e-01\n",
      "  4.2685905e-01  5.3453451e-01  7.7135575e-01  1.0000000e+00]\n",
      "[ 0.39134035 -0.11643707  0.35198596  0.06397329  1.0894313  -0.3448124\n",
      "  0.96610653  1.0000001   0.         -0.82465345  0.13308525 -0.09479392\n",
      "  0.5898845   0.          0.28883854  0.28753126  0.29274565  0.3049969\n",
      "  0.32770643  0.3665561   0.43136773  0.5414799   0.7800496   1.        ]\n",
      "[ 3.3058596e-01 -1.2168130e-01  3.8301927e-01  6.3471533e-02\n",
      "  1.1297147e+00  5.2194780e-01  8.4965312e-01 -9.9999994e-01\n",
      "  0.0000000e+00 -8.2516617e-01  0.0000000e+00  3.7407875e-04\n",
      "  7.6381320e-01  0.0000000e+00  2.9031396e-01  2.8900003e-01\n",
      "  2.9419559e-01  3.0650753e-01  3.3046803e-01  3.7023956e-01\n",
      "  4.3571201e-01  5.4840583e-01  7.8866267e-01  1.0000000e+00]\n",
      "[ 0.26320517 -0.1350477   0.41082814  0.07498122  1.1025882  -0.33712327\n",
      "  0.9701929   1.          0.         -0.8261781   0.          0.11258644\n",
      "  0.89772254  0.          0.29218802  0.2908656   0.29604602  0.30843538\n",
      "  0.33377573  0.37468162  0.440831    0.5564643   0.7987474   1.        ]\n",
      "[ 1.9437304e-01 -1.3820451e-01  4.2228284e-01  8.6664297e-02\n",
      "  1.1001589e+00  3.6811829e-04  8.5739100e-01 -9.9996734e-01\n",
      "  0.0000000e+00 -8.2804579e-01 -1.2516975e-05  2.3655647e-01\n",
      "  9.8592681e-01  0.0000000e+00  2.9453197e-01  2.9317838e-01\n",
      "  2.9837078e-01  3.1164080e-01  3.3767143e-01  3.7982103e-01\n",
      "  4.4676423e-01  5.6608033e-01  8.0960441e-01  1.0000000e+00]\n",
      "[ 1.2510863e-01 -1.3909982e-01  4.2680144e-01  7.1787864e-02\n",
      "  1.0889207e+00 -8.7551415e-02  7.4956846e-01 -1.0000329e+00\n",
      "  0.0000000e+00 -8.2947356e-01  4.4107437e-06  3.6293107e-01\n",
      "  1.0137161e+00  0.0000000e+00  2.9614970e-01  2.9473978e-01\n",
      "  2.9995981e-01  3.1445271e-01  3.4071821e-01  3.8398597e-01\n",
      "  4.5155543e-01  5.7431591e-01  8.1818527e-01  1.0000000e+00]\n",
      "[ 0.03057575 -0.18910131  0.36111605  0.0827245   1.120475    0.411983\n",
      "  0.87356025  0.9999998   1.         -0.7980874   0.3855312   0.4837072\n",
      "  0.9999997   0.          0.29843915  0.296977    0.30223668  0.31783447\n",
      "  0.34465173  0.3887627   0.45707676  0.58330107  0.8279937   1.        ]\n",
      "[-0.05390644 -0.16930301  0.31935033  0.10461605  1.1203507   0.\n",
      "  1.0291493   1.2931706   1.         -0.74469906  0.6819285   0.56210244\n",
      "  0.6231253   0.          0.3018917   0.30037612  0.30569598  0.32238543\n",
      "  0.35012826  0.39491987  0.46500358  0.5943994   0.840641    1.        ]\n",
      "[-0.06433987 -0.04999368  0.23058937  0.1777866   1.1455477   0.01770499\n",
      "  0.96084523  0.00119801  1.         -0.7524203   0.11289136  0.640624\n",
      "  0.59973854  0.          0.30983898  0.3082726   0.3144424   0.33162063\n",
      "  0.36066976  0.40672827  0.4801507   0.61498845  0.86286646  1.        ]\n",
      "[-8.0439195e-02 -4.5167767e-02  2.0879298e-01  1.8092035e-01\n",
      "  1.1394304e+00 -1.8490463e-02  9.3515283e-01 -2.5894245e-04\n",
      "  0.0000000e+00 -6.8053067e-01  9.9904764e-01  5.6346840e-01\n",
      " -6.8621844e-01  0.0000000e+00  3.1774521e-01  3.1613889e-01\n",
      "  3.2312599e-01  3.4077862e-01  3.7110263e-01  4.1841751e-01\n",
      "  4.9511153e-01  6.3592374e-01  8.8428646e-01  1.0000000e+00]\n",
      "[-9.0917364e-02 -2.0591265e-02  2.0781229e-01  1.7119625e-01\n",
      "  1.1284537e+00 -1.6595694e-01  9.3490529e-01  3.3450127e-04\n",
      "  0.0000000e+00 -6.0151929e-01  9.9973381e-01  4.4778299e-01\n",
      " -1.0002018e+00  0.0000000e+00  3.2499060e-01  3.2334766e-01\n",
      "  3.3112511e-01  3.4921476e-01  3.8073462e-01  4.2920682e-01\n",
      "  5.0895554e-01  6.5533561e-01  9.0402168e-01  1.0000000e+00]\n",
      "[-0.08038584  0.02116145  0.20681998  0.16736935  1.1284319   0.\n",
      "  0.862758   -0.6029716   0.         -0.52880204  0.91713494  0.33029044\n",
      " -0.99999994  0.          0.33215004  0.3304709   0.33903444  0.35770717\n",
      "  0.39026108  0.43987754  0.5226518   0.674545    0.924882    1.        ]\n",
      "[-4.9148150e-02  6.2489290e-02  2.0755656e-01  1.6168226e-01\n",
      "  1.1277554e+00 -6.1771274e-04  7.4471414e-01 -1.0002198e+00\n",
      "  0.0000000e+00 -4.6876881e-01  7.8006619e-01  2.2064447e-01\n",
      " -1.0000161e+00  0.0000000e+00  3.3908567e-01  3.3737147e-01\n",
      "  3.4671348e-01  3.6619276e-01  3.9951891e-01  4.5024627e-01\n",
      "  5.3624350e-01  6.9110149e-01  9.4738138e-01  1.0000000e+00]\n",
      "[ 0.00882157  0.11583553  0.22373663  0.1492747   1.0571325  -0.8538257\n",
      "  0.7340372   0.01652206  1.         -0.46251583  0.09784609  0.10665977\n",
      " -0.9999998   0.          0.3455013   0.34380347  0.3538917   0.37416032\n",
      "  0.40818846  0.45999628  0.5491808   0.7062475   0.9685551   1.        ]\n",
      "[ 0.07612772  0.13502054  0.21683106  0.13865462  1.0112404  -0.48860824\n",
      "  0.58697003 -0.9999998   1.         -0.44952273  0.17450595 -0.0061779\n",
      " -1.0000001   0.          0.35153177  0.35036623  0.36064705  0.38166222\n",
      "  0.41631863  0.46992326  0.5613701   0.72051173  0.988381    1.        ]\n",
      "[ 0.13106419  0.11001888  0.20702462  0.11940772  0.99685365 -0.16236418\n",
      "  0.46927965 -1.          1.         -0.4021287   0.59872997 -0.12228334\n",
      " -1.          0.          0.35659367  0.3559351   0.36637935  0.3880569\n",
      "  0.4232454   0.47842374  0.57182306  0.7326976   1.          1.        ]\n",
      "[ 0.18839718  0.11466802  0.20746854  0.10205586  0.97223073 -0.28991884\n",
      "  0.353369   -1.0000001   0.         -0.35547447  0.60813206 -0.22801399\n",
      " -1.          0.          0.36081654  0.360662    0.37124494  0.39352322\n",
      "  0.42916194  0.4857414   0.58084184  0.74312454  1.          1.        ]\n",
      "[ 0.24702638  0.11728666  0.21025737  0.0788326   0.9519677  -0.22905707\n",
      "  0.2373839  -1.          0.         -0.31947118  0.45805728 -0.3437146\n",
      " -0.99999994  0.          0.36396733  0.36431518  0.3750053   0.39780676\n",
      "  0.43379125  0.49155372  0.5880358   0.75095296  1.          1.        ]\n",
      "[ 0.30703023  0.11990292  0.21561971  0.05373496  0.94384104 -0.0855155\n",
      "  0.1223619  -1.          0.         -0.30475405  0.1980527  -0.4541304\n",
      " -0.9999998   0.          0.36591953  0.3667756   0.37775335  0.40078044\n",
      "  0.4369946   0.4957044   0.593579    0.7564001   1.          1.        ]\n",
      "[ 0.36516926  0.1160562   0.22471625  0.02166761  0.97467595  0.41045082\n",
      "  0.01050174 -1.0000001   0.         -0.32874444 -0.28121114 -0.57082415\n",
      " -0.9999998   0.          0.36634454  0.36772102  0.37899038  0.40209287\n",
      "  0.43838906  0.49775124  0.59657586  0.7588274   1.          1.        ]\n",
      "[ 0.42160523  0.11236621  0.23891784 -0.01205752  1.0509434   0.9999996\n",
      " -0.09283125 -1.0000001   0.         -0.4048498  -0.9044283  -0.6865647\n",
      " -1.0000001   0.          0.3651296   0.36705235  0.37856552  0.4016421\n",
      "  0.43786275  0.49757445  0.59682065  0.7580505   1.          1.        ]\n",
      "[ 4.7712147e-01  1.0901776e-01  2.4942665e-01 -1.9643553e-02\n",
      "  1.1264876e+00  1.0000010e+00 -1.9669294e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -4.9567312e-01 -1.0000004e+00 -6.3490832e-01\n",
      " -2.7815500e-07  0.0000000e+00  3.6398262e-01  3.6618429e-01\n",
      "  3.7794951e-01  4.0097326e-01  4.3711367e-01  4.9716300e-01\n",
      "  5.9679979e-01  7.5690746e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 5.3353173e-01  1.1262987e-01  2.3788349e-01 -1.0081328e-02\n",
      "  1.1194594e+00  1.1920929e-07 -6.5253973e-02  1.0000001e+00\n",
      "  0.0000000e+00 -5.7722735e-01 -1.0000001e+00 -5.1281869e-01\n",
      "  9.9999976e-01  0.0000000e+00  3.6341363e-01  3.6561185e-01\n",
      "  3.7762094e-01  4.0059292e-01  4.3669906e-01  4.9711442e-01\n",
      "  5.9719402e-01  7.5631583e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 5.9537041e-01  1.2358308e-01  2.5066528e-01 -2.6694279e-02\n",
      "  1.1174179e+00  1.7881393e-07 -5.0948858e-02  7.6392017e-02\n",
      "  0.0000000e+00 -6.6456777e-01 -1.0773374e+00 -3.9133739e-01\n",
      "  1.0000001e+00  0.0000000e+00  3.6205018e-01  3.6424014e-01\n",
      "  3.7647411e-01  3.9934447e-01  4.3545935e-01  4.9610168e-01\n",
      "  5.9625012e-01  7.5414735e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 6.5906304e-01  1.2726381e-01  2.5438341e-01 -4.0906224e-02\n",
      "  1.1166794e+00  5.9604645e-08 -9.9149704e-02 -4.3565831e-01\n",
      "  0.0000000e+00 -7.4621379e-01 -1.0000001e+00 -2.6863694e-01\n",
      "  9.9999982e-01  0.0000000e+00  3.6001036e-01  3.6218798e-01\n",
      "  3.7462327e-01  3.9735010e-01  4.3362689e-01  4.9413186e-01\n",
      "  5.9412783e-01  7.5062096e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 7.20993519e-01  1.23770684e-01  2.53785878e-01 -5.83288446e-02\n",
      "  1.11540365e+00 -5.96046448e-08 -1.19866610e-01 -2.10083202e-01\n",
      "  0.00000000e+00 -8.27926755e-01 -9.99999881e-01 -1.45613313e-01\n",
      "  1.00000012e+00  0.00000000e+00  3.57136816e-01  3.59323293e-01\n",
      "  3.71898741e-01  3.94430697e-01  4.30755109e-01  4.90962863e-01\n",
      "  5.90522826e-01  7.45408595e-01  1.00000000e+00  1.00000000e+00]\n",
      "[ 0.7727084   0.10340337  0.23203787 -0.06965657  1.1149594   0.\n",
      " -0.17094898 -0.4494928   0.         -0.8293568   0.         -0.11332309\n",
      "  0.24087663  0.          0.3537175   0.35611573  0.36857894  0.39088383\n",
      "  0.42714489  0.4869301   0.58582413  0.73904365  1.          1.        ]\n",
      "[ 8.1626463e-01  8.7000161e-02  2.2142443e-01 -9.3742192e-02\n",
      "  1.1093127e+00 -2.3841858e-07 -4.1356444e-02  9.9999982e-01\n",
      "  0.0000000e+00 -8.3088040e-01  0.0000000e+00 -1.8554604e-01\n",
      " -9.7021937e-01  1.0000000e+00  3.4916666e-01  3.5175312e-01\n",
      "  3.6406365e-01  3.8607243e-01  4.2209971e-01  4.8123699e-01\n",
      "  5.7906157e-01  7.3037010e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 8.58352184e-01  8.44277740e-02  2.24856511e-01 -1.15758926e-01\n",
      "  1.10518062e+00  4.17232513e-07  8.77959728e-02  1.00000012e+00\n",
      "  0.00000000e+00 -8.29858720e-01  0.00000000e+00 -2.33083606e-01\n",
      " -7.57970154e-01  1.00000000e+00  3.43504459e-01  3.46270740e-01\n",
      "  3.58389378e-01  3.80033225e-01  4.15682912e-01  4.73964125e-01\n",
      "  5.70351779e-01  7.19460785e-01  9.85882461e-01  1.00000000e+00]\n",
      "[ 9.0088105e-01  8.4913641e-02  2.2993216e-01 -1.3603519e-01\n",
      "  1.0996192e+00 -3.5762787e-07  2.1761465e-01  9.9999982e-01\n",
      "  0.0000000e+00 -8.3096880e-01  0.0000000e+00 -3.4998131e-01\n",
      " -9.9999994e-01  0.0000000e+00  3.3695376e-01  3.3989486e-01\n",
      "  3.5179040e-01  3.7301415e-01  4.0817410e-01  4.6543452e-01\n",
      "  5.6009495e-01  7.0676792e-01  9.6759558e-01  1.0000000e+00]\n",
      "[ 0.93145835  0.0607179   0.23932432 -0.15358216  1.1286858   0.44663236\n",
      "  0.3520019   1.          0.         -0.8316867   0.         -0.3820169\n",
      " -0.28027543  0.          0.32957253  0.3326919   0.34433535  0.365087\n",
      "  0.39966518  0.4557583   0.5484357   0.6924253   0.9477845   1.        ]\n",
      "[ 9.6707356e-01  7.1026176e-02  2.3511568e-01 -1.5572649e-01\n",
      "  1.1244322e+00  3.5762787e-07  4.8008239e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3259469e-01  0.0000000e+00 -4.6049774e-01\n",
      " -1.0310153e+00  1.0000000e+00  3.2208014e-01  3.2537034e-01\n",
      "  3.3675081e-01  3.5703060e-01  3.9100200e-01  4.4590092e-01\n",
      "  5.3654569e-01  6.7784464e-01  9.2780596e-01  1.0000000e+00]\n",
      "[ 9.9846947e-01  6.2941305e-02  2.3633200e-01 -1.7293990e-01\n",
      "  1.1218432e+00 -2.9802322e-08  6.1666346e-01  1.0788496e+00\n",
      "  0.0000000e+00 -8.3441210e-01  0.0000000e+00 -4.7842860e-01\n",
      " -5.5113077e-01  1.0000000e+00  3.1368878e-01  3.1714317e-01\n",
      "  3.2821551e-01  3.4798130e-01  3.8122988e-01  4.3476647e-01\n",
      "  5.2308172e-01  6.6145605e-01  9.0535635e-01  1.0000000e+00]\n",
      "[ 1.0225785e+00  4.8031762e-02  2.3367429e-01 -1.7875236e-01\n",
      "  1.1191850e+00  2.9802322e-08  7.5541091e-01  1.1193004e+00\n",
      "  0.0000000e+00 -8.3462083e-01  0.0000000e+00 -5.4097152e-01\n",
      " -5.1055539e-01  1.0000000e+00  3.0524263e-01  3.0870911e-01\n",
      "  3.1946680e-01  3.3870572e-01  3.7119809e-01  4.2333061e-01\n",
      "  5.0924081e-01  6.4465362e-01  8.8234222e-01  1.0000000e+00]\n",
      "[ 1.0410694e+00  3.6812648e-02  2.3060021e-01 -1.8535472e-01\n",
      "  1.1182183e+00 -1.4901161e-08  8.8731837e-01  1.0831558e+00\n",
      "  0.0000000e+00 -8.3490628e-01  0.0000000e+00 -6.0276091e-01\n",
      " -4.8242161e-01  1.0000000e+00  2.9659912e-01  2.9996744e-01\n",
      "  3.1040028e-01  3.2909319e-01  3.6078566e-01  4.1145483e-01\n",
      "  4.9485430e-01  6.2723649e-01  8.5848874e-01  1.0000000e+00]\n",
      "[ 1.0244021e+00 -3.2442492e-02  2.0329392e-01 -9.6789405e-02\n",
      "  1.1186225e+00  1.8653274e-04  9.4895267e-01  5.1248664e-01\n",
      "  0.0000000e+00 -8.3490986e-01  4.9799681e-05 -6.1713314e-01\n",
      " -1.4065762e-01  1.0000000e+00  2.9204258e-01  2.9535916e-01\n",
      "  3.0560982e-01  3.2401428e-01  3.5541975e-01  4.0538445e-01\n",
      "  4.8760989e-01  6.1807001e-01  8.4591401e-01  1.0000000e+00]\n",
      "[ 9.98966634e-01 -5.08395992e-02  2.18221173e-01 -3.40968333e-02\n",
      "  1.12285852e+00 -1.20857358e-03  9.34906721e-01  0.00000000e+00\n",
      "  0.00000000e+00 -8.34080875e-01  1.32620335e-05 -6.12188697e-01\n",
      "  5.01606055e-02  1.00000000e+00  2.90402949e-01  2.93700904e-01\n",
      "  3.03866655e-01  3.22166115e-01  3.53707165e-01  4.03537124e-01\n",
      "  4.85604942e-01  6.14798307e-01  8.41389120e-01  1.00000000e+00]\n",
      "[ 9.7133070e-01 -5.5299994e-02  2.2840734e-01 -2.9212898e-02\n",
      "  1.1227100e+00 -1.6652346e-03  9.3490684e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3273476e-01  1.2606382e-05 -6.0437679e-01\n",
      "  7.9941988e-02  1.0000000e+00  2.8900149e-01  2.9228354e-01\n",
      "  3.0237120e-01  3.2058060e-01  3.5230574e-01  4.0205449e-01\n",
      "  4.8406330e-01  6.1200964e-01  8.3752149e-01  1.0000000e+00]\n",
      "[ 9.4322568e-01 -5.6238923e-02  2.4080211e-01 -2.8225331e-02\n",
      "  1.1226561e+00 -3.1143427e-05  9.3490613e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3275622e-01  1.0132790e-06 -5.9370530e-01\n",
      "  8.3343089e-02  1.0000000e+00  2.8764126e-01  2.9090786e-01\n",
      "  3.0091718e-01  3.1919828e-01  3.5097399e-01  4.0065941e-01\n",
      "  4.8264545e-01  6.0930640e-01  8.3376765e-01  1.0000000e+00]\n",
      "[ 9.1370553e-01 -5.9071988e-02  2.5079140e-01 -2.8393889e-02\n",
      "  1.1226006e+00  1.3619661e-05  9.3490565e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3277971e-01 -4.4703484e-07 -5.8111966e-01\n",
      "  9.8707139e-02  1.0000000e+00  2.8626770e-01  2.8950530e-01\n",
      "  2.9944789e-01  3.1798562e-01  3.4964061e-01  3.9926836e-01\n",
      "  4.8124531e-01  6.0657817e-01  8.2997704e-01  1.0000000e+00]\n",
      "[ 8.82502139e-01 -6.24421798e-02  2.62367457e-01 -2.68721208e-02\n",
      "  1.12253833e+00  6.58631325e-06  9.34906721e-01  0.00000000e+00\n",
      "  0.00000000e+00 -8.32794130e-01 -2.08616257e-07 -5.65902948e-01\n",
      "  1.20010674e-01  1.00000000e+00  2.84959227e-01  2.88149148e-01\n",
      "  2.98045158e-01  3.16862375e-01  3.48405540e-01  3.97997379e-01\n",
      "  4.80008274e-01  6.03983462e-01  8.26366067e-01  1.00000000e+00]\n",
      "[ 8.4955853e-01 -6.5926336e-02  2.7461502e-01 -2.5497992e-02\n",
      "  1.1224697e+00  1.6093254e-06  9.3490672e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3280486e-01 -5.9604645e-08 -5.4785800e-01\n",
      "  1.4282581e-01  1.0000000e+00  2.8370833e-01  2.8684959e-01\n",
      "  2.9670095e-01  3.1582090e-01  3.4726042e-01  3.9683729e-01\n",
      "  4.7872099e-01  6.0150737e-01  8.2291394e-01  1.0000000e+00]\n",
      "[ 8.1492603e-01 -6.9308408e-02  2.8691265e-01 -2.5247488e-02\n",
      "  1.1223935e+00 -7.1525574e-07  9.3490684e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3281684e-01  2.9802322e-08 -5.2708197e-01\n",
      "  1.6479886e-01  1.0000000e+00  2.8246146e-01  2.8555253e-01\n",
      "  2.9535937e-01  3.1480074e-01  3.4624544e-01  3.9571142e-01\n",
      "  4.7693831e-01  5.9904164e-01  8.1947297e-01  1.0000000e+00]\n",
      "[ 7.7826399e-01 -7.3372915e-02  3.0142671e-01 -2.2940798e-02\n",
      "  1.1223106e+00  7.5697899e-06  9.3490684e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3282608e-01 -2.3841858e-07 -5.0261426e-01\n",
      "  1.9460654e-01  1.0000000e+00  2.8131384e-01  2.8435391e-01\n",
      "  2.9411957e-01  3.1391257e-01  3.4541416e-01  3.9483812e-01\n",
      "  4.7533259e-01  5.9677905e-01  8.1630588e-01  1.0000000e+00]\n",
      "[ 7.4132371e-01 -7.4022777e-02  3.0100685e-01 -1.5465437e-02\n",
      "  1.1212442e+00  1.8775463e-06  8.4911084e-01 -7.3642701e-01\n",
      "  0.0000000e+00 -8.3282018e-01 -2.3841858e-07 -4.7472596e-01\n",
      "  2.2467895e-01  1.0000000e+00  2.8049466e-01  2.8350866e-01\n",
      "  2.9344276e-01  3.1341979e-01  3.4502155e-01  3.9469627e-01\n",
      "  4.7430229e-01  5.9522253e-01  8.1410348e-01  1.0000000e+00]\n",
      "[ 0.69735944 -0.08819208  0.32182142 -0.01579471  1.0831804  -0.4747703\n",
      "  0.9694232   1.          0.         -0.83314174  0.         -0.4380592\n",
      "  0.2906077   1.          0.27961785  0.28262246  0.29296932  0.3129141\n",
      "  0.34462583  0.39457378  0.47323045  0.59323174  0.81179696  1.        ]\n",
      "[ 0.64960617 -0.09549519  0.34751582 -0.01700668  1.1006598   0.08628863\n",
      "  0.93490684  0.          0.         -0.83335215  0.         -0.39560628\n",
      "  0.33571896  1.          0.27861625  0.28161007  0.29239932  0.3123053\n",
      "  0.3441287   0.3943594   0.47198227  0.59073365  0.8091549   1.        ]\n",
      "[ 6.0257620e-01 -9.4148442e-02  3.7216523e-01  8.0101768e-04\n",
      "  1.1004808e+00 -7.7950954e-04  9.3490684e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3343059e-01  3.2305717e-05 -3.4776449e-01\n",
      "  3.9226314e-01  1.0000000e+00  2.7848396e-01  2.8147635e-01\n",
      "  2.9278299e-01  3.1271511e-01  3.4477368e-01  3.9550447e-01\n",
      "  4.7219193e-01  5.8985025e-01  8.0938959e-01  1.0000000e+00]\n",
      "[ 5.5245763e-01 -1.0032392e-01  3.9386660e-01  5.3345584e-03\n",
      "  1.1003449e+00  2.3007393e-05  9.3490696e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3351886e-01 -8.9406967e-07 -2.9283798e-01\n",
      "  4.4244123e-01  1.0000000e+00  2.7854174e-01  2.8176680e-01\n",
      "  2.9339841e-01  3.1355053e-01  3.4570432e-01  3.9700601e-01\n",
      "  4.7273922e-01  5.8929205e-01  8.1092566e-01  1.0000000e+00]\n",
      "[ 4.9864930e-01 -1.0771498e-01  4.1710526e-01  1.0616272e-02\n",
      "  1.1001952e+00  1.5974045e-05  9.3490672e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3366644e-01 -6.5565109e-07 -2.2951996e-01\n",
      "  5.1037043e-01  0.0000000e+00  2.7882254e-01  2.8261584e-01\n",
      "  2.9428250e-01  3.1469414e-01  3.4696516e-01  3.9891779e-01\n",
      "  4.7368017e-01  5.8911908e-01  8.1321287e-01  1.0000000e+00]\n",
      "[ 4.4097152e-01 -1.1535454e-01  4.3815899e-01  1.6761070e-02\n",
      "  1.0996559e+00  2.0265579e-06  9.1753316e-01 -1.5415721e-01\n",
      "  0.0000000e+00 -8.3329040e-01 -2.9802322e-07 -1.5843785e-01\n",
      "  5.8680409e-01  0.0000000e+00  2.7937225e-01  2.8376576e-01\n",
      "  2.9547986e-01  3.1618389e-01  3.4896162e-01  4.0118337e-01\n",
      "  4.7477943e-01  5.8942348e-01  8.1637913e-01  1.0000000e+00]\n",
      "[ 3.6973041e-01 -1.4264005e-01  4.6653622e-01  1.0819252e-02\n",
      "  1.1612046e+00  7.9231620e-01  8.0184448e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -8.3386141e-01 -2.3841858e-07 -6.2350750e-02\n",
      "  7.5263959e-01  0.0000000e+00  2.7979040e-01  2.8459904e-01\n",
      "  2.9642007e-01  3.1733298e-01  3.5067582e-01  4.0191260e-01\n",
      "  4.7526494e-01  5.8901024e-01  8.1859279e-01  1.0000000e+00]\n",
      "[ 3.0071187e-01 -1.4249611e-01  4.8624682e-01  2.6694875e-02\n",
      "  1.1349087e+00  5.9604645e-08  8.5592651e-01 -4.0504377e-02\n",
      "  0.0000000e+00 -8.3491033e-01  0.0000000e+00  3.9137602e-02\n",
      "  8.2822222e-01  0.0000000e+00  2.8153789e-01  2.8637657e-01\n",
      "  2.9848856e-01  3.1954741e-01  3.5360050e-01  4.0391612e-01\n",
      "  4.7721630e-01  5.9109122e-01  8.2370079e-01  1.0000000e+00]\n",
      "[ 2.1920639e-01 -1.6294666e-01  5.0748897e-01  2.6480835e-02\n",
      "  1.1126697e+00 -2.7380002e-01  9.7696793e-01  9.9999946e-01\n",
      "  0.0000000e+00 -8.3490688e-01  2.3841858e-07  1.6234607e-01\n",
      "  9.9828291e-01  0.0000000e+00  2.8305501e-01  2.8791973e-01\n",
      "  3.0032158e-01  3.2154927e-01  3.5626283e-01  4.0558001e-01\n",
      "  4.7875619e-01  5.9359968e-01  8.3108258e-01  1.0000000e+00]\n",
      "[ 1.38028517e-01 -1.62100047e-01  5.11054575e-01  1.34225665e-02\n",
      "  1.12556958e+00 -6.98685646e-04  9.34906602e-01  0.00000000e+00\n",
      "  0.00000000e+00 -8.34906220e-01  1.25169754e-05  2.88733542e-01\n",
      "  1.02477419e+00  0.00000000e+00  2.83896834e-01  2.88886815e-01\n",
      "  3.01437289e-01  3.23177159e-01  3.58066440e-01  4.06303734e-01\n",
      "  4.79202569e-01  5.94703257e-01  8.36148441e-01  1.00000000e+00]\n",
      "[ 6.2079772e-02 -1.5199724e-01  5.1124811e-01  5.2955323e-03\n",
      "  1.1226668e+00  1.2773275e-04  8.2422394e-01 -9.9998850e-01\n",
      "  0.0000000e+00 -8.3490700e-01 -4.2319298e-06  4.1096246e-01\n",
      "  9.9946737e-01  0.0000000e+00  2.8440282e-01  2.8961417e-01\n",
      "  3.0219626e-01  3.2441953e-01  3.5880288e-01  4.0655968e-01\n",
      "  4.7873893e-01  5.9510773e-01  8.4006256e-01  1.0000000e+00]\n",
      "[-1.21233845e-02 -1.48707747e-01  5.15741050e-01 -1.69456049e-04\n",
      "  1.04161787e+00 -9.99974132e-01  1.06165695e+00  2.85485649e+00\n",
      "  1.00000000e+00 -8.34906995e-01 -7.15255737e-07  5.32422960e-01\n",
      "  9.99784052e-01  0.00000000e+00  2.84610003e-01  2.90039033e-01\n",
      "  3.02639574e-01  3.25324088e-01  3.58658582e-01  4.06141162e-01\n",
      "  4.77292299e-01  5.94885528e-01  8.42969000e-01  1.00000000e+00]\n",
      "[-0.1027237  -0.1753577   0.40487212  0.01936147  1.1863419   1.0726467\n",
      "  0.9348949   0.          1.         -0.8077983   0.24447113  0.64666927\n",
      "  0.9999997   0.          0.28583324  0.29131484  0.30426294  0.32707664\n",
      "  0.35971358  0.40707156  0.47769484  0.59660137  0.8457252   1.        ]\n",
      "[-0.09639673 -0.04681025  0.23129292  0.15914245  1.1521896   0.01820651\n",
      "  0.9358678  -0.0030038   1.         -0.82236576  0.22633442  0.6691185\n",
      "  0.0419873   1.          0.2947733   0.30042636  0.31400898  0.33755344\n",
      "  0.37039757  0.41886032  0.49061412  0.6138499   0.86974216  1.        ]\n",
      "[-0.09963615 -0.0081174   0.20921637  0.16976668  1.1352684  -0.00647154\n",
      "  0.9282913  -0.32089922  1.         -0.7376487   0.9966999   0.59329534\n",
      " -1.0020027   1.          0.30300587  0.30881682  0.32298252  0.34719983\n",
      "  0.38023797  0.42971915  0.502517    0.62973815  0.89186454  1.        ]\n",
      "[-8.4045179e-02  3.0900910e-02  2.2153705e-01  1.6192652e-01\n",
      "  1.1349072e+00 -5.7724118e-04  8.5543180e-01 -6.7548227e-01\n",
      "  1.0000000e+00 -6.5976894e-01  9.9974698e-01  4.8066956e-01\n",
      " -1.0001405e+00  0.0000000e+00  3.1097814e-01  3.1694195e-01\n",
      "  3.3168802e-01  3.5592565e-01  3.8974127e-01  4.4019234e-01\n",
      "  5.1396090e-01  6.4505821e-01  9.1332358e-01  1.0000000e+00]\n",
      "[-5.2161589e-02  6.3842259e-02  2.2290517e-01  1.5465753e-01\n",
      "  1.1342139e+00 -3.9464235e-04  7.3730373e-01 -1.0001396e+00\n",
      "  0.0000000e+00 -6.0249245e-01  7.2807932e-01  3.6373788e-01\n",
      " -1.0000190e+00  1.0000000e+00  3.1865859e-01  3.2476971e-01\n",
      "  3.4008211e-01  3.6427569e-01  3.9888465e-01  4.5026243e-01\n",
      "  5.2584618e-01  6.5978682e-01  9.3434334e-01  1.0000000e+00]\n",
      "[-2.5291737e-02  5.3828854e-02  2.2038545e-01  1.4112525e-01\n",
      "  1.1330080e+00 -2.9802322e-08  6.1986089e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -5.3768533e-01  8.2202101e-01  2.4678105e-01\n",
      " -1.0000001e+00  1.0000000e+00  3.2568893e-01  3.3207342e-01\n",
      "  3.4777796e-01  3.7190023e-01  4.0702543e-01  4.5911852e-01\n",
      "  5.3706592e-01  6.7427170e-01  9.5352614e-01  1.0000000e+00]\n",
      "[ 2.0922718e-03  5.4722972e-02  2.1906625e-01  1.2328907e-01\n",
      "  1.1319141e+00 -1.9788742e-05  5.0366533e-01 -1.0000067e+00\n",
      "  1.0000000e+00 -4.7313458e-01  8.4085965e-01  1.3872612e-01\n",
      " -1.0000006e+00  0.0000000e+00  3.3185828e-01  3.3854070e-01\n",
      "  3.5455111e-01  3.7856117e-01  4.1411802e-01  4.6655384e-01\n",
      "  5.4686850e-01  6.8714058e-01  9.7026747e-01  1.0000000e+00]\n",
      "[ 0.03060478  0.05709857  0.21817473  0.11019466  1.1155679  -0.17841217\n",
      "  0.38757563 -0.99999994  0.         -0.40094796  0.9173113   0.02359974\n",
      " -1.0000004   0.          0.33743465  0.34440044  0.36068794  0.38455954\n",
      "  0.42049348  0.4732076   0.5556968   0.6987485   0.98493004  1.        ]\n",
      "[ 0.07902542  0.09675721  0.22627707  0.09511816  1.084435   -0.37115812\n",
      "  0.2721904  -0.9999998   1.         -0.36428046  0.4861042  -0.08449125\n",
      " -0.99999994  0.          0.34237778  0.3496183   0.36615258  0.38983935\n",
      "  0.4260857   0.47899362  0.56346864  0.70899814  0.99758667  1.        ]\n",
      "[ 0.11866276  0.07930781  0.2194632   0.07394198  1.0754172  -0.08888099\n",
      "  0.15592778 -1.          1.         -0.3065406   0.7329339  -0.19996345\n",
      " -1.          0.          0.34629542  0.35378215  0.37017384  0.39397845\n",
      "  0.43044603  0.4834435   0.5695628   0.71707267  1.          1.        ]\n",
      "[ 0.14289117  0.04831681  0.20940778  0.04479039  1.1225905   0.59847164\n",
      "  0.04110926 -1.          0.         -0.22841746  1.0000002  -0.30687034\n",
      " -0.99999994  0.          0.34875676  0.3564506   0.37253925  0.39649597\n",
      "  0.43305394  0.48599038  0.5732141   0.7224926   1.          1.        ]\n",
      "[ 0.19252358  0.09920829  0.23547363  0.02512182  1.1207489   0.\n",
      " -0.07483327 -0.99999994  0.         -0.23174109 -0.02969581 -0.42431498\n",
      " -0.9999998   0.          0.3504638   0.35836488  0.37408474  0.39814085\n",
      "  0.43470252  0.4874538   0.57536495  0.7268988   1.          1.        ]\n",
      "[ 2.5128970e-01  1.1740386e-01  2.5025797e-01  9.7543903e-04\n",
      "  1.1192343e+00 -1.7881393e-07 -1.9029784e-01 -1.0000001e+00\n",
      "  0.0000000e+00 -2.8903642e-01 -6.8941325e-01 -5.4056537e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.5121495e-01  3.5918725e-01\n",
      "  3.7448046e-01  3.9849886e-01  4.3501678e-01  4.8743811e-01\n",
      "  5.7574564e-01  7.2883034e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 3.1368265e-01  1.2458775e-01  2.5737143e-01 -1.9174848e-02\n",
      "  1.1181762e+00  1.7881393e-07 -3.0534887e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -3.7287065e-01 -1.0000000e+00 -6.5502405e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.5109594e-01  3.5906550e-01\n",
      "  3.7389195e-01  3.9774331e-01  4.3419200e-01  4.8616740e-01\n",
      "  5.7461601e-01  7.2862071e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 3.73068154e-01  1.18112534e-01  2.62463659e-01 -2.57762391e-02\n",
      "  1.11634612e+00  1.19209290e-07 -4.21110153e-01 -1.00000000e+00\n",
      "  0.00000000e+00 -4.60308552e-01 -1.04317307e+00 -6.34907603e-01\n",
      "  1.98682155e-08  0.00000000e+00  3.50727201e-01  3.58688414e-01\n",
      "  3.73029470e-01  3.96695077e-01  4.32902753e-01  4.84662622e-01\n",
      "  5.73062062e-01  7.27832973e-01  1.00000000e+00  1.00000000e+00]\n",
      "[ 4.1897294e-01  9.1707140e-02  2.4561149e-01 -2.9788168e-02\n",
      "  1.1105254e+00 -5.9604645e-08 -2.9309893e-01  9.9999946e-01\n",
      "  0.0000000e+00 -5.4349613e-01 -1.0251887e+00 -5.1274490e-01\n",
      "  9.9999970e-01  0.0000000e+00  3.5002527e-01  3.5797057e-01\n",
      "  3.7184876e-01  3.9532006e-01  4.3112224e-01  4.8310941e-01\n",
      "  5.7103795e-01  7.2626722e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 4.6302083e-01  8.7968498e-02  2.4671832e-01 -4.8127607e-02\n",
      "  1.1052285e+00  2.9802322e-07 -1.6482711e-01  1.0000001e+00\n",
      "  0.0000000e+00 -6.2481475e-01 -9.9999994e-01 -3.9011133e-01\n",
      "  9.9999982e-01  0.0000000e+00  3.4845608e-01  3.5622936e-01\n",
      "  3.6975297e-01  3.9297757e-01  4.2830884e-01  4.8034701e-01\n",
      "  5.6761414e-01  7.2268838e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.52023906  0.11429984  0.2408087  -0.07902039  1.0605111  -0.4973489\n",
      " -0.01558661  1.1799954   0.         -0.704143   -0.95106834 -0.5052161\n",
      " -0.99999946  0.          0.34545332  0.35276902  0.36616126  0.3890584\n",
      "  0.42382392  0.47560778  0.5619107   0.7157799   0.9934415   1.        ]\n",
      "[ 0.5687814   0.09697556  0.255677   -0.08440785  1.0377382  -0.22990286\n",
      "  0.11221856  0.9999998   0.         -0.799391   -1.1823351  -0.3999684\n",
      "  0.8562768   0.          0.34219822  0.34902585  0.36227596  0.384821\n",
      "  0.41897982  0.4704811   0.55574465  0.70828974  0.98298603  1.        ]\n",
      "[ 0.60404986  0.0702007   0.27066338 -0.11751512  1.1149716   0.99999976\n",
      "  0.04428589 -0.6673216   0.         -0.8808172  -1.         -0.28105867\n",
      "  0.96433467  0.          0.33739382  0.34368116  0.3567284   0.37881824\n",
      "  0.41223142  0.4631584   0.5470224   0.69720757  0.96836364  1.        ]\n",
      "[ 6.2160689e-01  5.2588984e-02  2.3400271e-01 -1.0446600e-01\n",
      "  1.1195908e+00  2.6822090e-07  1.7761511e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3491939e-01  0.0000000e+00 -2.1915627e-01\n",
      "  9.9999952e-01  0.0000000e+00  3.3308047e-01  3.3892342e-01\n",
      "  3.5179004e-01  3.7348586e-01  4.0626335e-01  4.5663929e-01\n",
      "  5.3927726e-01  6.8725199e-01  9.5510381e-01  1.0000000e+00]\n",
      "[ 6.4559340e-01  4.9244002e-02  2.3496929e-01 -1.2172379e-01\n",
      "  1.1165931e+00 -2.6822090e-07  3.0514467e-01  9.9999982e-01\n",
      "  0.0000000e+00 -8.3490753e-01  0.0000000e+00 -2.9721379e-01\n",
      " -1.2642022e+00  1.0000000e+00  3.2796034e-01  3.3332324e-01\n",
      "  3.4595045e-01  3.6722234e-01  3.9928472e-01  4.4896510e-01\n",
      "  5.3018308e-01  6.7542726e-01  9.3950313e-01  1.0000000e+00]\n",
      "[ 6.6207737e-01  3.3978589e-02  2.3208363e-01 -1.3606326e-01\n",
      "  1.1151125e+00  2.5331974e-07  4.3036520e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3410579e-01  0.0000000e+00 -2.6492715e-01\n",
      " -3.7990227e-01  1.0000000e+00  3.2196841e-01  3.2684210e-01\n",
      "  3.3914050e-01  3.5999367e-01  3.9127946e-01  4.4008261e-01\n",
      "  5.1969302e-01  6.6157824e-01  9.2150789e-01  1.0000000e+00]\n",
      "[ 6.7273003e-01  2.1313636e-02  2.3230387e-01 -1.4421147e-01\n",
      "  1.1120334e+00 -1.7881393e-07  5.5474019e-01  9.9999994e-01\n",
      "  0.0000000e+00 -8.3414727e-01  0.0000000e+00 -3.0753434e-01\n",
      " -3.4770548e-01  1.0000000e+00  3.1568500e-01  3.2014155e-01\n",
      "  3.3210355e-01  3.5252401e-01  3.8301647e-01  4.3089917e-01\n",
      "  5.0885433e-01  6.4722979e-01  9.0291452e-01  1.0000000e+00]\n",
      "[ 6.7585003e-01  5.9775091e-03  2.3121586e-01 -1.4990753e-01\n",
      "  1.1109061e+00  1.3783574e-07  6.7786527e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3452016e-01  0.0000000e+00 -3.4431088e-01\n",
      " -2.9700324e-01  1.0000000e+00  3.0880523e-01  3.1316465e-01\n",
      "  3.2478070e-01  3.4475088e-01  3.7442881e-01  4.2133683e-01\n",
      "  4.9757650e-01  6.3225275e-01  8.8356793e-01  1.0000000e+00]\n",
      "[ 6.7112911e-01 -9.4930883e-03  2.2956929e-01 -1.5503931e-01\n",
      "  1.1097974e+00  3.3527613e-08  7.9957771e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3483440e-01  0.0000000e+00 -3.7397861e-01\n",
      " -2.4589401e-01  1.0000000e+00  3.0165732e-01  3.0591583e-01\n",
      "  3.1717783e-01  3.3668053e-01  3.6552659e-01  4.1140145e-01\n",
      "  4.8586893e-01  6.1664546e-01  8.6348403e-01  1.0000000e+00]\n",
      "[ 6.5517372e-01 -3.1970717e-02  2.2394957e-01 -1.5555300e-01\n",
      "  1.1099105e+00  6.7353249e-04  9.1998971e-01  1.0000719e+00\n",
      "  0.0000000e+00 -8.3490878e-01 -2.3514032e-05 -3.9571142e-01\n",
      " -1.7794426e-01  1.0000000e+00  2.9446355e-01  2.9862049e-01\n",
      "  3.0952844e-01  3.2856080e-01  3.5657591e-01  4.0140218e-01\n",
      "  4.7409046e-01  6.0091805e-01  8.4327853e-01  1.0000000e+00]\n",
      "[ 6.3544953e-01 -3.9372765e-02  2.1167405e-01 -1.4721061e-01\n",
      "  1.1098955e+00  1.2335181e-04  9.2013812e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490670e-01 -4.3213367e-06 -4.1040921e-01\n",
      " -1.2558819e-01  1.0000000e+00  2.8763503e-01  2.9169559e-01\n",
      "  3.0226842e-01  3.2085434e-01  3.4808326e-01  3.9191058e-01\n",
      "  4.6291173e-01  5.8598107e-01  8.2410187e-01  1.0000000e+00]\n",
      "[ 6.1066663e-01 -4.9514703e-02  2.2174725e-01 -1.4604202e-01\n",
      "  1.1098213e+00 -1.9106269e-04  9.2034805e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490592e-01  6.3180923e-06 -4.1895342e-01\n",
      " -7.5735390e-02  1.0000000e+00  2.8085265e-01  2.8481746e-01\n",
      "  2.9505143e-01  3.1319359e-01  3.3962548e-01  3.8248339e-01\n",
      "  4.5179760e-01  5.7119673e-01  8.0501878e-01  1.0000000e+00]\n",
      "[ 5.8157194e-01 -5.8191881e-02  2.3289897e-01 -1.4612727e-01\n",
      "  1.1096880e+00 -4.4703484e-07  9.2059720e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3262277e-01  2.9253453e-02 -4.2517436e-01\n",
      " -5.4439526e-02  1.0000000e+00  2.7405924e-01  2.7792814e-01\n",
      "  2.8781727e-01  3.0544293e-01  3.3113346e-01  3.7304127e-01\n",
      "  4.4065541e-01  5.5643576e-01  7.8558266e-01  1.0000000e+00]\n",
      "[ 5.4818940e-01 -6.6902310e-02  2.7062395e-01 -3.9459962e-02\n",
      "  1.1091698e+00 -5.0073266e-03  9.2085171e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3321697e-01  2.1964312e-04 -3.9942563e-01\n",
      "  2.7861297e-01  1.0000000e+00  2.7228573e-01  2.7603281e-01\n",
      "  2.8582326e-01  3.0303347e-01  3.2852134e-01  3.7058231e-01\n",
      "  4.3755397e-01  5.5349213e-01  7.8037363e-01  1.0000000e+00]\n",
      "[ 5.0963026e-01 -7.7107087e-02  3.0074948e-01  6.0066227e-03\n",
      "  1.1091967e+00  4.6431124e-03  9.2154789e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3295178e-01 -1.9451976e-04 -3.5304093e-01\n",
      "  3.2060602e-01  0.0000000e+00  2.7261636e-01  2.7622157e-01\n",
      "  2.8601873e-01  3.0287319e-01  3.2834759e-01  3.7105086e-01\n",
      "  4.3781015e-01  5.5556273e-01  7.8104115e-01  1.0000000e+00]\n",
      "[ 4.6784800e-01 -8.3579093e-02  3.2518473e-01  9.9034393e-03\n",
      "  1.1089368e+00 -2.7757883e-04  9.2204297e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3280063e-01  9.1791153e-06 -3.0214059e-01\n",
      "  4.1875997e-01  1.0000000e+00  2.7313977e-01  2.7659369e-01\n",
      "  2.8640401e-01  3.0288172e-01  3.2835683e-01  3.7178823e-01\n",
      "  4.3835425e-01  5.5818564e-01  7.8197455e-01  1.0000000e+00]\n",
      "[ 4.2233461e-01 -9.1069125e-02  3.5043514e-01  1.3974300e-02\n",
      "  1.1086447e+00 -2.7656555e-05  9.2267191e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3275527e-01  6.5565109e-07 -2.4354577e-01\n",
      "  4.7659862e-01  0.0000000e+00  2.7384931e-01  2.7714187e-01\n",
      "  2.8697166e-01  3.0305004e-01  3.2894087e-01  3.7278518e-01\n",
      "  4.3917468e-01  5.6134999e-01  7.8338194e-01  1.0000000e+00]\n",
      "[ 3.7303776e-01 -9.8661736e-02  3.7348455e-01  1.8931486e-02\n",
      "  1.1037881e+00 -5.6456864e-02  9.2346239e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3281130e-01 -5.9604645e-08 -1.7633677e-01\n",
      "  5.4460412e-01  0.0000000e+00  2.7466658e-01  2.7790651e-01\n",
      "  2.8757173e-01  3.0342439e-01  3.3009723e-01  3.7408954e-01\n",
      "  4.4048026e-01  5.6513619e-01  7.8537387e-01  1.0000000e+00]\n",
      "[ 3.19411725e-01 -1.07482426e-01  3.97234827e-01  2.50731688e-02\n",
      "  1.09208143e+00 -1.40562654e-01  9.24702406e-01  0.00000000e+00\n",
      "  0.00000000e+00 -8.33573878e-01 -5.96046448e-08 -9.68155861e-02\n",
      "  6.26503050e-01  0.00000000e+00  2.75679499e-01  2.78931379e-01\n",
      "  2.88165092e-01  3.04050446e-01  3.31584215e-01  3.75424474e-01\n",
      "  4.42798942e-01  5.69652200e-01  7.88069427e-01  1.00000000e+00]\n",
      "[ 0.24858974 -0.14173084  0.42841542  0.01361728  1.1619327   0.8923933\n",
      "  0.8081982  -1.          0.         -0.83399016  0.          0.0064137\n",
      "  0.82358545  0.          0.2760894   0.27934608  0.28809804  0.3039797\n",
      "  0.33235002  0.37593147  0.44415462  0.5720719   0.78909314  1.        ]\n",
      "[ 1.7008233e-01 -1.6258723e-01  4.4809029e-01  2.6709188e-02\n",
      "  1.1349071e+00  2.3841858e-07  9.8703647e-01  9.9999994e-01\n",
      "  0.0000000e+00 -8.1789607e-01  2.5229108e-01  1.0502672e-01\n",
      "  7.6934952e-01  0.0000000e+00  2.7722630e-01  2.8040737e-01\n",
      "  2.8876007e-01  3.0499905e-01  3.3402118e-01  3.7742943e-01\n",
      "  4.4676253e-01  5.7440835e-01  7.9211789e-01  1.0000000e+00]\n",
      "[ 9.6951209e-02 -1.4674971e-01  4.6758547e-01  4.2372707e-02\n",
      "  1.1326065e+00  3.0988455e-04  8.7372208e-01 -9.9997169e-01\n",
      "  0.0000000e+00 -8.1931651e-01 -1.1682510e-05  2.3063731e-01\n",
      "  1.0027841e+00  0.0000000e+00  2.7892467e-01  2.8159514e-01\n",
      "  2.8998324e-01  3.0716428e-01  3.3639246e-01  3.7969244e-01\n",
      "  4.5034018e-01  5.7788259e-01  7.9558289e-01  1.0000000e+00]\n",
      "[ 2.4267495e-02 -1.4609355e-01  4.7311255e-01  2.8366078e-02\n",
      "  1.0607157e+00 -9.0218389e-01  1.0350591e+00  2.5170090e+00\n",
      "  1.0000000e+00 -8.2140183e-01  1.7881393e-07  3.5701931e-01\n",
      "  1.0003039e+00  0.0000000e+00  2.7992016e-01  2.8206912e-01\n",
      "  2.9047132e-01  3.0854511e-01  3.3776462e-01  3.8099414e-01\n",
      "  4.5274821e-01  5.7993466e-01  7.9713887e-01  1.0000000e+00]\n",
      "[-0.04688053 -0.13990565  0.3810088   0.04254453  1.172913    0.8089115\n",
      "  0.93490136  0.          0.         -0.8152725   0.05435348  0.4781584\n",
      "  0.99999994  0.          0.28147998  0.28330073  0.29178134  0.31058064\n",
      "  0.33970153  0.38321325  0.45680207  0.5832671   0.8005799   1.        ]\n",
      "[-4.9653657e-02 -4.5164257e-02  2.5526550e-01  1.5288499e-01\n",
      "  1.1468314e+00  2.7405173e-02  9.5151436e-01  5.3576925e-03\n",
      "  0.0000000e+00 -8.3588320e-01 -5.2639842e-04  5.5985808e-01\n",
      "  6.3878161e-01  0.0000000e+00  2.8905460e-01  2.9092434e-01\n",
      "  3.0018148e-01  3.1952199e-01  3.4918880e-01  3.9460802e-01\n",
      "  4.7184318e-01  5.9924883e-01  8.2046080e-01  1.0000000e+00]\n",
      "[-6.6207826e-02 -4.7176961e-02  2.1602669e-01  1.8717277e-01\n",
      "  1.1405013e+00 -1.3902456e-02  9.3523061e-01 -9.6499920e-05\n",
      "  0.0000000e+00 -8.3537155e-01  1.8361211e-04  6.3160700e-01\n",
      "  7.3837137e-01  0.0000000e+00  2.9783136e-01  2.9975784e-01\n",
      "  3.0977809e-01  3.2973692e-01  3.6008227e-01  4.0757936e-01\n",
      "  4.8877466e-01  6.1781514e-01  8.4336030e-01  1.0000000e+00]\n",
      "[-0.08276565 -0.03273418  0.21777943  0.18413468  1.134564   -0.1080483\n",
      "  0.93490523  0.          0.         -0.8304908   0.07133161  0.68681216\n",
      "  0.30462882  1.          0.30614847  0.30812877  0.31889662  0.3394429\n",
      "  0.37042302  0.41991284  0.50490826  0.6354495   0.86500466  1.        ]\n",
      "[-0.0947552  -0.02365042  0.20785652  0.17906314  1.1221166  -0.16118784\n",
      "  0.9346018   0.          0.         -0.74440247  1.0000001   0.58641887\n",
      " -1.          1.          0.31425223  0.31628495  0.32777402  0.3487542\n",
      "  0.3804933   0.43191776  0.5205774   0.65261966  0.8860916   1.        ]\n",
      "[-8.0866732e-02  2.7880888e-02  2.1158825e-01  1.7047726e-01\n",
      "  1.1220332e+00 -1.4901161e-08  8.5441548e-01 -6.7120403e-01\n",
      "  0.0000000e+00 -6.9040471e-01  6.8564355e-01  4.6959561e-01\n",
      " -1.0000000e+00  0.0000000e+00  3.2206380e-01  3.2414705e-01\n",
      "  3.3635065e-01  3.5766453e-01  3.9021456e-01  4.4352260e-01\n",
      "  5.3359509e-01  6.6910470e-01  9.0643221e-01  1.0000000e+00]\n",
      "[-0.04995729  0.061896    0.21345237  0.16377321  1.1211286  -0.00121802\n",
      "  0.7362795  -1.0004395   0.         -0.64356077  0.6007084   0.35430187\n",
      " -1.0000272   0.          0.3296127   0.332013    0.34465328  0.36628485\n",
      "  0.39987016  0.4549667   0.5461908   0.6847048   0.92611736  1.        ]\n",
      "[-0.00668405  0.08650947  0.21579482  0.15405333  1.1047378  -0.1902008\n",
      "  0.6199802  -1.0000001   0.         -0.60437924  0.5222472   0.24459815\n",
      " -1.          0.          0.33672342  0.33957058  0.3524986   0.3744212\n",
      "  0.4092157   0.46651417  0.5580824   0.69942904  0.94466823  1.        ]\n",
      "[ 0.0509025   0.11516427  0.23255149  0.13858475  1.0542747  -0.6001341\n",
      "  0.50448275 -1.0000001   0.         -0.6283794  -0.2959      0.24311757\n",
      " -0.02513125  0.          0.34318757  0.34649783  0.3596896   0.3818572\n",
      "  0.41779953  0.47718906  0.5689574   0.7128858   0.9615522   1.        ]\n",
      "[ 0.11295009  0.12409204  0.22344786  0.12411401  1.0102696  -0.52949184\n",
      "  0.4007852  -0.98618525  1.         -0.61439925  0.18390054  0.12658727\n",
      " -1.          0.          0.3489756   0.35272393  0.3661527   0.38853157\n",
      "  0.4255218   0.48682037  0.57872146  0.7249643   0.9787231   1.        ]\n",
      "[ 0.1689798   0.11213131  0.21813974  0.10758679  0.9763929  -0.42052624\n",
      "  0.27925497 -1.0000001   1.         -0.582076    0.4317652   0.01745951\n",
      " -1.0000001   0.          0.35395312  0.358119    0.37164488  0.39429963\n",
      "  0.43222594  0.49523035  0.58722687  0.73501074  0.99502784  1.        ]\n",
      "[ 0.21639764  0.09496948  0.21068774  0.0890918   0.9578478  -0.2068485\n",
      "  0.16290599 -1.          0.         -0.5239762   0.7370422  -0.09752369\n",
      " -0.99999994  0.          0.35804227  0.36260098  0.37614372  0.39907268\n",
      "  0.43781063  0.5022945   0.59435207  0.74301     1.          1.        ]\n",
      "[ 0.26657522  0.10036088  0.21420604  0.06408682  0.9458367  -0.13764697\n",
      "  0.04682022 -1.          0.         -0.48675406  0.48897022 -0.20517969\n",
      " -0.99999994  0.          0.36095506  0.36589593  0.37941512  0.40254351\n",
      "  0.44194725  0.5076457   0.5995669   0.7487406   1.          1.        ]\n",
      "[ 0.32329628  0.11343792  0.22324716  0.03871977  0.93383044 -0.12625784\n",
      " -0.06908059 -1.          0.         -0.48416048  0.04043454 -0.32255924\n",
      " -0.9999998   0.          0.36287463  0.36803383  0.38148743  0.40489534\n",
      "  0.44467464  0.5111681   0.6029176   0.75224847  1.          1.        ]\n",
      "[ 0.37775955  0.10867252  0.23141441  0.00250789  0.9728448   0.5037917\n",
      " -0.18072915 -1.0000001   0.         -0.528188   -0.51876456 -0.43697417\n",
      " -0.9999998   0.          0.36327818  0.3684431   0.38177007  0.4054604\n",
      "  0.44529518  0.5115787   0.6034848   0.7524431   1.          1.        ]\n",
      "[ 0.43091702  0.10587807  0.2415762  -0.02969944  1.0503      1.0000006\n",
      " -0.28573418 -1.0000001   0.         -0.6123887  -1.0000001  -0.55120254\n",
      " -1.0000001   0.          0.3621688   0.36731794  0.38046238  0.40432385\n",
      "  0.44439235  0.5099068   0.6015799   0.7496897   1.          1.        ]\n",
      "[ 0.4738662   0.08552369  0.24803658 -0.02653016  1.1272041   1.0000005\n",
      " -0.31529868 -0.3637929   0.         -0.6938274  -1.0000002  -0.4396\n",
      "  0.90847045  0.          0.3611862   0.36632138  0.37928337  0.40333357\n",
      "  0.4437103   0.5084048   0.59987926  0.7471641   1.          1.        ]\n",
      "[ 5.2449334e-01  1.0110692e-01  2.3827130e-01 -2.4892595e-02\n",
      "  1.1210738e+00 -4.1723251e-07 -1.8560600e-01  9.9999994e-01\n",
      "  0.0000000e+00 -7.7528065e-01 -1.0000000e+00 -3.1685960e-01\n",
      "  1.0000001e+00  0.0000000e+00  3.6029691e-01  3.6541945e-01\n",
      "  3.7820926e-01  4.0244281e-01  4.4311988e-01  5.0703818e-01\n",
      "  5.9833550e-01  7.4484885e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 5.7353282e-01  9.7923592e-02  2.4079296e-01 -4.3458771e-02\n",
      "  1.1152979e+00 -4.1723251e-07 -5.5743933e-02  9.9999994e-01\n",
      "  0.0000000e+00 -8.5675007e-01 -9.9999988e-01 -1.9390404e-01\n",
      "  1.0000001e+00  0.0000000e+00  3.5852808e-01  3.6349162e-01\n",
      "  3.7621295e-01  4.0056109e-01  4.4141042e-01  5.0446326e-01\n",
      "  5.9535623e-01  7.4082947e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 6.0501552e-01  7.1022302e-02  2.2007547e-01 -5.2832972e-02\n",
      "  1.1151257e+00  4.7683716e-07  7.5158715e-02  1.0000001e+00\n",
      "  0.0000000e+00 -8.3491111e-01  0.0000000e+00 -1.7379367e-01\n",
      "  3.9640626e-01  0.0000000e+00  3.5627264e-01  3.6108601e-01\n",
      "  3.7372318e-01  3.9811781e-01  4.3901777e-01  5.0123703e-01\n",
      "  5.9159350e-01  7.3593730e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 6.3690376e-01  6.4719565e-02  2.2262281e-01 -6.6337064e-02\n",
      "  1.1113248e+00 -4.7683716e-07  2.0366418e-01  9.9999982e-01\n",
      "  0.0000000e+00 -8.3490920e-01  0.0000000e+00 -7.7480555e-02\n",
      "  7.9396361e-01  0.0000000e+00  3.5336459e-01  3.5801545e-01\n",
      "  3.7054515e-01  3.9494240e-01  4.3581024e-01  4.9711022e-01\n",
      "  5.8676302e-01  7.2976393e-01  9.9471420e-01  1.0000000e+00]\n",
      "[ 6.6606396e-01  5.9576407e-02  2.2399695e-01 -8.1658058e-02\n",
      "  1.1080556e+00 -4.1723251e-07  3.3189929e-01  9.9999976e-01\n",
      "  0.0000000e+00 -8.3490765e-01  0.0000000e+00 -1.3069606e-01\n",
      " -1.2479124e+00  1.0000000e+00  3.4972170e-01  3.5420081e-01\n",
      "  3.6659700e-01  3.9093870e-01  4.3166625e-01  4.9197435e-01\n",
      "  5.8073336e-01  7.2216833e-01  9.8459220e-01  1.0000000e+00]\n",
      "[ 6.97568238e-01  6.35680035e-02  2.27311239e-01 -1.09277815e-01\n",
      "  1.10512304e+00 -3.57627869e-07  4.59071636e-01  9.99999940e-01\n",
      "  0.00000000e+00 -8.31743658e-01  0.00000000e+00 -1.27535939e-01\n",
      " -6.56491220e-01  1.00000000e+00  3.44675750e-01  3.48964989e-01\n",
      "  3.61177951e-01  3.85353893e-01  4.25736398e-01  4.84911263e-01\n",
      "  5.72413802e-01  7.11855173e-01  9.70951557e-01  1.00000000e+00]\n",
      "[ 7.2699225e-01  5.8665972e-02  2.3010021e-01 -1.2272248e-01\n",
      "  1.1017201e+00  4.4703484e-07  5.8541989e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3216476e-01  0.0000000e+00 -1.8283689e-01\n",
      " -4.7179231e-01  1.0000000e+00  3.3912352e-01  3.4321523e-01\n",
      "  3.5538867e-01  3.7919953e-01  4.1916671e-01  4.7715154e-01\n",
      "  5.6326717e-01  7.0055640e-01  9.5603210e-01  1.0000000e+00]\n",
      "[ 7.5225645e-01  5.0284371e-02  2.3145233e-01 -1.3392502e-01\n",
      "  1.0993621e+00  2.0861626e-07  7.1004581e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3266079e-01  0.0000000e+00 -2.3623049e-01\n",
      " -4.5195079e-01  1.0000000e+00  3.3304045e-01  3.3692735e-01\n",
      "  3.4906039e-01  3.7244722e-01  4.1192269e-01  4.6866220e-01\n",
      "  5.5325383e-01  6.8822771e-01  9.3874866e-01  1.0000000e+00]\n",
      "[ 0.76330876  0.02174916  0.23877104 -0.15059319  1.1373767   0.50125307\n",
      "  0.81244826  0.8204844   0.         -0.83334213  0.         -0.2818395\n",
      " -0.3857113   0.          0.32612303  0.32982665  0.34189218  0.36479875\n",
      "  0.4036792   0.45907193  0.5419348   0.6743347   0.91833454  1.        ]\n",
      "[ 7.7373236e-01  1.9941112e-02  2.3166293e-01 -1.5103558e-01\n",
      "  1.1349077e+00  5.9604645e-08  9.7504699e-01  1.3207715e+00\n",
      "  0.0000000e+00 -8.3467239e-01  0.0000000e+00 -3.2582211e-01\n",
      " -3.7474009e-01  0.0000000e+00  3.1909627e-01  3.2272011e-01\n",
      "  3.3471116e-01  3.5713661e-01  3.9540896e-01  4.4947255e-01\n",
      "  5.3060275e-01  6.6043931e-01  8.9788383e-01  1.0000000e+00]\n",
      "[ 7.8957546e-01  2.5746606e-02  2.1862260e-01 -1.4618126e-01\n",
      "  1.1351417e+00  4.4703484e-08  9.3492591e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3497030e-01  0.0000000e+00 -3.7361503e-01\n",
      " -3.8174632e-01  0.0000000e+00  3.1235963e-01  3.1590694e-01\n",
      "  3.2781720e-01  3.4978077e-01  3.8745305e-01  4.4026801e-01\n",
      "  5.1973373e-01  6.4713031e-01  8.7825036e-01  1.0000000e+00]\n",
      "[ 7.9653060e-01  1.3985690e-02  2.1233498e-01 -1.5087490e-01\n",
      "  1.1349083e+00  7.4505806e-09  9.1833615e-01 -1.4301236e-01\n",
      "  0.0000000e+00 -8.3490777e-01  0.0000000e+00 -4.1489279e-01\n",
      " -3.4411189e-01  0.0000000e+00  3.0530104e-01  3.0876821e-01\n",
      "  3.2057962e-01  3.4205827e-01  3.7907600e-01  4.3062121e-01\n",
      "  5.0833791e-01  6.3320416e-01  8.5763782e-01  1.0000000e+00]\n",
      "[ 8.0092037e-01  8.7908050e-03  1.9985995e-01 -1.4863169e-01\n",
      "  1.1342802e+00  3.7252903e-09  8.1270230e-01 -8.9528108e-01\n",
      "  0.0000000e+00 -8.3490789e-01  0.0000000e+00 -4.5301151e-01\n",
      " -3.1817317e-01  0.0000000e+00  2.9834902e-01  3.0173725e-01\n",
      "  3.1344241e-01  3.3444285e-01  3.7079969e-01  4.2111859e-01\n",
      "  4.9710944e-01  6.1950022e-01  8.3731085e-01  1.0000000e+00]\n",
      "[ 7.9254228e-01 -1.6683627e-02  1.9807069e-01 -1.5537167e-01\n",
      "  1.1340814e+00 -2.2351742e-08  7.6778185e-01 -3.7947598e-01\n",
      "  0.0000000e+00 -8.3490896e-01  0.0000000e+00 -4.8159623e-01\n",
      " -2.3918103e-01  0.0000000e+00  2.9105216e-01  2.9435751e-01\n",
      "  3.0593970e-01  3.2653987e-01  3.6207983e-01  4.1114274e-01\n",
      "  4.8531815e-01  6.0513180e-01  8.1594265e-01  1.0000000e+00]\n",
      "[ 7.7233213e-01 -4.0347699e-02  2.1167542e-01 -1.6322993e-01\n",
      "  1.1338692e+00 -1.1920929e-06  8.4270108e-01  6.1947495e-01\n",
      "  0.0000000e+00 -8.3490711e-01  1.4901161e-07 -5.0130963e-01\n",
      " -1.6758186e-01  0.0000000e+00  2.8336263e-01  2.8658065e-01\n",
      "  2.9803777e-01  3.1826439e-01  3.5290366e-01  4.0063080e-01\n",
      "  4.7289467e-01  5.8998418e-01  7.9438066e-01  1.0000000e+00]\n",
      "[ 7.4952734e-01 -4.5540225e-02  2.2214215e-01 -1.6658504e-01\n",
      "  1.1337292e+00  1.4901161e-07  9.2441452e-01  6.7791396e-01\n",
      "  0.0000000e+00 -8.3490747e-01 -2.9802322e-08 -5.1874864e-01\n",
      " -1.4942539e-01  0.0000000e+00  2.7550885e-01  2.7873120e-01\n",
      "  2.8997365e-01  3.0982950e-01  3.4355074e-01  3.8989538e-01\n",
      "  4.6020919e-01  5.7450414e-01  7.7356631e-01  1.0000000e+00]\n",
      "[ 7.2635055e-01 -4.6201065e-02  2.1982543e-01 -1.5978058e-01\n",
      "  1.1337415e+00  9.6678734e-05  9.2459667e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490807e-01 -3.1590462e-06 -5.2249551e-01\n",
      "  1.9250666e-01  1.0000000e+00  2.6796800e-01  2.7129522e-01\n",
      "  2.8223774e-01  3.0174857e-01  3.3459029e-01  3.7958887e-01\n",
      "  4.4803277e-01  5.5963165e-01  7.5356805e-01  1.0000000e+00]\n",
      "[ 7.0010877e-01 -5.3375036e-02  2.2363040e-01 -2.2181049e-02\n",
      "  1.1178539e+00 -1.3198373e-01  9.3120909e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3544546e-01  1.5199184e-05 -5.0240123e-01\n",
      "  2.2244716e-01  0.0000000e+00  2.6764166e-01  2.7119488e-01\n",
      "  2.8213334e-01  3.0199862e-01  3.3486754e-01  3.7918076e-01\n",
      "  4.4762549e-01  5.5867982e-01  7.5226200e-01  1.0000000e+00]\n",
      "[ 6.6636348e-01 -6.7465231e-02  2.0216727e-01  3.2214399e-02\n",
      "  1.1136363e+00  3.6646426e-03  8.1970632e-01 -9.9964970e-01\n",
      "  0.0000000e+00 -8.3537632e-01 -1.5729666e-04 -4.6199310e-01\n",
      "  2.8121001e-01  1.0000000e+00  2.6956481e-01  2.7336130e-01\n",
      "  2.8438714e-01  3.0479074e-01  3.3796355e-01  3.8185543e-01\n",
      "  4.5087677e-01  5.6209695e-01  7.5682479e-01  1.0000000e+00]\n",
      "[ 0.63021106 -0.07280946  0.22297864  0.04177235  1.0488138  -0.8011903\n",
      "  0.94116473  0.9999998   0.         -0.82319546  0.10988879 -0.45260513\n",
      "  0.30372426  1.          0.27147937  0.27554098  0.28665474  0.30763254\n",
      "  0.34054622  0.38452208  0.45412588  0.56546694  0.76132154  1.        ]\n",
      "[ 0.5896865  -0.08143449  0.2513063   0.04364746  1.0338055  -0.20834875\n",
      "  0.93490684  0.          0.         -0.814187    0.1217429  -0.3974105\n",
      "  0.3443409   1.          0.27343872  0.27779552  0.2890002   0.3106054\n",
      "  0.34296682  0.38725522  0.45737344  0.5688826   0.7677307   1.        ]\n",
      "[ 0.54393137 -0.0917351   0.27735117  0.05016664  1.0277731  -0.07207757\n",
      "  0.9349067   0.          0.         -0.8028079   0.14393863 -0.36109996\n",
      "  0.40024891  0.          0.27586368  0.2803638   0.29188126  0.31397587\n",
      "  0.34573498  0.3904675   0.46098045  0.5728073   0.77535075  1.        ]\n",
      "[ 0.49563405 -0.09655537  0.31174627  0.05241305  1.0684111   0.5231635\n",
      "  0.8172951  -1.0000001   0.         -0.80246216  0.00120389 -0.29270673\n",
      "  0.56581277  0.          0.27849704  0.28304014  0.2951787   0.31752294\n",
      "  0.34859642  0.39381146  0.4647041   0.5768243   0.78329176  1.        ]\n",
      "[ 0.44183332 -0.10796414  0.3445468   0.05710205  1.1440804   1.0000001\n",
      "  0.62808406 -1.6660681   0.         -0.8030248   0.         -0.20887399\n",
      "  0.6679787   0.          0.28135872  0.2859485   0.29877353  0.32138988\n",
      "  0.35169774  0.3974382   0.46873814  0.58114177  0.79192144  1.        ]\n",
      "[ 0.38139126 -0.12144587  0.36163107  0.0667866   1.134907   -0.08963424\n",
      "  0.7542602   1.0000001   0.         -0.803943    0.         -0.1204555\n",
      "  0.730632    0.          0.2846569   0.2893005   0.302862    0.32540432\n",
      "  0.35531124  0.40165192  0.47344673  0.586204    0.8018666   1.        ]\n",
      "[ 0.31699938 -0.12884247  0.3824798   0.06618809  1.1341596   0.\n",
      "  0.8471377   0.75906986  0.         -0.80419225  0.         -0.02072299\n",
      "  0.804964    0.          0.28792042  0.29290864  0.30694267  0.32865584\n",
      "  0.35886157  0.40579963  0.47806776  0.5911312   0.8081781   1.        ]\n",
      "[ 0.25332293 -0.12737493  0.40787143  0.07715525  1.1333289   0.\n",
      "  0.8472408  -0.01481946  0.         -0.8041701   0.          0.083588\n",
      "  0.85664773  0.          0.29171917  0.2973857   0.3116342   0.33247882\n",
      "  0.36308154  0.41066363  0.48335198  0.5970024   0.8152965   1.        ]\n",
      "[ 0.18508749 -0.13679159  0.4271534   0.08667251  1.1129613  -0.23992676\n",
      "  0.85217595  0.01059898  0.         -0.8057542   0.          0.20651066\n",
      "  0.97088045  0.          0.29592803  0.30231187  0.31679642  0.33673793\n",
      "  0.3678657   0.4159237   0.48874485  0.6035905   0.82332003  1.        ]\n",
      "[ 1.1581622e-01 -1.3909155e-01  4.2913410e-01  7.5631492e-02\n",
      "  1.1088502e+00 -2.6939511e-03  7.4355608e-01 -1.0002542e+00\n",
      "  0.0000000e+00 -8.0745727e-01  8.8512897e-05  3.3323121e-01\n",
      "  1.0120481e+00  0.0000000e+00  2.9971379e-01  3.0668637e-01\n",
      "  3.2060528e-01  3.4039092e-01  3.7198558e-01  4.2033425e-01\n",
      "  4.9328351e-01  6.0913211e-01  8.2997566e-01  1.0000000e+00]\n",
      "[ 0.03501185 -0.16224323  0.42810488  0.06618676  1.052116   -0.6942898\n",
      "  0.86850137  0.99999994  0.         -0.79441917  0.18381912  0.45770144\n",
      "  0.9999998   0.          0.30346575  0.3105256   0.32349977  0.34346405\n",
      "  0.37546912  0.42403278  0.49700934  0.6136838   0.8361651   1.        ]\n",
      "[-0.04539984 -0.16147628  0.43278083  0.05206052  1.0395802  -0.09722638\n",
      "  1.1030979   2.0870488   1.         -0.77987516  0.20115238  0.58165777\n",
      "  0.9999997   0.          0.30654988  0.31368145  0.3256855   0.34582514\n",
      "  0.37812814  0.42680642  0.49967375  0.616927    0.84176576  1.        ]\n",
      "[-1.3941664e-01 -1.8122770e-01  3.3507484e-01  7.9204552e-02\n",
      "  1.1710258e+00  1.0063571e+00  9.3488854e-01  1.0170490e-03\n",
      "  0.0000000e+00 -7.3734832e-01  4.1870964e-01  6.9460189e-01\n",
      "  9.9988127e-01  0.0000000e+00  3.1082338e-01  3.1805441e-01\n",
      "  3.2942739e-01  3.4988394e-01  3.8256609e-01  4.3163192e-01\n",
      "  5.0483310e-01  6.2325698e-01  8.5150963e-01  1.0000000e+00]\n",
      "[-1.4597198e-01 -5.0146271e-02  2.5213015e-01  1.6927858e-01\n",
      "  1.1460961e+00  1.1329800e-02  9.5097196e-01  2.3460388e-04\n",
      "  0.0000000e+00 -7.7471620e-01 -2.1307555e-01  8.2005185e-01\n",
      "  9.9925679e-01  0.0000000e+00  3.2002929e-01  3.2682136e-01\n",
      "  3.3847848e-01  3.5958433e-01  3.9308152e-01  4.4339088e-01\n",
      "  5.1793575e-01  6.3944268e-01  8.7525386e-01  1.0000000e+00]\n",
      "[-0.16148448 -0.04308215  0.23634967  0.17303614  1.1391575  -0.03853458\n",
      "  0.9351247   0.00597938  0.         -0.7024898   0.99561214  0.70400405\n",
      " -1.0030988   0.          0.32884574  0.33520547  0.34716162  0.36888885\n",
      "  0.40308353  0.45421046  0.530508    0.6562564   0.8954142   1.        ]\n",
      "[-0.17176647 -0.02015851  0.23685972  0.16661637  1.1268075  -0.18221807\n",
      "  0.93490505  0.          0.         -0.6249549   0.978587    0.5875909\n",
      " -1.          0.          0.33715463  0.34307158  0.3553083   0.37762234\n",
      "  0.41246507  0.4643322   0.5422799   0.673265    0.9125055   1.        ]\n",
      "[-1.6027579e-01  2.2983145e-02  2.4504364e-01  1.5039991e-01\n",
      "  1.1265852e+00 -3.7774444e-05  8.6230373e-01 -6.0842538e-01\n",
      "  0.0000000e+00 -6.2302095e-01  2.4379060e-02  5.9106755e-01\n",
      "  2.8362095e-02  0.0000000e+00  3.4483710e-01  3.5028157e-01\n",
      "  3.6278909e-01  3.8563421e-01  4.2105949e-01  4.7357571e-01\n",
      "  5.5302733e-01  6.8891031e-01  9.2801887e-01  1.0000000e+00]\n",
      "[-1.2768240e-01  6.5181434e-02  2.4477467e-01  1.3686435e-01\n",
      "  1.1256011e+00  2.1964312e-05  7.4432039e-01 -9.9999237e-01\n",
      "  0.0000000e+00 -6.2077665e-01  3.6670476e-02  4.7289813e-01\n",
      " -9.9999970e-01  0.0000000e+00  3.5195017e-01  3.5691667e-01\n",
      "  3.6972970e-01  3.9301184e-01  4.2896581e-01  4.8206037e-01\n",
      "  5.6289059e-01  7.0334411e-01  9.4219714e-01  1.0000000e+00]\n",
      "[-0.09233505  0.07065849  0.24372044  0.12531047  1.1181183  -0.07573396\n",
      "  0.627497   -1.          0.         -0.6095429   0.15655768  0.3444832\n",
      " -1.0996977   0.          0.35851905  0.36300367  0.37610108  0.39978445\n",
      "  0.43621597  0.48982197  0.57191736  0.71571535  0.9556081   1.        ]\n",
      "[-0.05528088  0.07402612  0.2457918   0.1027202   1.116063   -0.00583586\n",
      "  0.5113515  -1.          0.         -0.6166492  -0.0684365   0.22880119\n",
      " -1.          0.          0.36366853  0.36802608  0.38136807  0.40530556\n",
      "  0.44219124  0.49617442  0.5793061   0.7243717   0.9667182   1.        ]\n",
      "[-2.6415737e-02  5.7679981e-02  2.3978023e-01  9.4687968e-02\n",
      "  1.1143399e+00  2.9802322e-08  3.9549863e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -5.8607453e-01  3.9946631e-01  1.1284250e-01\n",
      " -9.9999982e-01  0.0000000e+00  3.6822116e-01  3.7263325e-01\n",
      "  3.8620278e-01  4.1032752e-01  4.4758984e-01  5.0197226e-01\n",
      "  5.8606362e-01  7.3227465e-01  9.7685063e-01  1.0000000e+00]\n",
      "[ 6.9552520e-03  6.6666394e-02  2.4332671e-01  7.1484379e-02\n",
      "  1.1126581e+00 -5.9604645e-08  2.7970415e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -5.7853299e-01  1.1324686e-01 -2.6997328e-03\n",
      " -1.0000001e+00  0.0000000e+00  3.7170756e-01  3.7616140e-01\n",
      "  3.8991842e-01  4.1416496e-01  4.5149606e-01  5.0632465e-01\n",
      "  5.9115380e-01  7.3816907e-01  9.8436326e-01  1.0000000e+00]\n",
      "[ 0.05459509  0.09520917  0.25346205  0.05276929  1.0770725  -0.42218637\n",
      "  0.17836863 -0.8774691   0.         -0.61276823 -0.40391135 -0.11831486\n",
      " -0.9999998   0.          0.37437433  0.37886015  0.39277533  0.4170908\n",
      "  0.45441526  0.5095713   0.5949525   0.7425016   0.989834    1.        ]\n",
      "[ 0.10950198  0.10969147  0.26082054  0.02489701  1.0471312  -0.3566547\n",
      "  0.06276214 -1.          0.         -0.6913052  -0.9332059  -0.23055685\n",
      " -0.9999998   0.          0.37575185  0.38029164  0.39427972  0.41858384\n",
      "  0.45579004  0.5110884   0.59673095  0.7443978   0.99212474  1.        ]\n",
      "[ 0.14273322  0.06629831  0.24638318 -0.001778    1.0869939   0.5144309\n",
      " -0.05169725 -1.0000001   0.         -0.73724836 -0.53445375 -0.3455392\n",
      " -1.0000001   0.          0.37580174  0.38039485  0.39438674  0.4186044\n",
      "  0.4555957   0.51085013  0.5964585   0.74384016  0.9926691   1.        ]\n",
      "[ 0.16200694  0.03827473  0.23744708 -0.02263407  1.1654824   1.0000001\n",
      " -0.14144206 -0.81706315  0.         -0.75974077 -0.24461825 -0.4617467\n",
      " -0.99999994  0.          0.3748239   0.37945524  0.3934126   0.41748467\n",
      "  0.4541841   0.5092498   0.5945947   0.7413761   0.9904867   1.        ]\n",
      "[ 1.9293086e-01  5.3558737e-02  2.5647232e-01 -1.5422157e-02\n",
      "  1.1349144e+00 -2.9802322e-08  2.4303555e-02  9.9999976e-01\n",
      "  0.0000000e+00 -8.4500957e-01 -1.0000000e+00 -3.3551526e-01\n",
      "  1.0000004e+00  0.0000000e+00  3.7449089e-01  3.7917259e-01\n",
      "  3.9311516e-01  4.1707867e-01  4.5352355e-01  5.0848877e-01\n",
      "  5.9371173e-01  7.4017197e-01  9.9034977e-01  1.0000000e+00]\n",
      "[ 2.02078179e-01  2.29080562e-02  2.44592175e-01 -1.38543025e-02\n",
      "  1.13403249e+00  2.83122063e-07  1.51317358e-01  1.00000024e+00\n",
      "  0.00000000e+00 -8.34911048e-01  0.00000000e+00 -2.27898598e-01\n",
      "  9.99999821e-01  0.00000000e+00  3.73957038e-01  3.78683478e-01\n",
      "  3.92524064e-01  4.16451544e-01  4.52637732e-01  5.07476807e-01\n",
      "  5.93106270e-01  7.39037037e-01  9.89546299e-01  1.00000000e+00]\n",
      "[ 0.2232825   0.04237516  0.24605998 -0.01179303  1.0729431  -0.74523723\n",
      "  0.27458876  1.0000001   0.         -0.828433    0.13135189 -0.10167122\n",
      "  1.0000001   0.          0.37349048  0.3782634   0.39200288  0.4158986\n",
      "  0.4518281   0.5065497   0.59268963  0.7380364   0.9889639   1.        ]\n",
      "[ 0.2467779   0.04694235  0.24718589 -0.02913914  1.0057051  -0.82526255\n",
      "  0.39781755  1.          0.         -0.83222455  0.          0.02468038\n",
      "  1.0000004   0.          0.37221462  0.37702376  0.39063445  0.41444674\n",
      "  0.4500524   0.5045411   0.59091693  0.735409    0.98589337  1.        ]\n",
      "[ 0.27102506  0.04888896  0.24690858 -0.04350308  0.9305907  -0.9307842\n",
      "  0.52116024  1.0000001   0.         -0.8349086   0.          0.1499731\n",
      "  0.9999997   0.          0.3702752   0.37509614  0.38855535  0.41206992\n",
      "  0.44746768  0.5016268   0.58800435  0.73141706  0.9807307   1.        ]\n",
      "[ 0.28286466  0.02375014  0.23782392 -0.05762758  0.87659055 -0.6652594\n",
      "  0.6432576   1.          0.         -0.8047485   0.43486363  0.27910352\n",
      "  0.9999997   0.          0.3676526   0.3724394   0.38572583  0.40890935\n",
      "  0.44403562  0.49776474  0.58387464  0.72598445  0.9733279   1.        ]\n",
      "[ 0.29044703  0.01529267  0.23567493 -0.08072468  0.8963924   0.25926304\n",
      "  0.526184   -0.9999998   0.         -0.76254904  0.5937132   0.23544085\n",
      " -1.9562925   1.          0.36391613  0.36865428  0.38173106  0.40452805\n",
      "  0.43927178  0.49242055  0.57787424  0.71831447  0.9624903   1.        ]\n",
      "[ 0.31663844  0.05301332  0.2463393  -0.11151696  0.88966805 -0.07741249\n",
      "  0.40959847 -1.          0.         -0.7464523   0.07031444  0.1830715\n",
      " -0.9999997   1.          0.35874024  0.363411    0.37622675  0.39855683\n",
      "  0.4327781   0.48514298  0.569468    0.7077462   0.9472433   1.        ]\n",
      "[ 0.3405743   0.04791306  0.24345683 -0.12393246  0.8765214  -0.13339528\n",
      "  0.29372895 -1.          0.         -0.7252005   0.27801937  0.06584334\n",
      " -1.          0.          0.35307658  0.3576736   0.3702124   0.39205176\n",
      "  0.4257056   0.47721624  0.5602419   0.69619864  0.93049043  1.        ]\n",
      "[ 0.35773522  0.03414514  0.24354237 -0.15056652  0.90857923  0.44231892\n",
      "  0.11585331 -1.5579087   0.         -0.70203906  0.31316543 -0.04904342\n",
      " -1.          0.          0.34613594  0.3505909   0.36286077  0.38414258\n",
      "  0.41711038  0.46758178  0.5488754   0.6820835   0.9098106   1.        ]\n",
      "[ 0.3661008   0.01671574  0.22908214 -0.16568689  0.9017772  -0.04159385\n",
      "  0.24093962  0.9999996   0.         -0.685787    0.22175029 -0.1663456\n",
      " -1.          0.          0.3384662   0.34275556  0.3547512   0.3754503\n",
      "  0.407667    0.45699584  0.53626895  0.6665131   0.88717145  1.        ]\n",
      "[ 0.3878422   0.04330117  0.2464376  -0.19439307  0.8889772  -0.13558774\n",
      "  0.36593908  1.          0.         -0.7397517  -0.62179476 -0.27871847\n",
      " -0.99999994  0.          0.32948828  0.33359125  0.34526616  0.36530122\n",
      "  0.39664257  0.44463706  0.5214876   0.64830184  0.86408377  1.        ]\n",
      "[ 0.40408224  0.03228456  0.26463422 -0.22225684  0.9669905   1.\n",
      "  0.2542613  -0.99999994  0.         -0.821175   -1.0000001  -0.27480543\n",
      " -0.00617254  0.          0.31918237  0.32307738  0.33438435  0.35367164\n",
      "  0.3840112   0.43047655  0.50449985  0.62782276  0.8376629   1.        ]\n",
      "[ 0.3947453  -0.01877798  0.24748032 -0.21508856  1.0450504   1.0000001\n",
      "  0.24936932 -0.08330242  0.         -0.82313615  0.         -0.15198565\n",
      "  0.9999997   0.          0.3091475   0.3128431   0.3237919   0.34235853\n",
      "  0.37172428  0.41670194  0.48794866  0.6082466   0.81197864  1.        ]\n",
      "[ 0.37329304 -0.04318346  0.23280372 -0.22341986  1.1042379   0.79925513\n",
      "  0.3792522   1.0000002   0.         -0.78907925  0.47502816 -0.13971043\n",
      " -1.548843    1.          0.29867557  0.3021712   0.3127465   0.3305807\n",
      "  0.35893437  0.40236297  0.47064957  0.5878901   0.7852863   1.        ]\n",
      "[ 3.7174922e-01 -3.0500782e-03  2.3732199e-01 -2.4804151e-01\n",
      "  1.1002414e+00  1.8626451e-08  5.7959795e-01  1.5957193e+00\n",
      "  0.0000000e+00 -7.9710501e-01 -9.4089322e-02 -2.0552504e-01\n",
      " -9.9999982e-01  0.0000000e+00  2.8704384e-01  2.9032552e-01\n",
      "  3.0048624e-01  3.1752646e-01  3.4476006e-01  3.8647225e-01\n",
      "  4.5140776e-01  5.6535101e-01  7.5574815e-01  1.0000000e+00]\n",
      "[ 3.77571434e-01  1.16068665e-02  2.67033607e-01 -2.55814701e-01\n",
      "  1.09873295e+00 -1.41561031e-07  7.02700257e-01  9.99999821e-01\n",
      "  0.00000000e+00 -8.78036261e-01 -9.99999881e-01 -9.79487896e-02\n",
      "  1.24413334e-01  1.00000000e+00  2.75068671e-01  2.78192490e-01\n",
      "  2.87831575e-01  3.04137021e-01  3.30220073e-01  3.70173097e-01\n",
      "  4.32229102e-01  5.42210102e-01  7.26079047e-01  1.00000000e+00]\n",
      "[ 0.35064727 -0.03908532  0.24972485 -0.26068836  1.1574361   0.6485926\n",
      "  0.72828305  0.17934881  0.         -0.83491534  0.         -0.18305898\n",
      " -0.30172324  1.          0.26288348  0.2658689   0.27498436  0.290562\n",
      "  0.31548086  0.35365057  0.41293374  0.5187792   0.6961868   1.        ]\n",
      "[ 3.1073466e-01 -8.2202226e-02  3.1362286e-01 -8.8200495e-02\n",
      "  1.1348686e+00 -5.1273108e-03  8.9796746e-01  9.9949676e-01\n",
      "  0.0000000e+00 -8.3533287e-01  2.1708012e-04 -1.4840317e-01\n",
      "  3.4227917e-01  0.0000000e+00  2.5891453e-01  2.6185489e-01\n",
      "  2.7061650e-01  2.8594673e-01  3.1045204e-01  3.4801334e-01\n",
      "  4.0635607e-01  5.1057172e-01  6.8528050e-01  1.0000000e+00]\n",
      "[ 2.5714073e-01 -1.0681626e-01  3.5394862e-01 -2.5947351e-02\n",
      "  1.1349086e+00  1.4464259e-03  1.0183465e+00  1.0001599e+00\n",
      "  0.0000000e+00 -8.3490807e-01 -8.8632107e-05 -8.0037594e-02\n",
      "  4.4512686e-01  1.0000000e+00  2.5749055e-01  2.6041472e-01\n",
      "  2.6886204e-01  2.8409287e-01  3.0841470e-01  3.4573486e-01\n",
      "  4.0381342e-01  5.0703841e-01  6.8017131e-01  1.0000000e+00]\n",
      "[ 2.0752512e-01 -9.9383421e-02  3.5680652e-01 -6.6945385e-03\n",
      "  1.1337978e+00  5.6964159e-04  9.0178990e-01 -9.9995130e-01\n",
      "  0.0000000e+00 -8.3073026e-01 -1.9371510e-05 -2.4604797e-03\n",
      "  5.7815796e-01  1.0000000e+00  2.5697502e-01  2.5989336e-01\n",
      "  2.6804933e-01  2.8323409e-01  3.0745628e-01  3.4466735e-01\n",
      "  4.0356463e-01  5.0520164e-01  6.7718840e-01  1.0000000e+00]\n",
      "[ 1.5231644e-01 -1.1103327e-01  3.8172475e-01  4.5534777e-03\n",
      "  1.0862495e+00 -5.7928813e-01  8.8732553e-01 -1.5483172e-01\n",
      "  0.0000000e+00 -8.3209217e-01 -5.9604645e-08  8.3090246e-02\n",
      "  6.9108695e-01  0.0000000e+00  2.5693247e-01  2.5961903e-01\n",
      "  2.6770726e-01  2.8285840e-01  3.0703506e-01  3.4420300e-01\n",
      "  4.0415570e-01  5.0418633e-01  6.7518675e-01  1.0000000e+00]\n",
      "[ 9.18192491e-02 -1.21971324e-01  3.98002535e-01  1.49383796e-02\n",
      "  1.02916908e+00 -6.47645593e-01  1.20773542e+00  2.82215214e+00\n",
      "  1.00000000e+00 -8.33965302e-01  2.38418579e-07  1.83684826e-01\n",
      "  8.09055984e-01  0.00000000e+00  2.57312268e-01  2.59699702e-01\n",
      "  2.67790467e-01  2.82918066e-01  3.07099849e-01  3.44283909e-01\n",
      "  4.05485630e-01  5.03920197e-01  6.74093306e-01  1.00000000e+00]\n",
      "[ 2.3161927e-02 -1.3455032e-01  4.0518007e-01  2.6519038e-02\n",
      "  1.0032640e+00 -5.2957147e-01  1.4631488e+00  2.3734763e+00\n",
      "  1.0000000e+00 -8.3088195e-01  5.9604645e-08  2.9514790e-01\n",
      "  9.4840878e-01  0.0000000e+00  2.5830254e-01  2.6040259e-01\n",
      "  2.6851523e-01  2.8365561e-01  3.0790043e-01  3.4518993e-01\n",
      "  4.0782362e-01  5.0482148e-01  6.7496544e-01  1.0000000e+00]\n",
      "[-0.06688172 -0.16557209  0.37280446  0.0278718   1.2662129   0.9979357\n",
      "  1.1026732   0.02418081  0.         -0.7985514   0.18262106  0.39544135\n",
      "  1.0000026   0.          0.25886658  0.26087412  0.26900145  0.28414705\n",
      "  0.30843675  0.34579462  0.40953496  0.5059248   0.6754698   1.        ]\n",
      "[-0.01744327 -0.03122039  0.23848887  0.116997    1.1799458   0.02579191\n",
      "  1.1089773   0.00635666  0.         -0.9049368  -0.47149885  0.5385946\n",
      "  0.99976444  0.          0.2668869   0.26895663  0.27732167  0.29293063\n",
      "  0.31797802  0.35649154  0.42360032  0.52235144  0.69464827  1.        ]\n",
      "[-1.5506929e-02 -3.5990879e-02  1.7062083e-01  1.6113123e-01\n",
      "  1.1620452e+00 -1.8843800e-02  1.0711834e+00 -4.5623383e-03\n",
      "  0.0000000e+00 -8.3728898e-01  3.3102930e-04  4.2052722e-01\n",
      "  5.8740848e-01  0.0000000e+00  2.7598286e-01  2.7812314e-01\n",
      "  2.8675956e-01  3.0289972e-01  3.2880506e-01  3.6903450e-01\n",
      "  4.3807679e-01  5.4082072e-01  7.1661818e-01  1.0000000e+00]\n",
      "[-1.6618429e-02 -2.2722762e-02  1.5031169e-01  1.6808863e-01\n",
      "  1.1469606e+00 -1.1809920e-01  9.9346447e-01  2.8616190e-04\n",
      "  0.0000000e+00 -8.3591968e-01  1.3188779e-02  5.1881891e-01\n",
      "  1.0000929e+00  0.0000000e+00  2.8426352e-01  2.8646803e-01\n",
      "  2.9535046e-01  3.1197417e-01  3.3866078e-01  3.8102990e-01\n",
      "  4.5063180e-01  5.5765718e-01  7.3848820e-01  1.0000000e+00]\n",
      "[-1.5332301e-02  2.7237267e-03  1.3842827e-01  1.7204130e-01\n",
      "  1.1248281e+00  5.5879354e-09  9.3372899e-01 -4.0476814e-01\n",
      "  0.0000000e+00 -7.7649003e-01  7.3371416e-01  4.4603878e-01\n",
      " -5.0432426e-01  1.0000000e+00  2.9227078e-01  2.9453737e-01\n",
      "  3.0365708e-01  3.2074833e-01  3.4819052e-01  3.9265254e-01\n",
      "  4.6276435e-01  5.7395172e-01  7.6397765e-01  1.0000000e+00]\n",
      "[ 3.0338597e-03  3.7000321e-02  1.3357970e-01  1.7464370e-01\n",
      "  1.1248821e+00  1.4901161e-08  8.4738761e-01 -7.4095696e-01\n",
      "  0.0000000e+00 -6.9755226e-01  1.0000002e+00  3.3645678e-01\n",
      " -1.0072309e+00  1.0000000e+00  3.0038136e-01  3.0271086e-01\n",
      "  3.1207129e-01  3.2963613e-01  3.5784361e-01  4.0441093e-01\n",
      "  4.7505829e-01  5.8855087e-01  7.8976083e-01  1.0000000e+00]\n",
      "[ 0.02444584  0.04293869  0.13391487  0.16773231  1.0449605  -1.0038469\n",
      "  0.9670159   0.99977523  0.         -0.61839074  1.0024593   0.2221312\n",
      " -0.9898746   1.          0.3081855   0.3105755   0.32016718  0.33819035\n",
      "  0.36713156  0.4157395   0.4868828   0.6022836   0.81440705  1.        ]\n",
      "[ 0.04851485  0.04814475  0.12994416  0.14624904  1.0264904  -0.22539622\n",
      "  0.88189566 -0.17411578  1.         -0.5414525   1.0000001   0.11596292\n",
      " -0.99999994  1.          0.3149613   0.31740388  0.3271954   0.3456181\n",
      "  0.37519497  0.42561007  0.49713758  0.6141732   0.83500737  1.        ]\n",
      "[ 0.05616956  0.01531815  0.12021814  0.11347301  1.0757295   0.6633448\n",
      "  0.75671625 -0.99999994  1.         -0.44981146  1.1703779   0.00368834\n",
      " -1.0000005   0.          0.3201717   0.32265204  0.33259857  0.35132873\n",
      "  0.3813943   0.43325135  0.50500596  0.6232659   0.8509423   1.        ]\n",
      "[ 0.07444675  0.03661929  0.1251768   0.10057428  1.094044    0.23804706\n",
      "  0.6384469  -0.99999994  0.         -0.37073225  0.9999999  -0.11164141\n",
      " -1.          0.          0.32482585  0.32733288  0.3374237   0.35642877\n",
      "  0.38696396  0.4401191   0.5125539   0.6313467   0.86525327  1.        ]\n",
      "[ 0.09922931  0.04949018  0.12644202  0.08865553  1.0842301  -0.10680303\n",
      "  0.52226555 -1.          0.         -0.2927971   0.9999998  -0.21838093\n",
      " -1.          0.          0.32891968  0.33144918  0.3416669   0.36091396\n",
      "  0.39231154  0.44595167  0.5192895   0.63841444  0.87791693  1.        ]\n",
      "[ 0.12878741  0.05913996  0.12574099  0.07787549  1.0252261  -0.7330308\n",
      "  0.5349628   0.33922574  1.         -0.21374497  1.0000002  -0.33300376\n",
      " -0.99999994  0.          0.33254042  0.335089    0.3454189   0.36488014\n",
      "  0.3970697   0.4506278   0.5252624   0.6446339   0.8888649   1.        ]\n",
      "[ 0.15783258  0.05827068  0.13254918  0.0552445   1.0322691   0.05651259\n",
      "  0.39890426 -1.          1.         -0.16938727  0.57340324 -0.37299323\n",
      " -0.7282853   1.          0.33511636  0.33767578  0.34808543  0.36769962\n",
      "  0.40054592  0.45392433  0.52956134  0.6491626   0.8964624   1.        ]\n",
      "[ 0.17176652  0.02784354  0.12255459  0.01838195  1.0953711   0.8065894\n",
      "  0.2829218  -1.0000001   1.         -0.100659    0.8630671  -0.47061467\n",
      " -0.99093646  1.          0.33588085  0.33843815  0.34887132  0.36853197\n",
      "  0.40175974  0.45484242  0.53093666  0.6503871   0.89894426  1.        ]\n",
      "[ 0.184195    0.02460538  0.12828323 -0.00225612  1.1734424   1.\n",
      "  0.17047393 -1.          0.         -0.047206    0.67553866 -0.5501772\n",
      " -0.69811773  0.          0.33569804  0.33824575  0.348673    0.36832467\n",
      "  0.40181392  0.45450896  0.5307959   0.64985114  0.8987801   1.        ]\n",
      "[ 0.23337878  0.08721763  0.15441376 -0.01124233  1.1349137   0.\n",
      "  0.11205006 -0.9999998   0.         -0.0775612  -0.2665534  -0.66328096\n",
      " -0.9999998   0.          0.3355775   0.33811468  0.34853786  0.36818445\n",
      "  0.40199462  0.45424116  0.5307822   0.6493954   0.89885265  1.        ]\n",
      "[ 2.8303215e-01  9.8531425e-02  1.7154326e-01 -2.1579854e-02\n",
      "  1.1323975e+00  0.0000000e+00 -3.4145117e-03 -1.0000000e+00\n",
      "  0.0000000e+00 -1.6320702e-01 -9.9999988e-01 -6.3490772e-01\n",
      "  1.9868216e-08  0.0000000e+00  3.3470303e-01  3.3722278e-01\n",
      "  3.4761953e-01  3.6721593e-01  4.0128264e-01  4.5296711e-01\n",
      "  5.2957833e-01  6.4751703e-01  8.9685684e-01  1.0000000e+00]\n",
      "[ 3.2562286e-01  8.5133448e-02  1.6494824e-01 -4.0137038e-02\n",
      "  1.1315804e+00  5.9604645e-08 -4.0395260e-03 -2.4623135e-02\n",
      "  0.0000000e+00 -2.4341543e-01 -1.0000000e+00 -6.3358295e-01\n",
      " -5.9604645e-08  0.0000000e+00  3.3283183e-01  3.3532730e-01\n",
      "  3.4566793e-01  3.6515430e-01  3.9931729e-01  4.5038724e-01\n",
      "  5.2676111e-01  6.4380968e-01  8.9203560e-01  1.0000000e+00]\n",
      "[ 0.3680846   0.08488533  0.17103435 -0.04517394  1.131074    0.\n",
      " -0.05819535 -0.4655818   0.         -0.32435024 -1.         -0.5121782\n",
      "  0.9999997   0.          0.3307166   0.33318558  0.34346253  0.3628246\n",
      "  0.39706233  0.44748187  0.52355826  0.6396425   0.88654405  1.        ]\n",
      "[ 0.40794313  0.07967805  0.16806746 -0.06224481  1.1305605   0.\n",
      " -0.07482517 -0.15339607  0.         -0.4034273  -0.97392    -0.38977015\n",
      "  1.          0.          0.32778537  0.33022672  0.34041464  0.35960487\n",
      "  0.39379564  0.4435108   0.51904684  0.6339806   0.8787633   1.        ]\n",
      "[ 0.45355082  0.09117809  0.19822158 -0.05686069  1.1286473   0.\n",
      " -0.19087577 -0.9999998   0.         -0.48439527 -1.0097666  -0.3633597\n",
      "  0.20948984  1.          0.3250905   0.32751176  0.33761868  0.3566513\n",
      "  0.39089563  0.43983957  0.51496303  0.6287241   0.87174875  1.        ]\n",
      "[ 4.9251047e-01  7.7747829e-02  1.8015084e-01 -9.0479173e-02\n",
      "  1.1238041e+00 -5.9604645e-08 -6.2661290e-02  9.9999934e-01\n",
      "  0.0000000e+00 -5.6904441e-01 -9.9999988e-01 -4.7500241e-01\n",
      " -9.9999970e-01  1.0000000e+00  3.2081270e-01  3.2320210e-01\n",
      "  3.3317831e-01  3.5196063e-01  3.8599548e-01  4.3409568e-01\n",
      "  5.0831074e-01  6.2056679e-01  8.6023355e-01  1.0000000e+00]\n",
      "[ 5.29376268e-01  7.35550374e-02  1.80648431e-01 -1.08854055e-01\n",
      "  1.11905050e+00  2.98023224e-07  6.56370521e-02  1.00000012e+00\n",
      "  0.00000000e+00 -6.53801739e-01 -1.00000012e+00 -5.87741613e-01\n",
      " -1.00000036e+00  0.00000000e+00  3.15666050e-01  3.18017125e-01\n",
      "  3.27835560e-01  3.46316665e-01  3.80019844e-01  4.27207857e-01\n",
      "  5.00261366e-01  6.10803306e-01  8.46276700e-01  1.00000000e+00]\n",
      "[ 0.5657505   0.07272127  0.19569544 -0.1003656   1.118827    0.\n",
      "  0.057262   -0.0818086   0.         -0.734721   -1.0000002  -0.46606374\n",
      "  0.9999995   0.          0.3108963   0.31321186  0.32288444  0.34108645\n",
      "  0.37454358  0.42080703  0.49283677  0.6017159   0.8334212   1.        ]\n",
      "[ 5.9554154e-01  5.9512701e-02  1.9008608e-01 -1.1995193e-01\n",
      "  1.1158102e+00 -1.1920929e-07  1.5739316e-01  7.8637677e-01\n",
      "  0.0000000e+00 -8.1612396e-01 -9.9968415e-01 -3.3398139e-01\n",
      "  1.0642117e+00  0.0000000e+00  3.0519119e-01  3.0746424e-01\n",
      "  3.1696177e-01  3.3496478e-01  3.6789727e-01  4.1317809e-01\n",
      "  4.8390126e-01  5.9090704e-01  8.1792134e-01  1.0000000e+00]\n",
      "[ 0.6180063   0.04490527  0.17304106 -0.11844611  1.1159685   0.\n",
      "  0.13474035 -0.19303079  0.         -0.8197987   0.         -0.32351482\n",
      " -1.2583851   1.          0.29954848  0.3017795   0.31110364  0.32894975\n",
      "  0.36129087  0.40564185  0.4750447   0.580237    0.8024026   1.        ]\n",
      "[ 6.2750417e-01  1.9379400e-02  1.5021418e-01 -1.4937729e-01\n",
      "  1.1137991e+00 -5.9604645e-08  2.5959492e-01  9.9999982e-01\n",
      "  0.0000000e+00 -7.9365456e-01  3.8385713e-01 -3.7697077e-01\n",
      " -1.0000000e+00  1.0000000e+00  2.9235411e-01  2.9453155e-01\n",
      "  3.0363351e-01  3.2113978e-01  3.5271305e-01  3.9607707e-01\n",
      "  4.6366417e-01  5.6673038e-01  7.8186059e-01  1.0000000e+00]\n",
      "[ 0.6454728   0.03582717  0.17809206 -0.165586    1.1096172  -0.01062807\n",
      "  0.38555038  1.          0.         -0.8425699  -0.60933906 -0.35790884\n",
      " -0.10388782  1.          0.28449532  0.28661537  0.2954737   0.31263587\n",
      "  0.34337306  0.3856204   0.4512498   0.55195737  0.7594843   1.        ]\n",
      "[ 6.49582505e-01  1.08408285e-02  1.63739547e-01 -1.71488613e-01\n",
      "  1.10888445e+00  1.49011612e-07  5.11095166e-01  1.00000012e+00\n",
      "  0.00000000e+00 -8.34910214e-01  0.00000000e+00 -4.04610515e-01\n",
      " -3.62783223e-01  1.00000000e+00  2.76342213e-01  2.78403431e-01\n",
      "  2.87007987e-01  3.03769171e-01  3.33634615e-01  3.74785811e-01\n",
      "  4.38342690e-01  5.36880076e-01  7.36168146e-01  1.00000000e+00]\n",
      "[ 6.4237571e-01 -1.4390767e-02  1.5981729e-01 -1.7029880e-01\n",
      "  1.1073483e+00  7.4505806e-08  6.3438237e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3491039e-01  0.0000000e+00 -4.1226816e-01\n",
      "  6.0044646e-02  1.0000000e+00  2.6821786e-01  2.7022049e-01\n",
      "  2.7857211e-01  2.9493317e-01  3.2392991e-01  3.6398965e-01\n",
      "  4.2548072e-01  5.2187920e-01  7.1293271e-01  1.0000000e+00]\n",
      "[ 6.2120283e-01 -3.9998926e-02  1.6972357e-01 -3.7216458e-02\n",
      "  1.1016245e+00 -1.1362433e-03  7.6175368e-01  9.8037535e-01\n",
      "  0.0000000e+00 -8.3597910e-01  1.4476478e-04 -4.0201592e-01\n",
      "  1.6691498e-01  0.0000000e+00  2.6730621e-01  2.6930460e-01\n",
      "  2.7762792e-01  2.9425609e-01  3.2318625e-01  3.6268061e-01\n",
      "  4.2423499e-01  5.1984346e-01  7.1104890e-01  1.0000000e+00]\n",
      "[ 5.9041816e-01 -5.9616040e-02  1.6896285e-01  1.7867917e-02\n",
      "  1.0990117e+00  3.1959713e-03  8.8734722e-01  1.0002983e+00\n",
      "  0.0000000e+00 -8.3572477e-01 -1.4159083e-04 -3.5855544e-01\n",
      "  2.4849457e-01  1.0000000e+00  2.6847553e-01  2.7048537e-01\n",
      "  2.7884519e-01  2.9592869e-01  3.2502329e-01  3.6411017e-01\n",
      "  4.2633811e-01  5.2155328e-01  7.1531564e-01  1.0000000e+00]\n",
      "[ 0.55534256 -0.07056302  0.19607198  0.01637514  1.1117523   0.19369213\n",
      "  1.0105617   1.          0.         -0.83544385  0.         -0.3339908\n",
      "  0.3392355   0.          0.26937535  0.27139512  0.27978304  0.29735726\n",
      "  0.32659233  0.36516643  0.42804536  0.52278614  0.7189244   1.        ]\n",
      "[ 5.3305203e-01 -4.3701425e-02  1.8804985e-01  2.2315675e-02\n",
      "  1.1192045e+00 -2.9802322e-08  9.3490779e-01 -4.3142068e-01\n",
      "  0.0000000e+00 -8.3506471e-01  0.0000000e+00 -3.0213380e-01\n",
      "  1.8208927e-01  1.0000000e+00  2.7028063e-01  2.7231014e-01\n",
      "  2.8072634e-01  2.9876980e-01  3.2789776e-01  3.6623666e-01\n",
      "  4.2974746e-01  5.2418846e-01  7.2249830e-01  1.0000000e+00]\n",
      "[ 5.0374889e-01 -5.8261391e-02  2.1259785e-01  2.2986960e-02\n",
      "  1.1193354e+00 -2.0861626e-07  9.3489254e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490640e-01  0.0000000e+00 -2.6823390e-01\n",
      "  3.1355658e-01  1.0000000e+00  2.7110663e-01  2.7314568e-01\n",
      "  2.8158772e-01  3.0014384e-01  3.2874843e-01  3.6718678e-01\n",
      "  4.3135408e-01  5.2540910e-01  7.2595519e-01  1.0000000e+00]\n",
      "[ 4.7082227e-01 -6.5855168e-02  2.3605569e-01  2.7737195e-02\n",
      "  1.1192842e+00  1.7881393e-07  9.3490589e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490795e-01  0.0000000e+00 -2.2332239e-01\n",
      "  3.6697364e-01  0.0000000e+00  2.7211872e-01  2.7416572e-01\n",
      "  2.8280872e-01  3.0177328e-01  3.2980072e-01  3.6836216e-01\n",
      "  4.3328556e-01  5.2693331e-01  7.3006517e-01  1.0000000e+00]\n",
      "[ 4.3372720e-01 -7.4184477e-02  2.6015630e-01  3.2734886e-02\n",
      "  1.1192315e+00  2.0861626e-07  9.3490684e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490664e-01  0.0000000e+00 -1.7097831e-01\n",
      "  4.2804936e-01  0.0000000e+00  2.7332884e-01  2.7538496e-01\n",
      "  2.8459141e-01  3.0367553e-01  3.3107173e-01  3.7003732e-01\n",
      "  4.3495572e-01  5.2878749e-01  7.3487335e-01  1.0000000e+00]\n",
      "[ 3.9204097e-01 -8.3362557e-02  2.8505102e-01  3.8033567e-02\n",
      "  1.1191707e+00  2.3841858e-07  9.3490601e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490598e-01  0.0000000e+00 -1.1019850e-01\n",
      "  4.9842533e-01  0.0000000e+00  2.7474660e-01  2.7681336e-01\n",
      "  2.8664169e-01  3.0586329e-01  3.3257252e-01  3.7228554e-01\n",
      "  4.3650562e-01  5.3098887e-01  7.3968703e-01  1.0000000e+00]\n",
      "[ 3.4526077e-01 -9.3533345e-02  3.1091988e-01  4.3702044e-02\n",
      "  1.1191082e+00  2.3841858e-07  9.3490469e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490825e-01  0.0000000e+00 -3.9334059e-02\n",
      "  5.8024609e-01  0.0000000e+00  2.7638474e-01  2.7846387e-01\n",
      "  2.8897491e-01  3.0835298e-01  3.3431771e-01  3.7486306e-01\n",
      "  4.3833244e-01  5.3355968e-01  7.4519068e-01  1.0000000e+00]\n",
      "[ 2.9760543e-01 -9.5421813e-02  3.2476905e-01  5.6478433e-02\n",
      "  1.1171679e+00  2.0217896e-04  8.2080507e-01 -9.9998164e-01\n",
      "  0.0000000e+00 -8.3490866e-01 -6.7353249e-06  3.8112342e-02\n",
      "  6.3610333e-01  0.0000000e+00  2.7859384e-01  2.8068957e-01\n",
      "  2.9194069e-01  3.1114298e-01  3.3672684e-01  3.7823716e-01\n",
      "  4.4097766e-01  5.3716356e-01  7.5234288e-01  1.0000000e+00]\n",
      "[ 0.23746522 -0.12064926  0.3494785   0.0656449   1.0599074  -0.70922256\n",
      "  0.94241285  1.0000001   0.         -0.8273073   0.10264307  0.1270613\n",
      "  0.72124356  0.          0.2811511   0.2838591   0.29532298  0.31373432\n",
      "  0.33953127  0.38211435  0.44409087  0.541374    0.7605463   1.        ]\n",
      "[ 1.7673668e-01 -1.2218260e-01  3.6945510e-01  7.4860752e-02\n",
      "  1.0315083e+00 -3.1448853e-01  8.3241528e-01 -1.0000001e+00\n",
      "  0.0000000e+00 -8.2928663e-01 -5.9604645e-08  2.3791432e-01\n",
      "  8.8222569e-01  0.0000000e+00  2.8407562e-01  2.8752261e-01\n",
      "  2.9913443e-01  3.1671402e-01  3.4275597e-01  3.8651645e-01\n",
      "  4.4770819e-01  5.4933745e-01  7.6984346e-01  1.0000000e+00]\n",
      "[ 0.10438095 -0.1454784   0.386685    0.07173194  0.9515936  -0.99858105\n",
      "  1.1142632   2.6979866   1.         -0.8270974   0.0550186   0.36441725\n",
      "  1.0059694   0.          0.28674802  0.29096207  0.30271283  0.31940973\n",
      "  0.3462743   0.39059293  0.45091772  0.5568584   0.78400767  1.        ]\n",
      "[ 3.2153565e-02 -1.3815111e-01  2.8217643e-01  9.7484924e-02\n",
      "  1.0927880e+00  7.3401242e-01  9.3489087e-01  1.4623006e-05\n",
      "  0.0000000e+00 -8.1062329e-01  1.1054510e-01  4.7800267e-01\n",
      "  9.9926043e-01  0.0000000e+00  2.9082432e-01  2.9557917e-01\n",
      "  3.0726308e-01  3.2370791e-01  3.5145962e-01  3.9578432e-01\n",
      "  4.5665690e-01  5.6681299e-01  8.0236626e-01  1.0000000e+00]\n",
      "[-0.03339223 -0.13096608  0.2506489   0.10630266  1.1453344   0.65889215\n",
      "  0.9349064   0.          0.         -0.80155116  0.1204325   0.6009546\n",
      "  1.0000001   0.          0.2957847   0.30062383  0.3117922   0.32847947\n",
      "  0.3571622   0.4011655   0.46317765  0.5776739   0.82221484  1.        ]\n",
      "[-5.1500648e-02 -4.8602451e-02  2.1007815e-01  1.6814457e-01\n",
      "  1.1386123e+00  2.8651536e-02  9.3510669e-01  7.1794190e-03\n",
      "  0.0000000e+00 -8.0890316e-01 -6.0415268e-04  6.8931955e-01\n",
      "  7.0932013e-01  0.0000000e+00  3.0402109e-01  3.0899495e-01\n",
      "  3.1980637e-01  3.3692256e-01  3.6688325e-01  4.1092962e-01\n",
      "  4.7481790e-01  5.9540069e-01  8.5132694e-01  1.0000000e+00]\n",
      "[-7.0419438e-02 -3.8222011e-02  2.0886263e-01  1.7838620e-01\n",
      "  1.1350201e+00 -1.4901161e-08  9.3491220e-01 -8.7659799e-02\n",
      "  0.0000000e+00 -8.0939627e-01  0.0000000e+00  7.7103323e-01\n",
      "  6.7386436e-01  0.0000000e+00  3.1252950e-01  3.1764257e-01\n",
      "  3.2810280e-01  3.4566298e-01  3.7693447e-01  4.2104560e-01\n",
      "  4.8687145e-01  6.1320031e-01  8.7993896e-01  1.0000000e+00]\n",
      "[-9.6266195e-02 -5.1653165e-02  2.0760001e-01  1.8787283e-01\n",
      "  1.1349000e+00 -1.7201304e-03  9.3494725e-01 -5.1299733e-04\n",
      "  0.0000000e+00 -8.0956423e-01  3.8385391e-05  8.7056911e-01\n",
      "  8.2535774e-01  0.0000000e+00  3.2143638e-01  3.2669517e-01\n",
      "  3.3681342e-01  3.5514864e-01  3.8746968e-01  4.3167835e-01\n",
      "  4.9953175e-01  6.3183844e-01  9.0979552e-01  1.0000000e+00]\n",
      "[-1.0549704e-01 -1.8363053e-02  1.9836219e-01  1.9517422e-01\n",
      "  1.1349071e+00  2.2351742e-08  8.9601099e-01 -3.2804918e-01\n",
      "  0.0000000e+00 -7.3228884e-01  9.7789043e-01  7.5370765e-01\n",
      " -1.0000000e+00  0.0000000e+00  3.3071929e-01  3.3612996e-01\n",
      "  3.4593678e-01  3.6523411e-01  3.9847299e-01  4.4283533e-01\n",
      "  5.1280057e-01  6.5127230e-01  9.3588167e-01  1.0000000e+00]\n",
      "[-8.8736266e-02  3.3603616e-02  2.0012732e-01  1.9109106e-01\n",
      "  1.1346247e+00  1.4901161e-08  7.9999435e-01 -8.0803555e-01\n",
      "  0.0000000e+00 -6.7660898e-01  7.0613027e-01  6.3673013e-01\n",
      " -1.0000000e+00  0.0000000e+00  3.3991426e-01  3.4518212e-01\n",
      "  3.5496584e-01  3.7522027e-01  4.0871412e-01  4.5387337e-01\n",
      "  5.2812642e-01  6.7018700e-01  9.6171457e-01  1.0000000e+00]\n",
      "[-0.06378692  0.04998993  0.19930363  0.18048008  1.1334653  -0.00300598\n",
      "  0.68194705 -1.001035    0.         -0.6213931   0.70017993  0.5194155\n",
      " -1.0000497   0.          0.34864405  0.3534972   0.3635166   0.384691\n",
      "  0.41811863  0.4645835   0.5430027   0.6876363   0.9861327   1.        ]\n",
      "[-0.01873858  0.08999417  0.20986116  0.17233957  1.0683686  -0.78284925\n",
      "  0.6631942   0.09740999  1.         -0.5964521   0.33888078  0.40736115\n",
      " -1.          0.          0.3570488   0.36146063  0.3717057   0.3937886\n",
      "  0.42710778  0.47484964  0.5573327   0.70440674  1.          1.        ]\n",
      "[ 0.01690348  0.07173634  0.1973766   0.15622267  1.0476794  -0.19912834\n",
      "  0.51520765 -0.9999998   1.         -0.5399826   0.7289691   0.29631537\n",
      " -1.          0.          0.36469573  0.36869663  0.3791468   0.4020613\n",
      "  0.43527186  0.48417652  0.57037205  0.7196584   1.          1.        ]\n",
      "[ 0.04403238  0.05440641  0.19119702  0.13282217  1.0574902   0.14054996\n",
      "  0.39756858 -1.0000001   1.         -0.4697623   0.8876295   0.17998457\n",
      " -1.          0.          0.37118277  0.37477756  0.38554886  0.40905115\n",
      "  0.44210842  0.49200472  0.5814439   0.7325567   1.          1.        ]\n",
      "[ 0.06861539  0.0491414   0.18925491  0.10994519  1.0814847   0.31191975\n",
      "  0.2813493  -1.          0.         -0.40253705  0.8726589   0.07210243\n",
      " -1.          0.          0.3765626   0.37974802  0.39097926  0.41481256\n",
      "  0.44766566  0.49839088  0.5904395   0.7463663   1.          1.        ]\n",
      "[ 0.094074    0.05087072  0.19239558  0.0831133   1.1211358   0.5151459\n",
      "  0.16578108 -1.          0.         -0.35427803  0.61584854 -0.04426897\n",
      " -0.99999994  0.          0.38071844  0.38348123  0.39512512  0.41921115\n",
      "  0.45179352  0.5031689   0.59727716  0.7572472   1.          1.        ]\n",
      "[ 1.4314036e-01  9.8032348e-02  2.1485530e-01  6.1945401e-02\n",
      "  1.1193541e+00  1.7881393e-07  5.0339162e-02 -1.0000000e+00\n",
      "  0.0000000e+00 -3.8170862e-01 -3.2075593e-01 -1.5933168e-01\n",
      " -9.9999982e-01  0.0000000e+00  3.8399783e-01  3.8628393e-01\n",
      "  3.9833075e-01  4.2229539e-01  4.5482883e-01  5.0673008e-01\n",
      "  6.0265017e-01  7.6611978e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 1.9305615e-01  9.9740297e-02  2.3184945e-01  5.3804018e-02\n",
      "  1.1177770e+00  1.1920929e-07 -6.5298080e-02 -1.0000000e+00\n",
      "  0.0000000e+00 -4.6256626e-01 -1.0000000e+00 -7.4256301e-02\n",
      "  6.8896103e-01  0.0000000e+00  3.8671079e-01  3.8868478e-01\n",
      "  4.0114033e-01  4.2466918e-01  4.5738551e-01  5.0979590e-01\n",
      "  6.0741621e-01  7.7420014e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 2.4148442e-01  9.6783668e-02  2.3309276e-01  3.8954694e-02\n",
      "  1.1163119e+00  5.9604645e-08 -1.8123031e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -5.4370993e-01 -1.0000000e+00  3.8517714e-02\n",
      "  9.1691208e-01  0.0000000e+00  3.8839200e-01  3.9037454e-01\n",
      "  4.0321076e-01  4.2628103e-01  4.5924997e-01  5.1301718e-01\n",
      "  6.1100996e-01  7.8058958e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 2.8627470e-01  8.9538790e-02  2.2900963e-01  2.2363715e-02\n",
      "  1.1163329e+00 -5.9604645e-08 -2.4100542e-01 -5.1391929e-01\n",
      "  0.0000000e+00 -6.2502605e-01 -9.9999994e-01  1.6170466e-01\n",
      "  1.0000001e+00  0.0000000e+00  3.8928321e-01  3.9127031e-01\n",
      "  4.0444854e-01  4.2704633e-01  4.6021840e-01  5.1510143e-01\n",
      "  6.1327589e-01  7.8503668e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 3.2341051e-01  7.4230030e-02  2.1522279e-01  5.1666009e-03\n",
      "  1.1123731e+00 -5.9604645e-08 -1.3090611e-01  8.6180705e-01\n",
      "  0.0000000e+00 -7.0682198e-01 -9.9999994e-01  2.8678548e-01\n",
      "  1.0000001e+00  0.0000000e+00  3.8935328e-01  3.9134073e-01\n",
      "  4.0480885e-01  4.2693967e-01  4.6022943e-01  5.1597136e-01\n",
      "  6.1413068e-01  7.8689188e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 3.7096217e-01  9.5056511e-02  2.1645635e-01 -2.7734788e-02\n",
      "  1.1103909e+00  5.9604645e-08 -7.7829719e-02  4.0304044e-01\n",
      "  0.0000000e+00 -7.6389807e-01 -6.7993212e-01  1.7295504e-01\n",
      " -9.9999970e-01  0.0000000e+00  3.8791037e-01  3.8993889e-01\n",
      "  4.0358585e-01  4.2520469e-01  4.5846796e-01  5.1469409e-01\n",
      "  6.1247176e-01  7.8519613e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 4.2411119e-01  1.0627337e-01  2.2485533e-01 -5.0487522e-02\n",
      "  1.1085811e+00  1.1920929e-07 -4.4049144e-02  2.4163930e-01\n",
      "  0.0000000e+00 -8.4750515e-01 -9.9999988e-01  6.1178148e-02\n",
      " -1.0000004e+00  0.0000000e+00  3.8539693e-01  3.8768476e-01\n",
      "  4.0125281e-01  4.2231131e-01  4.5545006e-01  5.1192486e-01\n",
      "  6.0906047e-01  7.8114307e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 4.6578115e-01  8.8112287e-02  2.1513671e-01 -4.6594977e-02\n",
      "  1.1098001e+00  5.9604645e-08 -1.5888059e-01 -9.9999970e-01\n",
      "  0.0000000e+00 -8.3490872e-01  0.0000000e+00 -7.4414730e-02\n",
      " -1.0000004e+00  0.0000000e+00  3.8307497e-01  3.8560712e-01\n",
      "  3.9910248e-01  4.1963512e-01  4.5266083e-01  5.0937986e-01\n",
      "  6.0592175e-01  7.7742583e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 5.0933474e-01  8.7492935e-02  2.1556605e-01 -6.3988797e-02\n",
      "  1.1086497e+00 -5.9604645e-08 -2.7532840e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -8.3490878e-01  0.0000000e+00 -1.9250631e-01\n",
      " -9.9999994e-01  0.0000000e+00  3.7991601e-01  3.8268784e-01\n",
      "  3.9608103e-01  4.1605526e-01  4.4889000e-01  5.0565982e-01\n",
      "  6.0140467e-01  7.7184796e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 5.4190797e-01  6.5592349e-02  1.9640037e-01 -8.4268644e-02\n",
      "  1.1050863e+00 -8.9406967e-08 -1.6021991e-01  9.0808803e-01\n",
      "  0.0000000e+00 -8.3490890e-01  0.0000000e+00 -3.1115425e-01\n",
      " -9.9999994e-01  0.0000000e+00  3.7580621e-01  3.7878308e-01\n",
      "  3.9203960e-01  4.1146791e-01  4.4401139e-01  5.0052327e-01\n",
      "  5.9524357e-01  7.6399213e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 5.7275808e-01  6.2136792e-02  1.9678932e-01 -1.0228780e-01\n",
      "  1.1010202e+00  2.9802322e-07 -3.2897830e-02  1.0000001e+00\n",
      "  0.0000000e+00 -8.3490968e-01  0.0000000e+00 -4.2990434e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.7084684e-01  3.7401980e-01\n",
      "  3.8697663e-01  4.0596601e-01  4.3813753e-01  4.9418238e-01\n",
      "  5.8767235e-01  7.5422454e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 6.0089457e-01  5.6288805e-02  2.0011872e-01 -1.1513849e-01\n",
      "  1.0969559e+00  2.3841858e-07  9.4426870e-02  1.0000001e+00\n",
      "  0.0000000e+00 -8.3490878e-01  0.0000000e+00 -4.9691641e-01\n",
      " -5.6465822e-01  0.0000000e+00  3.6527088e-01  3.6863804e-01\n",
      "  3.8109654e-01  3.9979738e-01  4.3154016e-01  4.8698005e-01\n",
      "  5.7908982e-01  7.4309492e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.62271017  0.04407666  0.20342638 -0.14544028  1.1218479   0.3797969\n",
      "  0.22616023  0.9999998   0.         -0.8349095   0.         -0.61598325\n",
      " -0.9999998   0.          0.35826322  0.3618136   0.3737447   0.39208478\n",
      "  0.42326438  0.47775936  0.56814146  0.7287663   1.          1.        ]\n",
      "[ 6.4760113e-01  4.9708575e-02  2.0834909e-01 -1.4392763e-01\n",
      "  1.1182015e+00  2.6822090e-07  3.5337687e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3490652e-01  0.0000000e+00 -6.1540973e-01\n",
      " -5.9604645e-08  0.0000000e+00  3.5131690e-01  3.5505724e-01\n",
      "  3.6645198e-01  3.8443419e-01  4.1505891e-01  4.6864259e-01\n",
      "  5.5731124e-01  7.1461004e-01  9.8960495e-01  1.0000000e+00]\n",
      "[ 6.6847718e-01  4.2914916e-02  2.1554631e-01 -1.5004154e-01\n",
      "  1.1156118e+00 -1.7881393e-07  4.8016071e-01  9.9999994e-01\n",
      "  0.0000000e+00 -8.3490938e-01  0.0000000e+00 -4.9512267e-01\n",
      "  1.0000004e+00  0.0000000e+00  3.4409711e-01  3.4800485e-01\n",
      "  3.5884470e-01  3.7645361e-01  4.0649816e-01  4.5912221e-01\n",
      "  5.4600340e-01  6.9945776e-01  9.7248024e-01  1.0000000e+00]\n",
      "[ 6.8796253e-01  4.0115219e-02  2.1641329e-01 -1.6624397e-01\n",
      "  1.1135597e+00 -1.7881393e-07  6.0587883e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3490938e-01  0.0000000e+00 -3.7479496e-01\n",
      "  1.0000004e+00  0.0000000e+00  3.3635518e-01  3.4017500e-01\n",
      "  3.5044661e-01  3.6764345e-01  3.9703497e-01  4.4851223e-01\n",
      "  5.3341925e-01  6.8235964e-01  9.5359945e-01  1.0000000e+00]\n",
      "[ 7.0621264e-01  3.7609302e-02  2.1727175e-01 -1.8245198e-01\n",
      "  1.1121732e+00  1.7881393e-07  7.3008108e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3490640e-01  0.0000000e+00 -2.5444305e-01\n",
      "  9.9999970e-01  0.0000000e+00  3.2784569e-01  3.3156887e-01\n",
      "  3.4125894e-01  3.5800490e-01  3.8667062e-01  4.3681431e-01\n",
      "  5.1956075e-01  6.6342366e-01  9.3296516e-01  1.0000000e+00]\n",
      "[ 7.4031365e-01  6.9667220e-02  2.1082038e-01 -1.8489566e-01\n",
      "  1.1117848e+00  2.9802322e-08  6.1341548e-01 -9.9999952e-01\n",
      "  0.0000000e+00 -8.3490914e-01  0.0000000e+00 -3.8430083e-01\n",
      " -1.5404868e+00  1.0000000e+00  3.1923705e-01  3.2286248e-01\n",
      "  3.3198833e-01  3.4827936e-01  3.7620634e-01  4.2495981e-01\n",
      "  5.0552571e-01  6.4418691e-01  9.1118783e-01  1.0000000e+00]\n",
      "[ 0.7709588   0.06235229  0.20440437 -0.21334104  1.1127418   0.\n",
      "  0.5269015  -0.7273689   0.         -0.81690925  0.23952475 -0.3776065\n",
      " -0.9999998   1.          0.30909303  0.31260324  0.32115373  0.3369131\n",
      "  0.36395285  0.41091606  0.48893195  0.6212224   0.8831934   1.        ]\n",
      "[ 0.7954442   0.04899696  0.20193811 -0.23373216  1.0795293  -0.39108488\n",
      "  0.64970326  0.99999976  0.         -0.79988474  0.22347772 -0.49572003\n",
      " -1.          1.          0.29817662  0.30156285  0.30953214  0.32472122\n",
      "  0.35079908  0.3957712   0.47105104  0.59638345  0.8530673   1.        ]\n",
      "[ 0.8154722   0.03978603  0.2180911  -0.25363734  1.0736599  -0.0559053\n",
      "  0.77266407  1.0000001   0.         -0.80968755 -0.11472927 -0.5392891\n",
      " -0.3756311   0.          0.2863369   0.2895887   0.29692551  0.31150308\n",
      "  0.33653104  0.37934703  0.45165908  0.5694503   0.8203932   1.        ]\n",
      "[ 0.82444793  0.01766178  0.22232772 -0.25779644  1.0886025   0.19978644\n",
      "  0.8942144   1.          0.         -0.812941    0.         -0.6209533\n",
      " -0.07359082  1.          0.27428064  0.2773405   0.28408483  0.29805177\n",
      "  0.32199898  0.36262548  0.43191463  0.54344416  0.7868788   1.        ]\n",
      "[ 8.0590415e-01 -3.7229933e-02  1.7026407e-01 -2.8294558e-02\n",
      "  1.1121279e+00  2.9243758e-01  1.0135130e+00  1.0001613e+00\n",
      "  0.0000000e+00 -8.2961690e-01  1.7881393e-06 -5.7298017e-01\n",
      "  1.3241410e-01  0.0000000e+00  2.7291128e-01  2.7560571e-01\n",
      "  2.8230786e-01  2.9626971e-01  3.2007372e-01  3.6099318e-01\n",
      "  4.2987001e-01  5.4073727e-01  7.8316683e-01  1.0000000e+00]\n",
      "[ 7.8806376e-01 -3.6455449e-02  1.4414628e-01  1.1401279e-02\n",
      "  1.1346178e+00 -5.9172511e-05  9.3490565e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3035141e-01  1.9520521e-06 -5.5709958e-01\n",
      "  1.2903838e-01  1.0000000e+00  2.7333981e-01  2.7572796e-01\n",
      "  2.8243309e-01  2.9648346e-01  3.2030463e-01  3.6186513e-01\n",
      "  4.3077767e-01  5.4205269e-01  7.8452510e-01  1.0000000e+00]\n",
      "[ 7.6735795e-01 -4.1414671e-02  1.5998347e-01  2.2354303e-02\n",
      "  1.1346302e+00  5.0455332e-04  9.3490660e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3025926e-01 -2.4467707e-05 -5.3456950e-01\n",
      "  1.7439550e-01  1.0000000e+00  2.7434456e-01  2.7639577e-01\n",
      "  2.8311712e-01  2.9729626e-01  3.2118276e-01  3.6358228e-01\n",
      "  4.3266311e-01  5.4561836e-01  7.8729790e-01  1.0000000e+00]\n",
      "[ 7.4456096e-01 -4.5613199e-02  1.7713156e-01  2.5582364e-02\n",
      "  1.1345922e+00 -2.9414892e-05  9.3490648e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3024836e-01  9.5367432e-07 -5.0934136e-01\n",
      "  2.0676781e-01  1.0000000e+00  2.7549657e-01  2.7717492e-01\n",
      "  2.8391522e-01  2.9823920e-01  3.2220146e-01  3.6553955e-01\n",
      "  4.3481633e-01  5.4966086e-01  7.9047710e-01  1.0000000e+00]\n",
      "[ 7.1971601e-01 -4.9711842e-02  1.9316430e-01  2.7225325e-02\n",
      "  1.1345513e+00 -1.2516975e-06  9.3490660e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3024484e-01  2.9802322e-08 -4.8128366e-01\n",
      "  2.2960551e-01  0.0000000e+00  2.7671903e-01  2.7799070e-01\n",
      "  2.8475085e-01  2.9923084e-01  3.2327276e-01  3.6762598e-01\n",
      "  4.3710825e-01  5.5398786e-01  7.9385072e-01  1.0000000e+00]\n",
      "[ 6.9243038e-01 -5.4598514e-02  2.1168210e-01  3.1223960e-02\n",
      "  1.1345031e+00  7.0333481e-06  9.3490684e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3025241e-01 -2.3841858e-07 -4.4932020e-01\n",
      "  2.6118734e-01  0.0000000e+00  2.7812076e-01  2.7894688e-01\n",
      "  2.8573027e-01  3.0038482e-01  3.2465443e-01  3.7000051e-01\n",
      "  4.3972296e-01  5.5887878e-01  7.9771906e-01  1.0000000e+00]\n",
      "[ 6.6427177e-01 -5.6317165e-02  2.1604960e-01  4.1092996e-02\n",
      "  1.1336949e+00  1.6689301e-06  8.4983253e-01 -7.2295982e-01\n",
      "  0.0000000e+00 -8.3016253e-01 -2.3841858e-07 -4.1397095e-01\n",
      "  2.9328081e-01  0.0000000e+00  2.7998042e-01  2.8035280e-01\n",
      "  2.8717038e-01  3.0202812e-01  3.2731518e-01  3.7303293e-01\n",
      "  4.4310451e-01  5.6490105e-01  8.0285120e-01  1.0000000e+00]\n",
      "[ 0.62750876 -0.07370582  0.24062419  0.04375606  1.1021227  -0.39536834\n",
      "  0.9565437   0.8883013   0.         -0.82366765  0.08098856 -0.3756305\n",
      "  0.31521294  0.          0.28144705  0.28180814  0.2887497   0.30373952\n",
      "  0.33014685  0.37623033  0.4464749   0.5713595   0.8082705   1.        ]\n",
      "[ 0.5919463  -0.07138614  0.26737192  0.04548829  1.1029968   0.\n",
      "  0.93490684 -0.1552409   0.         -0.8243521   0.         -0.32761717\n",
      "  0.38014957  0.          0.28291547  0.2832784   0.29040626  0.30548206\n",
      "  0.33311018  0.37938386  0.44987914  0.5781822   0.813887    1.        ]\n",
      "[ 5.5314094e-01 -7.7663325e-02  2.9331079e-01  4.9315635e-02\n",
      "  1.1029086e+00 -2.0861626e-07  9.3490672e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.2445776e-01  0.0000000e+00 -2.7498388e-01\n",
      "  4.2735717e-01  0.0000000e+00  2.8450000e-01  2.8486496e-01\n",
      "  2.9219562e-01  3.0736431e-01  3.3632210e-01  3.8280064e-01\n",
      "  4.5356539e-01  5.8499604e-01  8.1958777e-01  1.0000000e+00]\n",
      "[ 5.1082116e-01 -8.4702313e-02  3.1596485e-01  5.4635666e-02\n",
      "  1.1028085e+00  4.5418739e-05  9.3490672e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.2461590e-01 -1.4901161e-06 -2.1525371e-01\n",
      "  4.8406884e-01  0.0000000e+00  2.8626999e-01  2.8663725e-01\n",
      "  2.9418817e-01  3.0946031e-01  3.3986032e-01  3.8656926e-01\n",
      "  4.5763844e-01  5.9189928e-01  8.2324982e-01  1.0000000e+00]\n",
      "[ 4.6480790e-01 -9.2025667e-02  3.3614644e-01  6.1468776e-02\n",
      "  1.1024311e+00  5.3644180e-07  9.1594136e-01 -1.6443042e-01\n",
      "  0.0000000e+00 -8.2443684e-01 -5.9604645e-08 -1.4884067e-01\n",
      "  5.4941660e-01  0.0000000e+00  2.8830403e-01  2.8869939e-01\n",
      "  2.9646337e-01  3.1252709e-01  3.4381071e-01  3.9078805e-01\n",
      "  4.6221501e-01  5.9957957e-01  8.2748985e-01  1.0000000e+00]\n",
      "[ 4.1604188e-01 -9.7847506e-02  3.4581810e-01  7.2622277e-02\n",
      "  1.1001964e+00  2.9206276e-06  8.0893886e-01 -9.4007593e-01\n",
      "  0.0000000e+00 -8.2509083e-01 -4.1723251e-07 -7.1094990e-02\n",
      "  6.2042421e-01  0.0000000e+00  2.9081357e-01  2.9139811e-01\n",
      "  2.9923466e-01  3.1669959e-01  3.4840086e-01  3.9571837e-01\n",
      "  4.6760613e-01  6.0843557e-01  8.3279914e-01  1.0000000e+00]\n",
      "[ 3.6153179e-01 -1.0940060e-01  3.7269866e-01  7.8889661e-02\n",
      "  1.0967288e+00 -1.9073486e-06  7.0507312e-01 -9.4224167e-01\n",
      "  0.0000000e+00 -8.2596785e-01  2.3841858e-07  1.8288493e-02\n",
      "  7.1719891e-01  0.0000000e+00  2.9353020e-01  2.9431865e-01\n",
      "  3.0223373e-01  3.2121018e-01  3.5325769e-01  4.0104890e-01\n",
      "  4.7377098e-01  6.1800742e-01  8.3854830e-01  1.0000000e+00]\n",
      "[ 0.29704028 -0.12940697  0.40060058  0.08366633  1.0503428  -0.57049906\n",
      "  0.8288561   0.9999997   0.         -0.8272278   0.          0.12679642\n",
      "  0.8666944   0.          0.29634994  0.29735735  0.30535415  0.32594588\n",
      "  0.35818186  0.4064208   0.48265702  0.62664837  0.84449965  1.        ]\n",
      "[ 0.224671   -0.14503324  0.4286281   0.08035772  1.0216608  -0.35643232\n",
      "  0.9497936   1.          0.         -0.8284724   0.          0.25158697\n",
      "  0.99678326  0.          0.29903185  0.3001475   0.30929244  0.33048922\n",
      "  0.36288086  0.4113217   0.4913175   0.6340995   0.8511867   1.        ]\n",
      "[ 1.5630335e-01 -1.3717806e-01  4.3037599e-01  7.8474022e-02\n",
      "  9.8989022e-01 -4.5572305e-01  9.3490672e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3041972e-01  1.6093254e-06  3.7736326e-01\n",
      "  1.0054969e+00  0.0000000e+00  3.0167225e-01  3.0279773e-01\n",
      "  3.1340212e-01  3.3488056e-01  3.6741331e-01  4.1603529e-01\n",
      "  4.9973869e-01  6.4127165e-01  8.5824192e-01  1.0000000e+00]\n",
      "[ 0.08627752 -0.14042282  0.43229142  0.05691013  0.9891434   0.02551484\n",
      "  0.89367294  1.5243207   1.         -0.82858956  0.0384329   0.5014695\n",
      "  1.          0.          0.3033237   0.30445534  0.3164656   0.33803752\n",
      "  0.37072825  0.41938987  0.50636023  0.646416    0.8628121   1.        ]\n",
      "[ 0.00273206 -0.166645    0.40950492  0.0416314   1.0020347   0.26334065\n",
      "  1.0080135   1.          1.         -0.8108929   0.22006273  0.62454224\n",
      "  1.          0.          0.30432793  0.3060083   0.3187626   0.340261\n",
      "  0.3731668   0.4217876   0.5109689   0.650124    0.86572975  1.        ]\n",
      "[-0.08570988 -0.17522115  0.3791959   0.04036195  1.1231805   1.0167485\n",
      "  0.93490183  0.          1.         -0.783348    0.3230207   0.74455327\n",
      "  0.9999998   0.          0.30517286  0.30794704  0.32078215  0.34220892\n",
      "  0.37510514  0.42387658  0.51474774  0.65302455  0.86821234  1.        ]\n",
      "[-0.10911674 -0.04664065  0.2527751   0.15501116  1.1245679   0.01635876\n",
      "  0.93490607  0.00283738  1.         -0.8013899  -0.22235781  0.865518\n",
      "  0.99980086  0.          0.31193268  0.31555304  0.3287052   0.35048264\n",
      "  0.38388905  0.43550482  0.528104    0.66740775  0.8871602   1.        ]\n",
      "[-0.12957157 -0.04088964  0.2230111   0.16710165  1.1215194  -0.03793183\n",
      "  0.93490684  0.00642715  1.         -0.72268486  0.9960283   0.74781555\n",
      " -1.0023063   0.          0.3192989   0.3236915   0.33718282  0.35936004\n",
      "  0.39334705  0.44805074  0.54233855  0.6829169   0.90826446  1.        ]\n",
      "[-1.3049209e-01 -1.7243460e-03  2.2439829e-01  1.6592120e-01\n",
      "  1.1216152e+00  2.5145710e-08  8.8555092e-01 -4.1136882e-01\n",
      "  1.0000000e+00 -6.4315838e-01  9.9999934e-01  6.2943602e-01\n",
      " -1.0000008e+00  0.0000000e+00  3.2670134e-01  3.3186871e-01\n",
      "  3.4556839e-01  3.6827987e-01  4.0285063e-01  4.6065536e-01\n",
      "  5.5664027e-01  6.9850093e-01  9.2947078e-01  1.0000000e+00]\n",
      "[-0.10712898  0.04685128  0.22770664  0.16109306  1.1212413   0.\n",
      "  0.7834642  -0.8591723   1.         -0.5802632   0.8002918   0.5137323\n",
      " -1.          0.          0.33403462  0.3398983   0.35378373  0.37703514\n",
      "  0.41217405  0.47304967  0.56983304  0.7126859   0.94970566  1.        ]\n",
      "[-0.07821451  0.05787405  0.22461066  0.15385023  1.1205268  -0.00294593\n",
      "  0.6659872  -1.001031    1.         -0.5042023   1.0005945   0.40849614\n",
      " -0.9994405   0.          0.34154925  0.34754485  0.36160338  0.3853577\n",
      "  0.4210428   0.48487273  0.5817889   0.7243763   0.9682489   1.        ]\n",
      "[-0.03429625  0.08787333  0.23141061  0.14562851  1.0639937  -0.6795419\n",
      "  0.6476498   0.04798159  1.         -0.44053024  0.82341665  0.29801393\n",
      " -1.          0.          0.34876528  0.35488757  0.3691048   0.39313462\n",
      "  0.42953986  0.49610838  0.59324765  0.73549896  0.9859787   1.        ]\n",
      "[ 0.00740382  0.08379854  0.22250491  0.12585041  1.0420847  -0.19402692\n",
      "  0.50168884 -1.0000001   1.         -0.36361426  0.9999996   0.1691413\n",
      " -1.359682    1.          0.35506025  0.36129302  0.3756396   0.39989722\n",
      "  0.4376248   0.50546306  0.6032168   0.7450752   1.          1.        ]\n",
      "[ 0.05018289  0.08570164  0.22428122  0.10361256  1.0272466  -0.17120704\n",
      "  0.38425785 -1.0000001   1.         -0.297679    0.8308715   0.06790656\n",
      " -0.9999988   1.          0.36028084  0.36660525  0.38103944  0.40545925\n",
      "  0.44487113  0.5132615   0.6114268   0.75274503  1.          1.        ]\n",
      "[ 0.0872121   0.0740454   0.2225044   0.07264918  1.0501938   0.30712906\n",
      "  0.26822722 -1.          0.         -0.24317363  0.6911243  -0.04845881\n",
      " -0.9999998   1.          0.36406362  0.3703991   0.3849229   0.4094203\n",
      "  0.45025277  0.5189725   0.61728925  0.7578973   1.          1.        ]\n",
      "[ 0.12487848  0.07496617  0.23139863  0.03668364  1.114994    0.8405426\n",
      "  0.15861034 -1.0000001   0.         -0.2373402   0.10216826 -0.1604687\n",
      " -0.99999994  0.          0.3661728   0.372432    0.38703552  0.41150433\n",
      "  0.4534893   0.5222652   0.6203235   0.760237    1.          1.        ]\n",
      "[ 1.9125955e-01  1.3263275e-01  2.5924781e-01  2.3793163e-02\n",
      "  1.1129917e+00  1.1920929e-07  4.4020593e-02 -1.0000000e+00\n",
      "  0.0000000e+00 -3.0752647e-01 -8.5041577e-01 -2.7701080e-01\n",
      " -9.9999982e-01  0.0000000e+00  3.6782950e-01  3.7399378e-01\n",
      "  3.8865855e-01  4.1305530e-01  4.5619446e-01  5.2492642e-01\n",
      "  6.2246901e-01  7.6217532e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 2.5934243e-01  1.3593951e-01  2.6318598e-01  4.4984017e-03\n",
      "  1.1114523e+00  2.3841858e-07 -6.9704056e-02 -1.0000000e+00\n",
      "  0.0000000e+00 -3.9124599e-01 -1.0000000e+00 -3.9034414e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.6858159e-01  3.7463540e-01\n",
      "  3.8932532e-01  4.1359371e-01  4.5773643e-01  5.2627885e-01\n",
      "  6.2315154e-01  7.6239109e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 3.2531315e-01  1.3184617e-01  2.6539224e-01 -8.7539665e-03\n",
      "  1.1096587e+00  1.7881393e-07 -1.8470180e-01 -9.9999994e-01\n",
      "  0.0000000e+00 -4.7431880e-01 -1.0261899e+00 -4.6008837e-01\n",
      " -5.9359235e-01  0.0000000e+00  3.6870638e-01  3.7463948e-01\n",
      "  3.8918662e-01  4.1343156e-01  4.5846862e-01  5.2672219e-01\n",
      "  6.2282228e-01  7.6141888e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 3.8439399e-01  1.1805544e-01  2.7133593e-01 -8.0455551e-03\n",
      "  1.1081545e+00  1.1920929e-07 -3.0007374e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -5.5593079e-01 -1.0000001e+00 -3.3750844e-01\n",
      "  9.9999976e-01  0.0000000e+00  3.6884192e-01  3.7465170e-01\n",
      "  3.8903871e-01  4.1327441e-01  4.5922816e-01  5.2718735e-01\n",
      "  6.2249810e-01  7.6043880e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 4.3573019e-01  1.0259931e-01  2.5819233e-01 -2.5256779e-02\n",
      "  1.1055378e+00 -5.9604645e-08 -2.5362802e-01  3.4379688e-01\n",
      "  0.0000000e+00 -6.3746506e-01 -9.9999988e-01 -2.1467721e-01\n",
      "  1.0000001e+00  0.0000000e+00  3.6812347e-01  3.7380293e-01\n",
      "  3.8800892e-01  4.1223109e-01  4.5885327e-01  5.2605087e-01\n",
      "  6.2082636e-01  7.5790930e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 4.9880293e-01  1.2599705e-01  2.6122034e-01 -6.3546874e-02\n",
      "  1.1052948e+00  5.9604645e-08 -2.7620459e-01 -2.2182554e-01\n",
      "  0.0000000e+00 -7.1536249e-01 -9.3149203e-01 -3.2829022e-01\n",
      " -9.9999934e-01  0.0000000e+00  3.6557552e-01  3.7115929e-01\n",
      "  3.8512316e-01  4.0984297e-01  4.5619506e-01  5.2230304e-01\n",
      "  6.1630774e-01  7.5203949e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 5.6296724e-01  1.2822309e-01  2.6458317e-01 -8.1206024e-02\n",
      "  1.1044261e+00  1.1920929e-07 -3.1394958e-01 -3.4906816e-01\n",
      "  0.0000000e+00 -7.9844373e-01 -1.0000001e+00 -4.4328105e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.6213940e-01  3.6767069e-01\n",
      "  3.8136262e-01  4.0649322e-01  4.5225167e-01  5.1740319e-01\n",
      "  6.1044675e-01  7.4459106e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 6.2236637e-01  1.1867339e-01  2.5705832e-01 -9.8912418e-02\n",
      "  1.1013801e+00 -5.9604645e-08 -2.5916255e-01  4.0400925e-01\n",
      "  0.0000000e+00 -8.8174158e-01 -9.9999988e-01 -5.5853963e-01\n",
      " -9.9999982e-01  0.0000000e+00  3.5785019e-01  3.6331597e-01\n",
      "  3.7671158e-01  4.0213239e-01  4.4719088e-01  5.1132840e-01\n",
      "  6.0322297e-01  7.3556268e-01  9.9991465e-01  1.0000000e+00]\n",
      "[ 6.5451485e-01  8.1361130e-02  2.3254800e-01 -9.8675728e-02\n",
      "  1.1050062e+00  5.9604645e-08 -1.3222051e-01  9.4566327e-01\n",
      "  0.0000000e+00 -8.3492273e-01  0.0000000e+00 -6.7200184e-01\n",
      " -6.6075993e-01  0.0000000e+00  3.5360065e-01  3.5900152e-01\n",
      "  3.7212417e-01  3.9772588e-01  4.4212657e-01  5.0532955e-01\n",
      "  5.9611011e-01  7.2674668e-01  9.8771274e-01  1.0000000e+00]\n",
      "[ 6.9124454e-01  7.5204581e-02  2.3800850e-01 -1.1032741e-01\n",
      "  1.1005278e+00 -1.7881393e-07 -3.4408569e-03  1.0000000e+00\n",
      "  0.0000000e+00 -8.3491087e-01  0.0000000e+00 -6.3491249e-01\n",
      "  1.3907750e-07  0.0000000e+00  3.4885344e-01  3.5418180e-01\n",
      "  3.6700222e-01  3.9279225e-01  4.3646276e-01  4.9863085e-01\n",
      "  5.8816999e-01  7.1691501e-01  9.7409189e-01  1.0000000e+00]\n",
      "[ 7.2432607e-01  6.7567430e-02  2.4497347e-01 -1.1720139e-01\n",
      "  1.0967264e+00  2.6822090e-07  1.2529427e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3491004e-01  0.0000000e+00 -5.1417673e-01\n",
      "  9.9999976e-01  0.0000000e+00  3.4363320e-01  3.4876105e-01\n",
      "  3.6138105e-01  3.8732052e-01  4.3020737e-01  4.9127534e-01\n",
      "  5.7946259e-01  7.0617342e-01  9.5915473e-01  1.0000000e+00]\n",
      "[ 0.7425452   0.03742404  0.2538466  -0.14899549  1.1479213   0.73273253\n",
      "  0.2626735   0.9999998   0.         -0.8349102   0.         -0.39386237\n",
      "  1.0000004   0.          0.33691508  0.34181285  0.35418144  0.38013515\n",
      "  0.42207322  0.48184243  0.5683305   0.6925649   0.94005805  1.        ]\n",
      "[ 7.6571828e-01  4.6525516e-02  2.4650779e-01 -1.5630406e-01\n",
      "  1.1349089e+00  2.3841858e-07  5.1170933e-01  1.8570471e+00\n",
      "  0.0000000e+00 -8.3490938e-01  0.0000000e+00 -2.9343855e-01\n",
      " -1.3672090e+00  1.0000000e+00  3.2988539e-01  3.3455393e-01\n",
      "  3.4665984e-01  3.7256700e-01  4.1353291e-01  4.7198358e-01\n",
      "  5.5670762e-01  6.7839974e-01  9.2011946e-01  1.0000000e+00]\n",
      "[ 7.9173452e-01  5.1950943e-02  2.4879652e-01 -1.7329831e-01\n",
      "  1.1319842e+00  1.1920929e-07  6.3702416e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3473194e-01  0.0000000e+00 -3.4966850e-01\n",
      " -5.4272032e-01  1.0000000e+00  3.2200217e-01  3.2642967e-01\n",
      "  3.3824161e-01  3.6401099e-01  4.0391535e-01  4.6094364e-01\n",
      "  5.4370904e-01  6.6261822e-01  8.9782089e-01  1.0000000e+00]\n",
      "[ 8.1189871e-01  4.0217072e-02  2.4823874e-01 -1.8200460e-01\n",
      "  1.1302767e+00  2.9802322e-08  7.6359642e-01  1.0211993e+00\n",
      "  0.0000000e+00 -8.3490920e-01  0.0000000e+00 -4.1239512e-01\n",
      " -5.0699025e-01  1.0000000e+00  3.1371909e-01  3.1790003e-01\n",
      "  3.2940331e-01  3.5499173e-01  3.9379281e-01  4.4935042e-01\n",
      "  5.3006607e-01  6.4607990e-01  8.7441695e-01  1.0000000e+00]\n",
      "[ 8.2498759e-01  2.6225016e-02  2.4359399e-01 -1.8773024e-01\n",
      "  1.1294599e+00  1.4901161e-08  8.7702382e-01  9.3222737e-01\n",
      "  0.0000000e+00 -8.3491081e-01  0.0000000e+00 -4.7318089e-01\n",
      " -5.0859898e-01  1.0000000e+00  3.0514684e-01  3.0908033e-01\n",
      "  3.2027534e-01  3.4562454e-01  3.8329762e-01  4.3736014e-01\n",
      "  5.1596385e-01  6.2901390e-01  8.5034060e-01  1.0000000e+00]\n",
      "[ 8.3330888e-01  1.6949715e-02  2.4527851e-01 -1.9135273e-01\n",
      "  1.1294661e+00 -1.0430813e-07  9.9686575e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3491027e-01  0.0000000e+00 -5.7412148e-01\n",
      " -9.6766180e-01  1.0000000e+00  2.9638523e-01  3.0007932e-01\n",
      "  3.1140813e-01  3.3605552e-01  3.7258029e-01  4.2512280e-01\n",
      "  5.0157279e-01  6.1160499e-01  8.2650340e-01  1.0000000e+00]\n",
      "[ 8.4432197e-01  1.7169120e-02  2.2986774e-01 -1.9311896e-01\n",
      "  1.1352067e+00  1.1175871e-07  9.3493176e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3498651e-01  0.0000000e+00 -5.6283236e-01\n",
      " -3.9894494e-01  1.0000000e+00  2.8733149e-01  2.9091272e-01\n",
      "  3.0230534e-01  3.2623225e-01  3.6161178e-01  4.1265503e-01\n",
      "  4.8692602e-01  5.9410995e-01  8.0228508e-01  1.0000000e+00]\n",
      "[ 8.4440506e-01  1.6466646e-04  2.2351825e-01 -1.9512597e-01\n",
      "  1.1349155e+00 -1.2456439e-07  9.3490708e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3491069e-01  1.5133992e-09 -6.0526872e-01\n",
      " -3.5345843e-01  1.0000000e+00  2.7823889e-01  2.8170678e-01\n",
      "  2.9315653e-01  3.1635934e-01  3.5059109e-01  4.0013328e-01\n",
      "  4.7221726e-01  5.7703507e-01  7.7796829e-01  1.0000000e+00]\n",
      "[ 8.1877953e-01 -5.0801892e-02  2.3852724e-01 -1.3552502e-01\n",
      "  1.1349225e+00  1.9645691e-03  9.3490767e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3491188e-01 -1.3500452e-05 -6.1517930e-01\n",
      " -9.8876476e-02  1.0000000e+00  2.7189767e-01  2.7528656e-01\n",
      "  2.8702599e-01  3.0974355e-01  3.4309128e-01  3.9141876e-01\n",
      "  4.6192828e-01  5.6470627e-01  7.6081169e-01  1.0000000e+00]\n",
      "[ 7.8557712e-01 -6.6442534e-02  2.7166224e-01 -9.9138662e-02\n",
      "  1.1346657e+00 -3.6925077e-05  9.1799903e-01 -1.4520931e-01\n",
      "  0.0000000e+00 -8.3434731e-01 -1.3679266e-05 -5.9651875e-01\n",
      "  2.7685300e-01  1.0000000e+00  2.6724997e-01  2.7058089e-01\n",
      "  2.8282258e-01  3.0520746e-01  3.3781034e-01  3.8505256e-01\n",
      "  4.5435113e-01  5.5518180e-01  7.4800718e-01  1.0000000e+00]\n",
      "[ 7.5209904e-01 -6.8803020e-02  2.7978426e-01  1.2899196e-03\n",
      "  1.1243368e+00 -7.5179547e-02  9.2270446e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3512700e-01  1.2189150e-05 -5.6223524e-01\n",
      "  2.8691688e-01  1.0000000e+00  2.6781902e-01  2.7115703e-01\n",
      "  2.8426614e-01  3.0676529e-01  3.3914882e-01  3.8589951e-01\n",
      "  4.5516348e-01  5.5478364e-01  7.4883872e-01  1.0000000e+00]\n",
      "[ 7.1395481e-01 -7.7005208e-02  2.9768193e-01  4.2332843e-02\n",
      "  1.1219276e+00  3.6535561e-03  9.2599750e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3511901e-01 -1.5434623e-04 -5.2438307e-01\n",
      "  3.2095405e-01  1.0000000e+00  2.7011067e-01  2.7369496e-01\n",
      "  2.8762200e-01  3.1005627e-01  3.4270853e-01  3.8913181e-01\n",
      "  4.5874026e-01  5.5794924e-01  7.5413537e-01  1.0000000e+00]\n",
      "[ 6.7332447e-01 -8.1379853e-02  3.1770387e-01  4.5314960e-02\n",
      "  1.1209472e+00 -3.9756298e-05  9.2744970e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3499044e-01  1.3113022e-06 -4.9084067e-01\n",
      "  3.9070761e-01  0.0000000e+00  2.7232435e-01  2.7686489e-01\n",
      "  2.9095322e-01  3.1322756e-01  3.4621379e-01  3.9226055e-01\n",
      "  4.6218416e-01  5.6126106e-01  7.5918072e-01  1.0000000e+00]\n",
      "[ 6.3479060e-01 -7.6694392e-02  3.1718165e-01  3.9004870e-02\n",
      "  1.1205316e+00 -2.9802322e-08  8.7037039e-01 -4.9032483e-01\n",
      "  0.0000000e+00 -8.3490795e-01  0.0000000e+00 -4.4392300e-01\n",
      "  3.1955996e-01  1.0000000e+00  2.7413237e-01  2.7961668e-01\n",
      "  2.9384506e-01  3.1593302e-01  3.4896642e-01  3.9482841e-01\n",
      "  4.6497577e-01  5.6381029e-01  7.6316601e-01  1.0000000e+00]\n",
      "[ 0.5884383  -0.09252806  0.3414726   0.03795025  1.0917658  -0.36062938\n",
      "  0.99051464  1.0000001   0.         -0.8349095   0.         -0.38444483\n",
      "  0.45365754  1.          0.2758512   0.28234798  0.29671532  0.3185866\n",
      "  0.35113186  0.3972644   0.46655035  0.5661234   0.7672841   1.        ]\n",
      "[ 0.53683794 -0.10295729  0.36978316  0.03524051  1.1284888   0.24517417\n",
      "  0.9349067   0.          0.         -0.83481055  0.         -0.32150328\n",
      "  0.5147399   0.          0.2777406   0.28495175  0.29927298  0.32106587\n",
      "  0.35305735  0.39922327  0.46722668  0.56798327  0.7712395   1.        ]\n",
      "[ 4.8669630e-01 -1.0035876e-01  3.8426980e-01  4.6088945e-02\n",
      "  1.1279490e+00  8.3446503e-07  9.1040063e-01 -2.1408069e-01\n",
      "  0.0000000e+00 -8.3481020e-01 -1.1920929e-07 -2.5377905e-01\n",
      "  5.4989189e-01  0.0000000e+00  2.8089631e-01  2.8818935e-01\n",
      "  3.0222842e-01  3.2423651e-01  3.5569343e-01  4.0196967e-01\n",
      "  4.6868941e-01  5.7089740e-01  7.7678519e-01  1.0000000e+00]\n",
      "[ 4.3131468e-01 -1.1080434e-01  4.1166899e-01  4.8799433e-02\n",
      "  1.1275116e+00 -3.5762787e-07  9.1163635e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490652e-01  0.0000000e+00 -1.7668366e-01\n",
      "  6.3005680e-01  0.0000000e+00  2.8423169e-01  2.9161134e-01\n",
      "  3.0534595e-01  3.2758105e-01  3.5846129e-01  4.0484890e-01\n",
      "  4.7018823e-01  5.7409656e-01  7.8259903e-01  1.0000000e+00]\n",
      "[ 0.3718729  -0.11888707  0.43591368  0.05394617  1.1237067  -0.04073316\n",
      "  0.9130839   0.          0.         -0.83490616  0.         -0.08931887\n",
      "  0.7113492   0.          0.2878553   0.29532903  0.30874553  0.33053502\n",
      "  0.36150572  0.40802494  0.47191262  0.5786737   0.7890122   1.        ]\n",
      "[ 3.0868426e-01 -1.2649874e-01  4.4506049e-01  6.5131314e-02\n",
      "  1.1209663e+00  3.4189224e-04  8.0148983e-01 -9.9996835e-01\n",
      "  0.0000000e+00 -8.3490711e-01 -1.1384487e-05  9.7872019e-03\n",
      "  8.0799097e-01  0.0000000e+00  2.9200140e-01  2.9910657e-01\n",
      "  3.1269154e-01  3.3387193e-01  3.6513928e-01  4.1187242e-01\n",
      "  4.7431296e-01  5.8423203e-01  7.9847759e-01  1.0000000e+00]\n",
      "[ 0.23772395 -0.14206561  0.47163588  0.0763737   1.0490663  -0.8924317\n",
      "  0.92468405  0.9999997   0.         -0.8349075   0.          0.127298\n",
      "  0.957784    0.          0.29668528  0.3034022   0.31718227  0.33773047\n",
      "  0.3691032   0.41569415  0.47787368  0.590699    0.8106734   1.        ]\n",
      "[ 1.6294408e-01 -1.4972717e-01  4.7740069e-01  6.0104340e-02\n",
      "  1.0108893e+00 -4.6651381e-01  9.2785680e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490670e-01  6.9737434e-06  2.5340539e-01\n",
      "  1.0234095e+00  0.0000000e+00  3.0058852e-01  3.0689716e-01\n",
      "  3.2044825e-01  3.4070498e-01  3.7210628e-01  4.1725215e-01\n",
      "  4.8079386e-01  5.9557861e-01  8.2042402e-01  1.0000000e+00]\n",
      "[ 0.07944351 -0.16739087  0.47803754  0.03865429  1.0229166   0.18969017\n",
      "  0.88633496  1.5419183   1.         -0.8243586   0.14669043  0.37825608\n",
      "  1.          0.          0.3029651   0.3093236   0.3221466   0.3425107\n",
      "  0.3738417   0.41748303  0.48210832  0.5980347   0.82692254  1.        ]\n",
      "[-0.03949266 -0.23730044  0.452727    0.0231382   1.0847552   0.8700881\n",
      "  0.99826217  1.          1.         -0.77601045  0.596528    0.5020922\n",
      "  1.0000002   0.          0.3044926   0.31088316  0.3230015   0.34336904\n",
      "  0.37461808  0.41680622  0.48226163  0.59869426  0.829805    1.        ]\n",
      "[-0.15509072 -0.2310507   0.41532022  0.00692058  1.2571299   2.1739182\n",
      "  0.8807565  -0.9999998   1.         -0.7425701   0.3980795   0.62195706\n",
      "  0.99999994  0.          0.30514884  0.3114789   0.3230028   0.3431943\n",
      "  0.3744274   0.41523936  0.48125815  0.5978547   0.8301767   1.        ]\n",
      "[-0.23167676 -0.17954817  0.41454494  0.0212159   1.1349087   0.\n",
      "  1.3294303   1.5737033   1.         -0.75214195  0.10855448  0.7566476\n",
      "  1.          0.          0.30713755  0.31280643  0.3243794   0.34446692\n",
      "  0.37528455  0.41527742  0.4822281   0.5995223   0.8343888   1.        ]\n",
      "[-2.8125888e-01 -1.4764981e-01  4.1594619e-01  2.9231653e-02\n",
      "  1.1360021e+00  5.9604645e-08  1.4447191e+00  1.8512188e+00\n",
      "  1.0000000e+00 -7.5357836e-01  3.4377646e-01  8.8561934e-01\n",
      "  1.0000001e+00  0.0000000e+00  3.0958125e-01  3.1460461e-01\n",
      "  3.2624415e-01  3.4625795e-01  3.7587216e-01  4.1608831e-01\n",
      "  4.8453912e-01  6.0210228e-01  8.3995348e-01  1.0000000e+00]\n",
      "[-0.2238907  -0.05409531  0.23765616  0.15080161  1.215111    0.06615132\n",
      "  1.2647383   0.02086241  1.         -0.7863944   0.542455    0.9356343\n",
      " -0.43519235  1.          0.32113305  0.32603025  0.3380925   0.35870725\n",
      "  0.38820842  0.43060887  0.50249076  0.62373865  0.8735781   1.        ]\n",
      "[-0.19789803 -0.04089465  0.18087597  0.18118517  1.1768842  -0.03947002\n",
      "  1.2136793  -0.00992123  1.         -0.7702417   0.58371496  0.9305355\n",
      "  0.00149973  1.          0.33235103  0.33718476  0.34956816  0.37087715\n",
      "  0.40038106  0.44486356  0.52004445  0.6457623   0.90715706  1.        ]\n",
      "[-1.8731515e-01 -2.4649112e-03  1.6547285e-01  1.8943094e-01\n",
      "  1.1500444e+00  9.8808948e-04  1.1005738e+00 -3.7958992e-01\n",
      "  1.0000000e+00 -6.9845480e-01  9.9847263e-01  8.0766708e-01\n",
      " -1.0013772e+00  0.0000000e+00  3.4237963e-01  3.4713012e-01\n",
      "  3.5978869e-01  3.8172069e-01  4.1117656e-01  4.5753795e-01\n",
      "  5.3568286e-01  6.6538578e-01  9.3713123e-01  1.0000000e+00]\n",
      "[-0.16984822  0.03689288  0.16346723  0.19026564  1.1114268   0.\n",
      "  0.9348966  -0.74022955  1.         -0.6168466   0.9999997   0.69014084\n",
      " -1.0000004   0.          0.35178575  0.35643628  0.36934185  0.3918562\n",
      "  0.42118907  0.46934333  0.5502966   0.6837278   0.96395767  1.        ]\n",
      "[-0.14159608  0.05666259  0.16199656  0.17998606  1.1108675  -0.00312316\n",
      "  0.8157525  -1.001102    1.         -0.53909093  0.98135644  0.57288384\n",
      " -1.0000454   0.          0.36035535  0.36511913  0.37824804  0.40086746\n",
      "  0.43047002  0.48032084  0.5636384   0.70090544  0.98871046  1.        ]\n",
      "[-0.0980858   0.08702799  0.16596074  0.16921534  1.0911794  -0.23609781\n",
      "  0.69877964 -0.9999998   1.         -0.48778197  0.67757404  0.46170408\n",
      " -1.0000001   1.          0.36842895  0.37329945  0.38663343  0.40896732\n",
      "  0.439168    0.4906351   0.5760201   0.71881616  1.          1.        ]\n",
      "[-0.05787182  0.08052394  0.16273035  0.15040661  1.0771629  -0.15813515\n",
      "  0.58151436 -1.          0.         -0.42783904  0.759757    0.34466535\n",
      " -0.99999976  1.          0.3756533   0.38061932  0.39413133  0.4161717\n",
      "  0.44719118  0.5001413   0.5870771   0.7348722   1.          1.        ]\n",
      "[-0.01037552  0.09491628  0.16694447  0.14285295  1.0219526  -0.6659195\n",
      "  0.4674843  -1.0000001   0.         -0.37307283  0.72866446  0.2380206\n",
      " -1.0000002   0.          0.38250375  0.38756034  0.401236    0.4229621\n",
      "  0.45497283  0.5093766   0.5975406   0.75012493  1.          1.        ]\n",
      "[ 0.03590965  0.0926403   0.16534993  0.11898948  0.98194075 -0.46809635\n",
      "  0.35191143 -1.          1.         -0.3207263   0.66547287  0.12204409\n",
      " -0.99999994  0.          0.38827702  0.3934099   0.40721405  0.42860997\n",
      "  0.46148703  0.51714474  0.60632014  0.76302963  1.          1.        ]\n",
      "[ 0.08069105  0.08948006  0.16443421  0.09597466  0.9540871  -0.33148286\n",
      "  0.23632264 -1.          0.         -0.27397984  0.61631787  0.01466745\n",
      " -1.          0.          0.39294294  0.39810053  0.4120331   0.43307623\n",
      "  0.4666942   0.5234034   0.613365    0.7734355   1.          1.        ]\n",
      "[ 0.13049161  0.09959526  0.17121303  0.07116743  0.9293986  -0.2802228\n",
      "  0.12043256 -1.          0.         -0.25562215  0.24092287 -0.10196221\n",
      " -0.99999994  0.          0.39649794  0.40163088  0.41568702  0.43633762\n",
      "  0.47057867  0.5281438   0.6186597   0.7809694   1.          1.        ]\n",
      "[ 0.17935736  0.09762481  0.1752678   0.04167384  0.9386257   0.13244206\n",
      "  0.00494063 -1.0000001   0.         -0.2690478  -0.149851   -0.21746099\n",
      " -0.9999998   0.          0.39866897  0.40375987  0.41789052  0.43810755\n",
      "  0.47282094  0.5309945   0.62190676  0.7856144   1.          1.        ]\n",
      "[ 0.21819492  0.07731695  0.17205147  0.01060897  1.0060451   0.8647188\n",
      " -0.10440993 -1.0000001   0.         -0.29442826 -0.2815932  -0.33202314\n",
      " -1.0000002   0.          0.3993389   0.40437138  0.41852346  0.4382797\n",
      "  0.47329375  0.5317998   0.6228795   0.7871223   1.          1.        ]\n",
      "[ 0.25904673  0.08134693  0.19087964 -0.00239588  1.0838823   1.0000007\n",
      " -0.21190202 -1.0000001   0.         -0.37505588 -1.0000002  -0.2888875\n",
      "  0.3450202   0.          0.39941427  0.40437448  0.4183829   0.43775833\n",
      "  0.47303003  0.53178275  0.6228844   0.7873997   1.          1.        ]\n",
      "[ 0.28572777  0.05303779  0.17922118 -0.00701027  1.1615863   1.0000002\n",
      " -0.2434721  -0.35122585  0.         -0.41530135 -0.47185123 -0.16549492\n",
      "  1.0000002   0.          0.3992303   0.40411958  0.41765347  0.4369951\n",
      "  0.4724807   0.53141916  0.62247896  0.7871283   1.          1.        ]\n",
      "[ 3.2566395e-01  7.2532795e-02  1.5923946e-01 -2.1107690e-02\n",
      "  1.1349143e+00  3.5762787e-07 -8.6472392e-02  1.0000001e+00\n",
      "  0.0000000e+00 -4.1558903e-01  7.1436703e-02 -2.7885342e-01\n",
      " -9.9999970e-01  0.0000000e+00  3.9864290e-01  4.0346527e-01\n",
      "  4.1658038e-01  4.3587232e-01  4.7149676e-01  5.3051972e-01\n",
      "  6.2143815e-01  7.8599983e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.37229005  0.09317504  0.18596148 -0.02328992  1.1038027  -0.3375209\n",
      "  0.03989154  0.99999994  0.         -0.49689272 -1.         -0.15610015\n",
      "  1.0000004   0.          0.39776048  0.40250245  0.41512623  0.43435082\n",
      "  0.4701154   0.52920145  0.61990666  0.78427166  1.          1.        ]\n",
      "[ 4.2487285e-01  1.0511151e-01  2.0183899e-01 -4.3244418e-02\n",
      "  1.1025873e+00  5.9604645e-08 -6.0762048e-02 -8.6755246e-01\n",
      "  0.0000000e+00 -5.7804745e-01 -1.0000001e+00 -3.4039974e-02\n",
      "  9.9999982e-01  0.0000000e+00  3.9595813e-01  4.0060341e-01\n",
      "  4.1268715e-01  4.3183494e-01  4.6761951e-01  5.2661932e-01\n",
      "  6.1688590e-01  7.8063107e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.47424176  0.09858517  0.18330035 -0.0734689   1.0800952  -0.22300303\n",
      "  0.06748158  0.9999998   0.         -0.641749   -0.7787485  -0.08922493\n",
      " -0.48808894  0.          0.3927227   0.39726204  0.40884042  0.42799842\n",
      "  0.4634651   0.5220949   0.6115709   0.77398497  1.          1.        ]\n",
      "[ 0.5261064   0.10339785  0.20853384 -0.11359303  1.1390655   0.76611114\n",
      " -0.0410707  -0.9999998   0.         -0.72590965 -1.         -0.20165205\n",
      " -1.0000001   0.          0.38760775  0.39200976  0.40299684  0.42206788\n",
      "  0.45704308  0.5149659   0.60321635  0.7634284   1.          1.        ]\n",
      "[ 0.5906402   0.12799585  0.20772347 -0.11486807  1.1349078   0.\n",
      " -0.15217042 -0.9999998   0.         -0.8097749  -1.0000002  -0.31504595\n",
      " -1.0000001   0.          0.3824089   0.3867517   0.39715672  0.4161356\n",
      "  0.45061925  0.50781834  0.59485257  0.7528548   1.          1.        ]\n",
      "[ 0.6394294   0.09755359  0.1851015  -0.11704407  1.1334496   0.\n",
      " -0.26843917 -0.99999994  0.         -0.81059015  0.         -0.43224502\n",
      " -1.0000001   0.          0.3770325   0.38131425  0.39119276  0.41003814\n",
      "  0.444024    0.50045234  0.5862034   0.7418797   1.          1.        ]\n",
      "[ 6.8072319e-01  8.2577743e-02  1.7375821e-01 -1.3760388e-01\n",
      "  1.1317312e+00 -5.9604645e-08 -2.3418212e-01  2.5934663e-01\n",
      "  0.0000000e+00 -8.1137645e-01  0.0000000e+00 -5.5061901e-01\n",
      " -1.0000000e+00  0.0000000e+00  3.7067127e-01  3.7488079e-01\n",
      "  3.8425237e-01  4.0288079e-01  4.3631354e-01  4.9177590e-01\n",
      "  5.7596999e-01  7.2883165e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 7.1724552e-01  7.2919995e-02  1.6751111e-01 -1.5679024e-01\n",
      "  1.1270697e+00  2.3841858e-07 -1.0660553e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.1280237e-01  0.0000000e+00 -6.6733742e-01\n",
      " -1.0000000e+00  0.0000000e+00  3.6340642e-01  3.6753345e-01\n",
      "  3.7640414e-01  3.9474520e-01  4.2751071e-01  4.8189330e-01\n",
      "  5.6428283e-01  7.1388775e-01  9.9703968e-01  1.0000000e+00]\n",
      "[ 7.5036281e-01  6.5099448e-02  1.7355464e-01 -1.6353922e-01\n",
      "  1.1222420e+00  2.9802322e-07  2.0368993e-02  1.0000001e+00\n",
      "  0.0000000e+00 -8.1938881e-01  0.0000000e+00 -6.3490772e-01\n",
      " -5.9604645e-08  0.0000000e+00  3.5591859e-01  3.5996056e-01\n",
      "  3.6830467e-01  3.8635477e-01  4.1843733e-01  4.7168764e-01\n",
      "  5.5223691e-01  6.9849080e-01  9.7618258e-01  1.0000000e+00]\n",
      "[ 7.7926439e-01  5.7662826e-02  1.7928255e-01 -1.6983122e-01\n",
      "  1.1177046e+00  2.6822090e-07  1.4782202e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.2321483e-01  0.0000000e+00 -5.1102674e-01\n",
      "  9.9999976e-01  0.0000000e+00  3.4802064e-01  3.5197294e-01\n",
      "  3.5977733e-01  3.7751254e-01  4.0886757e-01  4.6090007e-01\n",
      "  5.3953129e-01  6.8224204e-01  9.5418048e-01  1.0000000e+00]\n",
      "[ 8.0635202e-01  5.4000720e-02  1.8019390e-01 -1.8651022e-01\n",
      "  1.1137830e+00 -2.0861626e-07  2.7511382e-01  9.9999994e-01\n",
      "  0.0000000e+00 -8.2722479e-01  0.0000000e+00 -3.8629019e-01\n",
      "  1.0000004e+00  0.0000000e+00  3.3933538e-01  3.4296551e-01\n",
      "  3.5044301e-01  3.6781007e-01  3.9834541e-01  4.4903886e-01\n",
      "  5.2555913e-01  6.6435027e-01  9.2997807e-01  1.0000000e+00]\n",
      "[ 8.3176470e-01  5.0642274e-02  1.8122220e-01 -2.0319229e-01\n",
      "  1.1102321e+00  1.7881393e-07  4.0203309e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3121604e-01  0.0000000e+00 -3.7879527e-01\n",
      " -1.4597207e+00  1.0000000e+00  3.2986173e-01  3.3303955e-01\n",
      "  3.4030062e-01  3.5724619e-01  3.8686967e-01  4.3610269e-01\n",
      "  5.1031858e-01  6.4440483e-01  9.0357214e-01  1.0000000e+00]\n",
      "[ 8.5456914e-01  4.5889426e-02  1.8180847e-01 -2.2499923e-01\n",
      "  1.1081796e+00  2.0861626e-07  5.2809668e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3051848e-01  0.0000000e+00 -3.9718652e-01\n",
      " -5.5952913e-01  1.0000000e+00  3.1927121e-01  3.2199445e-01\n",
      "  3.2901472e-01  3.4546259e-01  3.7408981e-01  4.2164361e-01\n",
      "  4.9331188e-01  6.2190700e-01  8.7370980e-01  1.0000000e+00]\n",
      "[ 8.7192667e-01  3.4587041e-02  1.8155275e-01 -2.3268245e-01\n",
      "  1.1056933e+00  2.0861626e-07  6.5249026e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3078712e-01  0.0000000e+00 -4.6346414e-01\n",
      " -5.3988647e-01  1.0000000e+00  3.0839860e-01  3.1066906e-01\n",
      "  3.1744242e-01  3.3337218e-01  3.6099750e-01  4.0680003e-01\n",
      "  4.7608829e-01  5.9879422e-01  8.4264892e-01  1.0000000e+00]\n",
      "[ 8.8343465e-01  2.2809666e-02  1.7847097e-01 -2.4167117e-01\n",
      "  1.1042045e+00  5.9604645e-08  7.7529645e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3163315e-01  0.0000000e+00 -5.3138638e-01\n",
      " -5.7571465e-01  1.0000000e+00  2.9710087e-01  2.9892448e-01\n",
      "  3.0544177e-01  3.2082087e-01  3.4740612e-01  3.9137706e-01\n",
      "  4.5820075e-01  5.7475042e-01  8.1036007e-01  1.0000000e+00]\n",
      "[ 8.8637269e-01  5.6729829e-03  1.7398489e-01 -2.4362203e-01\n",
      "  1.1035627e+00  1.8626451e-08  8.9630318e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3244002e-01  0.0000000e+00 -5.8734024e-01\n",
      " -4.7339284e-01  0.0000000e+00  2.8569773e-01  2.8708372e-01\n",
      "  2.9334283e-01  3.0815914e-01  3.3369514e-01  3.7581080e-01\n",
      "  4.4015166e-01  5.5046695e-01  7.7776223e-01  1.0000000e+00]\n",
      "[ 8.8050008e-01 -1.1953013e-02  1.7003919e-01 -2.4727836e-01\n",
      "  1.1036382e+00 -7.4505806e-09  1.0286582e+00  1.1094785e+00\n",
      "  0.0000000e+00 -8.3328474e-01  0.0000000e+00 -6.3739955e-01\n",
      " -4.2425701e-01  0.0000000e+00  2.7410862e-01  2.7506456e-01\n",
      "  2.8106162e-01  2.9529837e-01  3.1976867e-01  3.5999128e-01\n",
      "  4.2181414e-01  5.2577055e-01  7.4348491e-01  1.0000000e+00]\n",
      "[ 8.5741735e-01 -4.1308884e-02  2.1159512e-01 -1.4452282e-01\n",
      "  1.1336613e+00  3.1887293e-03  9.3490791e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3450907e-01 -1.9222498e-05 -6.3142025e-01\n",
      "  1.7213316e-01  1.0000000e+00  2.6745468e-01  2.6785743e-01\n",
      "  2.7369738e-01  2.8776029e-01  3.1160590e-01  3.5089523e-01\n",
      "  4.1116261e-01  5.1211196e-01  7.2405690e-01  1.0000000e+00]\n",
      "[ 8.2822865e-01 -6.1263420e-02  2.2325788e-01 -9.5108226e-03\n",
      "  1.1289678e+00 -1.1848211e-02  9.3491137e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3525383e-01  3.9556623e-04 -6.0091710e-01\n",
      "  2.7849087e-01  0.0000000e+00  2.6764521e-01  2.6746842e-01\n",
      "  2.7329990e-01  2.8767669e-01  3.1151539e-01  3.5112998e-01\n",
      "  4.1122857e-01  5.1302123e-01  7.2535723e-01  1.0000000e+00]\n",
      "[ 7.9772907e-01 -6.2370583e-02  2.3562297e-01  4.7104802e-02\n",
      "  1.1265457e+00  2.8328598e-03  9.3491042e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3524722e-01 -1.2272596e-04 -5.7393754e-01\n",
      "  2.5956970e-01  0.0000000e+00  2.6980013e-01  2.6949784e-01\n",
      "  2.7537355e-01  2.9025358e-01  3.1466666e-01  3.5471115e-01\n",
      "  4.1512847e-01  5.1948011e-01  7.3412883e-01  1.0000000e+00]\n",
      "[ 7.6494884e-01 -6.5992720e-02  2.5357687e-01  5.0337877e-02\n",
      "  1.1251581e+00 -2.8505921e-04  9.3490922e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3516431e-01  9.6261501e-06 -5.5798864e-01\n",
      "  3.1543040e-01  1.0000000e+00  2.7173147e-01  2.7142704e-01\n",
      "  2.7773330e-01  2.9274958e-01  3.1777897e-01  3.5821953e-01\n",
      "  4.1892770e-01  5.2588165e-01  7.4248356e-01  1.0000000e+00]\n",
      "[ 7.2970515e-01 -7.0046373e-02  2.5538486e-01  4.1722964e-02\n",
      "  1.1248538e+00 -2.3841858e-07  9.3490863e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3505470e-01  0.0000000e+00 -5.0230646e-01\n",
      "  2.9185972e-01  1.0000000e+00  2.7307487e-01  2.7276891e-01\n",
      "  2.7949584e-01  2.9460740e-01  3.2018614e-01  3.6079454e-01\n",
      "  4.2189530e-01  5.3102160e-01  7.4866092e-01  1.0000000e+00]\n",
      "[ 6.9207227e-01 -7.5369462e-02  2.7392429e-01  4.5536205e-02\n",
      "  1.1246885e+00 -2.3841858e-07  9.3490684e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3088243e-01  3.4074217e-02 -4.6915019e-01\n",
      "  3.3885017e-01  0.0000000e+00  2.7441633e-01  2.7410886e-01\n",
      "  2.8128463e-01  2.9649293e-01  3.2265031e-01  3.6330917e-01\n",
      "  4.2520946e-01  5.3632540e-01  7.5500774e-01  1.0000000e+00]\n",
      "[ 6.5416175e-01 -7.5820945e-02  2.9297608e-01  5.0859552e-02\n",
      "  1.1243591e+00  8.9406967e-08  9.0703702e-01 -2.3777245e-01\n",
      "  0.0000000e+00 -8.3070475e-01  0.0000000e+00 -4.2246914e-01\n",
      "  3.8678670e-01  0.0000000e+00  2.7594170e-01  2.7563256e-01\n",
      "  2.8329071e-01  2.9860747e-01  3.2539359e-01  3.6611852e-01\n",
      "  4.2889729e-01  5.4218984e-01  7.6205146e-01  1.0000000e+00]\n",
      "[ 6.1520231e-01 -7.8203909e-02  2.9920113e-01  6.0785446e-02\n",
      "  1.1222943e+00  2.0563602e-06  7.9625821e-01 -9.6687317e-01\n",
      "  0.0000000e+00 -8.3098304e-01 -2.9802322e-07 -3.6905229e-01\n",
      "  4.2869887e-01  0.0000000e+00  2.7790976e-01  2.7775639e-01\n",
      "  2.8576577e-01  3.0143502e-01  3.2869536e-01  3.6954090e-01\n",
      "  4.3332902e-01  5.4904503e-01  7.7043885e-01  1.0000000e+00]\n",
      "[ 5.7287395e-01 -8.5001729e-02  3.2209259e-01  6.5590829e-02\n",
      "  1.1190584e+00 -1.3792515e-04  6.8459153e-01 -1.0000138e+00\n",
      "  0.0000000e+00 -8.3144689e-01  4.5299530e-06 -3.0936861e-01\n",
      "  4.8151013e-01  0.0000000e+00  2.8002879e-01  2.8034663e-01\n",
      "  2.8843069e-01  3.0469531e-01  3.3225048e-01  3.7322581e-01\n",
      "  4.3810076e-01  5.5570936e-01  7.7946973e-01  1.0000000e+00]\n",
      "[ 0.51842165 -0.10922547  0.34767976  0.06555148  1.0850468  -0.41703856\n",
      "  0.80755746  1.          0.         -0.8320287   0.         -0.23371327\n",
      "  0.60624486  0.          0.2820255   0.28285116  0.29100746  0.30789372\n",
      "  0.33573815  0.37681535  0.44278637  0.5622998   0.7878052   1.        ]\n",
      "[ 0.45709014 -0.12266059  0.37729353  0.05709007  1.1317959   0.604673\n",
      "  0.7168125  -0.78327656  0.         -0.8318282   0.         -0.15049934\n",
      "  0.68346673  0.          0.28352237  0.28489268  0.29310784  0.31061623\n",
      "  0.33845025  0.37980777  0.4467853   0.56803864  0.794921    1.        ]\n",
      "[ 3.8793993e-01 -1.3852398e-01  4.0114841e-01  6.3884854e-02\n",
      "  1.1312402e+00 -2.9802322e-07  8.3900905e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3265483e-01  0.0000000e+00 -4.7289610e-02\n",
      "  8.1260937e-01  0.0000000e+00  2.8558290e-01  2.8717360e-01\n",
      "  2.9574800e-01  3.1363398e-01  3.4141722e-01  3.8333273e-01\n",
      "  4.5207173e-01  5.7437438e-01  8.0279797e-01  1.0000000e+00]\n",
      "[ 3.2588533e-01 -1.2433437e-01  4.2217028e-01  7.9539716e-02\n",
      "  1.1293578e+00  9.5367432e-07  7.8273582e-01 -5.1033098e-01\n",
      "  0.0000000e+00 -8.3328617e-01 -1.1920929e-07  5.3276896e-02\n",
      "  8.1582659e-01  1.0000000e+00  2.8857529e-01  2.9018268e-01\n",
      "  2.9937407e-01  3.1747937e-01  3.4526160e-01  3.8811877e-01\n",
      "  4.5902413e-01  5.8234233e-01  8.1277412e-01  1.0000000e+00]\n",
      "[ 2.5001988e-01 -1.5197745e-01  4.5075965e-01  7.8052625e-02\n",
      "  1.1118182e+00 -2.1245992e-01  9.0463126e-01  9.9999791e-01\n",
      "  0.0000000e+00 -8.3420366e-01 -2.9802322e-07  1.7846435e-01\n",
      "  1.0063344e+00  1.0000000e+00  2.9138818e-01  2.9301125e-01\n",
      "  3.0284637e-01  3.2115212e-01  3.4891015e-01  3.9270711e-01\n",
      "  4.6579799e-01  5.9055793e-01  8.2215571e-01  1.0000000e+00]\n",
      "[ 1.7561767e-01 -1.4897443e-01  4.5162311e-01  6.5475374e-02\n",
      "  1.1110493e+00  1.3458729e-04  9.0668488e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3309239e-01  2.6823401e-02  3.0330729e-01\n",
      "  1.0023924e+00  1.0000000e+00  2.9360434e-01  2.9547930e-01\n",
      "  3.0569413e-01  3.2385412e-01  3.5184571e-01  3.9647931e-01\n",
      "  4.7155473e-01  5.9749675e-01  8.2977277e-01  1.0000000e+00]\n",
      "[ 1.07227676e-01 -1.37274608e-01  4.52911288e-01  5.71946464e-02\n",
      "  1.10782909e+00  4.83632088e-04  7.96090603e-01 -9.99956131e-01\n",
      "  0.00000000e+00 -8.35021138e-01 -1.58548355e-05  4.28573906e-01\n",
      "  9.97785091e-01  1.00000000e+00  2.95420676e-01  2.97829747e-01\n",
      "  3.08125824e-01  3.26117665e-01  3.54355127e-01  3.99708003e-01\n",
      "  4.76629138e-01  6.03589952e-01  8.36292267e-01  1.00000000e+00]\n",
      "[ 3.1882428e-02 -1.5122050e-01  4.5528609e-01  4.4909526e-02\n",
      "  1.1028050e+00 -7.7486038e-07  8.4957463e-01  1.6717577e+00\n",
      "  1.0000000e+00 -8.2773840e-01  1.0969663e-01  5.5300409e-01\n",
      "  9.9999982e-01  0.0000000e+00  2.9662043e-01  2.9955909e-01\n",
      "  3.0991495e-01  3.2770455e-01  3.5647336e-01  4.0227690e-01\n",
      "  4.8004121e-01  6.0837561e-01  8.4111696e-01  1.0000000e+00]\n",
      "[-0.0348714  -0.13155659  0.37832466  0.0761129   1.0859749   0.00339711\n",
      "  0.97574186  1.0003612   1.         -0.81798     0.09203422  0.6733187\n",
      "  0.9999626   0.          0.29976618  0.30305088  0.3133714   0.33126453\n",
      "  0.360695    0.4079615   0.4862247   0.6161976   0.8499878   1.        ]\n",
      "[-0.10504368 -0.14033023  0.33327577  0.0752318   1.1753287   1.1264532\n",
      "  0.91536707 -0.525132    1.         -0.75633925  0.7625813   0.6958168\n",
      "  0.19263452  0.          0.30299172  0.30631176  0.31652394  0.33459708\n",
      "  0.3646363   0.41324443  0.4919836   0.62328285  0.8572859   1.        ]\n",
      "[-1.1074027e-01 -4.6110705e-02  2.2234125e-01  1.6181953e-01\n",
      "  1.1453607e+00  7.2892308e-03  9.4115955e-01  1.5274684e-04\n",
      "  1.0000000e+00 -6.9673198e-01  1.0004451e+00  6.0056251e-01\n",
      " -8.8038462e-01  0.0000000e+00  3.1125215e-01  3.1466269e-01\n",
      "  3.2498249e-01  3.4353861e-01  3.7466651e-01  4.2546085e-01\n",
      "  5.0592452e-01  6.4064223e-01  8.7762392e-01  1.0000000e+00]\n",
      "[-0.11178822 -0.00322578  0.21837339  0.1635292   1.1349068  -0.00277825\n",
      "  0.9213631  -0.36851683  0.         -0.6188724   0.9985821   0.4860412\n",
      " -1.0008763   0.          0.31892318  0.3224178   0.33282915  0.35195222\n",
      "  0.3839824   0.43683395  0.5188882   0.6567799   0.89647514  1.        ]\n",
      "[-0.09776526  0.02814364  0.21861933  0.15589178  1.1349119   0.\n",
      "  0.84397304 -0.647567    1.         -0.54765546  0.90607363  0.371395\n",
      " -1.          0.          0.32623157  0.32980627  0.3402982   0.3600884\n",
      "  0.392859    0.44769233  0.5315108   0.67206675  0.9129311   1.        ]\n",
      "[-6.4752221e-02  6.6026174e-02  2.2229844e-01  1.4320453e-01\n",
      "  1.1341214e+00  2.6229024e-04  7.2614902e-01 -9.9990648e-01\n",
      "  0.0000000e+00 -5.0043774e-01  6.1070979e-01  2.5793248e-01\n",
      " -9.9999350e-01  0.0000000e+00  3.3301041e-01  3.3659267e-01\n",
      "  3.4721437e-01  3.6763677e-01  4.0135163e-01  4.5771840e-01\n",
      "  5.4333299e-01  6.8591660e-01  9.2653865e-01  1.0000000e+00]\n",
      "[-0.01588519  0.09767523  0.22982411  0.13731584  1.0743377  -0.720583\n",
      "  0.7146987   0.01090166  1.         -0.46737057  0.43365902  0.14489537\n",
      " -0.99999994  0.          0.33956617  0.34306815  0.3538942   0.37493807\n",
      "  0.40995076  0.46710777  0.55479425  0.69931775  0.9396052   1.        ]\n",
      "[ 0.03420068  0.10060883  0.22329332  0.11776005  1.0488962  -0.23963445\n",
      "  0.56688195 -0.99999994  1.         -0.43139902  0.46490365  0.03287172\n",
      " -0.99999994  0.          0.34526128  0.34868124  0.3596844   0.38128272\n",
      "  0.41745853  0.47528678  0.5647912   0.7109695   0.9508219   1.        ]\n",
      "[ 0.07784149  0.08732329  0.23383226  0.09925933  1.055175    0.096331\n",
      "  0.44934005 -1.          1.         -0.4397127  -0.08711401  0.10169697\n",
      "  0.5507233   0.          0.35004222  0.3533656   0.3645166   0.3866133\n",
      "  0.42384693  0.48220357  0.5732752   0.720774    0.95993346  1.        ]\n",
      "[ 0.10877026  0.06185639  0.2110362   0.07528692  1.0863823   0.40800574\n",
      "  0.33346772 -1.0000001   0.         -0.36513     0.9497684  -0.01259625\n",
      " -1.0000001   0.          0.3536172   0.35684702  0.36816025  0.39060256\n",
      "  0.42868957  0.4874145   0.57968956  0.72812116  0.9675939   1.        ]\n",
      "[ 0.1582309   0.0988135   0.22586948  0.05749398  1.0765505  -0.10599858\n",
      "  0.21815205 -1.          0.         -0.33855715  0.36098045 -0.12098289\n",
      " -0.9999998   0.          0.3564247   0.35954636  0.37111816  0.39374077\n",
      "  0.43259954  0.49157     0.5845881   0.73380035  0.9741752   1.        ]\n",
      "[ 0.2056816   0.09485984  0.22752947  0.03321242  1.083741    0.11160475\n",
      "  0.10242635 -1.0000001   0.         -0.3193105   0.25036204 -0.23805034\n",
      " -1.0000001   0.          0.3581052   0.36110893  0.3728965   0.3956275\n",
      "  0.43510407  0.49415445  0.58756864  0.73721474  0.9778908   1.        ]\n",
      "[ 0.24632655  0.08099975  0.22957768  0.00230861  1.136227    0.67661345\n",
      " -0.00896811 -1.0000001   0.         -0.3143741   0.08453631 -0.35202026\n",
      " -1.0000001   0.          0.35826755  0.36118153  0.37313008  0.39587533\n",
      "  0.43577138  0.49468338  0.5881278   0.73766327  0.9778485   1.        ]\n",
      "[ 3.13911140e-01  1.34945005e-01  2.57752895e-01 -1.41453873e-02\n",
      "  1.13448286e+00  2.38418579e-07 -1.23153925e-01 -9.99999940e-01\n",
      "  0.00000000e+00 -3.97525966e-01 -1.00000012e+00 -4.67089295e-01\n",
      " -1.00000012e+00  0.00000000e+00  3.57648194e-01  3.60557139e-01\n",
      "  3.72657746e-01  3.95729661e-01  4.35640007e-01  4.94295806e-01\n",
      "  5.87600768e-01  7.36756384e-01  9.76024628e-01  1.00000000e+00]\n",
      "[ 3.8061833e-01  1.3330296e-01  2.5855029e-01 -3.1055987e-02\n",
      "  1.1327064e+00  1.7881393e-07 -2.3819840e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -4.7981736e-01 -1.0000000e+00 -5.8040643e-01\n",
      " -9.6817517e-01  0.0000000e+00  3.5622621e-01  3.5912359e-01\n",
      "  3.7134528e-01  3.9469990e-01  4.3447939e-01  4.9285930e-01\n",
      "  5.8575529e-01  7.3423648e-01  9.7216165e-01  1.0000000e+00]\n",
      "[ 4.4678560e-01  1.3214007e-01  2.5920174e-01 -4.8376575e-02\n",
      "  1.1315120e+00 -1.7881393e-07 -3.5284424e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -5.6345671e-01 -9.9999988e-01 -6.9532955e-01\n",
      " -9.9999994e-01  0.0000000e+00  3.5398248e-01  3.5686162e-01\n",
      "  3.6917314e-01  3.9273947e-01  4.3214092e-01  4.9031377e-01\n",
      "  5.8256125e-01  7.3006594e-01  9.6621042e-01  1.0000000e+00]\n",
      "[ 5.0451249e-01  1.1349299e-01  2.5276640e-01 -5.4711483e-02\n",
      "  1.1281736e+00 -1.1920929e-07 -3.3642793e-01  1.0516461e-01\n",
      "  0.0000000e+00 -6.5538657e-01 -1.0000000e+00 -6.3490891e-01\n",
      "  1.9868216e-08  0.0000000e+00  3.5159388e-01  3.5445359e-01\n",
      "  3.6684862e-01  3.9061236e-01  4.2962256e-01  4.8756132e-01\n",
      "  5.7912725e-01  7.2560287e-01  9.5989227e-01  1.0000000e+00]\n",
      "[ 5.5456191e-01  9.9951610e-02  2.4196029e-01 -7.0881270e-02\n",
      "  1.1223054e+00  3.5762787e-07 -2.0732903e-01  1.0000001e+00\n",
      "  0.0000000e+00 -7.2390926e-01 -8.5622907e-01 -6.3439512e-01\n",
      "  0.0000000e+00  0.0000000e+00  3.4825468e-01  3.5122597e-01\n",
      "  3.6351806e-01  3.8737035e-01  4.2590865e-01  4.8342821e-01\n",
      "  5.7410103e-01  7.1920818e-01  9.5117480e-01  1.0000000e+00]\n",
      "[ 6.05182111e-01  1.01093456e-01  2.48425677e-01 -9.11444277e-02\n",
      "  1.11596322e+00  4.17232513e-07 -7.70907402e-02  1.00000000e+00\n",
      "  0.00000000e+00 -8.03923190e-01 -9.99999940e-01 -6.33561134e-01\n",
      " -3.97364310e-08  0.00000000e+00  3.43954146e-01  3.47039938e-01\n",
      "  3.59185547e-01  3.83052140e-01  4.21022654e-01  4.77953404e-01\n",
      "  5.67507744e-01  7.10889757e-01  9.40008998e-01  1.00000000e+00]\n",
      "[ 6.4039910e-01  7.0288651e-02  2.3639229e-01 -8.4450677e-02\n",
      "  1.1125642e+00  1.1920929e-07  2.8402448e-02  8.2666320e-01\n",
      "  0.0000000e+00 -8.0816811e-01  0.0000000e+00 -5.0884092e-01\n",
      "  9.9999970e-01  0.0000000e+00  3.3992770e-01  3.4312403e-01\n",
      "  3.5513258e-01  3.7902054e-01  4.1645625e-01  4.7283959e-01\n",
      "  5.6134421e-01  7.0310807e-01  9.2954993e-01  1.0000000e+00]\n",
      "[ 6.7257947e-01  6.4201161e-02  2.3539798e-01 -1.0200498e-01\n",
      "  1.1081157e+00 -2.9802322e-07  1.5629929e-01  9.9999982e-01\n",
      "  0.0000000e+00 -8.1240898e-01  0.0000000e+00 -3.8358891e-01\n",
      "  1.0000004e+00  0.0000000e+00  3.3506796e-01  3.3836493e-01\n",
      "  3.5020691e-01  3.7404206e-01  4.1086382e-01  4.6654794e-01\n",
      "  5.5381054e-01  6.9365078e-01  9.1697466e-01  1.0000000e+00]\n",
      "[ 7.0386577e-01  6.2398151e-02  2.3605117e-01 -1.2190927e-01\n",
      "  1.1039236e+00  1.7881393e-07  2.8424859e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.1530970e-01  0.0000000e+00 -2.8865433e-01\n",
      "  7.5541967e-01  0.0000000e+00  3.2927087e-01  3.3265829e-01\n",
      "  3.4430054e-01  3.6800194e-01  4.0411961e-01  4.5893490e-01\n",
      "  5.4473847e-01  6.8231052e-01  9.0201724e-01  1.0000000e+00]\n",
      "[ 7.3269588e-01  5.7476208e-02  2.3779342e-01 -1.3624702e-01\n",
      "  1.1001992e+00  2.6822090e-07  4.1160583e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.1947237e-01  0.0000000e+00 -3.4720194e-01\n",
      " -1.3678516e+00  1.0000000e+00  3.2278901e-01  3.2626054e-01\n",
      "  3.3782727e-01  3.6118984e-01  3.9653671e-01  4.5036051e-01\n",
      "  5.3454572e-01  6.6959697e-01  8.8531834e-01  1.0000000e+00]\n",
      "[ 7.5901568e-01  5.3363353e-02  2.3655240e-01 -1.5509194e-01\n",
      "  1.0996175e+00  2.9802322e-08  5.0739777e-01  7.6324964e-01\n",
      "  0.0000000e+00 -8.1997764e-01  0.0000000e+00 -3.3360338e-01\n",
      " -5.0618392e-01  1.0000000e+00  3.1525347e-01  3.1879655e-01\n",
      "  3.3033586e-01  3.5318038e-01  3.8765624e-01  4.4029653e-01\n",
      "  5.2262032e-01  6.5476453e-01  8.6594355e-01  1.0000000e+00]\n",
      "[ 0.7698553   0.02142113  0.25043404 -0.1764773   1.1771646   0.9999997\n",
      "  0.48126054 -0.27623427  0.         -0.8203928   0.         -0.38496685\n",
      " -0.41534293  0.          0.30697685  0.31046304  0.32195458  0.3442195\n",
      "  0.37773132  0.42904234  0.50929564  0.6382043   0.84434325  1.        ]\n",
      "[ 7.8771830e-01  2.6992790e-02  2.3394786e-01 -1.7261069e-01\n",
      "  1.1349077e+00  1.6391277e-07  6.8926263e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.2494950e-01  0.0000000e+00 -4.3794370e-01\n",
      " -4.2189792e-01  0.0000000e+00  2.9916188e-01  3.0255932e-01\n",
      "  3.1399122e-01  3.3570543e-01  3.6830992e-01  4.1835356e-01\n",
      "  4.9664980e-01  6.2249804e-01  8.2475811e-01  1.0000000e+00]\n",
      "[ 7.9464918e-01  1.3733110e-02  2.3276620e-01 -1.7928770e-01\n",
      "  1.1335883e+00 -3.7252903e-08  8.1138313e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.2527757e-01  0.0000000e+00 -4.8375833e-01\n",
      " -3.8466075e-01  0.0000000e+00  2.9077756e-01  2.9407978e-01\n",
      "  3.0543092e-01  3.2655314e-01  3.5819235e-01  4.0686864e-01\n",
      "  4.8307288e-01  6.0564750e-01  8.0463678e-01  1.0000000e+00]\n",
      "[ 7.9373908e-01 -1.8694971e-03  2.2884996e-01 -1.8265398e-01\n",
      "  1.1331170e+00  1.6763806e-08  9.2753434e-01  9.6360403e-01\n",
      "  0.0000000e+00 -8.2570177e-01 -4.6566129e-09 -5.2357256e-01\n",
      " -3.3540091e-01  0.0000000e+00  2.8221622e-01  2.8542119e-01\n",
      "  2.9667786e-01  3.1719476e-01  3.4785429e-01  3.9512864e-01\n",
      "  4.6920231e-01  5.8844125e-01  7.8414547e-01  1.0000000e+00]\n",
      "[ 7.9140037e-01 -4.8033879e-03  2.1581328e-01 -1.7722695e-01\n",
      "  1.1331763e+00  1.6950071e-07  9.2755044e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.2606733e-01 -3.7252903e-09 -5.6074166e-01\n",
      " -3.1291109e-01  0.0000000e+00  2.7391040e-01  2.7702105e-01\n",
      "  2.8817788e-01  3.0810696e-01  3.3781993e-01  3.8373056e-01\n",
      "  4.5574096e-01  5.7174850e-01  7.6430327e-01  1.0000000e+00]\n",
      "[ 7.78622866e-01 -2.56055817e-02  2.07925811e-01 -1.76984131e-01\n",
      "  1.13315630e+00 -1.63912773e-07  9.27630067e-01  0.00000000e+00\n",
      "  0.00000000e+00 -8.26497018e-01  0.00000000e+00 -5.61090231e-01\n",
      "  1.06568575e-01  1.00000000e+00  2.65591353e-01  2.68607527e-01\n",
      "  2.79653549e-01  2.98993111e-01  3.27763349e-01  3.72303128e-01\n",
      "  4.42251831e-01  5.55002987e-01  7.44478643e-01  1.00000000e+00]\n",
      "[ 7.5910074e-01 -4.4628043e-02  1.9012535e-01 -2.3527358e-02\n",
      "  1.1229470e+00 -1.8093437e-02  9.3491042e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3162200e-01  2.2858381e-05 -5.6078780e-01\n",
      "  1.8607663e-01  0.0000000e+00  2.6543623e-01  2.6845065e-01\n",
      "  2.7976629e-01  2.9906330e-01  3.2773364e-01  3.7237310e-01\n",
      "  4.4215879e-01  5.5471742e-01  7.4286807e-01  1.0000000e+00]\n",
      "[ 7.3728669e-01 -4.6584696e-02  1.8270908e-01  1.7382462e-02\n",
      "  1.1157473e+00  4.5746565e-05  8.2548952e-01 -9.8743391e-01\n",
      "  0.0000000e+00 -8.3531463e-01 -6.9737434e-06 -5.4073703e-01\n",
      "  1.9518815e-01  0.0000000e+00  2.6697224e-01  2.7025416e-01\n",
      "  2.8166547e-01  3.0093014e-01  3.2977948e-01  3.7482202e-01\n",
      "  4.4483915e-01  5.5780447e-01  7.4504274e-01  1.0000000e+00]\n",
      "[ 7.0608628e-01 -6.3429646e-02  1.8967593e-01  1.6982231e-02\n",
      "  1.0685735e+00 -5.3466082e-01  9.5112157e-01  1.0000024e+00\n",
      "  0.0000000e+00 -8.3535516e-01  3.8743019e-07 -4.7703791e-01\n",
      "  2.6428992e-01  1.0000000e+00  2.6830593e-01  2.7188051e-01\n",
      "  2.8336051e-01  3.0257550e-01  3.3158255e-01  3.7699628e-01\n",
      "  4.4719329e-01  5.6048483e-01  7.4672061e-01  1.0000000e+00]\n",
      "[ 6.7311311e-01 -6.6730656e-02  2.2236687e-01  1.5071558e-02\n",
      "  1.1075824e+00  5.1130557e-01  8.3413279e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -8.3330846e-01 -9.5367432e-07 -4.6282208e-01\n",
      "  2.8168064e-01  0.0000000e+00  2.6905721e-01  2.7295953e-01\n",
      "  2.8448507e-01  3.0359232e-01  3.3269683e-01  3.7839791e-01\n",
      "  4.4861838e-01  5.6199473e-01  7.4689072e-01  1.0000000e+00]\n",
      "[ 0.6380847  -0.07073531  0.25761586  0.0556221   1.094903   -0.14338681\n",
      "  0.9554589   1.0000001   0.         -0.8338703   0.0025816  -0.43148625\n",
      "  0.54586273  0.          0.2716745   0.27598748  0.2876409   0.30673075\n",
      "  0.33615795  0.38248703  0.45313874  0.5672549   0.75096303  1.        ]\n",
      "[ 5.9834343e-01 -7.9523347e-02  2.7660120e-01  9.1742851e-02\n",
      "  1.1220353e+00  3.4260324e-01  9.2823792e-01 -2.3024969e-01\n",
      "  0.0000000e+00 -8.3451265e-01 -2.9802322e-08 -3.6808634e-01\n",
      "  3.5816491e-01  1.0000000e+00  2.7587914e-01  2.8065687e-01\n",
      "  2.9250744e-01  3.1166485e-01  3.4174526e-01  3.8884434e-01\n",
      "  4.6017179e-01  5.7570523e-01  7.5879323e-01  1.0000000e+00]\n",
      "[ 5.59024394e-01 -7.85868466e-02  2.91684508e-01  1.00668915e-01\n",
      "  1.12190080e+00 -1.03950500e-04  9.28645253e-01  0.00000000e+00\n",
      "  0.00000000e+00 -8.32162261e-01  3.42726707e-06 -2.97324777e-01\n",
      "  5.26186466e-01  1.00000000e+00  2.80680507e-01  2.85748452e-01\n",
      "  2.97695994e-01  3.17053080e-01  3.47841561e-01  3.95487934e-01\n",
      "  4.67691809e-01  5.84948301e-01  7.69689381e-01  1.00000000e+00]\n",
      "[ 5.1584411e-01 -8.6370632e-02  3.1341690e-01  1.0562858e-01\n",
      "  1.1216540e+00 -4.0948391e-05  9.2914712e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3205581e-01  1.3709068e-06 -2.2676992e-01\n",
      "  5.8569193e-01  0.0000000e+00  2.8593877e-01  2.9110169e-01\n",
      "  3.0301037e-01  3.2271302e-01  3.5424867e-01  4.0241221e-01\n",
      "  4.7558495e-01  5.9428889e-01  7.8110391e-01  1.0000000e+00]\n",
      "[ 4.6955627e-01 -9.2748836e-02  3.2644081e-01  1.1461258e-01\n",
      "  1.1207738e+00  1.4305115e-06  8.7181902e-01 -4.9618968e-01\n",
      "  0.0000000e+00 -8.3253855e-01 -1.7881393e-07 -1.4649463e-01\n",
      "  6.5170622e-01  0.0000000e+00  2.9161713e-01  2.9688254e-01\n",
      "  3.0875742e-01  3.2883373e-01  3.6117175e-01  4.0990299e-01\n",
      "  4.8413083e-01  6.0349530e-01  7.9349971e-01  1.0000000e+00]\n",
      "[ 0.41630292 -0.10655526  0.354673    0.11842925  1.1200987   0.\n",
      "  0.854566   -0.15690784  0.         -0.83261085  0.         -0.05568552\n",
      "  0.75024384  0.          0.29748577  0.30285716  0.31468502  0.33524302\n",
      "  0.36832073  0.41762504  0.4929302   0.6129317   0.80620605  1.        ]\n",
      "[ 0.3530401  -0.12676635  0.38390306  0.12246344  1.1055883  -0.17972243\n",
      "  0.95922065  0.8677664   0.         -0.83370346  0.          0.05620098\n",
      "  0.89401656  0.          0.30352587  0.3088511   0.32077122  0.34193328\n",
      "  0.3756711   0.4255487   0.50191444  0.62254894  0.8186176   1.        ]\n",
      "[ 2.8600073e-01 -1.3417591e-01  4.0586877e-01  1.3169760e-01\n",
      "  1.1130054e+00  1.5020370e-04  9.3490684e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3473581e-01 -5.1259995e-06  1.7762029e-01\n",
      "  9.9722511e-01  0.0000000e+00  3.0996329e-01  3.1509942e-01\n",
      "  3.2726070e-01  3.4906498e-01  3.8317496e-01  4.3388742e-01\n",
      "  5.1136863e-01  6.3281775e-01  8.3187282e-01  1.0000000e+00]\n",
      "[ 2.12691844e-01 -1.46788582e-01  4.04476047e-01  1.20764278e-01\n",
      "  1.11278367e+00  5.36441803e-07  9.34907079e-01  0.00000000e+00\n",
      "  0.00000000e+00 -8.27688336e-01  1.02189004e-01  3.02224159e-01\n",
      "  1.00000036e+00  0.00000000e+00  3.15886229e-01  3.20826828e-01\n",
      "  3.33209157e-01  3.55616331e-01  3.90006393e-01  4.41341192e-01\n",
      "  5.19998789e-01  6.40202522e-01  8.43859494e-01  1.00000000e+00]\n",
      "[ 1.3557474e-01 -1.5443069e-01  4.0470111e-01  1.0661094e-01\n",
      "  1.1125306e+00 -4.1723251e-07  9.3490720e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.1499314e-01  1.7289644e-01  4.2677569e-01\n",
      "  9.9999982e-01  0.0000000e+00  3.2111454e-01  3.2584956e-01\n",
      "  3.3858031e-01  3.6138335e-01  3.9598691e-01  4.4784153e-01\n",
      "  5.2751195e-01  6.4614981e-01  8.5640103e-01  1.0000000e+00]\n",
      "[ 5.9592668e-02 -1.5212572e-01  4.0760669e-01  8.6548641e-02\n",
      "  1.1123184e+00 -3.5762787e-07  9.3490696e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.0700618e-01  1.1260861e-01  5.5100876e-01\n",
      "  1.0000000e+00  0.0000000e+00  3.2512769e-01  3.2990807e-01\n",
      "  3.4297895e-01  3.6607826e-01  4.0080258e-01  4.5303571e-01\n",
      "  5.3349435e-01  6.5044713e-01  8.7008923e-01  1.0000000e+00]\n",
      "[-2.0926159e-02 -1.6127153e-01  4.0528220e-01  7.3461905e-02\n",
      "  1.1120294e+00  4.7683716e-07  9.3490708e-01  0.0000000e+00\n",
      "  0.0000000e+00 -7.7732110e-01  3.8141954e-01  6.7379856e-01\n",
      "  1.0000000e+00  0.0000000e+00  3.2848442e-01  3.3331418e-01\n",
      "  3.4669632e-01  3.6982790e-01  4.0483099e-01  4.5734912e-01\n",
      "  5.3793943e-01  6.5365362e-01  8.8174331e-01  1.0000000e+00]\n",
      "[-9.8587275e-02 -1.5584822e-01  4.0981662e-01  6.6727228e-02\n",
      "  1.1087077e+00  5.9604645e-07  8.2418728e-01 -1.0000001e+00\n",
      "  0.0000000e+00 -7.5675440e-01  2.6015431e-01  7.9202992e-01\n",
      "  1.0000004e+00  1.0000000e+00  3.3151215e-01  3.3639583e-01\n",
      "  3.5006747e-01  3.7313873e-01  4.0837026e-01  4.6119112e-01\n",
      "  5.4146600e-01  6.5626270e-01  8.9237273e-01  1.0000000e+00]\n",
      "[-0.15040171 -0.10366212  0.26721525  0.17029107  1.109046    0.01166236\n",
      "  0.8927144   0.46362674  1.         -0.719697    0.46165392  0.86731935\n",
      "  0.62924075  1.          0.33946154  0.3445818   0.35858616  0.3819867\n",
      "  0.41786328  0.47180548  0.5529741   0.6698597   0.92688394  1.        ]\n",
      "[-0.19767511 -0.09457806  0.2646886   0.15470491  1.083065   -0.3032071\n",
      "  1.0121737   1.          1.         -0.6401049   1.          0.7505185\n",
      " -0.9845318   1.          0.34668413  0.35202783  0.3663348   0.39002162\n",
      "  0.42647463  0.48142937  0.5633709   0.6827014   0.9600808   1.        ]\n",
      "[-0.23523486 -0.07530138  0.26576468  0.14421557  1.0877128   0.06040695\n",
      "  1.0709934   0.72829384  1.         -0.5616074   0.9999997   0.6345967\n",
      " -1.0000001   0.          0.3534253   0.35898486  0.37357455  0.3975174\n",
      "  0.43449986  0.49039418  0.5730227   0.694625    0.9827457   1.        ]\n",
      "[-0.26941076 -0.06833398  0.25307152  0.12556663  1.1418128   0.9164486\n",
      "  0.9155774  -0.9999998   1.         -0.48325148  1.          0.513474\n",
      " -1.0491151   0.          0.35935166  0.3651083   0.37979454  0.40410358\n",
      "  0.4415431   0.49825788  0.5813386   0.70504576  0.99862444  1.        ]\n",
      "[-2.6967803e-01 -1.5066834e-03  2.6999792e-01  1.3434137e-01\n",
      "  1.1348933e+00  2.8945506e-04  8.9400977e-01 -3.9693186e-01\n",
      "  1.0000000e+00 -4.7053775e-01  1.6690341e-01  5.2290410e-01\n",
      "  7.1203001e-02  0.0000000e+00  3.6589420e-01  3.7186468e-01\n",
      "  3.8662985e-01  4.1137642e-01  4.4932485e-01  5.0694823e-01\n",
      "  5.8932000e-01  7.1656644e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-2.5224590e-01  3.4900054e-02  2.6230443e-01  1.3765129e-01\n",
      "  1.1346805e+00 -1.0430813e-07  8.0436558e-01 -7.5287300e-01\n",
      "  1.0000000e+00 -4.1371781e-01  7.2404402e-01  4.0719128e-01\n",
      " -1.0000000e+00  0.0000000e+00  3.7256294e-01  3.7874618e-01\n",
      "  3.9359918e-01  4.1870061e-01  4.5726475e-01  5.1574278e-01\n",
      "  5.9752303e-01  7.2805721e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-0.22396293  0.05660185  0.26258284  0.12748422  1.1335338  -0.00271738\n",
      "  0.6862599  -1.0009044   1.         -0.36153463  0.66380906  0.29042125\n",
      " -1.0000631   0.          0.37890023  0.38518864  0.4001141   0.42549002\n",
      "  0.4646307   0.5233773   0.6051048   0.73873913  1.          1.        ]\n",
      "[-0.18806064  0.07167246  0.26643983  0.12454472  1.082545   -0.61093414\n",
      "  0.6573347   0.00141957  1.         -0.29637358  0.8503233   0.18259907\n",
      " -1.0000001   0.          0.38508546  0.39147654  0.4064664   0.43210566\n",
      "  0.47178078  0.53079814  0.612443    0.7491171   1.          1.        ]\n",
      "[-0.15127899  0.07401144  0.25648957  0.10937987  1.0648975  -0.1921643\n",
      "  0.50818694 -0.9999998   1.         -0.2188822   1.0000004   0.0760392\n",
      " -0.99999994  0.          0.39060977  0.39709252  0.41213068  0.43799824\n",
      "  0.47814614  0.5373799   0.61890364  0.7583141   1.          1.        ]\n",
      "[-0.09648858  0.10968756  0.26556018  0.09381042  1.0209446  -0.52215374\n",
      "  0.39140332 -1.0000002   1.         -0.17172356  0.59920466 -0.03974664\n",
      " -1.          0.          0.39546323  0.40193143  0.41708326  0.44313374\n",
      "  0.48368573  0.54304516  0.62434274  0.7662111   1.          1.        ]\n",
      "[-0.0395554   0.11374816  0.2646209   0.0781147   0.966333   -0.658227\n",
      "  0.2765748  -1.          1.         -0.11903609  0.69575864 -0.14260197\n",
      " -1.          0.          0.39954486  0.4059217   0.42122397  0.44741035\n",
      "  0.48829055  0.54769015  0.6294761   0.7749006   1.          1.        ]\n",
      "[ 0.02606914  0.13117023  0.2718898   0.06056232  0.8827392  -0.9999999\n",
      "  0.16374516 -1.          0.         -0.07961532  0.50858533 -0.25334978\n",
      " -0.99999994  0.          0.40285945  0.40913075  0.424554    0.45082656\n",
      "  0.49195766  0.55130154  0.6337101   0.78244185  1.          1.        ]\n",
      "[ 0.09179297  0.13142328  0.27564698  0.03126309  0.82559067 -0.67543584\n",
      "  0.0488888  -1.0000001   0.         -0.07094291  0.11781967 -0.37004495\n",
      " -0.9999998   0.          0.4048285   0.41097388  0.42635912  0.4527417\n",
      "  0.49399057  0.55312365  0.6358574   0.78703237  1.          1.        ]\n",
      "[ 0.16424981  0.14483468  0.286319    0.0074938   0.772409   -0.63557607\n",
      " -0.06639254 -1.          0.         -0.10616668 -0.42545247 -0.48559463\n",
      " -1.0000001   0.          0.4057185   0.4117174   0.42702192  0.4534371\n",
      "  0.49470314  0.55299395  0.63630664  0.7892642   1.          1.        ]\n",
      "[ 0.23413192  0.13956256  0.29005572 -0.02221725  0.76898986 -0.03355229\n",
      " -0.18091464 -1.          0.         -0.18952052 -0.99999976 -0.59931827\n",
      " -0.9999998   0.          0.40520045  0.41103104  0.42620474  0.4525217\n",
      "  0.49351513  0.5508865   0.63456947  0.7884091   1.          1.        ]\n",
      "[ 0.2899163   0.11123508  0.2799311  -0.0511548   0.831778    0.81036115\n",
      " -0.28850353 -0.9999998   0.         -0.27351832 -1.0000001  -0.7146239\n",
      " -1.0000001   0.          0.40325466  0.40890226  0.4238994   0.45003146\n",
      "  0.4904998   0.54703254  0.6306582   0.7844114   1.          1.        ]\n",
      "[ 3.4090742e-01  9.9335320e-02  2.8463790e-01 -6.1908875e-02\n",
      "  9.0697509e-01  1.0000007e+00 -3.9331198e-01 -1.0000001e+00\n",
      "  0.0000000e+00 -3.6976472e-01 -1.0000001e+00 -6.3490951e-01\n",
      " -1.9868214e-07  0.0000000e+00  4.0096533e-01  4.0652686e-01\n",
      "  4.2133471e-01  4.4726449e-01  4.8717448e-01  5.4282224e-01\n",
      "  6.2634349e-01  7.7990520e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 3.8824812e-01  9.4337836e-02  2.8348127e-01 -7.8716174e-02\n",
      "  9.8378068e-01  9.9999934e-01 -4.1858268e-01 -3.3137345e-01\n",
      "  0.0000000e+00 -4.5031035e-01 -1.0000000e+00 -6.3357091e-01\n",
      "  1.9868216e-08  0.0000000e+00  3.9754775e-01  4.0306187e-01\n",
      "  4.1764629e-01  4.4330853e-01  4.8259288e-01  5.3729767e-01\n",
      "  6.2038910e-01  7.7302241e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.43095472  0.08495566  0.2782901  -0.09524564  1.0544715   0.9999994\n",
      " -0.3155496   0.68723106  0.         -0.5311133  -1.         -0.63172185\n",
      "  0.          0.          0.3933509   0.3988068   0.4131428   0.43848988\n",
      "  0.47709835  0.5308155   0.6132434   0.7644191   1.          1.        ]\n",
      "[ 4.73741263e-01  8.51593465e-02  2.88412750e-01 -1.16022825e-01\n",
      "  1.12675691e+00  1.00000072e+00 -2.50167608e-01  3.87131542e-01\n",
      "  0.00000000e+00 -6.11694038e-01 -1.00000000e+00 -6.30130649e-01\n",
      "  1.98682155e-08  0.00000000e+00  3.88183594e-01  3.93524081e-01\n",
      "  4.07618165e-01  4.32587892e-01  4.70437050e-01  5.23072302e-01\n",
      "  6.04576349e-01  7.53706634e-01  1.00000000e+00  1.00000000e+00]\n",
      "[ 5.2822608e-01  1.0888608e-01  2.9772401e-01 -1.0517349e-01\n",
      "  1.1232295e+00  5.9604645e-08 -1.8895745e-01  4.5733896e-01\n",
      "  0.0000000e+00 -6.9283551e-01 -1.0000000e+00 -5.0876188e-01\n",
      "  9.9999970e-01  0.0000000e+00  3.8355085e-01  3.8872918e-01\n",
      "  4.0265152e-01  4.2727590e-01  4.6439570e-01  5.1597154e-01\n",
      "  5.9671873e-01  7.4418211e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 5.8846033e-01  1.2032721e-01  2.9127651e-01 -1.3803448e-01\n",
      "  1.1231488e+00  5.9604645e-08 -2.2047651e-01 -2.8919277e-01\n",
      "  0.0000000e+00 -7.4457330e-01 -6.2441176e-01 -6.2620568e-01\n",
      " -9.9999946e-01  0.0000000e+00  3.7738460e-01  3.8238472e-01\n",
      "  3.9607984e-01  4.2026478e-01  4.5655340e-01  5.0697637e-01\n",
      "  5.8651102e-01  7.3127609e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 6.50318682e-01  1.23618156e-01  3.05038691e-01 -1.48291782e-01\n",
      "  1.12231803e+00 -1.19209290e-07 -2.52964735e-01 -3.03743333e-01\n",
      "  0.00000000e+00 -8.24735105e-01 -9.99999881e-01 -6.25444174e-01\n",
      "  2.98023224e-08  0.00000000e+00  3.70735288e-01  3.75546545e-01\n",
      "  3.88996780e-01  4.12709713e-01  4.48114425e-01  4.97317135e-01\n",
      "  5.75525880e-01  7.17338443e-01  1.00000000e+00  1.00000000e+00]\n",
      "[ 6.9181025e-01  8.2855836e-02  2.7167866e-01 -1.5516020e-01\n",
      "  1.1168787e+00 -1.1920929e-07 -1.2403309e-01  9.9999976e-01\n",
      "  0.0000000e+00 -8.2528031e-01  0.0000000e+00 -6.2300885e-01\n",
      "  1.9868214e-07  0.0000000e+00  3.6369652e-01  3.6832562e-01\n",
      "  3.8148546e-01  4.0474007e-01  4.3927485e-01  4.8730671e-01\n",
      "  5.6401557e-01  7.0247692e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 7.3193610e-01  8.0118418e-02  2.7503765e-01 -1.7244920e-01\n",
      "  1.1118431e+00  2.9802322e-07  4.6263337e-03  1.0000001e+00\n",
      "  0.0000000e+00 -8.2572323e-01  0.0000000e+00 -6.1225402e-01\n",
      "  7.4910201e-02  0.0000000e+00  3.5584292e-01  3.6027876e-01\n",
      "  3.7311900e-01  3.9586356e-01  4.2946473e-01  4.7625870e-01\n",
      "  5.5123955e-01  6.8583417e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 7.6836759e-01  7.2679065e-02  2.8106004e-01 -1.8003042e-01\n",
      "  1.1071322e+00  2.0861626e-07  1.3313359e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3004421e-01  0.0000000e+00 -4.8762488e-01\n",
      "  9.9698430e-01  0.0000000e+00  3.4762612e-01  3.5186192e-01\n",
      "  3.6436880e-01  3.8657999e-01  4.1921243e-01  4.6472600e-01\n",
      "  5.3788704e-01  6.6840863e-01  9.8886359e-01  1.0000000e+00]\n",
      "[ 8.0321157e-01  6.9553249e-02  2.8252733e-01 -1.9662865e-01\n",
      "  1.1033854e+00 -1.4901161e-07  2.5364399e-01  9.3791419e-01\n",
      "  0.0000000e+00 -8.3450800e-01  0.0000000e+00 -3.6173749e-01\n",
      "  1.0000004e+00  0.0000000e+00  3.3854747e-01  3.4265029e-01\n",
      "  3.5479635e-01  3.7642404e-01  4.0802845e-01  4.5220065e-01\n",
      "  5.2331930e-01  6.4926457e-01  9.5787370e-01  1.0000000e+00]\n",
      "[ 8.3509094e-01  6.5013342e-02  2.8342569e-01 -2.1390289e-01\n",
      "  1.1000688e+00 -2.6822090e-07  3.8233626e-01  9.9999994e-01\n",
      "  0.0000000e+00 -8.3491248e-01  0.0000000e+00 -4.0648031e-01\n",
      " -1.5697714e+00  1.0000000e+00  3.2862213e-01  3.3260468e-01\n",
      "  3.4436134e-01  3.6535290e-01  3.9586931e-01  4.3864018e-01\n",
      "  5.0747949e-01  6.2831217e-01  9.2378646e-01  1.0000000e+00]\n",
      "[ 8.6956912e-01  6.9791190e-02  2.8555387e-01 -2.3745829e-01\n",
      "  1.0990422e+00 -2.9802322e-08  4.6389735e-01  6.4350408e-01\n",
      "  0.0000000e+00 -8.3467728e-01  0.0000000e+00 -4.1801775e-01\n",
      " -6.5584463e-01  1.0000000e+00  3.1745073e-01  3.2129788e-01\n",
      "  3.3262151e-01  3.5278770e-01  3.8223165e-01  4.2350405e-01\n",
      "  4.8971096e-01  6.0463309e-01  8.8584518e-01  1.0000000e+00]\n",
      "[ 0.8931692   0.04695772  0.29273018 -0.2585209   1.1201286   0.31759837\n",
      "  0.5930791   0.99999994  0.         -0.8349081   0.         -0.49923992\n",
      " -0.6241629   1.          0.3054305   0.30913198  0.31999177  0.33926165\n",
      "  0.3675767   0.4072678   0.470616    0.5791172   0.8449416   1.        ]\n",
      "[ 9.1757977e-01  4.8839856e-02  2.8730503e-01 -2.6117247e-01\n",
      "  1.1178590e+00  8.9406967e-08  7.1783733e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3491427e-01  0.0000000e+00 -5.7314825e-01\n",
      " -6.2063390e-01  1.0000000e+00  2.9328522e-01  2.9683951e-01\n",
      "  3.0723214e-01  3.2560745e-01  3.5278291e-01  3.9089870e-01\n",
      "  4.5133948e-01  5.5376017e-01  8.0351806e-01  1.0000000e+00]\n",
      "[ 9.3614852e-01  3.7178863e-02  2.8566316e-01 -2.6779509e-01\n",
      "  1.1165470e+00 -1.4901161e-08  8.4040749e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3490825e-01  0.0000000e+00 -6.4366031e-01\n",
      " -5.9121007e-01  1.0000000e+00  2.8081936e-01  2.8419104e-01\n",
      "  2.9413709e-01  3.1160468e-01  3.3761144e-01  3.7413150e-01\n",
      "  4.3157017e-01  5.2964640e-01  7.6799643e-01  1.0000000e+00]\n",
      "[ 9.0473092e-01 -5.4600969e-02  2.8229851e-01 -1.6476883e-01\n",
      "  1.1189206e+00  3.4134984e-03  9.6313787e-01  9.9994987e-01\n",
      "  0.0000000e+00 -8.3410424e-01 -2.6136637e-05 -6.6239381e-01\n",
      " -1.7865686e-01  0.0000000e+00  2.7352268e-01  2.7676621e-01\n",
      "  2.8645238e-01  3.0324215e-01  3.2855099e-01  3.6384097e-01\n",
      "  4.1977334e-01  5.1519501e-01  7.4773610e-01  1.0000000e+00]\n",
      "[ 8.6483699e-01 -7.5457819e-02  3.0858198e-01 -8.9716531e-02\n",
      "  1.1291459e+00 -1.2148023e-03  9.3490767e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3450973e-01  1.0907650e-05 -6.4043701e-01\n",
      "  5.6682605e-02  0.0000000e+00  2.6949942e-01  2.7264747e-01\n",
      "  2.8218949e-01  2.9841539e-01  3.2332137e-01  3.5754904e-01\n",
      "  4.1297644e-01  5.0678974e-01  7.3649728e-01  1.0000000e+00]\n",
      "[ 8.2412416e-01 -8.1471100e-02  3.3333468e-01 -4.6831321e-02\n",
      "  1.1290011e+00 -8.6927414e-04  9.3490469e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3485156e-01 -3.5762787e-07 -6.3410628e-01\n",
      "  2.8229853e-02  1.0000000e+00  2.6728469e-01  2.7035427e-01\n",
      "  2.7981603e-01  2.9553244e-01  3.2019782e-01  3.5343835e-01\n",
      "  4.0892875e-01  5.0170511e-01  7.3023975e-01  1.0000000e+00]\n",
      "[ 7.8228283e-01 -8.5448302e-02  3.3676621e-01  2.6454724e-02\n",
      "  1.1264369e+00 -3.4841299e-03  9.3490791e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3502567e-01  1.4531612e-04 -5.8035123e-01\n",
      "  3.5605931e-01  1.0000000e+00  2.6886216e-01  2.7191550e-01\n",
      "  2.8143191e-01  2.9680714e-01  3.2086390e-01  3.5409948e-01\n",
      "  4.1075796e-01  5.0441438e-01  7.3449993e-01  1.0000000e+00]\n",
      "[ 7.3723423e-01 -9.0319328e-02  3.5172096e-01  5.1391408e-02\n",
      "  1.1260104e+00  3.6010742e-03  9.3490767e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3496845e-01 -1.4972687e-04 -5.4050803e-01\n",
      "  3.7614593e-01  1.0000000e+00  2.7129009e-01  2.7437100e-01\n",
      "  2.8355446e-01  2.9902914e-01  3.2241756e-01  3.5581407e-01\n",
      "  4.1392741e-01  5.1092994e-01  7.4324465e-01  1.0000000e+00]\n",
      "[ 6.8642867e-01 -1.0134885e-01  3.5353920e-01  8.2869746e-02\n",
      "  1.1260355e+00 -2.3698807e-04  9.3489850e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3491170e-01  1.1384487e-05 -4.8053610e-01\n",
      "  4.2227933e-01  1.0000000e+00  2.7505708e-01  2.7818078e-01\n",
      "  2.8704530e-01  3.0271047e-01  3.2548627e-01  3.5990661e-01\n",
      "  4.1909599e-01  5.2039272e-01  7.6090097e-01  1.0000000e+00]\n",
      "[ 6.34566069e-01 -1.03654444e-01  3.77457142e-01  8.52237791e-02\n",
      "  1.12605178e+00  2.38418579e-07  9.34905171e-01  0.00000000e+00\n",
      "  0.00000000e+00 -8.27403486e-01  4.16095853e-02 -4.09553409e-01\n",
      "  5.31497955e-01  1.00000000e+00  2.78897554e-01  2.82064855e-01\n",
      "  2.90585130e-01  3.06443483e-01  3.28558326e-01  3.64463657e-01\n",
      "  4.24181640e-01  5.30095696e-01  7.79083014e-01  1.00000000e+00]\n",
      "[ 5.8118945e-01 -1.0684306e-01  4.0220451e-01  8.8791683e-02\n",
      "  1.1259093e+00  2.3841858e-07  9.3490624e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.2664210e-01  1.0379255e-02 -3.3749425e-01\n",
      "  5.9703296e-01  0.0000000e+00  2.8291103e-01  2.8590101e-01\n",
      "  2.9427558e-01  3.0963400e-01  3.3174232e-01  3.6921516e-01\n",
      "  4.2948058e-01  5.4026169e-01  7.9840696e-01  1.0000000e+00]\n",
      "[ 5.2605611e-01 -1.1043033e-01  4.1387901e-01  9.7460225e-02\n",
      "  1.1247051e+00  1.6689301e-06  8.6808610e-01 -5.8116907e-01\n",
      "  0.0000000e+00 -8.2673478e-01 -2.3841858e-07 -2.5560343e-01\n",
      "  6.6451389e-01  0.0000000e+00  2.8732014e-01  2.8987134e-01\n",
      "  2.9836220e-01  3.1298855e-01  3.3533639e-01  3.7447456e-01\n",
      "  4.3535966e-01  5.5487174e-01  8.2010061e-01  1.0000000e+00]\n",
      "[ 0.4649489  -0.12258324  0.44091246  0.10344248  1.0803483  -0.5546373\n",
      "  0.98819697  1.0000001   0.         -0.8274601   0.         -0.16071999\n",
      "  0.7625982   0.          0.29197145  0.29405382  0.3026672   0.31651044\n",
      "  0.3396319   0.3800154   0.44155067  0.5714824   0.8430514   1.        ]\n",
      "[ 0.39875752 -0.13243921  0.46917164  0.10508806  1.0912755  -0.06779099\n",
      "  0.93490636  0.          0.         -0.82832795  0.         -0.05583119\n",
      "  0.8531261   0.          0.29639736  0.29817587  0.3063754   0.31991273\n",
      "  0.34451455  0.38540968  0.4486097   0.5883058   0.8618604   1.        ]\n",
      "[ 3.2179567e-01 -1.5394658e-01  4.9820697e-01  1.0097575e-01\n",
      "  1.1135714e+00  2.8175080e-01  9.3490469e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.2895416e-01 -6.5565109e-07  6.9106102e-02\n",
      "  1.0041043e+00  0.0000000e+00  3.0028987e-01  3.0209175e-01\n",
      "  3.0937192e-01  3.2304165e-01  3.4915611e-01  3.9037475e-01\n",
      "  4.5753857e-01  5.9957510e-01  8.7835193e-01  1.0000000e+00]\n",
      "[ 2.4718674e-01 -1.4939310e-01  4.9680984e-01  9.2817478e-02\n",
      "  1.1130846e+00 -4.9443245e-03  9.3490624e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.2937813e-01  1.6188622e-04  1.9601977e-01\n",
      "  1.0246326e+00  0.0000000e+00  3.0379161e-01  3.0561447e-01\n",
      "  3.1197408e-01  3.2601160e-01  3.5333475e-01  3.9482662e-01\n",
      "  4.6579093e-01  6.0772568e-01  8.9359623e-01  1.0000000e+00]\n",
      "[ 1.7874964e-01 -1.3730586e-01  4.9680337e-01  8.4591538e-02\n",
      "  1.1102265e+00  1.9067526e-04  8.2292461e-01 -9.9998301e-01\n",
      "  0.0000000e+00 -8.3078438e-01 -6.2584877e-06  3.2072347e-01\n",
      "  9.9909258e-01  0.0000000e+00  3.0690899e-01  3.0806771e-01\n",
      "  3.1418523e-01  3.2944712e-01  3.5705820e-01  3.9877322e-01\n",
      "  4.7338536e-01  6.1510414e-01  9.0329188e-01  1.0000000e+00]\n",
      "[ 0.10467368 -0.1489725   0.49844915  0.08227096  1.0299292  -0.9999987\n",
      "  0.9451841   1.          0.         -0.82360226  0.11662173  0.4462672\n",
      "  1.0000001   0.          0.30983475  0.31003875  0.3161954   0.33267337\n",
      "  0.3604521   0.40246692  0.48181573  0.6221046   0.9115621   1.        ]\n",
      "[ 0.03804401 -0.13407458  0.5069413   0.06546316  0.9630468  -0.88002855\n",
      "  1.1229603   2.6663568   1.         -0.8223957   0.04658169  0.5721377\n",
      "  1.          0.          0.31193507  0.31117302  0.31757236  0.334998\n",
      "  0.36278638  0.4064767   0.49083263  0.6312247   0.9176782   1.        ]\n",
      "[-0.05216352 -0.17467608  0.416495    0.07811236  1.1179619   0.96758646\n",
      "  0.9348931   0.          1.         -0.7580444   0.7050178   0.63626343\n",
      "  0.60125023  0.          0.31424272  0.31330416  0.32057506  0.3381655\n",
      "  0.36606807  0.41207376  0.5001851   0.64202964  0.92569     1.        ]\n",
      "[-0.08009144 -0.05574424  0.2814993   0.19394337  1.1194499   0.01598972\n",
      "  0.93490577  0.00266121  1.         -0.7502165   0.10185002  0.72330606\n",
      "  0.71697766  0.          0.32237542  0.3214126   0.32956305  0.34764665\n",
      "  0.37618902  0.42552477  0.5195164   0.6656556   0.95029366  1.        ]\n",
      "[-0.09537676 -0.03055378  0.26510906  0.20587292  1.1186529  -0.00815268\n",
      "  0.90893984 -0.21688752  1.         -0.67313546  0.9664267   0.6658594\n",
      " -0.48534235  0.          0.33116195  0.33017284  0.33919537  0.35773653\n",
      "  0.38704774  0.4398053   0.5374225   0.6908941   0.9767204   1.        ]\n",
      "[-8.6562514e-02  1.7712133e-02  2.6584709e-01  2.0175157e-01\n",
      "  1.1185873e+00  5.2154064e-08  8.2827967e-01 -6.7673808e-01\n",
      "  1.0000000e+00 -5.9412694e-01  1.0000000e+00  5.4925793e-01\n",
      " -9.9999976e-01  0.0000000e+00  3.3982825e-01  3.3881328e-01\n",
      "  3.4870291e-01  3.6764193e-01  3.9776474e-01  4.5391306e-01\n",
      "  5.5263364e-01  7.1618569e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-0.06156453  0.05003151  0.2665637   0.19362444  1.1178542  -0.00148118\n",
      "  0.710633   -1.0005267   1.         -0.52414733  0.9107622   0.44004905\n",
      " -1.0000299   0.          0.34813765  0.34756792  0.3578418   0.3771599\n",
      "  0.40933034  0.4689637   0.5672732   0.74061024  1.          1.        ]\n",
      "[-0.03060731  0.06202402  0.2677102   0.18365793  1.0856508  -0.37926927\n",
      "  0.6374785  -0.41768193  1.         -0.4496266   0.9504831   0.32540923\n",
      " -1.          0.          0.35602444  0.35602033  0.36654404  0.38621902\n",
      "  0.4207119   0.4840602   0.58123577  0.7623019   1.          1.        ]\n",
      "[ 0.00719078  0.07572287  0.26541552  0.16708149  1.0649194  -0.2270797\n",
      "  0.5063809  -0.9999997   1.         -0.3803969   0.916667    0.22296107\n",
      " -1.0000001   0.          0.3631433   0.36369503  0.3744456   0.3944379\n",
      "  0.43111664  0.49793828  0.5939571   0.7805612   1.          1.        ]\n",
      "[ 0.04774023  0.08115224  0.26371032  0.1518853   1.0372678  -0.32670325\n",
      "  0.39003038 -0.99999994  1.         -0.3032697   0.9999996   0.11627591\n",
      " -1.0000001   0.          0.3695599   0.37066     0.38156298  0.40188977\n",
      "  0.44063246  0.51071066  0.6085325   0.7972614   1.          1.        ]\n",
      "[ 0.09564328  0.09580833  0.26617947  0.1346181   0.9963569  -0.48726165\n",
      "  0.274494   -1.0000001   1.         -0.23430608  0.89424974  0.00927645\n",
      " -0.99999994  0.          0.37518796  0.37683588  0.38782713  0.40848765\n",
      "  0.44917294  0.5222851   0.62169147  0.8122513   1.          1.        ]\n",
      "[ 0.13829018  0.08528358  0.26193833  0.11081174  0.9730615  -0.27132487\n",
      "  0.15816867 -1.          0.         -0.15665841  1.0000005  -0.09742022\n",
      " -0.99999976  0.          0.3796925   0.38187322  0.39292344  0.41405138\n",
      "  0.45628223  0.5304118   0.6327523   0.8230709   1.          1.        ]\n",
      "[ 0.19447567  0.11238695  0.27702308  0.08865657  0.9280215  -0.5251791\n",
      "  0.04279703 -1.          0.         -0.12477413  0.4063611  -0.21417499\n",
      " -0.9999998   0.          0.38353446  0.38593265  0.39701173  0.41943777\n",
      "  0.46262935  0.5363183   0.64213836  0.8311109   1.          1.        ]\n",
      "[ 0.2591841   0.12935178  0.2907377   0.06418539  0.88632077 -0.49433422\n",
      " -0.07292271 -1.          0.         -0.14219397 -0.20335352 -0.32889688\n",
      " -1.0000001   0.          0.38644058  0.38885692  0.39993072  0.42357987\n",
      "  0.46840128  0.5407021   0.6495599   0.83697283  1.          1.        ]\n",
      "[ 0.32363334  0.12875831  0.29903635  0.03492028  0.88493186 -0.00312245\n",
      " -0.18818104 -1.0000001   0.         -0.20501454 -0.75678796 -0.44407868\n",
      " -1.0000001   0.          0.3879631   0.39038897  0.40141785  0.42617232\n",
      "  0.47239143  0.5432066   0.6546915   0.84015733  1.          1.        ]\n",
      "[ 0.37907353  0.11049475  0.29908097  0.00387156  0.94423336  0.76074183\n",
      " -0.29629862 -0.9999998   0.         -0.28960523 -1.         -0.55692303\n",
      " -1.0000002   0.          0.3879839   0.39037555  0.401353    0.4270619\n",
      "  0.4743997   0.543661    0.6570853   0.84042984  1.          1.        ]\n",
      "[ 0.43052277  0.10245965  0.30098456 -0.01825774  1.0223193   1.0000007\n",
      " -0.40216053 -1.          0.         -0.37398875 -1.0000002  -0.6716106\n",
      " -1.0000004   0.          0.38695428  0.38925627  0.40020224  0.42676312\n",
      "  0.47502804  0.5426828   0.65755254  0.8386665   1.          1.        ]\n",
      "[ 0.47900584  0.09551983  0.3070728  -0.02502388  1.09974     1.0000005\n",
      " -0.50009847 -0.92707014  0.         -0.4617935  -1.         -0.6349081\n",
      "  0.          0.          0.3857154   0.3879243   0.39883283  0.42625138\n",
      "  0.47543594  0.541431    0.6577007   0.8365037   1.          1.        ]\n",
      "[ 5.2364606e-01  8.8911541e-02  3.0283350e-01 -4.1481651e-02\n",
      "  1.1755314e+00  9.9999934e-01 -4.8805428e-01 -2.2017160e-02\n",
      "  0.0000000e+00 -5.4236126e-01 -9.9999988e-01 -6.3348317e-01\n",
      "  1.9868216e-08  0.0000000e+00  3.8358006e-01  3.8569355e-01\n",
      "  3.9687964e-01  4.2469954e-01  4.7460666e-01  5.3894377e-01\n",
      "  6.5613401e-01  8.3259642e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 5.8400691e-01  1.0834630e-01  2.9449159e-01 -4.1160945e-02\n",
      "  1.1349249e+00  2.9802322e-07 -3.2317138e-01  1.0000001e+00\n",
      "  0.0000000e+00 -6.2926602e-01 -1.0000001e+00 -6.2796354e-01\n",
      " -1.9868216e-08  0.0000000e+00  3.8185567e-01  3.8387981e-01\n",
      "  3.9582726e-01  4.2357340e-01  4.7422779e-01  5.3699774e-01\n",
      "  6.5521443e-01  8.2957059e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 6.35433435e-01  1.02728784e-01  3.03206414e-01 -5.02359383e-02\n",
      "  1.12852240e+00 -3.57627869e-07 -1.93538189e-01  9.99999821e-01\n",
      "  0.00000000e+00 -7.20423758e-01 -1.12653422e+00 -5.05780935e-01\n",
      "  9.99999702e-01  0.00000000e+00  3.79315615e-01  3.81242871e-01\n",
      "  3.93941820e-01  4.21601564e-01  4.72848713e-01  5.34822762e-01\n",
      "  6.52883828e-01  8.25095713e-01  1.00000000e+00  1.00000000e+00]\n",
      "[ 6.8189692e-01  9.2799097e-02  2.8331316e-01 -7.9334401e-02\n",
      "  1.1251564e+00  1.1920929e-07 -1.0442984e-01  6.8902922e-01\n",
      "  0.0000000e+00 -7.3879176e-01 -2.1160269e-01 -6.2332499e-01\n",
      " -9.9999970e-01  0.0000000e+00  3.7540686e-01  3.7724382e-01\n",
      "  3.9055672e-01  4.1864529e-01  4.6899778e-01  5.3065610e-01\n",
      "  6.4788008e-01  8.1784427e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 7.3253185e-01  1.0108903e-01  3.0467036e-01 -9.5648453e-02\n",
      "  1.1189668e+00 -4.1723251e-07  2.6336253e-02  9.9999994e-01\n",
      "  0.0000000e+00 -8.1890696e-01 -9.9999988e-01 -6.2232339e-01\n",
      "  0.0000000e+00  0.0000000e+00  3.7064174e-01  3.7245539e-01\n",
      "  3.8640007e-01  4.1489092e-01  4.6370801e-01  5.2544659e-01\n",
      "  6.4159995e-01  8.0906999e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 7.6763076e-01  6.9981240e-02  2.8280938e-01 -1.0271741e-01\n",
      "  1.1124127e+00  1.4901161e-07  1.8861437e-01  1.2572583e+00\n",
      "  0.0000000e+00 -8.1925702e-01  0.0000000e+00 -6.2098396e-01\n",
      " -3.9736431e-08  0.0000000e+00  3.6553729e-01  3.6732593e-01\n",
      "  3.8182178e-01  4.1060823e-01  4.5797452e-01  5.1959801e-01\n",
      "  6.3452125e-01  7.9955965e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 8.0103564e-01  6.6577867e-02  2.9048902e-01 -1.0925609e-01\n",
      "  1.1082489e+00  4.1723251e-07  3.1689882e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.2277352e-01  0.0000000e+00 -5.1220953e-01\n",
      "  8.7239450e-01  0.0000000e+00  3.6010689e-01  3.6186895e-01\n",
      "  3.7692121e-01  4.0598989e-01  4.5185900e-01  5.1331204e-01\n",
      "  6.2690687e-01  7.8941566e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 8.3243728e-01  6.2571071e-02  2.9227322e-01 -1.2445441e-01\n",
      "  1.1044023e+00 -3.2782555e-07  4.4454002e-01  9.9999982e-01\n",
      "  0.0000000e+00 -8.2706195e-01  0.0000000e+00 -3.8696110e-01\n",
      "  1.0000004e+00  0.0000000e+00  3.5395256e-01  3.5593557e-01\n",
      "  3.7125748e-01  4.0052772e-01  4.4486958e-01  5.0595367e-01\n",
      "  6.1797035e-01  7.7782208e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 8.6205786e-01  5.8998078e-02  2.9359809e-01 -1.4111356e-01\n",
      "  1.1010485e+00 -2.9802322e-08  5.7367229e-01  1.0201660e+00\n",
      "  0.0000000e+00 -8.3136553e-01  0.0000000e+00 -2.6111352e-01\n",
      "  1.0000004e+00  0.0000000e+00  3.4700802e-01  3.4970522e-01\n",
      "  3.6475894e-01  3.9414072e-01  4.3692532e-01  4.9742100e-01\n",
      "  6.0758567e-01  7.6464474e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 8.9172542e-01  5.9490338e-02  2.9447001e-01 -1.5631121e-01\n",
      "  1.0994239e+00  5.9604645e-08  6.7648411e-01  8.1719476e-01\n",
      "  0.0000000e+00 -8.3491218e-01  0.0000000e+00 -3.7897003e-01\n",
      " -1.4006268e+00  1.0000000e+00  3.3934447e-01  3.4274504e-01\n",
      "  3.5749915e-01  3.8690880e-01  4.2811143e-01  4.8781613e-01\n",
      "  5.9587854e-01  7.5002491e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.9178247   0.0530012   0.31030482 -0.18757008  1.1785727   0.99999934\n",
      "  0.5638195  -1.          0.         -0.83048016  0.         -0.35374403\n",
      " -0.5400139   1.          0.3299947   0.3341176   0.3485003   0.37779164\n",
      "  0.41728264  0.47579584  0.58119977  0.7320629   0.9925036   1.        ]\n",
      "[ 9.4951063e-01  5.4713011e-02  2.9848468e-01 -1.9534051e-01\n",
      "  1.1349108e+00 -2.3841858e-07  7.7592194e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3458614e-01  0.0000000e+00 -4.2559719e-01\n",
      " -5.5905825e-01  1.0000000e+00  3.2071242e-01  3.2549992e-01\n",
      "  3.3951169e-01  3.6862651e-01  4.0650281e-01  4.6374550e-01\n",
      "  5.6647390e-01  7.1444035e-01  9.6962941e-01  1.0000000e+00]\n",
      "[ 9.7135890e-01  4.3534923e-02  2.9745522e-01 -2.0288502e-01\n",
      "  1.1337804e+00  2.0861626e-07  8.9744639e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3492064e-01  0.0000000e+00 -4.8851085e-01\n",
      " -5.2969843e-01  1.0000000e+00  3.1084841e-01  3.1630680e-01\n",
      "  3.3041981e-01  3.5881022e-01  3.9502773e-01  4.5086098e-01\n",
      "  5.5072176e-01  6.9569790e-01  9.4532859e-01  1.0000000e+00]\n",
      "[ 9.8746091e-01  3.2221511e-02  2.9461625e-01 -2.0950884e-01\n",
      "  1.1338542e+00  4.4703484e-08  1.0167305e+00  1.0000000e+00\n",
      "  0.0000000e+00 -8.3491409e-01  0.0000000e+00 -5.4838061e-01\n",
      " -5.0271839e-01  1.0000000e+00  3.0113435e-01  3.0679950e-01\n",
      "  3.2104030e-01  3.4862480e-01  3.8318184e-01  4.3751100e-01\n",
      "  5.3439456e-01  6.7636359e-01  9.1891921e-01  1.0000000e+00]\n",
      "[ 1.0120310e+00  3.7626222e-02  2.8024131e-01 -2.1026361e-01\n",
      "  1.1353608e+00  2.9802322e-08  9.3494439e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3502835e-01  0.0000000e+00 -6.1188054e-01\n",
      " -5.0993901e-01  1.0000000e+00  2.9184970e-01  2.9734015e-01\n",
      "  3.1165105e-01  3.3842883e-01  3.7143466e-01  4.2418188e-01\n",
      "  5.1808184e-01  6.5721589e-01  8.9253688e-01  1.0000000e+00]\n",
      "[ 9.8874044e-01 -4.6068989e-02  2.5822645e-01 -1.2335988e-01\n",
      "  1.1349404e+00  3.0725002e-03  9.3490911e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3491266e-01 -2.5123358e-05 -6.2648642e-01\n",
      " -1.4652331e-01  1.0000000e+00  2.8643835e-01  2.9182702e-01\n",
      "  3.0645254e-01  3.3278364e-01  3.6440080e-01  4.1663632e-01\n",
      "  5.0889975e-01  6.4562821e-01  8.7667054e-01  1.0000000e+00]\n",
      "[ 9.5490080e-01 -6.7723021e-02  2.9247916e-01 -6.1988167e-02\n",
      "  1.1347857e+00 -1.2696683e-03  9.3490613e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3407021e-01  1.3619661e-05 -6.2068629e-01\n",
      "  5.4820258e-02  1.0000000e+00  2.8394002e-01  2.8928167e-01\n",
      "  3.0452579e-01  3.3069134e-01  3.6082956e-01  4.1353816e-01\n",
      "  5.0522304e-01  6.3953859e-01  8.6849785e-01  1.0000000e+00]\n",
      "[ 9.1863382e-01 -7.2584823e-02  3.0328611e-01 -5.9088364e-02\n",
      "  1.1346077e+00 -1.5898943e-03  9.3490517e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3267874e-01  6.8247318e-06 -6.1181509e-01\n",
      "  8.8108160e-02  1.0000000e+00  2.8158674e-01  2.8688413e-01\n",
      "  3.0278680e-01  3.2759982e-01  3.5741377e-01  4.1068178e-01\n",
      "  5.0184995e-01  6.3368398e-01  8.6066389e-01  1.0000000e+00]\n",
      "[ 8.8150060e-01 -7.4320540e-02  3.1705236e-01 -5.7240449e-02\n",
      "  1.1345137e+00 -2.3752451e-05  9.3490672e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3275086e-01  7.7486038e-07 -6.0032368e-01\n",
      "  8.5726522e-02  1.0000000e+00  2.7933258e-01  2.8504109e-01\n",
      "  3.0119309e-01  3.2455567e-01  3.5409254e-01  4.0800437e-01\n",
      "  4.9835834e-01  6.2796336e-01  8.5303080e-01  1.0000000e+00]\n",
      "[ 8.4237581e-01 -7.8306176e-02  3.2907519e-01 -5.5543408e-02\n",
      "  1.1344187e+00  1.7583370e-05  9.3490636e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3279920e-01 -5.6624413e-07 -5.8513892e-01\n",
      "  1.1563035e-01  1.0000000e+00  2.7716729e-01  2.8365549e-01\n",
      "  2.9972896e-01  3.2158962e-01  3.5085654e-01  4.0548685e-01\n",
      "  4.9465686e-01  6.2236381e-01  8.4557927e-01  1.0000000e+00]\n",
      "[ 8.0112576e-01 -8.2562082e-02  3.4253368e-01 -5.3354092e-02\n",
      "  1.1343160e+00  3.6954880e-06  9.3490684e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3283484e-01 -1.1920929e-07 -5.6576383e-01\n",
      "  1.4948048e-01  1.0000000e+00  2.7511492e-01  2.8242096e-01\n",
      "  2.9842448e-01  3.1872603e-01  3.4843519e-01  4.0316853e-01\n",
      "  4.9114951e-01  6.1692625e-01  8.3836716e-01  1.0000000e+00]\n",
      "[ 7.5859821e-01 -8.5180528e-02  3.5653853e-01 -3.9088607e-02\n",
      "  1.1341349e+00 -4.1067600e-05  9.3490636e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3300370e-01  1.3709068e-06 -5.6251526e-01\n",
      "  8.5860468e-02  1.0000000e+00  2.7375317e-01  2.8193432e-01\n",
      "  2.9791027e-01  3.1660575e-01  3.4735304e-01  4.0200809e-01\n",
      "  4.8882690e-01  6.1286080e-01  8.3295298e-01  1.0000000e+00]\n",
      "[ 7.1318293e-01 -9.0906508e-02  3.7076512e-01 -2.2641132e-02\n",
      "  1.1340117e+00  2.7298927e-05  9.3490696e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3302951e-01 -8.9406967e-07 -5.3741038e-01\n",
      "  1.9484068e-01  0.0000000e+00  2.7374479e-01  2.8227717e-01\n",
      "  2.9719844e-01  3.1531507e-01  3.4729463e-01  4.0209100e-01\n",
      "  4.8782316e-01  6.1052501e-01  8.2954633e-01  1.0000000e+00]\n",
      "[ 6.6522360e-01 -9.5919110e-02  3.8412449e-01 -4.4755312e-03\n",
      "  1.1335967e+00  2.9802322e-07  9.1552532e-01 -1.6852374e-01\n",
      "  0.0000000e+00 -8.3271712e-01 -5.9604645e-08 -4.9943328e-01\n",
      "  3.1315908e-01  0.0000000e+00  2.7496642e-01  2.8353691e-01\n",
      "  2.9685834e-01  3.1495425e-01  3.4837139e-01  4.0350413e-01\n",
      "  4.8828948e-01  6.0987204e-01  8.2797033e-01  1.0000000e+00]\n",
      "[ 6.1374217e-01 -1.0303157e-01  4.0404299e-01  1.6321078e-02\n",
      "  1.1329954e+00 -1.5145540e-04  8.9203942e-01 -2.0677781e-01\n",
      "  0.0000000e+00 -8.3234704e-01  2.0503998e-05 -4.4353044e-01\n",
      "  4.5500329e-01  1.0000000e+00  2.7722698e-01  2.8586793e-01\n",
      "  2.9752058e-01  3.1565684e-01  3.5076779e-01  4.0646595e-01\n",
      "  4.9045163e-01  6.1114353e-01  8.2796413e-01  1.0000000e+00]\n",
      "[ 5.57721853e-01 -1.12152025e-01  4.35361713e-01  3.23923677e-02\n",
      "  1.13269353e+00 -3.39746475e-06  9.18843985e-01  2.16773212e-01\n",
      "  0.00000000e+00 -8.32263708e-01  4.76837158e-07 -3.69708538e-01\n",
      "  5.97611785e-01  1.00000000e+00  2.80343890e-01  2.88838357e-01\n",
      "  2.98947006e-01  3.18182439e-01  3.54232550e-01  4.10687417e-01\n",
      "  4.93949234e-01  6.13882303e-01  8.29624355e-01  1.00000000e+00]\n",
      "[ 4.97532040e-01 -1.20474674e-01  4.55921948e-01  5.52046187e-02\n",
      "  1.13224387e+00  1.34348869e-04  9.19937253e-01  0.00000000e+00\n",
      "  0.00000000e+00 -8.32396328e-01 -4.47034836e-06 -2.73937821e-01\n",
      "  7.74512589e-01  0.00000000e+00  2.84586400e-01  2.91271985e-01\n",
      "  3.01465809e-01  3.22580695e-01  3.59139323e-01  4.16588515e-01\n",
      "  4.97732997e-01  6.18718386e-01  8.33760262e-01  1.00000000e+00]\n",
      "[ 4.3384001e-01 -1.2800960e-01  4.6278834e-01  8.4177904e-02\n",
      "  1.1292003e+00  3.1983852e-04  8.0880058e-01 -9.9997044e-01\n",
      "  0.0000000e+00 -8.3443850e-01 -1.0609627e-05 -1.6574669e-01\n",
      "  6.8008357e-01  1.0000000e+00  2.9019126e-01  2.9504493e-01\n",
      "  3.0537084e-01  3.2855350e-01  3.6599377e-01  4.2338821e-01\n",
      "  5.0310433e-01  6.2588257e-01  8.4110099e-01  1.0000000e+00]\n",
      "[ 0.36038545 -0.14728177  0.48895288  0.08531638  1.0791336  -0.62116843\n",
      "  0.9306898   0.9999997   0.         -0.83439237  0.         -0.04452837\n",
      "  0.9158962   0.          0.29545042  0.29880568  0.31001258  0.33460027\n",
      "  0.37293994  0.42980564  0.50843096  0.6321473   0.84859663  1.        ]\n",
      "[ 2.8114095e-01 -1.5867919e-01  5.1085269e-01  7.3291086e-02\n",
      "  1.1081085e+00  3.9227104e-01  8.1803942e-01 -1.0000018e+00\n",
      "  0.0000000e+00 -8.3490878e-01 -9.5367432e-07  7.7732801e-02\n",
      "  1.0095094e+00  0.0000000e+00  2.9856554e-01  3.0195621e-01\n",
      "  3.1503388e-01  3.4001982e-01  3.7919104e-01  4.3540663e-01\n",
      "  5.1278943e-01  6.3721979e-01  8.5516953e-01  1.0000000e+00]\n",
      "[ 2.0579557e-01 -1.5083323e-01  5.1220018e-01  6.7084365e-02\n",
      "  1.1034676e+00 -2.4883747e-03  7.1140605e-01 -1.0002385e+00\n",
      "  0.0000000e+00 -8.3490652e-01  8.1658363e-05  2.0209259e-01\n",
      "  1.0114266e+00  0.0000000e+00  3.0139536e-01  3.0481815e-01\n",
      "  3.1974941e-01  3.4521857e-01  3.8507265e-01  4.4060031e-01\n",
      "  5.1680380e-01  6.4174521e-01  8.6101490e-01  1.0000000e+00]\n",
      "[ 0.11953191 -0.17297566  0.51098233  0.05414468  1.0519758  -0.6204169\n",
      "  0.8373995   1.          0.         -0.82174283  0.17491645  0.32616514\n",
      "  0.9999998   0.          0.30355337  0.30801845  0.32373527  0.3496999\n",
      "  0.3894015   0.44433513  0.5202755   0.6449875   0.86515486  1.        ]\n",
      "[ 0.03364769 -0.17240472  0.5160781   0.03603352  1.0535493   0.08097661\n",
      "  0.7316636  -0.9999998   0.         -0.808454    0.19153982  0.45233303\n",
      "  0.9999998   0.          0.304825    0.3109162   0.3267809   0.35316363\n",
      "  0.39200082  0.44558737  0.52232116  0.6471954   0.8669105   1.        ]\n",
      "[-0.07079564 -0.20888688  0.42420018  0.05739903  1.1997969   1.8535769\n",
      "  0.62684387 -1.0041519   1.         -0.76711935  0.50653267  0.572783\n",
      "  0.9993281   0.          0.30708522  0.3145378   0.33062828  0.35742238\n",
      "  0.39565626  0.44824773  0.5259572   0.6514495   0.87018687  1.        ]\n",
      "[-0.12198085 -0.11569862  0.261425    0.20073883  1.1349093   0.03789437\n",
      "  0.8297133   0.500288    1.         -0.7634118   0.15668273  0.6993136\n",
      "  0.99791336  1.          0.31693536  0.3252045   0.34194595  0.36965725\n",
      "  0.408211    0.46089932  0.54141206  0.6703396   0.8916007   1.        ]\n",
      "[-0.18417591 -0.12442445  0.25956312  0.18786927  1.1227689  -0.14636618\n",
      "  0.95055825  1.          1.         -0.734711    0.35733858  0.8195295\n",
      "  1.0000001   0.          0.32625014  0.3347623   0.35209355  0.380549\n",
      "  0.41942003  0.47212645  0.55479336  0.68712157  0.9105214   1.        ]\n",
      "[-2.3667659e-01 -1.0543563e-01  2.6539081e-01  1.8371457e-01\n",
      "  1.1206425e+00  5.9604645e-08  1.0497034e+00  1.1396264e+00\n",
      "  1.0000000e+00 -7.2005200e-01  1.9518182e-01  9.4056588e-01\n",
      "  1.0000002e+00  1.0000000e+00  3.3536246e-01  3.4411237e-01\n",
      "  3.6202413e-01  3.9047807e-01  4.3036330e-01  4.8304984e-01\n",
      "  5.6733805e-01  7.0218384e-01  9.3065500e-01  1.0000000e+00]\n",
      "[-0.26546726 -0.05980771  0.25607193  0.18754958  1.1380571   0.00755009\n",
      "  0.9350557   0.00221294  1.         -0.64023787  0.9984884   0.8199613\n",
      " -1.0017012   0.          0.34492454  0.35392392  0.37243497  0.40095305\n",
      "  0.44076148  0.4950719   0.58070713  0.7178141   0.95502645  1.        ]\n",
      "[-2.6526114e-01  2.0445978e-04  2.6075944e-01  1.8144929e-01\n",
      "  1.1349078e+00 -4.3073669e-09  8.7773973e-01 -5.4445153e-01\n",
      "  1.0000000e+00 -5.9834546e-01  5.3562748e-01  7.0247853e-01\n",
      " -1.0000000e+00  0.0000000e+00  3.5419583e-01  3.6345187e-01\n",
      "  3.8253555e-01  4.1107395e-01  4.5071337e-01  5.0668615e-01\n",
      "  5.9353912e-01  7.3278707e-01  9.7847849e-01  1.0000000e+00]\n",
      "[-2.4205004e-01  4.6463627e-02  2.6388457e-01  1.7613286e-01\n",
      "  1.1340139e+00 -8.1762671e-04  7.5936061e-01 -1.0002785e+00\n",
      "  1.0000000e+00 -5.7833767e-01  2.5635841e-01  5.8391386e-01\n",
      " -1.0000113e+00  0.0000000e+00  3.6331305e-01  3.7289110e-01\n",
      "  3.9247039e-01  4.2101446e-01  4.6046767e-01  5.1807719e-01\n",
      "  6.0611314e-01  7.4744904e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-0.22407182  0.03594746  0.2544875   0.16603452  1.1331233  -0.00343378\n",
      "  0.64231664 -1.0011078   1.         -0.5043821   0.9905243   0.36704665\n",
      " -1.939846    0.          0.3718331   0.3817142   0.40175673  0.4302913\n",
      "  0.4695497   0.5286907   0.6181398   0.7614445   1.          1.        ]\n",
      "[-2.0807573e-01  3.2037228e-02  2.5758260e-01  1.4982162e-01\n",
      "  1.1313868e+00 -1.4901161e-08  5.2551264e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -4.5036629e-01  6.8597281e-01  2.4990600e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.7966159e-01  3.8982758e-01\n",
      "  4.0998685e-01  4.3877628e-01  4.7779182e-01  5.3834623e-01\n",
      "  6.2927842e-01  7.7437329e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-1.9257057e-01  3.0984387e-02  2.5652817e-01  1.3226296e-01\n",
      "  1.1295058e+00 -1.4901161e-08  4.0955627e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -3.9474070e-01  7.1089709e-01  1.3468283e-01\n",
      " -1.0000000e+00  0.0000000e+00  3.8665345e-01  3.9708114e-01\n",
      "  4.1702703e-01  4.4631085e-01  4.8503783e-01  5.4677123e-01\n",
      "  6.3908917e-01  7.8571773e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-0.14972362  0.08544391  0.27695155  0.11909982  1.0524698  -0.91704905\n",
      "  0.29918075 -0.9999998   0.         -0.3964902   0.00668168  0.02189076\n",
      " -1.          0.          0.39318416  0.40386677  0.4235452   0.4524864\n",
      "  0.49172705  0.55403763  0.64805824  0.79602647  1.          1.        ]\n",
      "[-0.10197481  0.09529922  0.28198415  0.09743351  0.9681754  -1.0000002\n",
      "  0.18906343 -1.          0.         -0.41835743 -0.24936387 -0.09399557\n",
      " -1.0000001   0.          0.398744    0.4096559   0.42902434  0.45747918\n",
      "  0.49744925  0.559988    0.6554581   0.80445474  1.          1.        ]\n",
      "[-0.05385123  0.09607606  0.28326458  0.07742587  0.88382673 -1.0000002\n",
      "  0.09520805 -0.41658083  1.         -0.4465589  -0.32831088 -0.21032095\n",
      " -1.0000001   0.          0.4034235   0.4144893   0.433513    0.46144506\n",
      "  0.5020407   0.564695    0.6613719   0.8105493   1.          1.        ]\n",
      "[ 0.00422323  0.11622615  0.2877273   0.05913963  0.8101074  -0.9562816\n",
      " -0.0398432  -1.          1.         -0.5033453  -0.6808913  -0.3262565\n",
      " -0.9999998   0.          0.40733746  0.41851062  0.43715668  0.4645302\n",
      "  0.5056637   0.56833476  0.66529197  0.81489146  1.          1.        ]\n",
      "[ 0.05431233  0.10016462  0.28125712  0.02812867  0.7834813  -0.3047355\n",
      " -0.1564275  -1.          1.         -0.5862696  -1.         -0.42694354\n",
      " -0.88190395  0.          0.40973285  0.42097172  0.43919724  0.46597144\n",
      "  0.5074706   0.5699866   0.666894    0.8165518   1.          1.        ]\n",
      "[ 8.9047357e-02  6.9338799e-02  2.6386052e-01  3.1775449e-05\n",
      "  8.2526618e-01  5.3498632e-01 -2.7101445e-01 -1.0000001e+00\n",
      "  0.0000000e+00 -6.6395932e-01 -9.1456759e-01 -5.4009080e-01\n",
      " -9.9999982e-01  0.0000000e+00  4.1068521e-01  4.2154202e-01\n",
      "  4.3973365e-01  4.6589598e-01  5.0759333e-01  5.6980759e-01\n",
      "  6.6642988e-01  8.1576478e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.1166857   0.055043    0.2569234  -0.02495725  0.9041744   1.0000004\n",
      " -0.3818512  -1.          0.         -0.74939495 -1.0000004  -0.6521158\n",
      " -1.0000001   0.          0.41040716  0.4208133   0.4389735   0.4644939\n",
      "  0.50624955  0.56802475  0.6641477   0.8128169   1.          1.        ]\n",
      "[ 0.13841228  0.04284501  0.26438537 -0.03225236  0.98271585  1.0000002\n",
      " -0.43117058 -0.48164073  0.         -0.83306223 -1.0000001  -0.6349118\n",
      "  0.          0.          0.4098172   0.41975093  0.43768066  0.46270984\n",
      "  0.5044919   0.5657764   0.6613268   0.80921906  1.          1.        ]\n",
      "[ 1.4026766e-01  3.4512854e-03  2.4216488e-01 -2.6708152e-02\n",
      "  1.0546083e+00  9.9999940e-01 -2.9784119e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3338284e-01  9.3132257e-09 -6.3468683e-01\n",
      "  5.4637592e-08  0.0000000e+00  4.0935618e-01  4.1885951e-01\n",
      "  4.3621948e-01  4.6116510e-01  5.0298011e-01  5.6389606e-01\n",
      "  6.5886682e-01  8.0607152e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 1.4722301e-01  1.3818078e-02  2.4884382e-01 -3.0554472e-02\n",
      "  1.0792050e+00  3.6810753e-01 -1.7079091e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.1350017e-01  2.5089955e-01 -6.3395238e-01\n",
      " -1.9868216e-08  0.0000000e+00  4.0875298e-01  4.1781345e-01\n",
      "  4.3458754e-01  4.5945966e-01  5.0127381e-01  5.6189764e-01\n",
      "  6.5615046e-01  8.0261350e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 1.3309626e-01 -2.8432729e-02  2.3593694e-01 -4.6836514e-02\n",
      "  1.1521274e+00  9.9999881e-01 -3.8193226e-02  9.9999982e-01\n",
      "  0.0000000e+00 -7.3448503e-01  1.0000002e+00 -6.3024831e-01\n",
      "  1.9868214e-07  0.0000000e+00  4.0725994e-01  4.1588041e-01\n",
      "  4.3207595e-01  4.5694828e-01  4.9845064e-01  5.5874640e-01\n",
      "  6.5216911e-01  7.9765815e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 1.3692319e-01  3.0991135e-03  2.4468078e-01 -4.6543546e-02\n",
      "  1.1349096e+00  4.0978193e-08  1.1008167e-01  1.0000004e+00\n",
      "  0.0000000e+00 -6.5830117e-01  9.9999988e-01 -6.2229049e-01\n",
      " -1.5894572e-07  0.0000000e+00  4.0600604e-01  4.1417828e-01\n",
      "  4.2978334e-01  4.5467609e-01  4.9575865e-01  5.5588454e-01\n",
      "  6.4849657e-01  7.9306424e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.16817218  0.06243545  0.27694467 -0.05667417  1.0531104  -0.9999994\n",
      "  0.23358363  1.          0.         -0.6791652  -0.22927926 -0.5000242\n",
      "  1.0000001   0.          0.4043453   0.41200814  0.4269433   0.4518414\n",
      "  0.492432    0.5523249   0.643985    0.7874432   1.          1.        ]\n",
      "[ 0.19844615  0.06037745  0.27675602 -0.07256821  0.97205204 -1.0000004\n",
      "  0.35731006  1.          0.         -0.7003922  -0.2183832  -0.37579095\n",
      "  0.99999994  0.          0.40147337  0.40906605  0.42331442  0.44816473\n",
      "  0.488204    0.547737    0.6383246   0.780453    1.          1.        ]\n",
      "[ 0.21178369  0.02665011  0.26910865 -0.10205147  0.9511236  -0.23038632\n",
      "  0.4810483   0.9999998   0.         -0.70927155 -0.07965125 -0.25275934\n",
      "  1.          0.          0.397141    0.40465176  0.4181997   0.44289613\n",
      "  0.48228058  0.54120797  0.63051146  0.77090424  1.          1.        ]\n",
      "[ 0.22508246  0.02626523  0.2796282  -0.14453924  1.0293365   1.0000002\n",
      "  0.36897922 -0.99999994  0.         -0.7589945  -0.59257674 -0.12887073\n",
      "  1.0000001   0.          0.39081466  0.39820576  0.41098362  0.43539253\n",
      "  0.4739529   0.53194547  0.6196229   0.7576802   1.          1.        ]\n",
      "[ 0.24517302  0.03986117  0.2676528  -0.17884926  1.106984    1.0000002\n",
      "  0.25806046 -1.          0.         -0.7903705  -0.35064366 -0.24360514\n",
      " -0.99999934  0.          0.38288972  0.38980207  0.4021333   0.42613497\n",
      "  0.46376166  0.5205457   0.6063724   0.74165285  1.          1.        ]\n",
      "[ 2.8260908e-01  7.4855663e-02  2.9538161e-01 -1.6475426e-01\n",
      "  1.1050342e+00  5.3644180e-07  1.4208525e-01 -1.0000001e+00\n",
      "  0.0000000e+00 -8.7126189e-01 -1.0000002e+00 -1.2163854e-01\n",
      "  9.9999952e-01  0.0000000e+00  3.7573013e-01  3.8193968e-01\n",
      "  3.9402217e-01  4.1768464e-01  4.5440751e-01  5.1012278e-01\n",
      "  5.9416360e-01  7.2684443e-01  9.9098438e-01  1.0000000e+00]\n",
      "[ 2.8340095e-01  1.4796099e-02  2.6498100e-01 -1.6904938e-01\n",
      "  1.1092718e+00  2.9802322e-08  2.7157211e-01  9.9999970e-01\n",
      "  0.0000000e+00 -8.3491206e-01  0.0000000e+00 -5.3792834e-02\n",
      "  1.0000002e+00  0.0000000e+00  3.6831087e-01  3.7389863e-01\n",
      "  3.8572675e-01  4.0901044e-01  4.4485411e-01  4.9943990e-01\n",
      "  5.8173835e-01  7.1181184e-01  9.6871227e-01  1.0000000e+00]\n",
      "[ 2.8442013e-01  2.0124842e-03  2.5956661e-01 -1.7934829e-01\n",
      "  1.1068518e+00  1.2200326e-07  3.9584285e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.1121075e-01  3.4366781e-01  7.2658002e-02\n",
      "  1.0000001e+00  0.0000000e+00  3.6028725e-01  3.6523822e-01\n",
      "  3.7679237e-01  3.9965725e-01  4.3456939e-01  4.8792633e-01\n",
      "  5.6837684e-01  6.9565946e-01  9.4462490e-01  1.0000000e+00]\n",
      "[ 0.30408725  0.0392804   0.26522434 -0.18479867  1.041246   -0.8083011\n",
      "  0.51874846  1.0000001   0.         -0.8147675   0.          0.19909799\n",
      "  0.9999997   0.          0.35207075  0.35637328  0.36766964  0.39008206\n",
      "  0.42404217  0.47614005  0.5547018   0.67912954  0.91996276  1.        ]\n",
      "[ 0.31540373  0.02260752  0.26413047 -0.21044129  1.0078425  -0.4040903\n",
      "  0.64119464  0.99999994  0.         -0.8162746   0.01909029  0.08098793\n",
      " -1.4839487   1.          0.34262317  0.34626862  0.35735703  0.3791408\n",
      "  0.41205397  0.46268594  0.5391659   0.66038275  0.89170736  1.        ]\n",
      "[ 0.33192757  0.03396126  0.2663657  -0.2478142   1.0452219   0.46355242\n",
      "  0.5241376  -1.0000001   0.         -0.80636555  0.          0.06703234\n",
      " -0.9999998   1.          0.33129543  0.3342693   0.34507704  0.36611223\n",
      "  0.39783278  0.44668326  0.5207853   0.6382467   0.8579625   1.        ]\n",
      "[ 0.3439792   0.02382253  0.27010882 -0.2731134   1.1216415   1.\n",
      "  0.3455788  -1.5726962   0.         -0.8089775   0.         -0.04779828\n",
      " -1.          0.          0.3185947   0.3212093   0.33170083  0.35192066\n",
      "  0.38235924  0.4292578   0.5008017   0.614194    0.82351935  1.        ]\n",
      "[ 3.6941564e-01  5.0836015e-02  2.6840931e-01 -2.7161917e-01\n",
      "  1.1195514e+00  5.9604645e-08  2.2966403e-01 -9.9999994e-01\n",
      "  0.0000000e+00 -8.1071508e-01  0.0000000e+00 -1.7488384e-01\n",
      " -1.0847639e+00  0.0000000e+00  3.0576184e-01  3.0827114e-01\n",
      "  3.1844848e-01  3.3786047e-01  3.6703044e-01  4.1199413e-01\n",
      "  4.8100632e-01  5.9036905e-01  7.9054385e-01  1.0000000e+00]\n",
      "[ 3.93809617e-01  4.87238206e-02  2.68791318e-01 -2.87425697e-01\n",
      "  1.11761904e+00 -2.08616257e-07  1.13749504e-01 -1.00000012e+00\n",
      "  0.00000000e+00 -8.12413990e-01  0.00000000e+00 -2.91718602e-01\n",
      " -9.99999821e-01  0.00000000e+00  2.92185426e-01  2.94583321e-01\n",
      "  3.04418117e-01  3.22974831e-01  3.50817919e-01  3.93722415e-01\n",
      "  4.60084558e-01  5.64384341e-01  7.55671144e-01  1.00000000e+00]\n",
      "[ 4.0053773e-01  1.3426309e-02  2.4970230e-01 -3.0036810e-01\n",
      "  1.1177620e+00  2.2351742e-08  1.5490669e-01  3.3696857e-01\n",
      "  0.0000000e+00 -7.7284664e-01  5.1029575e-01 -4.0895128e-01\n",
      " -1.0000001e+00  0.0000000e+00  2.7795744e-01  2.8023854e-01\n",
      "  2.8969362e-01  3.0735275e-01  3.3383641e-01  3.7455779e-01\n",
      "  4.3820059e-01  5.3715688e-01  7.1911675e-01  1.0000000e+00]\n",
      "[ 0.41538295  0.02958327  0.2685542  -0.32835293  1.1087424  -0.07858526\n",
      "  0.28006744  0.9999998   0.         -0.8178066  -0.5478045  -0.40900207\n",
      "  0.37540975  1.          0.26243463  0.26458836  0.27362624  0.29030594\n",
      "  0.31531075  0.35364693  0.414331    0.50745475  0.676756    1.        ]\n",
      "[ 3.7433219e-01 -8.2660347e-02  2.7471450e-01 -9.7899377e-02\n",
      "  1.1026326e+00 -6.5810680e-03  4.0815860e-01  1.0001704e+00\n",
      "  0.0000000e+00 -8.3664960e-01  3.3438206e-04 -2.7202117e-01\n",
      "  1.0016912e+00  1.0000000e+00  2.5830743e-01  2.6042730e-01\n",
      "  2.6949963e-01  2.8592777e-01  3.1032124e-01  3.4819883e-01\n",
      "  4.0769023e-01  4.9940234e-01  6.6587639e-01  1.0000000e+00]\n",
      "[ 3.2612434e-01 -9.4646223e-02  3.0936143e-01 -2.5564384e-02\n",
      "  1.0996325e+00  3.5417080e-03  5.3550941e-01  1.0000275e+00\n",
      "  0.0000000e+00 -8.3602262e-01 -1.8137693e-04 -1.9538522e-01\n",
      "  3.9448020e-01  1.0000000e+00  2.5720301e-01  2.5947660e-01\n",
      "  2.6855767e-01  2.8475666e-01  3.0891481e-01  3.4686559e-01\n",
      "  4.0558475e-01  4.9707443e-01  6.6339296e-01  1.0000000e+00]\n",
      "[ 2.8214592e-01 -8.8401318e-02  3.2862237e-01 -1.0052644e-02\n",
      "  1.0501027e+00 -5.9550536e-01  6.8043125e-01  1.3964891e+00\n",
      "  1.0000000e+00 -8.3294314e-01  6.6161156e-06 -1.6340852e-01\n",
      "  4.7886714e-01  1.0000000e+00  2.5639480e-01  2.5887701e-01\n",
      "  2.6793709e-01  2.8378004e-01  3.0785534e-01  3.4594280e-01\n",
      "  4.0390468e-01  4.9529737e-01  6.6175687e-01  1.0000000e+00]\n",
      "[ 0.20940554 -0.1452524   0.30604714 -0.01706599  1.0827177   0.385822\n",
      "  0.79377234  1.0000001   1.         -0.78124386  0.66084933 -0.13255465\n",
      "  0.16465212  1.          0.25514513  0.25781536  0.26683828  0.28232634\n",
      "  0.30627832  0.3444089   0.40158883  0.4926983   0.6588599   1.        ]\n",
      "[ 0.11238522 -0.19393055  0.323722   -0.02301285  1.161217    1.0020603\n",
      "  0.9159832   1.0000999   1.         -0.71900713  0.8340944  -0.08981383\n",
      "  0.27605468  1.          0.25347412  0.25634003  0.26531133  0.28040597\n",
      "  0.30419502  0.34231356  0.39860895  0.4892846   0.65483415  1.        ]\n",
      "[ 5.11838868e-02 -1.34397954e-01  3.67486447e-01  1.96565015e-04\n",
      "  1.13514769e+00  3.57627869e-07  1.03206587e+00  1.35140562e+00\n",
      "  1.00000000e+00 -7.17443943e-01  1.18739724e-01 -1.36160851e-03\n",
      "  7.02296436e-01  0.00000000e+00  2.53432810e-01  2.56310910e-01\n",
      "  2.65222818e-01  2.80007809e-01  3.03948164e-01  3.42141300e-01\n",
      "  3.97688746e-01  4.88501579e-01  6.54039502e-01  1.00000000e+00]\n",
      "[ 0.05985692 -0.02544802  0.23150909  0.09682696  1.1508033   0.01779473\n",
      "  0.9797089   0.00396747  1.         -0.76859564 -0.35424316  0.09164858\n",
      "  0.71323353  0.          0.25871462  0.2616527   0.27050257  0.2855819\n",
      "  0.31024283  0.34922695  0.40518007  0.49739468  0.66696846  1.        ]\n",
      "[ 0.05793319 -0.02208276  0.1669028   0.11544735  1.1419338   0.\n",
      "  0.9353101  -0.04881802  1.         -0.70033723  0.98557043 -0.02013099\n",
      " -0.99999994  0.          0.2644271   0.26743007  0.27628192  0.2916834\n",
      "  0.31707433  0.35672575  0.4134566   0.50711554  0.68113995  1.        ]\n",
      "[ 5.7900872e-02  4.1937962e-04  1.4033823e-01  1.1851513e-01\n",
      "  1.1306233e+00 -1.8754376e-01  9.3490553e-01  0.0000000e+00\n",
      "  1.0000000e+00 -6.2357581e-01  9.6738416e-01 -1.3504469e-01\n",
      " -1.0000000e+00  0.0000000e+00  2.6993394e-01  2.7299944e-01\n",
      "  2.8186676e-01  2.9757959e-01  3.2366452e-01  3.6363903e-01\n",
      "  4.2165703e-01  5.1654011e-01  6.9483817e-01  1.0000000e+00]\n",
      "[ 5.2986361e-02 -9.7481497e-03  1.3002253e-01  1.2783092e-01\n",
      "  1.1308205e+00 -2.2442266e-04  9.1130865e-01 -1.9483501e-01\n",
      "  1.0000000e+00 -5.4815322e-01  9.9989682e-01 -1.8096650e-01\n",
      " -1.4316908e+00  1.0000000e+00  2.7587289e-01  2.7900583e-01\n",
      "  2.8790784e-01  3.0395743e-01  3.3077794e-01  3.7113401e-01\n",
      "  4.3062571e-01  5.2677554e-01  7.0966023e-01  1.0000000e+00]\n",
      "[ 6.7191236e-02  2.8842567e-02  1.1846473e-01  1.1440046e-01\n",
      "  1.1318418e+00 -1.4901161e-08  8.4858239e-01 -5.1514971e-01\n",
      "  1.0000000e+00 -4.7531620e-01  1.0000000e+00 -2.1803987e-01\n",
      " -1.0000001e+00  0.0000000e+00  2.8113762e-01  2.8433034e-01\n",
      "  2.9326177e-01  3.0960980e-01  3.3708334e-01  3.7777522e-01\n",
      "  4.3857393e-01  5.3584373e-01  7.2411162e-01  1.0000000e+00]\n",
      "[ 9.7578242e-02  6.0825914e-02  1.2498060e-01  1.1604244e-01\n",
      "  1.1313120e+00 -2.9802322e-08  7.5020194e-01 -8.2918859e-01\n",
      "  1.0000000e+00 -4.2442685e-01  6.4155281e-01 -2.8827512e-01\n",
      " -6.0968935e-01  1.0000000e+00  2.8666350e-01  2.8991899e-01\n",
      "  2.9888028e-01  3.1556201e-01  3.4370118e-01  3.8474366e-01\n",
      "  4.4691467e-01  5.4535776e-01  7.4048913e-01  1.0000000e+00]\n",
      "[ 1.34987980e-01  7.47896656e-02  1.17684565e-01  1.13625735e-01\n",
      "  1.13032258e+00 -9.37938690e-04  6.33074105e-01 -1.00033998e+00\n",
      "  1.00000000e+00 -3.50338489e-01  9.43454921e-01 -3.79005194e-01\n",
      " -8.59526813e-01  1.00000000e+00  2.92062610e-01  2.95379400e-01\n",
      "  3.04373801e-01  3.21499884e-01  3.50168556e-01  3.91560853e-01\n",
      "  4.55070823e-01  5.54669201e-01  7.56482661e-01  1.00000000e+00]\n",
      "[ 0.17765044  0.08532322  0.11664744  0.09804841  1.1078789  -0.26371253\n",
      "  0.54250497 -0.603188    1.         -0.27277637  0.98173285 -0.48734045\n",
      " -1.0000001   1.          0.29674628  0.3000225   0.30912647  0.3266469\n",
      "  0.35577455  0.3974465   0.46212423  0.56387717  0.7703841   1.        ]\n",
      "[ 0.21682905  0.07832814  0.13314919  0.08882955  1.1064339   0.\n",
      "  0.41550565 -1.          1.         -0.24425556  0.4453874  -0.59963906\n",
      " -0.623292    1.          0.3010203   0.30420798  0.31343892  0.33133602\n",
      "  0.3608818   0.40276396  0.46851882  0.5724669   0.783121    1.        ]\n",
      "[ 2.5575280e-01  7.8126028e-02  1.3813053e-01  7.1345814e-02\n",
      "  1.1064806e+00  2.9802322e-08  2.9693764e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -2.6208672e-01 -9.1677427e-02 -5.1112890e-01\n",
      " -8.0043159e-02  1.0000000e+00  3.0427229e-01  3.0735910e-01\n",
      "  3.1668565e-01  3.3489311e-01  3.6475608e-01  4.0673476e-01\n",
      "  4.7332549e-01  5.7900262e-01  7.9283136e-01  1.0000000e+00]\n",
      "[ 0.29845944  0.0854248   0.16335592  0.07787246  1.0454012  -0.7322209\n",
      "  0.42062473  0.9999809   0.         -0.3418889  -0.9994346  -0.4556328\n",
      "  0.46921197  0.          0.3080552   0.31102353  0.3204613   0.3390305\n",
      "  0.3690065   0.4113513   0.478915    0.58660537  0.8040477   1.        ]\n",
      "[ 0.33765188  0.07828291  0.19244637  0.07178842  1.0603272   0.20487872\n",
      "  0.3048432  -0.99999046  0.         -0.42192045 -1.0003504  -0.3952793\n",
      "  0.5009988   0.          0.31153455  0.3143555   0.32389435  0.34282354\n",
      "  0.37273812  0.4155111   0.48365605  0.59359807  0.8144341   1.        ]\n",
      "[ 0.37667474  0.07794107  0.19432274  0.05533012  1.0748532   0.20175672\n",
      "  0.18955475 -0.9999984   0.         -0.5020865  -1.0000472  -0.33597124\n",
      "  0.488943    0.          0.3142391   0.3169056   0.32652184  0.3457591\n",
      "  0.3755585   0.41880253  0.48709232  0.5990336   0.82258046  1.        ]\n",
      "[ 0.40850708  0.06324493  0.22823077  0.04819209  1.150346    0.99999964\n",
      " -0.01837039 -1.8644114   0.         -0.582861   -0.99999976 -0.2681043\n",
      "  0.5513726   0.          0.3165838   0.31906095  0.32875377  0.34828615\n",
      "  0.377892    0.42160186  0.4898849   0.6037459   0.82974386  1.        ]\n",
      "[ 4.3936518e-01  5.8168951e-02  2.3612219e-01  6.6761635e-02\n",
      "  1.1349103e+00 -1.7881393e-07  1.2788200e-01  9.9999982e-01\n",
      "  0.0000000e+00 -6.6489619e-01 -1.0000000e+00 -1.9385386e-01\n",
      "  6.3120079e-01  0.0000000e+00  3.1989902e-01  3.2218859e-01\n",
      "  3.3215085e-01  3.5188505e-01  3.8135266e-01  4.2568061e-01\n",
      "  4.9410298e-01  6.1024773e-01  8.3972633e-01  1.0000000e+00]\n",
      "[ 4.67096508e-01  5.53833731e-02  2.66731620e-01  7.30566755e-02\n",
      "  1.13062167e+00  3.87430191e-07  2.55302727e-01  1.00000012e+00\n",
      "  0.00000000e+00 -7.47525036e-01 -1.02843451e+00 -1.06986284e-01\n",
      "  7.04554081e-01  0.00000000e+00  3.23210806e-01  3.25470954e-01\n",
      "  3.35729063e-01  3.55675876e-01  3.84969324e-01  4.29957747e-01\n",
      "  4.98495847e-01  6.16405904e-01  8.50398660e-01  1.00000000e+00]\n",
      "[ 5.0336730e-01  7.2521858e-02  2.7267969e-01  5.4595470e-02\n",
      "  1.1299719e+00  5.9604645e-08  2.6581299e-01  7.1310841e-02\n",
      "  0.0000000e+00 -8.2763070e-01 -1.0000000e+00 -8.0091476e-02\n",
      "  2.1655105e-01  0.0000000e+00  3.2562315e-01  3.2790017e-01\n",
      "  3.3842596e-01  3.5853302e-01  3.8758948e-01  4.3311051e-01\n",
      "  5.0162131e-01  6.2094998e-01  8.5868323e-01  1.0000000e+00]\n",
      "[ 0.5319836   0.0572046   0.2528552   0.05086461  1.1296154   0.\n",
      "  0.20611167 -0.5088549   0.         -0.82785475  0.         -0.1248225\n",
      " -0.3838893   0.          0.32785708  0.3301497   0.34092388  0.36096397\n",
      "  0.3900153   0.43602997  0.5045144   0.6251577   0.86635816  1.        ]\n",
      "[ 5.5200964e-01  4.0032867e-02  2.4768892e-01  2.9482847e-02\n",
      "  1.1276276e+00 -8.9406967e-08  2.8095484e-01  5.9685665e-01\n",
      "  0.0000000e+00 -8.2805055e-01  0.0000000e+00 -1.6148496e-01\n",
      " -3.1275961e-01  0.0000000e+00  3.2907012e-01  3.3137125e-01\n",
      "  3.4235293e-01  3.6210513e-01  3.9124829e-01  4.3759635e-01\n",
      "  5.0589800e-01  6.2742233e-01  8.7102973e-01  1.0000000e+00]\n",
      "[ 5.6385857e-01  2.3524845e-02  2.4791130e-01  2.1692367e-02\n",
      "  1.1251426e+00  2.8312206e-07  4.0622783e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.2969832e-01  0.0000000e+00 -8.0416322e-02\n",
      "  6.5282375e-01  0.0000000e+00  3.2989809e-01  3.3221099e-01\n",
      "  3.4338108e-01  3.6282742e-01  3.9202872e-01  4.3865180e-01\n",
      "  5.0670636e-01  6.2895334e-01  8.7458396e-01  1.0000000e+00]\n",
      "[ 5.7320070e-01  1.8556930e-02  2.4926504e-01  9.0143243e-03\n",
      "  1.1229568e+00 -4.4703484e-08  5.2773535e-01  9.7539216e-01\n",
      "  0.0000000e+00 -8.3278590e-01  0.0000000e+00 -1.3291049e-01\n",
      " -6.9641238e-01  1.0000000e+00  3.3011493e-01  3.3258936e-01\n",
      "  3.4377217e-01  3.6288583e-01  3.9218777e-01  4.3889651e-01\n",
      "  5.0715840e-01  6.2932026e-01  8.7635994e-01  1.0000000e+00]\n",
      "[ 0.587082    0.02863285  0.24862215 -0.00178356  1.1243833   0.\n",
      "  0.5208055  -0.0559449   0.         -0.8292348   0.         -0.08267832\n",
      " -0.14076711  0.          0.32968625  0.33231407  0.34348765  0.36224592\n",
      "  0.39164189  0.4381851   0.5068243   0.6284584   0.87623805  1.        ]\n",
      "[ 6.0155308e-01  2.8951041e-02  2.4752864e-01 -1.0989675e-02\n",
      "  1.1239963e+00 -1.4901161e-08  4.6504259e-01 -4.7045264e-01\n",
      "  0.0000000e+00 -8.2907164e-01  0.0000000e+00 -1.0299909e-01\n",
      " -1.5824565e-01  0.0000000e+00  3.2898483e-01  3.3176303e-01\n",
      "  3.4291807e-01  3.6131060e-01  3.9077291e-01  4.3691781e-01\n",
      "  5.0605077e-01  6.2707734e-01  8.7493628e-01  1.0000000e+00]\n",
      "[ 6.06260478e-01  9.40806977e-03  2.45585293e-01 -2.69080233e-02\n",
      "  1.12378216e+00 -1.86264515e-08  4.98741269e-01  2.76930153e-01\n",
      "  0.00000000e+00 -8.28980386e-01  0.00000000e+00 -1.16128206e-01\n",
      " -1.00828625e-01  0.00000000e+00  3.27514708e-01  3.30434859e-01\n",
      "  3.41545254e-01  3.59542191e-01  3.88993114e-01  4.34661686e-01\n",
      "  5.04039168e-01  6.24232531e-01  8.70937586e-01  1.00000000e+00]\n",
      "[ 5.9812641e-01 -1.6276311e-02  2.4254236e-01 -3.8295321e-02\n",
      "  1.1218718e+00  5.9604645e-08  6.2159264e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.2890934e-01  0.0000000e+00 -1.1819208e-01\n",
      " -9.8268287e-03  0.0000000e+00  3.2548046e-01  3.2853574e-01\n",
      "  3.3949915e-01  3.5716325e-01  3.8654509e-01  4.3168142e-01\n",
      "  5.0111735e-01  6.2055552e-01  8.6556381e-01  1.0000000e+00]\n",
      "[ 5.79728425e-01 -3.68871316e-02  2.39874467e-01 -4.10070755e-02\n",
      "  1.12105346e+00  1.49011612e-07  7.43254542e-01  1.00000012e+00\n",
      "  0.00000000e+00 -8.28877687e-01  0.00000000e+00 -1.09577656e-01\n",
      "  7.72214979e-02  0.00000000e+00  3.23295534e-01  3.26483577e-01\n",
      "  3.37083429e-01  3.54621857e-01  3.83918703e-01  4.28509086e-01\n",
      "  4.97951329e-01  6.16784573e-01  8.59824300e-01  1.00000000e+00]\n",
      "[ 5.5134422e-01 -5.6881364e-02  2.4283259e-01 -3.8996812e-02\n",
      "  1.1207950e+00 -3.1262636e-05  8.6393273e-01  9.9999666e-01\n",
      "  0.0000000e+00 -8.2892287e-01  1.0430813e-06 -8.8780880e-02\n",
      "  1.7518197e-01  0.0000000e+00  3.2125932e-01  3.2449502e-01\n",
      "  3.3472723e-01  3.5214305e-01  3.8136330e-01  4.2540848e-01\n",
      "  4.9488831e-01  6.1315298e-01  8.5422546e-01  1.0000000e+00]\n",
      "[ 5.2009583e-01 -6.2613748e-02  2.6029477e-01 -3.6875512e-02\n",
      "  1.1209294e+00 -2.1296740e-04  9.8360193e-01  9.9997944e-01\n",
      "  0.0000000e+00 -8.2901508e-01  7.1227551e-06 -6.2907577e-02\n",
      "  2.1396686e-01  0.0000000e+00  3.1937292e-01  3.2258967e-01\n",
      "  3.3243248e-01  3.4972891e-01  3.7888950e-01  4.2237350e-01\n",
      "  4.9196523e-01  6.0972762e-01  8.4877110e-01  1.0000000e+00]\n",
      "[ 4.8816860e-01 -6.4567171e-02  2.5956142e-01 -2.7827427e-02\n",
      "  1.1348180e+00  2.9754639e-04  9.3490672e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.2970029e-01 -1.0043383e-05 -3.4395814e-02\n",
      "  2.5081253e-01  0.0000000e+00  3.1785068e-01  3.2105207e-01\n",
      "  3.3051300e-01  3.4770957e-01  3.7684709e-01  4.1980737e-01\n",
      "  4.8962796e-01  6.0706246e-01  8.4420598e-01  1.0000000e+00]\n",
      "[ 4.5428529e-01 -6.7967951e-02  2.6152524e-01 -1.6041234e-02\n",
      "  1.1331471e+00  4.6938658e-05  8.1905615e-01 -9.9999541e-01\n",
      "  0.0000000e+00 -8.2983106e-01 -1.5795231e-06  2.5327206e-03\n",
      "  3.0103245e-01  0.0000000e+00  3.1692594e-01  3.2011801e-01\n",
      "  3.2920739e-01  3.4642386e-01  3.7551135e-01  4.1800731e-01\n",
      "  4.8825264e-01  6.0564786e-01  8.4109527e-01  1.0000000e+00]\n",
      "[ 4.1735908e-01 -7.4163720e-02  2.7942744e-01 -1.6904445e-02\n",
      "  1.1303357e+00 -3.4704804e-04  7.0617628e-01 -1.0000346e+00\n",
      "  0.0000000e+00 -8.3031833e-01  1.1652708e-05  4.5025468e-02\n",
      "  3.4246740e-01  0.0000000e+00  3.1594092e-01  3.1912306e-01\n",
      "  3.2781491e-01  3.4511012e-01  3.7408727e-01  4.1608688e-01\n",
      "  4.8678815e-01  6.0414350e-01  8.3777750e-01  1.0000000e+00]\n",
      "[ 3.7607193e-01 -8.2898207e-02  3.0266368e-01 -1.3283629e-02\n",
      "  1.1266079e+00 -8.5234642e-06  5.9575820e-01 -1.0000008e+00\n",
      "  0.0000000e+00 -8.3089465e-01  2.9802322e-07  9.5902324e-02\n",
      "  4.0934527e-01  0.0000000e+00  3.1509927e-01  3.1795469e-01\n",
      "  3.2653910e-01  3.4393355e-01  3.7281191e-01  4.1429731e-01\n",
      "  4.8556429e-01  6.0298413e-01  8.3473456e-01  1.0000000e+00]\n",
      "[ 0.33035734 -0.09171505  0.32410726 -0.01277369  1.117678   -0.06780547\n",
      "  0.51243395 -0.7728329   0.         -0.83151156  0.          0.1550715\n",
      "  0.4760703   0.          0.31425315  0.31668028  0.32523027  0.34273425\n",
      "  0.37131608  0.41245288  0.4843423   0.601857    0.8316121   1.        ]\n",
      "[ 0.27322522 -0.11467578  0.32029384 -0.01631595  1.062873   -0.6637108\n",
      "  0.63972056  0.9999998   0.         -0.8180643   0.17692506  0.21086013\n",
      "  0.44869888  0.          0.31318393  0.31518525  0.32369488  0.3412932\n",
      "  0.36940223  0.41032702  0.48232904  0.6002591   0.82795286  1.        ]\n",
      "[ 0.2162449  -0.11434534  0.34223828 -0.02277253  1.0061325  -0.6939424\n",
      "  0.76499057  0.99999994  0.         -0.8189594   0.          0.28993112\n",
      "  0.6347074   0.          0.3117829   0.31332925  0.32178876  0.3394714\n",
      "  0.36705902  0.4083417   0.479769    0.5980104   0.823414    1.        ]\n",
      "[ 0.15596761 -0.12102357  0.3699562  -0.01568411  0.937622   -0.84991246\n",
      "  0.9160652   2.256631    1.         -0.8201124   0.          0.38004005\n",
      "  0.7231191   0.          0.3105302   0.3117199   0.32031587  0.33793426\n",
      "  0.36498475  0.406947    0.47761312  0.59640414  0.81947345  1.        ]\n",
      "[ 0.08845832 -0.13483067  0.28449225  0.04010336  1.0164716   1.0089889\n",
      "  0.87707675 -0.28657588  0.         -0.80633676  0.17900026  0.4751652\n",
      "  0.7698458   0.          0.31170934  0.3129036   0.32169375  0.33938792\n",
      "  0.36618826  0.40916663  0.47968444  0.60014284  0.8223353   1.        ]\n",
      "[ 2.1462927e-02 -1.3382322e-01  2.7794144e-01  4.7569491e-02\n",
      "  1.1332051e+00  1.4687338e+00  7.5928426e-01 -1.0000128e+00\n",
      "  0.0000000e+00 -8.0579829e-01 -2.5629997e-06  5.9817022e-01\n",
      "  1.0150210e+00  0.0000000e+00  3.1323758e-01  3.1443766e-01\n",
      "  3.2342947e-01  3.4121910e-01  3.6780050e-01  4.1184840e-01\n",
      "  4.8228955e-01  6.0454583e-01  8.2552588e-01  1.0000000e+00]\n",
      "[-1.1275106e-02 -6.5441303e-02  1.7993391e-01  1.2844858e-01\n",
      "  1.1331375e+00  2.3543835e-06  7.9563010e-01  2.9447642e-01\n",
      "  0.0000000e+00 -8.0633557e-01 -5.9604645e-08  6.8931568e-01\n",
      "  7.4380302e-01  0.0000000e+00  3.1883630e-01  3.2005787e-01\n",
      "  3.2932937e-01  3.4734759e-01  3.7419024e-01  4.1988352e-01\n",
      "  4.9110559e-01  6.1696208e-01  8.3632797e-01  1.0000000e+00]\n",
      "[-4.27658893e-02 -6.29668012e-02  1.70231119e-01  1.46913201e-01\n",
      "  1.13241386e+00 -7.22754002e-03  8.23629200e-01  2.26867497e-01\n",
      "  0.00000000e+00 -8.06766033e-01  1.11848116e-04  7.85525441e-01\n",
      "  7.92024553e-01  0.00000000e+00  3.25320512e-01  3.26566905e-01\n",
      "  3.36141497e-01  3.54237437e-01  3.81612539e-01  4.29108083e-01\n",
      "  5.01282811e-01  6.31173134e-01  8.49027455e-01  1.00000000e+00]\n",
      "[-0.06430873 -0.0430704   0.17004018  0.15350708  1.1324743   0.\n",
      "  0.823534   -0.00345401  0.         -0.8070535   0.          0.86813515\n",
      "  0.68278104  0.          0.3321553   0.33342785  0.3433166   0.36150494\n",
      "  0.38944167  0.43881056  0.5120771   0.6461093   0.86246186  1.        ]\n",
      "[-6.3834071e-02  9.6367591e-04  1.7082676e-01  1.5334055e-01\n",
      "  1.1323144e+00  2.3283064e-09  7.7283216e-01 -4.2627630e-01\n",
      "  0.0000000e+00 -8.0723935e-01 -9.3132257e-10  9.1056281e-01\n",
      "  3.5053644e-01  0.0000000e+00  3.3907235e-01  3.4047258e-01\n",
      "  3.5057706e-01  3.6886096e-01  3.9772245e-01  4.4862580e-01\n",
      "  5.2413863e-01  6.6124260e-01  8.7606734e-01  1.0000000e+00]\n",
      "[-0.03807314  0.05158514  0.16993737  0.15293173  1.1312817   0.\n",
      "  0.66165835 -0.9447427   0.         -0.7769569   0.38249946  0.79166806\n",
      " -1.          0.          0.3460575   0.3475914   0.35790715  0.37629125\n",
      "  0.4065033   0.45808923  0.53630644  0.6766133   0.8906029   1.        ]\n",
      "[-0.00413232  0.06791575  0.17151307  0.14034021  1.121382   -0.10437366\n",
      "  0.5451692  -1.0000001   0.         -0.7536182   0.300611    0.6740617\n",
      " -1.          0.          0.3524723   0.35413694  0.36464694  0.38310677\n",
      "  0.41459563  0.4667303   0.54753625  0.6907992   0.9090346   1.        ]\n",
      "[ 0.02981672  0.06791551  0.17112069  0.12436666  1.1076832  -0.14894506\n",
      "  0.4293549  -1.          0.         -0.7278423   0.33594006  0.5576015\n",
      " -1.          0.          0.35813496  0.35992533  0.37060714  0.38911274\n",
      "  0.42177582  0.47437263  0.5575211   0.7034126   0.9253888   1.        ]\n",
      "[ 0.0707775   0.08192     0.17242406  0.11340567  1.039836   -0.8503176\n",
      "  0.4366519   0.05141203  0.         -0.7162975   0.16054249  0.44185412\n",
      " -1.          0.          0.36330754  0.36522108  0.37605938  0.3945907\n",
      "  0.42836413  0.4813652   0.5666993   0.7150072   0.9403948   1.        ]\n",
      "[ 0.13456096  0.12760407  0.16356193  0.11136495  0.9598107  -0.99463713\n",
      "  0.42083728 -0.14367706  1.         -0.7496329  -0.40037856  0.32629323\n",
      " -0.9999692   0.          0.36848402  0.3705153   0.38128924  0.40007827\n",
      "  0.43493778  0.48835537  0.57584625  0.7265622   0.95536757  1.        ]\n",
      "[ 0.19316924  0.11727019  0.16092758  0.09365144  0.9111226  -0.573896\n",
      "  0.3057717  -1.          0.         -0.7631043  -0.15327018  0.21038121\n",
      " -1.          0.          0.37281242  0.37495446  0.38565037  0.4046543\n",
      "  0.44047853  0.49421757  0.5835495   0.7346642   0.964782    1.        ]\n",
      "[ 0.24184233  0.09732351  0.15511861  0.06996256  0.8972051  -0.15309861\n",
      "  0.1900481  -1.0000001   1.         -0.765434   -0.01285839  0.09459448\n",
      " -0.99999994  0.          0.3759987   0.37824154  0.3888423   0.40800354\n",
      "  0.44462568  0.49855986  0.58932775  0.74054277  0.9710147   1.        ]\n",
      "[ 0.27070683  0.05755816  0.14270373  0.04231459  0.95052075  0.6800583\n",
      "  0.07705271 -1.          0.         -0.74193597  0.32097542 -0.0188365\n",
      " -1.0000001   0.          0.3778252   0.3801547   0.39064452  0.40989453\n",
      "  0.44710553  0.5010895   0.5928305   0.74390996  0.97436565  1.        ]\n",
      "[ 0.3011188   0.06053219  0.14935352  0.01137085  1.0282557   1.\n",
      " -0.04210293 -1.0832368   0.         -0.7500456  -0.07464135 -0.13479233\n",
      " -0.99999994  0.          0.37820822  0.38061535  0.39095867  0.41048795\n",
      "  0.44784528  0.5017036   0.5939752   0.744604    0.9745768   1.        ]\n",
      "[ 0.338195    0.07381053  0.16440268 -0.01230185  1.1060487   1.0000005\n",
      " -0.15020573 -1.0000001   0.         -0.8068945  -0.6884732  -0.1997273\n",
      " -0.56592816  0.          0.37756732  0.37997037  0.3901303   0.4099626\n",
      "  0.44727212  0.50086004  0.59334946  0.7432535   0.97234863  1.        ]\n",
      "[ 3.7107292e-01  6.5644123e-02  1.3773058e-01 -4.1161506e-03\n",
      "  1.1013386e+00  2.9802322e-07 -2.2478104e-02  1.0000004e+00\n",
      "  0.0000000e+00 -8.0836427e-01  0.0000000e+00 -3.1664705e-01\n",
      " -1.0000000e+00  0.0000000e+00  3.7733412e-01  3.7973568e-01\n",
      "  3.8974914e-01  4.0985844e-01  4.4715849e-01  5.0061268e-01\n",
      "  5.9332222e-01  7.4268436e-01  9.7114116e-01  1.0000000e+00]\n",
      "[ 3.99059594e-01  5.58460094e-02  1.43545091e-01 -1.31869148e-02\n",
      "  1.09723473e+00  3.57627869e-07  1.04712546e-01  1.00000012e+00\n",
      "  0.00000000e+00 -8.08575571e-01  0.00000000e+00 -3.36183071e-01\n",
      " -1.70737728e-01  0.00000000e+00  3.76656562e-01  3.79053831e-01\n",
      "  3.88905704e-01  4.09267753e-01  4.46377605e-01  5.00003219e-01\n",
      "  5.92579484e-01  7.41288066e-01  9.68946278e-01  1.00000000e+00]\n",
      "[ 0.40945065  0.02046107  0.15210861 -0.03281878  1.1445827   0.6802175\n",
      "  0.23833513  1.0000001   0.         -0.8118551   0.         -0.21197033\n",
      "  0.9999997   0.          0.37499225  0.3773789   0.38703862  0.4075935\n",
      "  0.44440988  0.4980433   0.5902403   0.73805815  0.9645732   1.        ]\n",
      "[ 4.2945608e-01  3.8446471e-02  1.4613180e-01 -4.2598315e-02\n",
      "  1.1349075e+00  1.7881393e-07  4.1839111e-01  1.3375655e+00\n",
      "  0.0000000e+00 -8.0320847e-01  1.3742173e-01 -1.7003775e-01\n",
      "  3.1930420e-01  0.0000000e+00  3.7294427e-01  3.7531787e-01\n",
      "  3.8478500e-01  4.0548533e-01  4.4198692e-01  4.9553210e-01\n",
      "  5.8725142e-01  7.3412633e-01  9.5941061e-01  1.0000000e+00]\n",
      "[ 4.4905940e-01  3.9090842e-02  1.5516438e-01 -5.3389553e-02\n",
      "  1.1318835e+00  2.0861626e-07  5.4379725e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.0646998e-01  0.0000000e+00 -4.7379255e-02\n",
      "  9.8048347e-01  0.0000000e+00  3.7033114e-01  3.7268811e-01\n",
      "  3.8194287e-01  4.0275908e-01  4.3889415e-01  4.9225256e-01\n",
      "  5.8335400e-01  7.2914207e-01  9.5298916e-01  1.0000000e+00]\n",
      "[ 0.47811785  0.05809718  0.15764755 -0.06129377  1.1318499   0.\n",
      "  0.5061741  -0.32215133  0.         -0.81056505  0.          0.07977343\n",
      "  1.0000004   0.          0.3673614   0.3696743   0.37873334  0.39963835\n",
      "  0.4353785   0.48847905  0.57887304  0.72349757  0.9457934   1.        ]\n",
      "[ 0.50601953  0.05586056  0.15587156 -0.07813232  1.131777    0.\n",
      "  0.47202766 -0.2902359   0.         -0.81439096  0.          0.16474563\n",
      " -1.333762    1.          0.36359474  0.36574554  0.37470832  0.39563033\n",
      "  0.4309178   0.48358956  0.5730748   0.7163831   0.9368943   1.        ]\n",
      "[ 0.54308206  0.07426122  0.15556099 -0.10159505  1.1304123   0.\n",
      "  0.35567617 -0.9999998   0.         -0.8031118   0.11875549  0.06305897\n",
      " -0.9999998   1.          0.35874036  0.36072883  0.36956868  0.39041284\n",
      "  0.42516714  0.47718018  0.5654822   0.7072606   0.9256626   1.        ]\n",
      "[ 0.57993245  0.07371455  0.14606789 -0.11499689  1.0659045  -0.7831446\n",
      "  0.4788041   0.9999997   0.         -0.80203927  0.0264391  -0.0541054\n",
      " -1.          0.          0.35328883  0.3551238   0.3638263   0.38452128\n",
      "  0.41870797  0.4699155   0.55688137  0.69704455  0.91319597  1.        ]\n",
      "[ 0.61488664  0.0698671   0.14855237 -0.13477938  1.0104028  -0.67621684\n",
      "  0.60150707  0.99999994  0.         -0.8033719   0.         -0.17079866\n",
      " -1.0000001   0.          0.3469009   0.34857816  0.35712025  0.37759298\n",
      "  0.4111385   0.46135172  0.5467461   0.68509597  0.8987011   1.        ]\n",
      "[ 0.6458523   0.06185509  0.15330967 -0.15319963  0.9906896  -0.24526456\n",
      "  0.6376635   0.2937612   0.         -0.80422086  0.         -0.25462127\n",
      " -0.7171379   0.          0.33963463  0.3411476   0.3495076   0.36969522\n",
      "  0.40252766  0.45157546  0.53517836  0.6715196   0.8822899   1.        ]\n",
      "[ 0.6675225   0.04320608  0.1615856  -0.17325066  1.0419278   0.66115606\n",
      "  0.52211225 -1.          0.         -0.8046139   0.         -0.2616378\n",
      " -0.06807032  0.          0.33139884  0.33273652  0.3408904   0.36073136\n",
      "  0.39276743  0.44046932  0.52203894  0.65614253  0.86112326  1.        ]\n",
      "[ 0.67483836  0.01427748  0.16715121 -0.18692641  1.1200588   1.0000004\n",
      "  0.4578024  -0.5953695   0.         -0.80808413  0.         -0.261554\n",
      " -1.1784867   1.          0.32248515  0.32363832  0.33156922  0.3510239\n",
      "  0.38220367  0.42843702  0.50780463  0.6395051   0.83700055  1.        ]\n",
      "[ 7.0476180e-01  6.0271807e-02  1.5735573e-01 -1.9557551e-01\n",
      "  1.1202691e+00 -2.9802322e-08  3.8466668e-01 -6.2403655e-01\n",
      "  0.0000000e+00 -8.0490696e-01  0.0000000e+00 -3.2421124e-01\n",
      " -9.9999982e-01  1.0000000e+00  3.1313673e-01  3.1411874e-01\n",
      "  3.2181638e-01  3.4081802e-01  3.7112382e-01  4.1576603e-01\n",
      "  4.9281850e-01  6.2185633e-01  8.1163919e-01  1.0000000e+00]\n",
      "[ 7.2618914e-01  4.2846583e-02  1.5640342e-01 -2.1868530e-01\n",
      "  1.1190159e+00  5.9604645e-08  4.4014084e-01  4.4545007e-01\n",
      "  0.0000000e+00 -8.0632597e-01  0.0000000e+00 -4.4197655e-01\n",
      " -1.0000000e+00  0.0000000e+00  3.0277014e-01  3.0357978e-01\n",
      "  3.1101915e-01  3.2948107e-01  3.5883662e-01  4.0167466e-01\n",
      "  4.7615531e-01  6.0075670e-01  7.8346729e-01  1.0000000e+00]\n",
      "[ 7.4089974e-01  2.9231546e-02  1.5645069e-01 -2.3324260e-01\n",
      "  1.1165285e+00  7.4505806e-08  5.6506288e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.0721945e-01  0.0000000e+00 -5.0576651e-01\n",
      " -5.4375076e-01  0.0000000e+00  2.9171661e-01  2.9235142e-01\n",
      "  2.9951563e-01  3.1738287e-01  3.4573480e-01  3.8700625e-01\n",
      "  4.5836484e-01  5.7822764e-01  7.5449777e-01  1.0000000e+00]\n",
      "[ 7.5186843e-01  2.1736743e-02  1.5973479e-01 -2.3842743e-01\n",
      "  1.1146481e+00  1.4901161e-07  6.8877077e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.0819118e-01  0.0000000e+00 -5.1007557e-01\n",
      " -1.0766492e+00  1.0000000e+00  2.8040808e-01  2.8086382e-01\n",
      "  2.8774655e-01  3.0500576e-01  3.3233073e-01  3.7200212e-01\n",
      "  4.4012961e-01  5.5517942e-01  7.2992200e-01  1.0000000e+00]\n",
      "[ 7.4817199e-01 -7.4100778e-03  1.4430778e-01 -2.4111852e-01\n",
      "  1.1137609e+00  1.8998981e-07  8.3205259e-01  1.1786504e+00\n",
      "  0.0000000e+00 -8.1163877e-01 -1.8626451e-08 -5.3705156e-01\n",
      " -1.3409705e-01  0.0000000e+00  2.6881295e-01  2.6920584e-01\n",
      "  2.7580285e-01  2.9240891e-01  3.1870803e-01  3.5675323e-01\n",
      "  4.2153838e-01  5.3169900e-01  7.0504355e-01  1.0000000e+00]\n",
      "[ 7.31367588e-01 -3.89346704e-02  1.05635904e-01 -4.27879132e-02\n",
      "  1.10501337e+00 -9.89834964e-03  9.59010839e-01  9.99046147e-01\n",
      "  0.00000000e+00 -8.28264654e-01  4.29019332e-04 -4.79932785e-01\n",
      "  1.61941811e-01  1.00000000e+00  2.67449766e-01  2.67840654e-01\n",
      "  2.74414867e-01  2.91142642e-01  3.17227423e-01  3.55095863e-01\n",
      "  4.19773817e-01  5.29471457e-01  7.01772153e-01  1.00000000e+00]\n",
      "[ 7.1727943e-01 -3.1261921e-02  1.0977603e-01  4.5059051e-02\n",
      "  1.1090432e+00  6.1647892e-03  9.3490958e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.2855821e-01 -2.7078390e-04 -4.7169995e-01\n",
      "  1.3019346e-01  0.0000000e+00  2.6984805e-01  2.7024242e-01\n",
      "  2.7716613e-01  2.9406160e-01  3.2021165e-01  3.5843632e-01\n",
      "  4.2424351e-01  5.3511822e-01  7.0634252e-01  1.0000000e+00]\n",
      "[ 7.00364769e-01 -3.41084711e-02  1.14940435e-01  6.55918643e-02\n",
      "  1.10825992e+00 -4.49568033e-05  8.72338414e-01 -5.31455219e-01\n",
      "  0.00000000e+00 -8.25946748e-01  6.04987144e-06 -4.61985469e-01\n",
      "  3.32499117e-01  0.00000000e+00  2.72692770e-01  2.73091316e-01\n",
      "  2.80393928e-01  2.97486186e-01  3.23730707e-01  3.62375498e-01\n",
      "  4.29469794e-01  5.41721642e-01  7.11828589e-01  1.00000000e+00]\n",
      "[ 6.8024111e-01 -4.0277485e-02  1.3406982e-01  8.5694447e-02\n",
      "  1.1076659e+00 -8.0466270e-07  8.1074893e-01 -5.2297777e-01\n",
      "  0.0000000e+00 -8.2602406e-01  1.1920929e-07 -4.1198575e-01\n",
      "  4.2651328e-01  0.0000000e+00  2.7638724e-01  2.7679116e-01\n",
      "  2.8455257e-01  3.0189830e-01  3.2828146e-01  3.6791247e-01\n",
      "  4.3613860e-01  5.5020922e-01  7.1901375e-01  1.0000000e+00]\n",
      "[ 6.5172988e-01 -5.7112236e-02  1.5829135e-01  8.7774232e-02\n",
      "  1.0802553e+00 -3.4132594e-01  9.3110526e-01  9.9999523e-01\n",
      "  0.0000000e+00 -8.2593375e-01  4.1723251e-07 -3.7744105e-01\n",
      "  3.8542235e-01  1.0000000e+00  2.8010190e-01  2.8051126e-01\n",
      "  2.8878689e-01  3.0639076e-01  3.3288798e-01  3.7370402e-01\n",
      "  4.4295028e-01  5.5888361e-01  7.2614199e-01  1.0000000e+00]\n",
      "[ 6.2142521e-01 -6.0699865e-02  1.8266805e-01  8.9252323e-02\n",
      "  1.0892889e+00  1.1313051e-01  9.3133891e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.2604581e-01  9.2387199e-07 -3.2167697e-01\n",
      "  4.1073942e-01  0.0000000e+00  2.8382030e-01  2.8423509e-01\n",
      "  2.9307795e-01  3.1094339e-01  3.3752966e-01  3.7959409e-01\n",
      "  4.4987434e-01  5.6770581e-01  7.3740178e-01  1.0000000e+00]\n",
      "[ 0.58627915 -0.07029033  0.20851737  0.08985086  1.1342702   0.5678737\n",
      "  0.8487724  -0.6952941   0.         -0.82600504  0.         -0.26591694\n",
      "  0.46238175  0.          0.28750533  0.2879255   0.29738867  0.3155169\n",
      "  0.3421636   0.38553414  0.45685315  0.57518494  0.7487667   1.        ]\n",
      "[ 5.5326909e-01 -6.6068344e-02  2.2547914e-01  1.0329113e-01\n",
      "  1.1340249e+00  2.9802322e-07  8.4441543e-01 -4.1739065e-02\n",
      "  0.0000000e+00 -8.2609683e-01 -2.9802322e-08 -2.0742393e-01\n",
      "  4.8154819e-01  0.0000000e+00  2.9178858e-01  2.9221502e-01\n",
      "  3.0236179e-01  3.2054308e-01  3.4752801e-01  3.9237234e-01\n",
      "  4.6488979e-01  5.8329463e-01  7.6187807e-01  1.0000000e+00]\n",
      "[ 5.1779205e-01 -7.1146578e-02  2.3417796e-01  1.1416701e-01\n",
      "  1.1324871e+00  1.4603138e-06  7.6156449e-01 -7.2271353e-01\n",
      "  0.0000000e+00 -8.2657409e-01 -2.0861626e-07 -1.4150345e-01\n",
      "  5.3703898e-01  0.0000000e+00  2.9655105e-01  2.9744697e-01\n",
      "  3.0785692e-01  3.2602605e-01  3.5347256e-01  3.9991489e-01\n",
      "  4.7375640e-01  5.9229779e-01  7.7636576e-01  1.0000000e+00]\n",
      "[ 0.47765326 -0.08062874  0.25570557  0.12569033  1.0733941  -0.733402\n",
      "  0.88350475  0.9999998   0.         -0.82732743  0.         -0.06576073\n",
      "  0.61812896  0.          0.30178303  0.30327812  0.31389216  0.33204865\n",
      "  0.3600022   0.40819812  0.48349386  0.60218793  0.7900966   1.        ]\n",
      "[ 0.43187994 -0.09167192  0.2821732   0.1267508   1.0409138  -0.40473503\n",
      "  0.9451171   0.5094076   0.         -0.82755476  0.          0.01840383\n",
      "  0.6938403   0.          0.30699056  0.3091375   0.31995657  0.338074\n",
      "  0.36729944  0.4165389   0.4933906   0.6120549   0.80043477  1.        ]\n",
      "[ 3.8199762e-01 -1.0010938e-01  2.9293379e-01  1.2786692e-01\n",
      "  1.0465693e+00  9.6241415e-02  8.3062065e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -8.2866782e-01 -5.9604645e-08  1.1379981e-01\n",
      "  7.6475924e-01  0.0000000e+00  3.1219169e-01  3.1501541e-01\n",
      "  3.2604018e-01  3.4410623e-01  3.7469119e-01  4.2485517e-01\n",
      "  5.0333381e-01  6.2148362e-01  8.1072271e-01  1.0000000e+00]\n",
      "[ 0.31677195 -0.13062134  0.32387304  0.12019961  1.1001812   0.69676983\n",
      "  0.71605086 -1.0000001   0.         -0.8296698   0.          0.23155957\n",
      "  0.94778556  0.          0.31691033  0.3204692   0.3313584   0.34964618\n",
      "  0.38159278  0.43261293  0.51261806  0.6282564   0.81988     1.        ]\n",
      "[ 0.24745901 -0.1387696   0.32857588  0.11288361  1.0937197  -0.07248408\n",
      "  0.8383894   1.000081    0.         -0.82966036  0.01503831  0.3583395\n",
      "  1.0168701   0.          0.3218863   0.32554182  0.33621335  0.3547691\n",
      "  0.3880345   0.43985015  0.521284    0.63437873  0.8281939   1.        ]\n",
      "[ 0.16947255 -0.15591443  0.33135378  0.08849116  1.1723242   1.0001432\n",
      "  0.748085   -0.7751109   0.         -0.8181456   0.14290929  0.48016137\n",
      "  1.0013455   0.          0.32573536  0.32943457  0.3398575   0.35869312\n",
      "  0.393043    0.4454667   0.52802247  0.6385659   0.83407724  1.        ]\n",
      "[ 0.10298155 -0.1379706   0.3313689   0.08185536  1.134908   -0.16456223\n",
      "  0.9219582   1.          0.         -0.8231032   0.          0.6091079\n",
      "  1.0000001   0.          0.32940605  0.33314696  0.34331566  0.3630646\n",
      "  0.3978331   0.45083612  0.5331578   0.64245206  0.8396174   1.        ]\n",
      "[ 0.04591029 -0.11431721  0.33362633  0.07601586  1.1050731  -0.36496508\n",
      "  0.9237211   0.          0.         -0.82325935  0.00355297  0.73071635\n",
      "  1.          0.          0.3327143   0.3363591   0.34639803  0.36702937\n",
      "  0.40215424  0.45571116  0.53735816  0.64573956  0.8443709   1.        ]\n",
      "[-0.01695268 -0.12612061  0.32970792  0.07125077  1.0638213  -0.5065271\n",
      "  0.9260994   0.          0.         -0.78532046  0.48495764  0.7805261\n",
      "  0.21945094  1.          0.3357483   0.33907935  0.34919944  0.37068406\n",
      "  0.4061094   0.46025595  0.5411514   0.6490802   0.84855276  1.        ]\n",
      "[-0.06696811 -0.10068621  0.33303717  0.05885324  0.98525286 -0.97623676\n",
      "  1.0404832   2.5913365   1.         -0.69911695  1.0000002   0.67915505\n",
      " -0.9999995   0.          0.33819136  0.34120128  0.3513847   0.3736782\n",
      "  0.409342    0.46397978  0.54404235  0.6539902   0.85142803  1.        ]\n",
      "[-0.13070767 -0.1245406   0.2425409   0.07871752  1.0774797   0.72442317\n",
      "  0.93489635 -0.12415707  1.         -0.6150082   1.0000001   0.6453088\n",
      " -0.2530844   0.          0.3416979   0.34449932  0.35478118  0.3777865\n",
      "  0.41380557  0.4690875   0.54879415  0.6610375   0.8573691   1.        ]\n",
      "[-0.18221779 -0.10302138  0.23933432  0.05646727  1.1747853   1.2274834\n",
      "  0.81657857 -1.000003    1.         -0.5355407   0.9999515   0.52690136\n",
      " -1.000085    0.          0.34412754  0.3467049   0.3574791   0.38069275\n",
      "  0.4169539   0.4727014   0.5518967   0.6659205   0.8615742   1.        ]\n",
      "[-0.18664746 -0.01697575  0.2104906   0.10896382  1.1349074   0.00594944\n",
      "  0.88278204 -0.17775017  1.         -0.5543254  -0.15419376  0.61670893\n",
      "  0.6974171   0.          0.3494273   0.3518252   0.36321425  0.38680032\n",
      "  0.42360553  0.4802939   0.5594023   0.6765718   0.8738702   1.        ]\n",
      "[-1.9772707e-01 -2.2211561e-02  2.0751558e-01  1.0909732e-01\n",
      "  1.1336929e+00 -2.9802322e-08  8.9789498e-01  2.8753880e-01\n",
      "  1.0000000e+00 -5.3714067e-01  2.3159684e-01  7.3927295e-01\n",
      "  9.9999994e-01  0.0000000e+00  3.5437575e-01  3.5668740e-01\n",
      "  3.6866787e-01  3.9260808e-01  4.2993015e-01  4.8751372e-01\n",
      "  5.6558722e-01  6.8669480e-01  8.8554138e-01  1.0000000e+00]\n",
      "[-1.8867669e-01  1.8634772e-02  1.9501168e-01  1.0692525e-01\n",
      "  1.1200111e+00  2.2351742e-08  8.1917900e-01 -4.7565392e-01\n",
      "  1.0000000e+00 -4.5834932e-01  9.9999994e-01  6.2502193e-01\n",
      " -1.0000004e+00  0.0000000e+00  3.5925180e-01  3.6159524e-01\n",
      "  3.7414303e-01  3.9841345e-01  4.3628168e-01  4.9476200e-01\n",
      "  5.7158399e-01  6.9673115e-01  8.9734143e-01  1.0000000e+00]\n",
      "[-1.5848103e-01  6.0558859e-02  1.9443212e-01  1.0573830e-01\n",
      "  1.1196648e+00  2.9802322e-08  7.2281915e-01 -9.0836948e-01\n",
      "  1.0000000e+00 -3.8155425e-01  9.7046506e-01  5.0823009e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.6409593e-01  3.6647099e-01\n",
      "  3.7958556e-01  4.0417892e-01  4.4260442e-01  5.0130868e-01\n",
      "  5.7753432e-01  7.0410180e-01  9.0906233e-01  1.0000000e+00]\n",
      "[-0.12551211  0.06602331  0.19769327  0.09149315  1.1186064  -0.00340953\n",
      "  0.6001044  -1.0011281   1.         -0.32863516  0.68746614  0.37479854\n",
      " -1.0002172   1.          0.36825997  0.37066218  0.3843174   0.4091884\n",
      "  0.44812804  0.5065943   0.5825254   0.7103114   0.9193241   1.        ]\n",
      "[-0.08653229  0.07800176  0.22330505  0.07851542  1.1072531  -0.12640077\n",
      "  0.4831885  -1.0000001   1.         -0.38731286 -0.737138    0.43762577\n",
      "  0.40757367  0.          0.37182435  0.37424982  0.3884623   0.41357082\n",
      "  0.45296675  0.5110777   0.5865793   0.71540433  0.9291098   1.        ]\n",
      "[-6.3207164e-02  4.6675023e-02  1.9987638e-01  6.8142831e-02\n",
      "  1.1053491e+00  2.9802322e-08  3.6671591e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -3.3747947e-01  6.3543153e-01  3.2094592e-01\n",
      " -9.9999994e-01  0.0000000e+00  3.7488315e-01  3.7749311e-01\n",
      "  3.9203390e-01  4.1734636e-01  4.5713633e-01  5.1491874e-01\n",
      "  5.9002417e-01  7.1974003e-01  9.3751913e-01  1.0000000e+00]\n",
      "[-0.02421842  0.07793795  0.21271135  0.05050426  1.068434   -0.42745876\n",
      "  0.2518844  -0.99999994  0.         -0.3280795   0.13475305  0.20567614\n",
      " -1.          0.          0.37716323  0.3801635   0.39480716  0.4202715\n",
      "  0.46037424  0.5177337   0.59233576  0.7227107   0.9438766   1.        ]\n",
      "[ 0.01398604  0.07633758  0.21105836  0.03287364  1.0398067  -0.32973543\n",
      "  0.13666058 -1.          1.         -0.3154142   0.17640668  0.09011865\n",
      " -1.          0.          0.37861505  0.38199058  0.39670464  0.42226574\n",
      "  0.46259007  0.5194687   0.59350276  0.7242915   0.9480301   1.        ]\n",
      "[ 0.04447166  0.06088793  0.2099464   0.01475269  1.0349218  -0.04109183\n",
      "  0.0205555  -1.0000001   1.         -0.30834186  0.09786358  0.04534841\n",
      " -0.39654014  0.          0.37919724  0.38293383  0.39768422  0.42328396\n",
      "  0.4637346   0.5200693   0.593465    0.7244098   0.94987094  1.        ]\n",
      "[ 0.05370378  0.01832225  0.18833292 -0.01545399  1.1021364   0.84999704\n",
      " -0.09439266 -1.0000001   0.         -0.24907549  0.75470644 -0.07098401\n",
      " -1.          0.          0.37829095  0.3823322   0.39705232  0.42259866\n",
      "  0.46300668  0.5187425   0.5914416   0.7221031   0.9477267   1.        ]\n",
      "[ 7.7892363e-02  4.8211180e-02  1.9648492e-01 -2.7069524e-02\n",
      "  1.0993819e+00  2.9802322e-08  1.2323856e-02  8.4267169e-01\n",
      "  0.0000000e+00 -2.5502625e-01 -4.3452352e-02 -1.8485105e-01\n",
      " -9.9999982e-01  0.0000000e+00  3.7690169e-01  3.8125333e-01\n",
      "  3.9591244e-01  4.2138544e-01  4.6170032e-01  5.1677954e-01\n",
      "  5.8913368e-01  7.1895075e-01  9.4430947e-01  1.0000000e+00]\n",
      "[ 0.10234497  0.04877133  0.21656398 -0.03656008  1.1027814   0.09745827\n",
      "  0.14008379  1.0000001   0.         -0.3362241  -1.         -0.06107938\n",
      "  0.9999997   0.          0.37504402  0.37973267  0.39431217  0.41968223\n",
      "  0.4598587   0.51418996  0.5864905   0.7149265   0.9396752   1.        ]\n",
      "[ 0.15322168  0.10162458  0.23164657 -0.07144229  1.1015035   0.\n",
      "  0.02435452 -0.99999934  0.         -0.42026734 -1.0000001  -0.17317712\n",
      " -1.0000004   0.          0.37162542  0.37665144  0.3910914   0.41625425\n",
      "  0.45612568  0.50955224  0.5813582   0.70821345  0.93091124  1.        ]\n",
      "[ 0.192563    0.07866523  0.2358295  -0.06745049  1.0995188   0.\n",
      " -0.09191632 -1.          0.         -0.50177205 -1.0063438  -0.05099297\n",
      "  1.0000005   0.          0.36835656  0.37372887  0.38803476  0.41301712\n",
      "  0.45258495  0.50510705  0.57647306  0.7017365   0.9225509   1.        ]\n",
      "[ 0.22812408  0.07098061  0.20970646 -0.10172565  1.0886309  -0.08630195\n",
      "  0.03517056  0.99999946  0.         -0.56474787 -0.73758805 -0.1628201\n",
      " -0.99999946  0.          0.36381623  0.3691399   0.383252    0.40794274\n",
      "  0.44702443  0.49859264  0.5689733   0.69266653  0.90990204  1.        ]\n",
      "[ 0.24260046  0.02869704  0.2169663  -0.11776658  1.1366092   0.6943216\n",
      "  0.16976362  1.0000001   0.         -0.64609516 -1.0000001  -0.0381887\n",
      "  0.99999976  0.          0.35846993  0.3637154   0.37760136  0.40194425\n",
      "  0.44045126  0.49097684  0.560139    0.6821457   0.89503735  1.        ]\n",
      "[ 0.27420804  0.06252594  0.20877151 -0.12338251  1.13491     0.\n",
      "  0.1243751  -0.41662693  0.         -0.6497751  -0.01743782 -0.15363908\n",
      " -0.9999998   0.          0.35293838  0.3581029   0.37175676  0.39573783\n",
      "  0.43349752  0.48314908  0.5510177   0.67138296  0.8797108   1.        ]\n",
      "[ 0.31424433  0.08005066  0.21734016 -0.14922805  1.1216061  -0.15866914\n",
      "  0.13847971  0.10570997  0.         -0.7067991  -0.6758971  -0.26863384\n",
      " -0.99999994  0.          0.3462071   0.35127315  0.36464846  0.38818505\n",
      "  0.42504895  0.47373283  0.53995806  0.65854436  0.86117244  1.        ]\n",
      "[ 3.6354354e-01  9.8525770e-02  2.3019798e-01 -1.7053299e-01\n",
      "  1.1199996e+00  1.7881393e-07  2.2616446e-02 -1.0000000e+00\n",
      "  0.0000000e+00 -7.9068762e-01 -1.0000001e+00 -3.8197780e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.3850729e-01  3.4346065e-01\n",
      "  3.5651934e-01  3.7954536e-01  4.1543362e-01  4.6301618e-01\n",
      "  5.2732706e-01  6.4398724e-01  8.4002262e-01  1.0000000e+00]\n",
      "[ 0.40637606  0.08562085  0.2230292  -0.18963984  1.1195736   0.\n",
      " -0.00145018 -0.21699256  0.         -0.8749586  -0.9999999  -0.49506593\n",
      " -0.9999998   0.          0.32988286  0.33470142  0.3474176   0.36986804\n",
      "  0.4047539   0.45111325  0.5132162   0.62791985  0.8164365   1.        ]\n",
      "[ 0.42241183  0.04726728  0.19846426 -0.18999779  1.1250848   0.\n",
      "  0.06507039  0.4855225   0.         -0.83492875  0.         -0.64563274\n",
      " -0.9999998   0.          0.32134324  0.3260223   0.33840874  0.36028573\n",
      "  0.39426404  0.43942192  0.49935624  0.61223406  0.79335636  1.        ]\n",
      "[ 4.3874088e-01  3.3130020e-02  2.0265488e-01 -1.9864672e-01\n",
      "  1.1218418e+00 -2.5331974e-07  1.9130492e-01  9.9999982e-01\n",
      "  0.0000000e+00 -8.3491087e-01  0.0000000e+00 -6.3490140e-01\n",
      "  5.9604645e-08  0.0000000e+00  3.1225827e-01  3.1678846e-01\n",
      "  3.2882407e-01  3.5009143e-01  3.8309139e-01  4.2696959e-01\n",
      "  4.8544240e-01  5.9551251e-01  7.6990449e-01  1.0000000e+00]\n",
      "[ 4.5141441e-01  2.6402092e-02  2.1245523e-01 -2.0595421e-01\n",
      "  1.1193311e+00  2.3841858e-07  3.1745148e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3490640e-01  0.0000000e+00 -5.1481569e-01\n",
      "  9.9999970e-01  0.0000000e+00  3.0279547e-01  3.0717051e-01\n",
      "  3.1884071e-01  3.3947319e-01  3.7145305e-01  4.1399822e-01\n",
      "  4.7094741e-01  5.7809281e-01  7.4547523e-01  1.0000000e+00]\n",
      "[ 4.61935550e-01  2.09231712e-02  2.10906267e-01 -2.20489711e-01\n",
      "  1.11644423e+00  1.04308128e-07  4.42466497e-01  1.00000012e+00\n",
      "  0.00000000e+00 -8.29879105e-01  1.05233416e-01 -3.91088843e-01\n",
      "  1.00000012e+00  0.00000000e+00  2.92628407e-01  2.96838403e-01\n",
      "  3.08116078e-01  3.28064620e-01  3.58991593e-01  4.00109470e-01\n",
      "  4.55477804e-01  5.59490204e-01  7.19313502e-01  1.00000000e+00]\n",
      "[ 0.47790283  0.03181479  0.21166222 -0.23219195  1.0919805  -0.2848919\n",
      "  0.5659082   1.          0.         -0.8333156   0.         -0.26674008\n",
      "  1.0000002   0.          0.28192538  0.2859627   0.29682717  0.31605452\n",
      "  0.34590128  0.3855198   0.43926057  0.5399809   0.6918285   1.        ]\n",
      "[ 0.49093196  0.02594955  0.21108319 -0.24926043  1.0731914  -0.21766904\n",
      "  0.6886934   1.          0.         -0.8334728   0.04100016 -0.26258254\n",
      " -0.13545658  1.          0.27040958  0.27426282  0.28468278  0.30313239\n",
      "  0.33185992  0.36987022  0.42191577  0.5191033   0.66285986  1.        ]\n",
      "[ 4.7937810e-01 -1.3756430e-02  2.2035669e-01 -1.8838926e-01\n",
      "  1.0834047e+00  8.1544615e-02  8.1189466e-01  9.9998683e-01\n",
      "  0.0000000e+00 -8.3494008e-01  1.5869737e-06 -4.3600726e-01\n",
      " -1.4379505e+00  0.0000000e+00  2.6179126e-01  2.6550081e-01\n",
      "  2.7558789e-01  2.9346192e-01  3.2119700e-01  3.5798597e-01\n",
      "  4.0856153e-01  5.0236344e-01  6.4230227e-01  1.0000000e+00]\n",
      "[ 4.4387904e-01 -6.0239837e-02  2.3721991e-01 -5.4033801e-02\n",
      "  1.0794547e+00 -3.0808479e-02  9.4157267e-01  1.0001073e+00\n",
      "  0.0000000e+00 -8.3729339e-01  8.5532665e-06 -3.9411616e-01\n",
      "  3.1339809e-01  0.0000000e+00  2.6049355e-01  2.6417804e-01\n",
      "  2.7421486e-01  2.9202643e-01  3.1906462e-01  3.5560936e-01\n",
      "  4.0525192e-01  4.9924535e-01  6.3744819e-01  1.0000000e+00]\n",
      "[ 4.0025920e-01 -7.9356417e-02  2.4985124e-01 -1.4865749e-02\n",
      "  1.1387198e+00  7.5674725e-01  8.5930955e-01 -7.5047922e-01\n",
      "  0.0000000e+00 -8.3681095e-01 -3.6060810e-06 -2.7158260e-01\n",
      "  1.0000492e+00  0.0000000e+00  2.6066869e-01  2.6435566e-01\n",
      "  2.7442384e-01  2.9225278e-01  3.1863123e-01  3.5512635e-01\n",
      "  4.0391487e-01  4.9782276e-01  6.3568902e-01  1.0000000e+00]\n",
      "[ 3.5677454e-01 -8.6756796e-02  2.4372274e-01 -2.3561537e-02\n",
      "  1.1330748e+00  8.0686808e-04  9.8931766e-01  1.0000709e+00\n",
      "  0.0000000e+00 -8.3630866e-01  1.8191424e-01 -1.2659836e-01\n",
      "  1.1899952e+00  1.0000000e+00  2.6014337e-01  2.6382291e-01\n",
      "  2.7389815e-01  2.9169294e-01  3.1738079e-01  3.5373268e-01\n",
      "  4.0161258e-01  4.9522796e-01  6.3242221e-01  1.0000000e+00]\n",
      "[ 3.1675750e-01 -8.0773458e-02  2.5241816e-01 -2.9074668e-04\n",
      "  1.1355312e+00 -1.7023087e-04  9.3496883e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3640212e-01  1.8000603e-05 -9.4465852e-02\n",
      "  9.9233365e-01  1.0000000e+00  2.6095110e-01  2.6464206e-01\n",
      "  2.7477759e-01  2.9262951e-01  3.1768215e-01  3.5332450e-01\n",
      "  4.0113950e-01  4.9485549e-01  6.3287491e-01  1.0000000e+00]\n",
      "[ 2.7176023e-01 -8.9674264e-02  2.8135121e-01  2.5732040e-03\n",
      "  1.1349294e+00  1.7881393e-07  9.3490863e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3491498e-01  0.0000000e+00 -3.4752131e-02\n",
      "  5.1535118e-01  1.0000000e+00  2.6108450e-01  2.6477736e-01\n",
      "  2.7494946e-01  2.9281256e-01  3.1712434e-01  3.5193112e-01\n",
      "  3.9979360e-01  4.9315935e-01  6.3178730e-01  1.0000000e+00]\n",
      "[ 0.22211504 -0.0992639   0.30759642  0.00940303  1.1344445   0.\n",
      "  0.9090998  -0.226161    0.         -0.8349061   0.          0.03949612\n",
      "  0.60374385  0.          0.26151407  0.2652132   0.27543643  0.2932913\n",
      "  0.31684512  0.35075143  0.40019992  0.49177888  0.63129425  1.        ]\n",
      "[ 0.16816393 -0.1079229   0.3336232   0.01796037  1.1330613   0.\n",
      "  0.8343637  -0.65698594  0.         -0.8349058   0.          0.12528092\n",
      "  0.6987795   0.          0.26232928  0.26607624  0.27633274  0.29338902\n",
      "  0.3169507   0.349898    0.4012023   0.49086872  0.63161916  1.        ]\n",
      "[ 1.07980110e-01 -1.20434225e-01  3.61921579e-01  2.56224256e-02\n",
      "  1.12958372e+00 -5.32865524e-05  9.28243518e-01  1.53186321e+00\n",
      "  1.00000000e+00 -8.34906340e-01  1.78813934e-06  2.25333273e-01\n",
      "  8.15788269e-01  0.00000000e+00  2.63478041e-01  2.67280757e-01\n",
      "  2.77583688e-01  2.93781191e-01  3.17374349e-01  3.49294692e-01\n",
      "  4.02714819e-01  4.90325749e-01  6.32622242e-01  1.00000000e+00]\n",
      "[ 9.2711441e-02 -2.7708506e-02  1.7305081e-01  1.1025319e-01\n",
      "  1.1137699e+00  1.5527159e-02  9.3490434e-01  2.5896430e-03\n",
      "  0.0000000e+00 -8.3062100e-01 -2.9085577e-04  2.6638871e-01\n",
      "  3.7704185e-01  0.0000000e+00  2.6888368e-01  2.7278268e-01\n",
      "  2.8329769e-01  2.9926819e-01  3.2330200e-01  3.5503250e-01\n",
      "  4.1126415e-01  4.9835509e-01  6.4514601e-01  1.0000000e+00]\n",
      "[ 7.6016434e-02 -3.3417393e-02  1.2730344e-01  1.4209303e-01\n",
      "  1.1131098e+00 -8.2013458e-03  9.3504357e-01  2.0325284e-03\n",
      "  0.0000000e+00 -8.3087122e-01  6.0126185e-05  3.2596403e-01\n",
      "  4.9257603e-01  0.0000000e+00  2.7555183e-01  2.7956215e-01\n",
      "  2.9033852e-01  3.0619931e-01  3.3051905e-01  3.6249349e-01\n",
      "  4.2187414e-01  5.0873244e-01  6.6094327e-01  1.0000000e+00]\n",
      "[ 5.6479879e-02 -3.9097831e-02  1.2469710e-01  1.5539505e-01\n",
      "  1.1131208e+00 -8.6320937e-04  9.3497646e-01 -2.5930008e-04\n",
      "  0.0000000e+00 -8.3122432e-01  1.9431114e-05  3.9433730e-01\n",
      "  5.6287223e-01  0.0000000e+00  2.8282863e-01  2.8695896e-01\n",
      "  2.9802045e-01  3.1379622e-01  3.3801395e-01  3.7071344e-01\n",
      "  4.3346566e-01  5.2021635e-01  6.7951930e-01  1.0000000e+00]\n",
      "[ 3.5817154e-02 -4.1330412e-02  1.2248521e-01  1.6134991e-01\n",
      "  1.1130477e+00 -1.6161501e-03  9.3492436e-01 -4.8432747e-04\n",
      "  0.0000000e+00 -8.3162928e-01  3.6329031e-05  4.6729714e-01\n",
      "  5.9947872e-01  0.0000000e+00  2.9037809e-01  2.9463214e-01\n",
      "  3.0582747e-01  3.2169402e-01  3.4582466e-01  3.7927976e-01\n",
      "  4.4549787e-01  5.3221077e-01  6.9924629e-01  1.0000000e+00]\n",
      "[ 1.4826881e-02 -4.2013779e-02  1.1680680e-01  1.6172144e-01\n",
      "  1.1127796e+00 -3.4764409e-03  9.3490720e-01 -1.9868216e-08\n",
      "  0.0000000e+00 -8.0858070e-01  2.9461893e-01  5.0192463e-01\n",
      "  2.7769223e-01  0.0000000e+00  2.9794696e-01  3.0231452e-01\n",
      "  3.1335801e-01  3.2961527e-01  3.5367393e-01  3.8871446e-01\n",
      "  4.5578572e-01  5.4425806e-01  7.1901417e-01  1.0000000e+00]\n",
      "[-0.00343484 -0.03650872  0.11881287  0.16831486  1.1127398   0.\n",
      "  0.9256934  -0.07757484  0.         -0.8087936   0.          0.57430404\n",
      "  0.59884506  0.          0.30584416  0.31032747  0.3212206   0.3378858\n",
      "  0.36187872  0.39939776  0.46624893  0.55684733  0.73964316  1.        ]\n",
      "[-1.2632705e-02 -1.8394465e-02  1.1831373e-01  1.6404097e-01\n",
      "  1.0994774e+00 -1.6567871e-01  9.2576110e-01  1.9868216e-08\n",
      "  0.0000000e+00 -8.0906785e-01  0.0000000e+00  6.3162619e-01\n",
      "  4.7238791e-01  0.0000000e+00  3.1357351e-01  3.1817013e-01\n",
      "  3.2891202e-01  3.4597623e-01  3.6989996e-01  4.0985245e-01\n",
      "  4.7647932e-01  5.6915694e-01  7.6059109e-01  1.0000000e+00]\n",
      "[-0.0354402  -0.04567434  0.106828    0.1301726   1.1774992   0.98490435\n",
      "  0.80736876 -1.0000001   0.         -0.77613646  0.41381016  0.5916054\n",
      " -0.33726373  0.          0.31965324  0.32433897  0.33492827  0.3523046\n",
      "  0.3761353   0.41806245  0.4844421   0.57874143  0.7771691   1.        ]\n",
      "[-0.0448909  -0.01924249  0.11339312  0.13700218  1.1137996  -0.7970332\n",
      "  0.9741675   1.3909683   0.         -0.74706054  0.37174314  0.552587\n",
      " -0.3334019   0.          0.32608405  0.33086407  0.3412894   0.35899577\n",
      "  0.3827249   0.42674556  0.4928583   0.58921933  0.7947025   1.        ]\n",
      "[-0.03640112  0.01693738  0.13008128  0.12790146  1.0536778  -0.9051327\n",
      "  0.9561124   1.1048349   1.         -0.7870098  -0.4791537   0.67583585\n",
      "  0.99999994  0.          0.33210665  0.33697495  0.34719497  0.36479717\n",
      "  0.38878223  0.43485695  0.50061053  0.59990114  0.81108135  1.        ]\n",
      "[-0.03016052  0.01256235  0.10361476  0.11457264  1.0854967   0.42789838\n",
      "  0.8325674  -0.9995164   1.         -0.7315041   0.70292413  0.5709626\n",
      " -0.89583415  0.          0.33755395  0.34250212  0.35257027  0.37000787\n",
      "  0.39433548  0.44220695  0.50770706  0.6096203   0.8273391   1.        ]\n",
      "[-0.01848078  0.02350621  0.10003014  0.10464461  1.111567    0.3320881\n",
      "  0.71390486 -0.9999998   0.         -0.6528932   1.          0.40487415\n",
      " -1.4209076   0.          0.3425357   0.3475569   0.357475    0.3747502\n",
      "  0.39938962  0.4489244   0.51416916  0.61848986  0.84412384  1.        ]\n",
      "[ 1.79266669e-02  7.27540255e-02  1.11877374e-01  8.96665826e-02\n",
      "  1.11045873e+00  9.48309898e-05  5.97378016e-01 -9.99967575e-01\n",
      "  0.00000000e+00 -6.35499656e-01  2.48594612e-01  2.93699145e-01\n",
      " -9.99997616e-01  0.00000000e+00  3.46905619e-01  3.51990849e-01\n",
      "  3.61721516e-01  3.78794491e-01  4.03699845e-01  4.54794645e-01\n",
      "  5.19702196e-01  6.26174748e-01  8.58948052e-01  1.00000000e+00]\n",
      "[ 0.06027534  0.08470239  0.11566949  0.07263093  1.0943176  -0.17920741\n",
      "  0.4809243  -1.          0.         -0.63038296  0.07634753  0.17656553\n",
      " -1.0000001   0.          0.35052553  0.3556341   0.36518785  0.38203862\n",
      "  0.40748426  0.45963702  0.5241942   0.63245326  0.8713203   1.        ]\n",
      "[ 0.12722589  0.13376871  0.13135774  0.04742561  1.0580679  -0.43080774\n",
      "  0.36602193 -1.0000001   1.         -0.6996338  -0.8305915   0.0636735\n",
      " -0.9999998   0.          0.3530474   0.35787377  0.3674877   0.38406065\n",
      "  0.41043457  0.46236834  0.5270428   0.6366312   0.8801475   1.        ]\n",
      "[ 0.19075233  0.12703674  0.12723978  0.03641827  1.0202949  -0.4417754\n",
      "  0.25052184 -0.99999994  1.         -0.74553007 -0.5583352  -0.05356908\n",
      " -1.0000001   0.          0.35504746  0.35960096  0.36926132  0.3855602\n",
      "  0.41275668  0.46421474  0.5291793   0.6398587   0.88723904  1.        ]\n",
      "[ 0.24597456  0.11033623  0.12509619  0.0067819   1.0244716   0.0728454\n",
      "  0.13551909 -0.9999998   0.         -0.79853714 -0.6363745  -0.16934657\n",
      " -1.          0.          0.35561976  0.3598988   0.36956716  0.3855722\n",
      "  0.41335022  0.46429965  0.52929866  0.64043844  0.8896924   1.        ]\n",
      "[ 0.2876028   0.08290914  0.1290153  -0.02239253  1.0880347   0.8218571\n",
      "  0.02658892 -1.0000001   0.         -0.86995465 -0.87038946 -0.19755387\n",
      " -0.26650557  0.          0.35477397  0.35876042  0.3683982   0.38407162\n",
      "  0.4122209   0.46259758  0.52737325  0.6383593   0.88762057  1.        ]\n",
      "[ 0.31048054  0.05885246  0.11447415 -0.03418091  1.1724689   1.0000005\n",
      " -0.07785988 -1.          0.         -0.83491385  0.         -0.35544717\n",
      " -1.          0.          0.35346293  0.35720897  0.36680505  0.38219818\n",
      "  0.41054735  0.46044046  0.5249225   0.6355096   0.88371795  1.        ]\n",
      "[ 3.5289359e-01  7.5741887e-02  1.0731920e-01 -3.2963131e-02\n",
      "  1.1349298e+00 -5.9604645e-08  1.3022363e-02  2.7654496e-01\n",
      "  0.0000000e+00 -8.3492523e-01  0.0000000e+00 -4.7592986e-01\n",
      " -1.0000000e+00  0.0000000e+00  3.5250407e-01  3.5601968e-01\n",
      "  3.6558381e-01  3.8071209e-01  4.0930364e-01  4.5873961e-01\n",
      "  5.2299345e-01  6.3332987e-01  8.8104063e-01  1.0000000e+00]\n",
      "[ 0.38413867  0.06268393  0.11079147 -0.03502013  1.1154052  -0.20359881\n",
      "  0.13902396  0.9999998   0.         -0.8349095   0.         -0.44495833\n",
      "  0.2506094   0.          0.35103378  0.35429826  0.36381614  0.37865043\n",
      "  0.40743345  0.45636228  0.52029145  0.6301664   0.87660366  1.        ]\n",
      "[ 0.4184659   0.06866438  0.11016013 -0.05192751  1.0837457  -0.3608679\n",
      "  0.26431298  1.0000001   0.         -0.8349082   0.         -0.44622445\n",
      " -0.01910374  0.          0.34877363  0.35178596  0.36123636  0.3757656\n",
      "  0.40460694  0.4530102   0.5164733   0.62553793  0.8694353   1.        ]\n",
      "[ 0.43572447  0.03558886  0.11924807 -0.07319459  1.1044234   0.30966553\n",
      "  0.39431798  1.0000001   0.         -0.8349094   0.         -0.32591534\n",
      "  0.9999997   0.          0.3454809   0.34821394  0.3575684   0.37174982\n",
      "  0.40052092  0.4483255   0.51113135  0.61894906  0.8591102   1.        ]\n",
      "[ 4.5889938e-01  4.7595158e-02  1.2072086e-01 -8.2015343e-02\n",
      "  1.1029136e+00 -5.9604645e-08  4.9184084e-01  7.7189332e-01\n",
      "  0.0000000e+00 -8.3490962e-01  0.0000000e+00 -2.0533645e-01\n",
      "  1.0000004e+00  0.0000000e+00  3.4178203e-01  3.4423378e-01\n",
      "  3.5344025e-01  3.6730748e-01  3.9594266e-01  4.4313616e-01\n",
      "  5.0521165e-01  6.1160415e-01  8.4745151e-01  1.0000000e+00]\n",
      "[ 0.48445708  0.05113554  0.12018568 -0.09413607  1.1022844   0.\n",
      "  0.5267668   0.27897128  0.         -0.8329458   0.07328418 -0.07914555\n",
      "  0.99999976  0.          0.3375061   0.3396747   0.34858486  0.3622616\n",
      "  0.39066523  0.4372323   0.49847388  0.6031871   0.8338956   1.        ]\n",
      "[ 0.5119457   0.05502249  0.11828726 -0.10682584  1.1022218   0.\n",
      "  0.50701654 -0.169827    0.         -0.82791024  0.11899215 -0.07811987\n",
      " -1.5100154   1.          0.33262956  0.33451793  0.34313437  0.35659727\n",
      "  0.38466203  0.43059528  0.49089634  0.5936623   0.8183571   1.        ]\n",
      "[ 0.53882354  0.05438316  0.1065214  -0.12874217  1.1028833   0.\n",
      "  0.45565212 -0.43105564  0.         -0.78615594  0.50514376 -0.13535392\n",
      " -0.99999994  1.          0.326617    0.3282492   0.33659703  0.34980342\n",
      "  0.37729257  0.42261407  0.48177764  0.5820753   0.79903305  1.        ]\n",
      "[ 5.5429840e-01  3.1044656e-02  9.9010840e-02 -1.4806113e-01\n",
      "  1.1017594e+00  4.4703484e-08  5.2338874e-01  5.4912460e-01\n",
      "  0.0000000e+00 -7.2804582e-01  7.3303765e-01 -2.5377285e-01\n",
      " -1.0000005e+00  1.0000000e+00  3.1976256e-01  3.2114908e-01\n",
      "  3.2923898e-01  3.4215668e-01  3.6890799e-01  4.1362000e-01\n",
      "  4.7149819e-01  5.6894690e-01  7.7691740e-01  1.0000000e+00]\n",
      "[ 0.58058023  0.05254091  0.11518218 -0.1649159   1.10168     0.\n",
      "  0.5212929  -0.02398086  0.         -0.7207083   0.09644601 -0.32339096\n",
      " -0.59494156  1.          0.31211588  0.31327182  0.3210643   0.33366126\n",
      "  0.35961485  0.4036304   0.4600818   0.55438274  0.7524365   1.        ]\n",
      "[ 5.95376313e-01  2.94314604e-02  1.21317856e-01 -1.79395348e-01\n",
      "  1.09937167e+00 -2.38418579e-07  6.45663857e-01  1.00000000e+00\n",
      "  0.00000000e+00 -7.42899776e-01 -2.71352232e-01 -3.54428768e-01\n",
      " -2.56747454e-01  1.00000000e+00  3.03554118e-01  3.04678321e-01\n",
      "  3.12152356e-01  3.24399650e-01  3.49471897e-01  3.92738402e-01\n",
      "  4.47633654e-01  5.38493693e-01  7.28984594e-01  1.00000000e+00]\n",
      "[ 0.60694003  0.02285181  0.14886063 -0.19364098  1.1236684   0.3344415\n",
      "  0.77022254  0.99999976  0.         -0.79243714 -0.61177146 -0.3551824\n",
      " -0.00888781  1.          0.29427147  0.2953613   0.3024471   0.31431365\n",
      "  0.33850986  0.38088715  0.43409702  0.5212711   0.70401657  1.        ]\n",
      "[ 6.2794882e-01  4.1807294e-02  1.7787848e-01 -1.8816796e-01\n",
      "  1.1228082e+00  1.7881393e-07  8.9167595e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.7303656e-01 -1.0000000e+00 -3.2555830e-01\n",
      "  2.2960784e-01  1.0000000e+00  2.8521490e-01  2.8627121e-01\n",
      "  2.9290402e-01  3.0439612e-01  3.2787520e-01  3.6925140e-01\n",
      "  4.2083576e-01  5.0447518e-01  6.7979419e-01  1.0000000e+00]\n",
      "[ 6.2875873e-01  1.5582558e-02  1.4410833e-01 -1.7552817e-01\n",
      "  1.1299500e+00 -2.2351742e-08  8.9475715e-01  1.7624637e-02\n",
      "  0.0000000e+00 -8.3491856e-01  0.0000000e+00 -4.1341209e-01\n",
      " -3.8800859e-01  1.0000000e+00  2.7684292e-01  2.7786821e-01\n",
      "  2.8415400e-01  2.9530278e-01  3.1798604e-01  3.5856578e-01\n",
      "  4.0865734e-01  4.8894179e-01  6.5726984e-01  1.0000000e+00]\n",
      "[ 6.1591864e-01 -2.5616257e-02  1.4248738e-01 -1.8035334e-01\n",
      "  1.1299574e+00  4.0382147e-06  1.0145035e+00  1.0000004e+00\n",
      "  0.0000000e+00 -8.3490610e-01 -1.3411045e-07 -4.1823101e-01\n",
      "  1.0673449e-01  1.0000000e+00  2.6813200e-01  2.6912501e-01\n",
      "  2.7503616e-01  2.8582722e-01  3.0770755e-01  3.4709015e-01\n",
      "  3.9597070e-01  4.7318560e-01  6.3385874e-01  1.0000000e+00]\n",
      "[ 6.0106707e-01 -3.6195293e-02  1.5356527e-01 -3.6608204e-02\n",
      "  1.1348554e+00 -5.1581860e-03  9.3491781e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3609098e-01  2.3311377e-04 -4.0506458e-01\n",
      "  1.5173550e-01  0.0000000e+00  2.6700598e-01  2.6799485e-01\n",
      "  2.7354553e-01  2.8427809e-01  3.0663282e-01  3.4568819e-01\n",
      "  3.9398074e-01  4.7082910e-01  6.3141084e-01  1.0000000e+00]\n",
      "[ 5.7755792e-01 -4.4649329e-02  1.6892827e-01  2.1001937e-02\n",
      "  1.1327945e+00  5.5885315e-04  8.8007104e-01 -4.9827942e-01\n",
      "  0.0000000e+00 -8.3574814e-01 -8.7946653e-05 -3.8259721e-01\n",
      "  1.8609710e-01  0.0000000e+00  2.6816091e-01  2.6915404e-01\n",
      "  2.7430809e-01  2.8507060e-01  3.0835882e-01  3.4672484e-01\n",
      "  3.9516225e-01  4.7290859e-01  6.3534212e-01  1.0000000e+00]\n",
      "[ 0.5502107  -0.05368162  0.19781521  0.04185364  1.0927169  -0.4958127\n",
      "  1.0013233   0.9999998   0.         -0.83516705  0.         -0.35604143\n",
      "  0.4108857   0.          0.2698961   0.27089566  0.27558473  0.2863973\n",
      "  0.3108455   0.34841114  0.39708883  0.47618052  0.64100593  1.        ]\n",
      "[ 5.1681668e-01 -6.6348240e-02  2.2735138e-01  3.9494719e-02\n",
      "  1.1262650e+00  1.6167018e-01  9.3490493e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490753e-01 -1.8179417e-06 -3.1100786e-01\n",
      "  3.7323472e-01  1.0000000e+00  2.7120525e-01  2.7219898e-01\n",
      "  2.7636251e-01  2.8720561e-01  3.1287241e-01  3.4950095e-01\n",
      "  3.9837831e-01  4.7866708e-01  6.4562261e-01  1.0000000e+00]\n",
      "[ 4.8341495e-01 -6.6798761e-02  2.4872835e-01  4.7014471e-02\n",
      "  1.1262207e+00  3.8743019e-06  9.3490469e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490574e-01 -1.1920929e-07 -2.6182175e-01\n",
      "  4.0230107e-01  0.0000000e+00  2.7291217e-01  2.7331075e-01\n",
      "  2.7749130e-01  2.8911078e-01  3.1542191e-01  3.5103482e-01\n",
      "  4.0018010e-01  4.8189810e-01  6.5142959e-01  1.0000000e+00]\n",
      "[ 4.4764641e-01 -7.1561128e-02  2.6646048e-01  5.4589529e-02\n",
      "  1.1257792e+00  5.6624413e-07  8.8815737e-01 -3.9950594e-01\n",
      "  0.0000000e+00 -8.3490789e-01 -8.9406967e-08 -2.0673835e-01\n",
      "  4.5056239e-01  0.0000000e+00  2.7493456e-01  2.7469361e-01\n",
      "  2.7889532e-01  2.9182976e-01  3.1838837e-01  3.5291764e-01\n",
      "  4.0238470e-01  4.8571962e-01  6.5818620e-01  1.0000000e+00]\n",
      "[ 4.0860564e-01 -7.8155734e-02  2.8456670e-01  6.2537506e-02\n",
      "  1.1242726e+00  1.4901161e-07  7.9531622e-01 -8.0941111e-01\n",
      "  0.0000000e+00 -8.3490807e-01 -2.9802322e-08 -1.4426923e-01\n",
      "  5.1121998e-01  0.0000000e+00  2.7728388e-01  2.7635717e-01\n",
      "  2.8058431e-01  2.9494506e-01  3.2178715e-01  3.5516194e-01\n",
      "  4.0500659e-01  4.9015340e-01  6.6592759e-01  1.0000000e+00]\n",
      "[ 0.360569   -0.0963243   0.3110769   0.06871889  1.0757818  -0.59939605\n",
      "  0.91687584  0.9999998   0.         -0.83418113  0.01410145 -0.06802082\n",
      "  0.6197385   0.          0.27983758  0.278161    0.28241572  0.29833478\n",
      "  0.32505327  0.35759702  0.40785185  0.4949733   0.67654485  1.        ]\n",
      "[ 0.30787915 -0.10559457  0.34166107  0.06821419  1.0976632   0.29758757\n",
      "  0.8016676  -1.          0.         -0.8347313   0.          0.01930094\n",
      "  0.7053936   0.          0.28188294  0.27979913  0.28433877  0.30167148\n",
      "  0.3270947   0.35984287  0.41048586  0.49970996  0.688635    1.        ]\n",
      "[ 0.23024242 -0.15553057  0.35857973  0.06997459  1.1001712   0.03913522\n",
      "  0.9231392   0.9999998   0.         -0.80555433  0.3707208   0.10114032\n",
      "  0.6617957   0.          0.28344333  0.281348    0.28746465  0.3049879\n",
      "  0.32904443  0.36199385  0.41300777  0.50522715  0.70078254  1.        ]\n",
      "[ 1.5996780e-01 -1.4070226e-01  3.9573887e-01  7.9840012e-02\n",
      "  1.0995449e+00  1.5187263e-04  9.2470396e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.0652255e-01 -3.2186508e-06  2.2503805e-01\n",
      "  9.9535865e-01  0.0000000e+00  2.8532904e-01  2.8321978e-01\n",
      "  2.9107684e-01  3.0882028e-01  3.3137941e-01  3.6463517e-01\n",
      "  4.1650483e-01  5.1162183e-01  7.1468472e-01  1.0000000e+00]\n",
      "[ 0.08909439 -0.14199504  0.39912838  0.07010815  1.1164771   0.24345046\n",
      "  0.92876184  1.2227144   1.         -0.80658305  0.01473534  0.3525179\n",
      "  1.0201987   0.          0.2867246   0.284605    0.29418898  0.3117909\n",
      "  0.33316377  0.36666915  0.4201309   0.51707786  0.72879994  1.        ]\n",
      "[ 6.2849686e-02 -5.1204279e-02  2.0901948e-01  1.8615492e-01\n",
      "  1.1057246e+00  3.4300506e-02  9.2825520e-01  2.3477077e-03\n",
      "  1.0000000e+00 -8.0572212e-01 -5.6064129e-04  4.3835151e-01\n",
      "  7.1258754e-01  0.0000000e+00  2.9465470e-01  2.9306793e-01\n",
      "  3.0332464e-01  3.2025334e-01  3.4220630e-01  3.7668395e-01\n",
      "  4.3294299e-01  5.3398854e-01  7.6185346e-01  1.0000000e+00]\n",
      "[ 3.8229827e-02 -4.9256593e-02  1.9770916e-01  2.0499045e-01\n",
      "  1.1045070e+00 -1.2502700e-02  9.3022335e-01  3.8828254e-03\n",
      "  1.0000000e+00 -8.0614471e-01  7.4058771e-05  5.2992302e-01\n",
      "  7.5604993e-01  0.0000000e+00  3.0338812e-01  3.0268580e-01\n",
      "  3.1327909e-01  3.2956019e-01  3.5215110e-01  3.8769394e-01\n",
      "  4.4695571e-01  5.5270213e-01  7.9586673e-01  1.0000000e+00]\n",
      "[ 0.01385167 -0.04876614  0.1971969   0.21830598  1.1044904   0.\n",
      "  0.92322993 -0.06820152  1.         -0.8067246   0.          0.62776244\n",
      "  0.80422276  0.          0.31274316  0.31292984  0.32388166  0.33952227\n",
      "  0.362811    0.39947677  0.46191072  0.5730591   0.82690626  1.        ]\n",
      "[ 3.8622126e-03 -1.9900834e-02  1.8339580e-01  2.2399639e-01\n",
      "  1.1044958e+00  7.4505806e-09  8.8173169e-01 -3.5297880e-01\n",
      "  1.0000000e+00 -7.2841400e-01  9.8803669e-01  5.2990645e-01\n",
      " -8.3475953e-01  1.0000000e+00  3.2246801e-01  3.2348981e-01\n",
      "  3.3481118e-01  3.4986702e-01  3.7392020e-01  4.1170868e-01\n",
      "  4.7752523e-01  5.9404379e-01  8.5884088e-01  1.0000000e+00]\n",
      "[ 2.4519481e-02  4.1391749e-02  1.8791109e-01  2.1485585e-01\n",
      "  1.1039526e+00  2.9802322e-08  7.7393258e-01 -9.1015059e-01\n",
      "  1.0000000e+00 -6.8407863e-01  5.6827152e-01  4.1396707e-01\n",
      " -1.0000000e+00  0.0000000e+00  3.3186051e-01  3.3372742e-01\n",
      "  3.4540710e-01  3.5986310e-01  3.8465634e-01  4.2439845e-01\n",
      "  4.9337262e-01  6.1438793e-01  8.8609201e-01  1.0000000e+00]\n",
      "[ 0.04683761  0.04464561  0.18252543  0.20963497  1.102959   -0.00254983\n",
      "  0.6567887  -1.0008942   1.         -0.6154527   0.89026153  0.30397862\n",
      " -1.0000614   0.          0.34100088  0.3436899   0.354798    0.3695908\n",
      "  0.3951042   0.43695602  0.50879407  0.6363955   0.91153747  1.        ]\n",
      "[ 0.06839234  0.0432141   0.18019171  0.19444054  1.096238   -0.06437217\n",
      "  0.5400285  -1.          0.         -0.5367887   1.0000002   0.18900084\n",
      " -0.99999994  0.          0.34945536  0.3529476   0.36344063  0.37859377\n",
      "  0.4047753   0.44860607  0.52311724  0.65781826  0.9351653   1.        ]\n",
      "[ 0.09937923  0.06191829  0.18349296  0.18246832  1.0547498  -0.4927274\n",
      "  0.47559208 -0.32785007  1.         -0.46836668  0.89271426  0.0828926\n",
      " -1.          0.          0.3575838   0.3616447   0.3715092   0.38699874\n",
      "  0.41380617  0.4595229   0.5365623   0.67800766  0.9586756   1.        ]\n",
      "[ 0.12583062  0.05313496  0.17848873  0.16037259  1.039458   -0.17457694\n",
      "  0.3388002  -1.          1.         -0.39040273  1.0000002  -0.02660275\n",
      " -0.99999994  0.          0.36516076  0.3693077   0.37856477  0.39436567\n",
      "  0.4217057   0.46911246  0.5483975   0.69586414  0.9798348   1.        ]\n",
      "[ 0.15929194  0.06705758  0.18155515  0.14374435  1.007871   -0.36048868\n",
      "  0.22265029 -1.0000001   1.         -0.32058197  0.8818483  -0.14178908\n",
      " -0.99999994  0.          0.37198073  0.37620512  0.38484323  0.40094244\n",
      "  0.42873842  0.47770438  0.55935776  0.7131109   0.99888635  1.        ]\n",
      "[ 0.18508911  0.05154988  0.17675467  0.11863549  1.0059793  -0.0129649\n",
      "  0.10595918 -1.0000001   1.         -0.24261625  1.0000002  -0.2477963\n",
      " -0.9999998   0.          0.37757707  0.381865    0.3898953   0.4062388\n",
      "  0.43449634  0.48470017  0.56836075  0.7275191   1.          1.        ]\n",
      "[ 0.20419505  0.03817602  0.17593502  0.08854203  1.0443813   0.49734163\n",
      " -0.01020551 -1.0000001   0.         -0.17268342  0.8837402  -0.36374784\n",
      " -0.99999994  0.          0.38176212  0.38609758  0.39352125  0.41004664\n",
      "  0.4391115   0.49018735  0.5750933   0.7385766   1.          1.        ]\n",
      "[ 0.22320028  0.03770858  0.19300167  0.06480506  1.1230385   0.9999997\n",
      " -0.12150061 -1.          0.         -0.17232868  0.01610591 -0.35452747\n",
      "  0.03908064  0.          0.38484845  0.38913605  0.39597195  0.4126305\n",
      "  0.44240567  0.49422646  0.5800584   0.7471462   1.          1.        ]\n",
      "[ 2.5891659e-01  7.1251929e-02  1.9483259e-01  4.9534529e-02\n",
      "  1.1180234e+00 -5.9604645e-08  6.7215562e-03  9.9999970e-01\n",
      "  0.0000000e+00 -2.1834509e-01 -5.3854144e-01 -4.7056246e-01\n",
      " -1.0000004e+00  0.0000000e+00  3.8728979e-01  3.9090267e-01\n",
      "  3.9776963e-01  4.1453275e-01  4.4494230e-01  4.9739608e-01\n",
      "  5.8398581e-01  7.5418693e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 3.0189061e-01  8.5886829e-02  2.2042343e-01  5.1647458e-02\n",
      "  1.1176623e+00  5.9604645e-08 -6.0710549e-02 -5.7753432e-01\n",
      "  0.0000000e+00 -2.9947767e-01 -1.0000001e+00 -3.4884226e-01\n",
      "  9.9999952e-01  0.0000000e+00  3.8984406e-01  3.9269769e-01\n",
      "  3.9959615e-01  4.1646844e-01  4.4756967e-01  5.0070256e-01\n",
      "  5.8809495e-01  7.6122558e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 3.5661134e-01  1.0929813e-01  2.2442929e-01  1.3097924e-02\n",
      "  1.1162559e+00 -2.3841858e-07 -1.7626655e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -3.8343453e-01 -9.9999976e-01 -4.6194613e-01\n",
      " -9.9999958e-01  0.0000000e+00  3.9062110e-01  3.9271313e-01\n",
      "  3.9961186e-01  4.1651469e-01  4.4810438e-01  5.0161117e-01\n",
      "  5.8934498e-01  7.6334774e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 4.1037768e-01  1.0741262e-01  2.2431178e-01 -4.1332329e-03\n",
      "  1.1148822e+00  5.9604645e-08 -2.9228413e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -4.6719521e-01 -1.0000001e+00 -5.7653141e-01\n",
      " -1.0000004e+00  0.0000000e+00  3.9058498e-01  3.9192122e-01\n",
      "  3.9880607e-01  4.1570348e-01  4.4768491e-01  5.0142395e-01\n",
      "  5.8928686e-01  7.6373863e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 4.6070835e-01  1.0055986e-01  2.1954559e-01 -2.1173283e-02\n",
      "  1.1144105e+00 -1.1920929e-07 -3.5782325e-01 -5.6667584e-01\n",
      "  0.0000000e+00 -5.5107367e-01 -9.9999994e-01 -6.9152880e-01\n",
      " -9.9999970e-01  0.0000000e+00  3.8973480e-01  3.9033604e-01\n",
      "  3.9721745e-01  4.1404924e-01  4.4631785e-01  5.0014240e-01\n",
      "  5.8791918e-01  7.6238710e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 5.0741172e-01  9.1634944e-02  2.2135213e-01 -2.6797034e-02\n",
      "  1.1122375e+00  5.9604645e-08 -4.0355670e-01 -3.9520466e-01\n",
      "  0.0000000e+00 -6.4230388e-01 -1.0000001e+00 -6.3490856e-01\n",
      " -1.9868216e-08  0.0000000e+00  3.8877752e-01  3.8862127e-01\n",
      "  3.9549929e-01  4.1225824e-01  4.4481355e-01  4.9871227e-01\n",
      "  5.8690232e-01  7.6082188e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 5.4340291e-01  7.1924038e-02  2.1113540e-01 -3.3153355e-02\n",
      "  1.1072315e+00 -8.9406967e-08 -2.7687562e-01  9.9999982e-01\n",
      "  0.0000000e+00 -7.2323787e-01 -1.0000000e+00 -5.1264727e-01\n",
      "  1.0000004e+00  0.0000000e+00  3.8731876e-01  3.8645741e-01\n",
      "  3.9332172e-01  4.0998840e-01  4.4274515e-01  4.9661520e-01\n",
      "  5.8506316e-01  7.5815874e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.5845973   0.08239947  0.21151157 -0.04334792  1.0697854  -0.41456512\n",
      " -0.15162194  1.0000002   0.         -0.8040585  -1.         -0.39113402\n",
      "  0.99999994  0.          0.38538703  0.38382462  0.39066628  0.40722045\n",
      "  0.44012216  0.4938809   0.58239686  0.7544883   1.          1.        ]\n",
      "[ 0.59399027  0.01851885  0.19371897 -0.06725641  1.1137037   0.6164793\n",
      " -0.02110147  1.0000001   0.         -0.80753416  0.         -0.26618445\n",
      "  0.9999997   0.          0.38204145  0.38005707  0.38685298  0.40340388\n",
      "  0.43612766  0.48955402  0.57761025  0.74826103  1.          1.        ]\n",
      "[ 6.1322594e-01  3.8370892e-02  1.8387397e-01 -8.2554363e-02\n",
      "  1.1104703e+00  2.6822090e-07  1.0487652e-01  1.0000001e+00\n",
      "  0.0000000e+00 -7.8371078e-01  3.0311704e-01 -2.9848695e-01\n",
      " -2.8520796e-01  0.0000000e+00  3.7759161e-01  3.7563032e-01\n",
      "  3.8236663e-01  3.9896467e-01  4.3132836e-01  4.8428780e-01\n",
      "  5.7155895e-01  7.4051553e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 6.44766629e-01  6.29616380e-02  2.18756303e-01 -1.03651695e-01\n",
      "  1.10617590e+00 -3.57627869e-07  2.32842565e-01  9.99999821e-01\n",
      "  0.00000000e+00 -8.64838719e-01 -9.99999821e-01 -1.75228477e-01\n",
      "  1.00000012e+00  0.00000000e+00  3.72061312e-01  3.70128751e-01\n",
      "  3.76789540e-01  3.93424928e-01  4.25339222e-01  4.77700800e-01\n",
      "  5.63939631e-01  7.30790257e-01  1.00000000e+00  1.00000000e+00]\n",
      "[ 0.66376156  0.04952518  0.20125322 -0.09962231  1.1119883   0.\n",
      "  0.21388572 -0.1951288   0.         -0.834915    0.         -0.09657311\n",
      "  0.99999976  0.          0.3667676   0.3648625   0.3714489   0.3880854\n",
      "  0.41956654  0.47132733  0.5564862   0.72132033  1.          1.        ]\n",
      "[ 6.7837268e-01  3.0243212e-02  1.9491893e-01 -1.2285884e-01\n",
      "  1.1094871e+00 -8.9406967e-08  3.4013295e-01  9.9999976e-01\n",
      "  0.0000000e+00 -8.3490628e-01  0.0000000e+00  2.3822367e-02\n",
      "  1.0000004e+00  0.0000000e+00  3.6036998e-01  3.5849813e-01\n",
      "  3.6498982e-01  3.8155380e-01  4.1250512e-01  4.6347868e-01\n",
      "  5.4713565e-01  7.0953161e-01  9.9363911e-01  1.0000000e+00]\n",
      "[ 6.8610209e-01  1.5451922e-02  1.9245645e-01 -1.3758813e-01\n",
      "  1.1070111e+00  1.3411045e-07  4.6518219e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3491075e-01  0.0000000e+00 -2.2386432e-02\n",
      " -3.8197699e-01  1.0000000e+00  3.5328215e-01  3.5144714e-01\n",
      "  3.5783106e-01  3.7427029e-01  4.0463078e-01  4.5469534e-01\n",
      "  5.3657043e-01  6.9626433e-01  9.7266728e-01  1.0000000e+00]\n",
      "[ 6.9253737e-01  1.2884255e-02  1.9400655e-01 -1.5308289e-01\n",
      "  1.1049247e+00 -1.4901161e-07  5.8955693e-01  9.9999994e-01\n",
      "  0.0000000e+00 -8.3490735e-01  0.0000000e+00 -6.9759369e-02\n",
      " -3.9505661e-01  1.0000000e+00  3.4545949e-01  3.4367499e-01\n",
      "  3.4992772e-01  3.6619225e-01  3.9589748e-01  4.4492838e-01\n",
      "  5.2473861e-01  6.8144965e-01  9.4912338e-01  1.0000000e+00]\n",
      "[ 6.92694545e-01  3.41903855e-04  1.92429364e-01 -1.61784634e-01\n",
      "  1.10347450e+00  1.47148967e-07  7.12623119e-01  1.00000012e+00\n",
      "  0.00000000e+00 -8.34905982e-01  2.32830644e-10 -1.11634016e-01\n",
      " -3.49012405e-01  1.00000000e+00  3.37217301e-01  3.35495204e-01\n",
      "  3.41599137e-01  3.57656777e-01  3.86686504e-01  4.34592485e-01\n",
      "  5.12166262e-01  6.65734172e-01  9.24070954e-01  1.00000000e+00]\n",
      "[ 7.0238370e-01  1.9442655e-02  1.8439575e-01 -1.5812567e-01\n",
      "  1.1024973e+00  5.2154064e-08  6.1280584e-01 -8.5335237e-01\n",
      "  0.0000000e+00 -8.3490819e-01  0.0000000e+00 -1.6205907e-01\n",
      " -4.2127895e-01  1.0000000e+00  3.2919711e-01  3.2753518e-01\n",
      "  3.3349431e-01  3.4934220e-01  3.7772283e-01  4.2451829e-01\n",
      "  4.9989355e-01  6.5040278e-01  8.9960277e-01  1.0000000e+00]\n",
      "[ 7.1105033e-01  1.7391251e-02  1.8375574e-01 -1.7064618e-01\n",
      "  1.1008224e+00 -1.1920929e-07  4.9703157e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -8.3491027e-01  0.0000000e+00 -2.1358001e-01\n",
      " -4.3036982e-01  1.0000000e+00  3.2059115e-01  3.1899205e-01\n",
      "  3.2479572e-01  3.4039038e-01  3.6805487e-01  4.1365260e-01\n",
      "  4.8661879e-01  6.3294882e-01  8.7424725e-01  1.0000000e+00]\n",
      "[ 7.1034175e-01 -1.2696955e-03  1.8349096e-01 -1.9090666e-01\n",
      "  1.0935764e+00 -9.1179006e-02  5.1750231e-01  1.6967674e-01\n",
      "  0.0000000e+00 -8.3490866e-01  9.3132257e-10 -2.5921953e-01\n",
      " -3.8116574e-01  1.0000000e+00  3.1100887e-01  3.0947709e-01\n",
      "  3.1510767e-01  3.3037859e-01  3.5721666e-01  4.0147167e-01\n",
      "  4.7221926e-01  6.1291516e-01  8.4937334e-01  1.0000000e+00]\n",
      "[ 0.6998106  -0.02097577  0.19217175 -0.20332573  1.0907903  -0.01763292\n",
      "  0.64056957  0.99999994  0.         -0.8349091   0.         -0.29679346\n",
      " -0.31463692  1.          0.30079302  0.29933277  0.30477875  0.31970066\n",
      "  0.345655    0.38847762  0.4568571   0.59152895  0.82283586  1.        ]\n",
      "[ 0.6780252  -0.04351963  0.21142314 -0.21588562  1.1264093   0.4662133\n",
      "  0.76405275  1.0000002   0.         -0.8349095   0.         -0.32460535\n",
      " -0.23570436  1.          0.2898926   0.2885097   0.29375878  0.30832425\n",
      "  0.3333467   0.3746445   0.44050908  0.5688249   0.79459804  1.        ]\n",
      "[ 6.6112411e-01 -3.3672381e-02  2.1723925e-01 -2.0441367e-01\n",
      "  1.1258943e+00  6.2584877e-07  8.9148188e-01  1.0527178e+00\n",
      "  0.0000000e+00 -8.3490628e-01 -8.9406967e-08 -3.6451650e-01\n",
      " -3.3561906e-01  1.0000000e+00  2.7951947e-01  2.7821207e-01\n",
      "  2.8327382e-01  2.9753128e-01  3.2168859e-01  3.6154208e-01\n",
      "  4.2503685e-01  5.4744375e-01  7.6787812e-01  1.0000000e+00]\n",
      "[ 6.4012688e-01 -4.1871671e-02  2.2919525e-01 -1.9996041e-01\n",
      "  1.1258998e+00 -7.7605247e-05  1.0113251e+00  9.9999267e-01\n",
      "  0.0000000e+00 -8.3490920e-01  2.5629997e-06 -3.7359536e-01\n",
      "  1.7446359e-01  1.0000000e+00  2.6930490e-01  2.6806900e-01\n",
      "  2.7294621e-01  2.8693169e-01  3.1025866e-01  3.4869611e-01\n",
      "  4.0987992e-01  5.2660698e-01  7.4219865e-01  1.0000000e+00]\n",
      "[ 6.1303365e-01 -5.5262338e-02  2.3346667e-01 -3.9242689e-02\n",
      "  1.1346422e+00 -5.7801306e-03  9.3492508e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3730090e-01  2.6437640e-04 -3.4677505e-01\n",
      "  2.3090637e-01  0.0000000e+00  2.6802561e-01  2.6679558e-01\n",
      "  2.7172533e-01  2.8601119e-01  3.0951750e-01  3.4786314e-01\n",
      "  4.0905964e-01  5.2690196e-01  7.4045801e-01  1.0000000e+00]\n",
      "[ 5.7521021e-01 -7.1805023e-02  2.1699052e-01  2.1332679e-02\n",
      "  1.1318400e+00  5.2505732e-04  8.5544288e-01 -7.2886246e-01\n",
      "  0.0000000e+00 -8.3618540e-01 -8.3386898e-05 -3.0479968e-01\n",
      "  2.9924318e-01  1.0000000e+00  2.6885551e-01  2.6762167e-01\n",
      "  2.7300391e-01  2.8735700e-01  3.1126443e-01  3.4982648e-01\n",
      "  4.1156748e-01  5.3202289e-01  7.4477041e-01  1.0000000e+00]\n",
      "[ 0.53496426 -0.0808555   0.24384731  0.0307793   1.0811925  -0.627391\n",
      "  0.97615695  1.0000001   0.         -0.8316421   0.         -0.27088535\n",
      "  0.43931612  1.          0.26939058  0.2681543   0.27403358  0.2884408\n",
      "  0.31275624  0.35150743  0.41375473  0.5368581   0.7486348   1.        ]\n",
      "[ 0.48536614 -0.09913649  0.27646673  0.03084895  1.1052983   0.14327538\n",
      "  0.9349066   0.          0.         -0.83175486  0.         -0.20354784\n",
      "  0.548101    0.          0.26970002  0.2684623   0.27489352  0.28934598\n",
      "  0.31408986  0.35320625  0.41657978  0.54163     0.75218475  1.        ]\n",
      "[ 4.3471220e-01 -1.0139387e-01  3.0125120e-01  4.4406652e-02\n",
      "  1.1051639e+00  4.1723251e-07  9.3490720e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3206975e-01  0.0000000e+00 -1.2627542e-01\n",
      "  6.2336117e-01  0.0000000e+00  2.7060321e-01  2.6936138e-01\n",
      "  2.7641299e-01  2.9094532e-01  3.1621891e-01  3.5582691e-01\n",
      "  4.2096749e-01  5.4815888e-01  7.5762087e-01  1.0000000e+00]\n",
      "[ 3.8795415e-01 -9.3757063e-02  3.2447094e-01  6.2679224e-02\n",
      "  1.1030827e+00  5.9604645e-07  8.2018220e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -8.3237886e-01  0.0000000e+00 -4.6094060e-02\n",
      "  6.5306443e-01  0.0000000e+00  2.7229235e-01  2.7132908e-01\n",
      "  2.7878812e-01  2.9359972e-01  3.1937015e-01  3.5962725e-01\n",
      "  4.2694116e-01  5.5572170e-01  7.6546836e-01  1.0000000e+00]\n",
      "[ 0.32814786 -0.12010625  0.34407225  0.07163376  1.0471108  -0.6976808\n",
      "  0.9413761   1.0000001   0.         -0.8218892   0.14350516  0.03425384\n",
      "  0.6453945   0.          0.2742612   0.27396217  0.2814936   0.29687327\n",
      "  0.32293105  0.36390814  0.43360242  0.56313056  0.77430207  1.        ]\n",
      "[ 0.2701959  -0.11653389  0.37306854  0.08210348  0.99853265 -0.6335808\n",
      "  0.93490493  0.          0.         -0.8237584   0.          0.13588756\n",
      "  0.81016415  0.          0.2765781   0.27699983  0.28461477  0.30062324\n",
      "  0.32701015  0.3687983   0.44114223  0.57155055  0.78976864  1.        ]\n",
      "[ 1.9852789e-01 -1.4366268e-01  3.9902988e-01  7.5827330e-02\n",
      "  1.0070375e+00  1.3902068e-01  8.2213289e-01 -1.0000006e+00\n",
      "  0.0000000e+00 -8.2499021e-01 -5.9604645e-08  2.6095194e-01\n",
      "  1.0014892e+00  0.0000000e+00  2.7848250e-01  2.7966931e-01\n",
      "  2.8735766e-01  3.0399579e-01  3.3088705e-01  3.7323633e-01\n",
      "  4.4822961e-01  5.7931882e-01  8.0519879e-01  1.0000000e+00]\n",
      "[ 1.2796676e-01 -1.4173827e-01  4.0288541e-01  6.7352287e-02\n",
      "  9.3448728e-01 -9.0393406e-01  1.0753707e+00  2.4549153e+00\n",
      "  1.0000000e+00 -8.2650256e-01  6.3776970e-06  3.8823193e-01\n",
      "  1.0190744e+00  0.0000000e+00  2.8067797e-01  2.8188419e-01\n",
      "  2.8998724e-01  3.0687425e-01  3.3428118e-01  3.7771249e-01\n",
      "  4.5531777e-01  5.8614790e-01  8.1908953e-01  1.0000000e+00]\n",
      "[ 4.1302305e-02 -1.6850013e-01  3.5537580e-01  4.8162408e-02\n",
      "  1.0777147e+00  9.8606443e-01  9.3489718e-01  1.1424223e-07\n",
      "  1.0000000e+00 -8.0454624e-01  2.0150006e-01  5.0404316e-01\n",
      "  9.9998903e-01  0.0000000e+00  2.8207129e-01  2.8328347e-01\n",
      "  2.9178783e-01  3.0877972e-01  3.3656603e-01  3.8140523e-01\n",
      "  4.6039960e-01  5.8976567e-01  8.2919729e-01  1.0000000e+00]\n",
      "[-0.04370534 -0.16996597  0.32177693  0.04733003  1.2128654   1.7069875\n",
      "  0.8174134  -0.9999997   1.         -0.78354114  0.25474685  0.62437856\n",
      "  0.9999998   0.          0.28347164  0.28468984  0.293581    0.3106773\n",
      "  0.3388341   0.38503718  0.4653853   0.5929711   0.8393127   1.        ]\n",
      "[-0.10344705 -0.13523053  0.31017444  0.06816977  1.1349095   0.\n",
      "  1.1121242   1.0405611   1.         -0.7855167   0.10941529  0.7530423\n",
      "  1.0000001   0.          0.286323    0.28755346  0.29688072  0.31425196\n",
      "  0.3428511   0.39074883  0.47295496  0.59897983  0.854587    1.        ]\n",
      "[-1.5595682e-01 -1.1554953e-01  3.1219223e-01  7.1401685e-02\n",
      "  1.1351241e+00  5.9604645e-08  1.2374165e+00  1.4718388e+00\n",
      "  1.0000000e+00 -7.9048556e-01  2.3381233e-02  8.7640852e-01\n",
      "  1.0000001e+00  0.0000000e+00  2.8902921e-01  2.9056230e-01\n",
      "  3.0002624e-01  3.1776807e-01  3.4668723e-01  3.9623579e-01\n",
      "  4.8024058e-01  6.0470295e-01  8.6929256e-01  1.0000000e+00]\n",
      "[-0.12737447 -0.04378926  0.19365652  0.14384612  1.1743159   0.03135256\n",
      "  1.1207271   0.00928134  1.         -0.8611153  -0.27324626  0.99399877\n",
      "  0.9982023   0.          0.29737565  0.29915074  0.30889443  0.32730633\n",
      "  0.35709354  0.40916747  0.49566454  0.62112606  0.90364003  1.        ]\n",
      "[-1.15934268e-01 -1.12977335e-02  1.58107311e-01  1.62852347e-01\n",
      "  1.15035117e+00  6.51329756e-05  1.03172743e+00 -2.54933864e-01\n",
      "  1.00000000e+00 -8.35848212e-01  2.76481986e-01  9.33072984e-01\n",
      "  1.47263214e-04  0.00000000e+00  3.05587471e-01  3.07576627e-01\n",
      "  3.17594737e-01  3.36651772e-01  3.67896944e-01  4.21783417e-01\n",
      "  5.10001302e-01  6.37403667e-01  9.37739551e-01  1.00000000e+00]\n",
      "[-9.9603601e-02  3.3257999e-02  1.5913619e-01  1.6317075e-01\n",
      "  1.1184044e+00  1.4901161e-08  9.3490463e-01 -6.5484440e-01\n",
      "  1.0000000e+00 -7.8557724e-01  6.2195361e-01  8.1366998e-01\n",
      " -1.0000000e+00  0.0000000e+00  3.1314796e-01  3.1535956e-01\n",
      "  3.2563117e-01  3.4529701e-01  3.7812835e-01  4.3399176e-01\n",
      "  5.2330518e-01  6.5318167e-01  9.6694493e-01  1.0000000e+00]\n",
      "[-6.5545686e-02  6.8242289e-02  1.6037789e-01  1.6035740e-01\n",
      "  1.1178308e+00 -6.9281459e-04  8.1609982e-01 -1.0002522e+00\n",
      "  1.0000000e+00 -7.3599148e-01  6.2373888e-01  6.9502276e-01\n",
      " -1.0000077e+00  0.0000000e+00  3.2053915e-01  3.2297644e-01\n",
      "  3.3349615e-01  3.5376203e-01  3.8816634e-01  4.4597843e-01\n",
      "  5.3634518e-01  6.6863275e-01  9.8798025e-01  1.0000000e+00]\n",
      "[-0.03320973  0.06476684  0.15655366  0.14937472  1.1171087  -0.00353426\n",
      "  0.698592   -1.0012747   1.         -0.6696271   0.86587054  0.5851177\n",
      " -1.000055    0.          0.32735625  0.33001035  0.34080854  0.36158353\n",
      "  0.39746195  0.45708796  0.548408    0.6829111   1.          1.        ]\n",
      "[ 0.00623444  0.07903834  0.15776762  0.14097075  1.0802684  -0.4422716\n",
      "  0.6459843  -0.27543643  1.         -0.59981436  0.89913386  0.47369927\n",
      " -1.          0.          0.3338186   0.33668706  0.34781042  0.36901224\n",
      "  0.4063116   0.46767408  0.55987906  0.69647425  1.          1.        ]\n",
      "[ 0.04881074  0.08552569  0.15238966  0.12471837  1.0616622  -0.17206603\n",
      "  0.51057965 -1.0000002   1.         -0.52328205  0.9999998   0.3128537\n",
      " -1.5850987   1.          0.3395425   0.34261197  0.35402927  0.37561017\n",
      "  0.4141984   0.47712055  0.56937     0.7088376   1.          1.        ]\n",
      "[ 0.09738934  0.09743196  0.15833214  0.09929852  1.0445375  -0.20200318\n",
      "  0.39350832 -1.          1.         -0.4761507   0.57548624  0.20230997\n",
      " -1.0849319   0.          0.34419453  0.34732187  0.3589908   0.38087413\n",
      "  0.42058024  0.48480496  0.57663125  0.72105646  1.          1.        ]\n",
      "[ 0.14775093  0.10082685  0.16029367  0.07750435  1.0287439  -0.17942396\n",
      "  0.27722335 -1.          0.         -0.44117585  0.43525577  0.10013318\n",
      " -1.0000001   0.          0.34787503  0.35103583  0.36292022  0.38517046\n",
      "  0.42571974  0.49103138  0.58234584  0.7309553   1.          1.        ]\n",
      "[ 0.2123323   0.12917615  0.17318895  0.05670128  0.98691916 -0.49067193\n",
      "  0.1617291  -1.          0.         -0.45092845 -0.11175954 -0.01677191\n",
      " -0.99999994  0.          0.3506569   0.35384294  0.36591482  0.38882452\n",
      "  0.4297585   0.4957672   0.5866489   0.7388167   1.          1.        ]\n",
      "[ 0.28076518  0.13679135  0.18175182  0.02858555  0.9609476  -0.30144912\n",
      "  0.04633248 -1.0000001   0.         -0.49831945 -0.5730139  -0.13235223\n",
      " -1.0000001   0.          0.35212487  0.3553243   0.36753815  0.39099702\n",
      "  0.43221447  0.4982011   0.5888912   0.7436297   1.          1.        ]\n",
      "[ 0.34244105  0.12308859  0.18448222 -0.0055098   0.9887777   0.36647117\n",
      " -0.06527281 -1.0000001   0.         -0.5721991  -0.87755877 -0.24496472\n",
      " -1.0000001   0.          0.35195598  0.35515386  0.3674499   0.39130557\n",
      "  0.43274555  0.49833715  0.58856845  0.7445955   1.          1.        ]\n",
      "[ 0.39531708  0.10532155  0.18600106 -0.03676536  1.0657518   1.0000005\n",
      " -0.16988075 -0.99999976  0.         -0.6564935  -1.0000002  -0.35800147\n",
      " -1.0000002   0.          0.3502872   0.3534699   0.36579296  0.38990423\n",
      "  0.43135497  0.49636623  0.58589524  0.742031    1.          1.        ]\n",
      "[ 0.44348586  0.09588262  0.18336166 -0.05536778  1.1412369   1.0000007\n",
      " -0.18356383 -0.25316754  0.         -0.74102503 -1.         -0.4711318\n",
      " -1.0000004   0.          0.34774008  0.35093352  0.3632154   0.38749012\n",
      "  0.42882192  0.49315292  0.58184713  0.7373677   1.          1.        ]\n",
      "[ 4.9945113e-01  1.1147003e-01  1.7460255e-01 -5.5208698e-02\n",
      "  1.1339704e+00  4.1723251e-07 -5.1115274e-02  1.0000000e+00\n",
      "  0.0000000e+00 -8.2477784e-01 -1.0000000e+00 -5.8594501e-01\n",
      " -1.0000004e+00  0.0000000e+00  3.4524038e-01  3.4848589e-01\n",
      "  3.6068207e-01  3.8509995e-01  4.2630470e-01  4.8998380e-01\n",
      "  5.7787675e-01  7.3273420e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 5.3867805e-01  7.8281276e-02  1.5770820e-01 -5.5085953e-02\n",
      "  1.1281796e+00  2.0861626e-07  9.1672480e-02  1.1058824e+00\n",
      "  0.0000000e+00 -8.2530630e-01  0.0000000e+00 -6.7058539e-01\n",
      " -7.2091609e-01  0.0000000e+00  3.4269565e-01  3.4598517e-01\n",
      "  3.5809386e-01  3.8261423e-01  4.2366388e-01  4.8671842e-01\n",
      "  5.7384092e-01  7.2787446e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 5.7625711e-01  7.3852152e-02  1.6653319e-01 -6.5511324e-02\n",
      "  1.1231019e+00 -4.4703484e-07  2.2020310e-01  9.9999994e-01\n",
      "  0.0000000e+00 -8.3258414e-01  0.0000000e+00 -6.3491023e-01\n",
      "  7.9472862e-08  0.0000000e+00  3.3974186e-01  3.4307674e-01\n",
      "  3.5508361e-01  3.7969500e-01  4.2054793e-01  4.8290291e-01\n",
      "  5.6916034e-01  7.2214115e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 6.0932523e-01  6.6660792e-02  1.7540605e-01 -7.2585568e-02\n",
      "  1.1191623e+00  5.0663948e-07  3.4884059e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3491486e-01  0.0000000e+00 -5.1202834e-01\n",
      "  9.9999970e-01  0.0000000e+00  3.3634940e-01  3.3972713e-01\n",
      "  3.5161680e-01  3.7628815e-01  4.1688845e-01  4.7848043e-01\n",
      "  5.6379092e-01  7.1540904e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 6.4022255e-01  6.3139684e-02  1.7654629e-01 -8.9222342e-02\n",
      "  1.1160518e+00 -3.8743019e-07  4.7706008e-01  9.9999994e-01\n",
      "  0.0000000e+00 -8.3490890e-01  0.0000000e+00 -3.9128506e-01\n",
      "  1.0000004e+00  0.0000000e+00  3.3216828e-01  3.3558017e-01\n",
      "  3.4732470e-01  3.7197995e-01  4.1221526e-01  4.7294840e-01\n",
      "  5.5718589e-01  7.0681465e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 6.7034161e-01  6.1578199e-02  1.7779714e-01 -1.0522816e-01\n",
      "  1.1139336e+00 -5.9604645e-08  5.9170580e-01  9.0308398e-01\n",
      "  0.0000000e+00 -8.3491170e-01  0.0000000e+00 -2.7048314e-01\n",
      "  1.0000004e+00  0.0000000e+00  3.2722524e-01  3.3066329e-01\n",
      "  3.4223574e-01  3.6680296e-01  4.0656549e-01  4.6634588e-01\n",
      "  5.4938704e-01  6.9642621e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 6.9873792e-01  5.8071584e-02  1.7864692e-01 -1.2212495e-01\n",
      "  1.1123126e+00  5.9604645e-08  7.1066236e-01  9.4951242e-01\n",
      "  0.0000000e+00 -8.3491129e-01  0.0000000e+00 -2.4778271e-01\n",
      " -1.3867545e+00  1.0000000e+00  3.2147843e-01  3.2493404e-01\n",
      "  3.3630598e-01  3.6070886e-01  3.9988476e-01  4.5861369e-01\n",
      "  5.4032868e-01  6.8414360e-01  9.9496669e-01  1.0000000e+00]\n",
      "[ 7.2611439e-01  5.5435602e-02  1.7781438e-01 -1.4713109e-01\n",
      "  1.1116244e+00 -4.1723251e-07  8.3312190e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3490288e-01  0.0000000e+00 -2.7671671e-01\n",
      " -5.4027623e-01  1.0000000e+00  3.1446674e-01  3.1792560e-01\n",
      "  3.2920352e-01  3.5316658e-01  3.9157426e-01  4.4910002e-01\n",
      "  5.2928907e-01  6.6886705e-01  9.7602135e-01  1.0000000e+00]\n",
      "[ 0.75312173  0.05403967  0.17553179 -0.15444933  1.1111665   0.\n",
      "  0.8998827   0.54861933  0.         -0.83490676  0.         -0.3416773\n",
      " -0.5401043   1.          0.3072027   0.3106606   0.32189664  0.34532782\n",
      "  0.38292727  0.4392253   0.51785505  0.65297246  0.9563867   1.        ]\n",
      "[ 0.77721506  0.04828886  0.16937663 -0.16096121  1.1110642   0.\n",
      "  0.92317235  0.19132769  0.         -0.8349086   0.         -0.40785277\n",
      " -0.55613166  1.          0.29967391  0.30307716  0.31424057  0.33711448\n",
      "  0.37385225  0.42889816  0.50593436  0.636292    0.93589765  1.        ]\n",
      "[ 7.9923111e-01  4.4328075e-02  1.6795166e-01 -1.6509624e-01\n",
      "  1.1111376e+00 -2.9802322e-08  9.2335391e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3491445e-01  0.0000000e+00 -5.1229692e-01\n",
      " -9.6257287e-01  1.0000000e+00  2.9197454e-01  2.9529035e-01\n",
      "  3.0636680e-01  3.2866755e-01  3.6451289e-01  4.1828576e-01\n",
      "  4.9370024e-01  6.1912590e-01  9.1465646e-01  1.0000000e+00]\n",
      "[ 8.2393819e-01  5.2059475e-02  1.5490428e-01 -1.7319037e-01\n",
      "  1.1126761e+00  2.9802322e-08  8.0436146e-01 -9.9999970e-01\n",
      "  0.0000000e+00 -8.3491218e-01  0.0000000e+00 -5.2025783e-01\n",
      " -5.1461780e-01  1.0000000e+00  2.8375491e-01  2.8697738e-01\n",
      "  2.9790941e-01  3.1959453e-01  3.5445511e-01  4.0692142e-01\n",
      "  4.8066553e-01  6.0064071e-01  8.9197272e-01  1.0000000e+00]\n",
      "[ 0.8405767   0.03331653  0.15373302 -0.18573648  1.0657165  -0.5832857\n",
      "  0.92497766  0.99999994  0.         -0.83490634  0.         -0.576028\n",
      " -0.46712252  1.          0.2750828   0.27820677  0.28897035  0.3100048\n",
      "  0.34381637  0.3949207   0.4669214   0.5816077   0.86804026  1.        ]\n",
      "[ 8.3834189e-01 -4.3229898e-03  1.6138124e-01 -2.0454909e-01\n",
      "  1.1350632e+00  8.7490952e-01  8.0724442e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -8.3491433e-01 -5.5879354e-09 -6.1534834e-01\n",
      "  1.5861254e-02  1.0000000e+00  2.6550382e-01  2.6851901e-01\n",
      "  2.7908403e-01  2.9939884e-01  3.3204398e-01  3.8165659e-01\n",
      "  4.5174631e-01  5.6227219e-01  8.4160513e-01  1.0000000e+00]\n",
      "[ 8.2276654e-01 -3.3601679e-02  1.3954423e-01 -2.3868442e-02\n",
      "  1.1271446e+00 -6.2489957e-03  9.3529892e-01  9.9953818e-01\n",
      "  0.0000000e+00 -8.3452976e-01  2.4937093e-04 -6.1601496e-01\n",
      "  1.3984074e-01  0.0000000e+00  2.6540092e-01  2.6841494e-01\n",
      "  2.7926770e-01  2.9959586e-01  3.3240864e-01  3.8170969e-01\n",
      "  4.5143679e-01  5.6209594e-01  8.4132111e-01  1.0000000e+00]\n",
      "[ 8.0749148e-01 -3.2648463e-02  1.2643439e-01  1.9512020e-02\n",
      "  1.1245158e+00  6.0781837e-04  9.3490875e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3499247e-01 -2.6226044e-05 -6.0730064e-01\n",
      "  1.3666596e-01  0.0000000e+00  2.6675123e-01  2.6978058e-01\n",
      "  2.8097409e-01  3.0142647e-01  3.3459798e-01  3.8379055e-01\n",
      "  4.5341799e-01  5.6485564e-01  8.4504759e-01  1.0000000e+00]\n",
      "[ 7.8893632e-01 -3.7829533e-02  1.3300171e-01  5.0423380e-02\n",
      "  1.1228034e+00 -2.1606684e-06  9.2749596e-01 -7.6923780e-02\n",
      "  0.0000000e+00 -8.3496326e-01  2.8312206e-07 -5.9029412e-01\n",
      "  3.3744696e-01  0.0000000e+00  2.6928601e-01  2.7234414e-01\n",
      "  2.8395960e-01  3.0462933e-01  3.3833909e-01  3.8754973e-01\n",
      "  4.5724693e-01  5.7099551e-01  8.5204285e-01  1.0000000e+00]\n",
      "[ 7.6750827e-01 -4.2747732e-02  1.3740781e-01  8.7693647e-02\n",
      "  1.1226078e+00  4.1723251e-07  8.8517737e-01 -3.5800481e-01\n",
      "  0.0000000e+00 -8.3491284e-01 -5.9604645e-08 -5.2395535e-01\n",
      "  5.6009609e-01  0.0000000e+00  2.7336073e-01  2.7646515e-01\n",
      "  2.8859943e-01  3.0960688e-01  3.4408277e-01  3.9348519e-01\n",
      "  4.6348268e-01  5.8153957e-01  8.6328787e-01  1.0000000e+00]\n",
      "[ 7.4558562e-01 -4.3866027e-02  1.5714647e-01  9.1460370e-02\n",
      "  1.1221902e+00 -5.4240227e-06  8.3226013e-01 -4.5028391e-01\n",
      "  0.0000000e+00 -8.3490896e-01  7.4505806e-07 -4.8718393e-01\n",
      "  3.2301113e-01  1.0000000e+00  2.7760461e-01  2.8075722e-01\n",
      "  2.9346126e-01  3.1502259e-01  3.5011467e-01  3.9968687e-01\n",
      "  4.6996248e-01  5.9261203e-01  8.7499970e-01  1.0000000e+00]\n",
      "[ 0.71747357 -0.05629819  0.17646588  0.09336738  1.0884776  -0.41865367\n",
      "  0.9528061   0.9999998   0.         -0.8349102   0.         -0.44117427\n",
      "  0.37802792  0.          0.2819243   0.28548715  0.29844654  0.3206027\n",
      "  0.35631636  0.40602404  0.47653946  0.6039953   0.8868887   1.        ]\n",
      "[ 0.6856641  -0.06362756  0.19853547  0.0882183   1.1142759   0.32493237\n",
      "  0.9053222  -0.39901578  0.         -0.8349237   0.         -0.39180708\n",
      "  0.40452468  0.          0.28598598  0.29003534  0.30320123  0.32595187\n",
      "  0.36226144  0.412028    0.48268974  0.614906    0.89785457  1.        ]\n",
      "[ 6.5552694e-01 -6.0267005e-02  2.1347535e-01  9.8519519e-02\n",
      "  1.1140351e+00  2.0861626e-07  8.8256788e-01 -1.9514830e-01\n",
      "  0.0000000e+00 -8.3490640e-01 -2.9802322e-08 -3.4088778e-01\n",
      "  4.1888547e-01  0.0000000e+00  2.9053241e-01  2.9510820e-01\n",
      "  3.0850434e-01  3.3191046e-01  3.6823350e-01  4.1873571e-01\n",
      "  4.8997453e-01  6.2706012e-01  9.1013342e-01  1.0000000e+00]\n",
      "[ 6.2423396e-01 -6.2693588e-02  2.1617456e-01  1.0825686e-01\n",
      "  1.1121626e+00  1.4498830e-04  7.6788783e-01 -9.9998641e-01\n",
      "  0.0000000e+00 -8.3491427e-01 -4.7683716e-06 -2.8554690e-01\n",
      "  4.5646858e-01  0.0000000e+00  2.9553527e-01  3.0065468e-01\n",
      "  3.1430259e-01  3.3841044e-01  3.7470224e-01  4.2530575e-01\n",
      "  4.9809903e-01  6.4048094e-01  9.2365313e-01  1.0000000e+00]\n",
      "[ 0.584785   -0.07898839  0.23797369  0.11278537  1.0623658  -0.6164152\n",
      "  0.8897728   0.9999997   0.         -0.83490914  0.         -0.21911204\n",
      "  0.54634833  0.          0.3007172   0.30642897  0.320339    0.34518975\n",
      "  0.38142076  0.4320307   0.506517    0.654544    0.9376501   1.        ]\n",
      "[ 0.5401621  -0.08924511  0.2643677   0.10799586  1.0853175   0.29833657\n",
      "  0.80697596 -0.71016264  0.         -0.83490556  0.         -0.14591694\n",
      "  0.59983844  0.          0.30565256  0.31200272  0.3263813   0.35176486\n",
      "  0.3878656   0.43840212  0.5145412   0.66819394  0.94980437  1.        ]\n",
      "[ 0.48687527 -0.10664521  0.2936343   0.10575079  1.1616012   0.9999999\n",
      "  0.61801183 -1.656659    0.         -0.83490556  0.         -0.06031322\n",
      "  0.6994663   0.          0.31098062  0.31750038  0.33242762  0.3582814\n",
      "  0.3941819   0.44456583  0.5223537   0.681733    0.9603546   1.        ]\n",
      "[ 0.43384758 -0.11049601  0.31317654  0.1223854   1.1349083   0.\n",
      "  0.71146846  0.29535475  0.         -0.8349075   0.          0.03265095\n",
      "  0.77957433  0.          0.3173457   0.3239989   0.33954194  0.36579195\n",
      "  0.40169385  0.4519878   0.5317037   0.6981252   0.97316074  1.        ]\n",
      "[ 0.37159342 -0.12437218  0.33345917  0.12275787  1.1237993  -0.12939543\n",
      "  0.83398604  1.          0.         -0.8349069   0.          0.14178813\n",
      "  0.88657266  0.          0.3235429   0.330326    0.3464955   0.37241787\n",
      "  0.4089701   0.4591023   0.5429617   0.7147322   0.9853542   1.        ]\n",
      "[ 3.0309716e-01 -1.3677561e-01  3.5583892e-01  1.2170233e-01\n",
      "  1.1234679e+00  2.5928020e-05  9.5497382e-01  1.0000006e+00\n",
      "  0.0000000e+00 -8.3490801e-01 -1.7881393e-07  2.6469648e-01\n",
      "  9.9838352e-01  0.0000000e+00  3.2969445e-01  3.3668470e-01\n",
      "  3.5341877e-01  3.7896854e-01  4.1535452e-01  4.6634984e-01\n",
      "  5.5456841e-01  7.3130661e-01  9.9619120e-01  1.0000000e+00]\n",
      "[ 2.3750067e-01 -1.3096684e-01  3.5319531e-01  1.1747758e-01\n",
      "  1.1295612e+00 -1.9162893e-03  9.3488538e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490926e-01  6.2823296e-05  3.8849664e-01\n",
      "  1.0092162e+00  0.0000000e+00  3.3561400e-01  3.4303963e-01\n",
      "  3.6008954e-01  3.8526118e-01  4.2130440e-01  4.7356629e-01\n",
      "  5.6575149e-01  7.4729311e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.17378978 -0.12770988  0.3523453   0.11083295  1.1050721  -0.3047579\n",
      "  0.93490636  0.          0.         -0.8340006   0.02822292  0.5128131\n",
      "  1.0000001   0.          0.34122744  0.34908047  0.3664306   0.39120892\n",
      "  0.42689008  0.48036402  0.576381    0.7572531   1.          1.        ]\n",
      "[ 1.1040927e-01 -1.2713689e-01  3.5379910e-01  9.5531598e-02\n",
      "  1.1024505e+00  4.1723251e-07  8.2225454e-01 -9.9999982e-01\n",
      "  0.0000000e+00 -8.3149278e-01  4.4715524e-02  6.3581687e-01\n",
      "  1.0000001e+00  0.0000000e+00  3.4611809e-01  3.5438153e-01\n",
      "  3.7148112e-01  3.9634016e-01  4.3160880e-01  4.8616752e-01\n",
      "  5.8577657e-01  7.6567829e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 4.0541407e-02 -1.4034249e-01  3.4895781e-01  8.4015109e-02\n",
      "  1.0978880e+00 -4.1723251e-07  7.1467370e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -7.7974308e-01  6.5653354e-01  6.8511373e-01\n",
      "  4.0011311e-01  0.0000000e+00  3.5043481e-01  3.5909101e-01\n",
      "  3.7568799e-01  4.0082851e-01  4.3565527e-01  4.9119458e-01\n",
      "  5.9422034e-01  7.7296638e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-0.02418877 -0.13012286  0.35229915  0.06624153  1.0779865  -0.17255294\n",
      "  0.6115372  -1.          0.         -0.7070913   0.9210828   0.6313567\n",
      " -0.46173584  0.          0.35414568  0.3629609   0.37902385  0.40383267\n",
      "  0.43871257  0.49508858  0.6011748   0.7785933   1.          1.        ]\n",
      "[-0.07307209 -0.09877042  0.36329916  0.05886622  0.99437153 -0.9156743\n",
      "  0.83011705  2.6405985   1.         -0.6298098   0.99999976  0.51611066\n",
      " -1.0000004   0.          0.35760933  0.36651078  0.38200864  0.40626094\n",
      "  0.44155756  0.499738    0.60756415  0.7835298   1.          1.        ]\n",
      "[-0.12778257 -0.10351848  0.32155558  0.04523113  1.1049842   1.1962384\n",
      "  0.6521974  -1.0013485   1.         -0.54169905  1.0003618   0.41169494\n",
      " -0.8317793   0.          0.36087584  0.3698586   0.38491398  0.4087352\n",
      "  0.44457516  0.50458425  0.61357784  0.78831416  1.          1.        ]\n",
      "[-0.13591087 -0.01613383  0.28264296  0.10944776  1.1056318   0.00440189\n",
      "  0.6321529  -0.26044095  1.         -0.4676677   0.93205476  0.29367846\n",
      " -1.000031    0.          0.36673468  0.37547207  0.39058986  0.41412002\n",
      "  0.45079345  0.51328516  0.62437683  0.7983523   1.          1.        ]\n",
      "[-1.1487412e-01  4.2273782e-02  2.8907341e-01  1.0444346e-01\n",
      "  1.1060117e+00 -2.9802322e-08  5.1641595e-01 -9.1711313e-01\n",
      "  1.0000000e+00 -4.2426297e-01  5.6126785e-01  1.8021882e-01\n",
      " -1.0000000e+00  0.0000000e+00  3.7248230e-01  3.8080546e-01\n",
      "  3.9613801e-01  4.1936192e-01  4.5685902e-01  5.2182049e-01\n",
      "  6.3545835e-01  8.0813706e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-0.09176504  0.0463035   0.28760475  0.09253317  1.1004788  -0.04491012\n",
      "  0.39944685 -0.9999998   1.         -0.36983514  0.6892185   0.06333691\n",
      " -1.          0.          0.37767065  0.38557228  0.40109676  0.42399293\n",
      "  0.4622486   0.52952427  0.6454958   0.816814    1.          1.        ]\n",
      "[-0.06644126  0.05064303  0.2881819   0.07624748  1.086819   -0.1439106\n",
      "  0.28363144 -1.          1.         -0.31644803  0.681839   -0.05123687\n",
      " -1.          0.          0.38209602  0.3895623   0.40469533  0.42778218\n",
      "  0.46670875  0.53609383  0.65411127  0.8239669   1.          1.        ]\n",
      "[-0.05249185  0.02778214  0.28210792  0.04526534  1.1291785   0.5434198\n",
      "  0.16775823 -1.0000001   0.         -0.26966047  0.59934205 -0.14793122\n",
      " -0.84835523  0.          0.3850143   0.39203018  0.40673184  0.42993486\n",
      "  0.4693555   0.5404595   0.6599095   0.8277388   1.          1.        ]\n",
      "[-2.37701815e-02  5.73534779e-02  2.93157518e-01  2.78483536e-02\n",
      "  1.12902331e+00  2.98023224e-08  1.05641365e-01 -5.30988872e-01\n",
      "  0.00000000e+00 -2.65464246e-01  7.27057755e-02 -2.63575792e-01\n",
      " -9.99999762e-01  0.00000000e+00  3.87212574e-01  3.93747836e-01\n",
      "  4.07982647e-01  4.31486726e-01  4.71094370e-01  5.43802857e-01\n",
      "  6.64378107e-01  8.29461396e-01  1.00000000e+00  1.00000000e+00]\n",
      "[ 4.9860985e-03  5.7465445e-02  2.9304633e-01  1.2677618e-02\n",
      "  1.1279207e+00 -2.9802322e-08  1.4122486e-02 -7.8287250e-01\n",
      "  0.0000000e+00 -2.5326139e-01  1.6914365e-01 -3.8041747e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.8843364e-01  3.9474463e-01\n",
      "  4.0849647e-01  4.3229058e-01  4.7291410e-01  5.4608500e-01\n",
      "  6.6704911e-01  8.2987642e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 4.6146117e-02  8.2182437e-02  3.0880415e-01 -1.4388621e-02\n",
      "  1.1266640e+00 -5.9604645e-08 -1.0219526e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -3.0555049e-01 -6.1378330e-01 -4.9510026e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.8820776e-01  3.9451510e-01\n",
      "  4.0772840e-01  4.3173668e-01  4.7330239e-01  5.4660743e-01\n",
      "  6.6619271e-01  8.2798940e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 8.39652717e-02  7.56111220e-02  3.26500744e-01 -1.52067365e-02\n",
      "  1.12465227e+00  5.96046448e-08 -2.18639374e-01 -1.00000012e+00\n",
      "  0.00000000e+00 -3.86481076e-01 -1.00000012e+00 -3.73439193e-01\n",
      "  9.99999523e-01  0.00000000e+00  3.87946337e-01  3.94249409e-01\n",
      "  4.06893760e-01  4.31126416e-01  4.73682910e-01  5.47124922e-01\n",
      "  6.65251791e-01  8.25954914e-01  1.00000000e+00  1.00000000e+00]\n",
      "[ 0.10502792  0.04209316  0.28279334 -0.03443361  1.1246955   0.\n",
      " -0.19996095  0.15023376  0.         -0.36518112  0.28056443 -0.49068677\n",
      " -0.9999997   0.          0.3866805   0.3927144   0.40508914  0.42944098\n",
      "  0.47267464  0.546021    0.66276395  0.82227194  1.          1.        ]\n",
      "[ 0.14072719  0.07138557  0.30074954 -0.05187703  1.0878674  -0.41085377\n",
      " -0.0749613   0.9999998   0.         -0.4341054  -0.84667766 -0.54121447\n",
      " -0.44248152  0.          0.38466737  0.3901829   0.4024779   0.42690745\n",
      "  0.47074166  0.5438484   0.6590465   0.8171278   1.          1.        ]\n",
      "[ 0.16251582  0.04348482  0.31309003 -0.073511    1.1272812   0.5129988\n",
      " -0.04697359  0.19295907  0.         -0.5148998  -1.         -0.41867518\n",
      "  0.9999997   0.          0.38159442  0.38656062  0.39874145  0.4231818\n",
      "  0.46747312  0.54012936  0.6536027   0.8099637   1.          1.        ]\n",
      "[ 1.9554725e-01  6.5847829e-02  2.9799178e-01 -1.0339976e-01\n",
      "  1.1233529e+00 -3.2782555e-07  8.0881238e-02  9.9999994e-01\n",
      "  0.0000000e+00 -6.0005575e-01 -9.9999976e-01 -5.2908158e-01\n",
      " -9.9999958e-01  0.0000000e+00  3.7714255e-01  3.8157377e-01\n",
      "  3.9367926e-01  4.1793695e-01  4.6239492e-01  5.3430712e-01\n",
      "  6.4596498e-01  8.0032676e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.22965252  0.06807931  0.30083042 -0.12040023  1.1214302   0.\n",
      "  0.1531635   0.56609255  0.         -0.6849422  -1.0000001  -0.6417897\n",
      " -1.0000001   0.          0.37190118  0.37578717  0.38790947  0.41181165\n",
      "  0.45630488  0.5273116   0.6370535   0.78922147  1.          1.        ]\n",
      "[ 0.2723539   0.08517953  0.32175156 -0.12384549  1.119979    0.\n",
      "  0.03710151 -0.9999997   0.         -0.7722297  -1.0742096  -0.6349127\n",
      "  0.          0.          0.36655605  0.36986163  0.38201204  0.40555084\n",
      "  0.45012653  0.52021843  0.6279424   0.777827    1.          1.        ]\n",
      "[ 0.30511233  0.06553365  0.3237634  -0.13269177  1.1196593   0.\n",
      "  0.01838219 -0.16453604  0.         -0.8528342  -1.         -0.513643\n",
      "  1.0000002   0.          0.36055693  0.36347398  0.37563545  0.39899078\n",
      "  0.44336444  0.5125282   0.6180954   0.76558363  0.9950187   1.        ]\n",
      "[ 3.1779534e-01  3.3208597e-02  3.0519831e-01 -1.3172652e-01\n",
      "  1.1229646e+00  1.4901161e-08  5.0496936e-02  2.3638506e-01\n",
      "  0.0000000e+00 -8.3490878e-01  0.0000000e+00 -4.1123927e-01\n",
      "  1.0000005e+00  0.0000000e+00  3.5431159e-01  3.5717809e-01\n",
      "  3.6933553e-01  3.9292127e-01  4.3661991e-01  5.0488001e-01\n",
      "  6.0837024e-01  7.5354743e-01  9.7921234e-01  1.0000000e+00]\n",
      "[ 3.2753003e-01  2.0502081e-02  2.9756081e-01 -1.4972638e-01\n",
      "  1.1205109e+00 -2.3841858e-07  1.7614746e-01  9.9999982e-01\n",
      "  0.0000000e+00 -8.3491087e-01  1.4901161e-08 -2.9101706e-01\n",
      "  1.0000004e+00  0.0000000e+00  3.4713316e-01  3.4994158e-01\n",
      "  3.6205611e-01  3.8576213e-01  4.2867669e-01  4.9579957e-01\n",
      "  5.9714180e-01  7.3979235e-01  9.6117526e-01  1.0000000e+00]\n",
      "[ 3.4545770e-01  3.7071235e-02  3.0670807e-01 -1.6109535e-01\n",
      "  1.1210061e+00  4.4703484e-08  1.4162624e-01 -2.9410437e-01\n",
      "  0.0000000e+00 -8.3490527e-01  0.0000000e+00 -1.7054546e-01\n",
      "  9.9999976e-01  0.0000000e+00  3.3943385e-01  3.4217998e-01\n",
      "  3.5423741e-01  3.7803066e-01  4.2011556e-01  4.8597649e-01\n",
      "  5.8508396e-01  7.2506195e-01  9.4186717e-01  1.0000000e+00]\n",
      "[ 0.35351294  0.01706237  0.29575714 -0.18179873  1.1176395  -0.01400033\n",
      "  0.2670694   0.99999976  0.         -0.83490664  0.         -0.05024838\n",
      "  1.0000002   0.          0.3307386   0.3335      0.34536713  0.36910686\n",
      "  0.41022265  0.4745782   0.5714135   0.7085098   0.92019916  1.        ]\n",
      "[ 3.6015826e-01  1.4164699e-02  2.9586104e-01 -1.9907047e-01\n",
      "  1.1155477e+00  2.3841858e-07  3.9239186e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3491117e-01 -7.4505806e-09  7.0044160e-02\n",
      "  9.9999970e-01  0.0000000e+00  3.2122442e-01  3.2410610e-01\n",
      "  3.3563897e-01  3.5923508e-01  3.9927262e-01  4.6193618e-01\n",
      "  5.5642605e-01  6.9044542e-01  8.9656746e-01  1.0000000e+00]\n",
      "[ 3.6392242e-01  7.6007484e-03  2.9269049e-01 -2.1923499e-01\n",
      "  1.1134002e+00  9.6857548e-08  5.1691526e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3490545e-01 -3.7252903e-09  1.6585886e-02\n",
      " -4.4598702e-01  1.0000000e+00  3.1076258e-01  3.1375149e-01\n",
      "  3.2491592e-01  3.4825620e-01  3.8708740e-01  4.4783884e-01\n",
      "  5.3991163e-01  6.7063546e-01  8.7064445e-01  1.0000000e+00]\n",
      "[ 0.37938243  0.03104155  0.29872784 -0.21884811  1.1117682   0.\n",
      "  0.401021   -0.99999946  0.         -0.83491105  0.         -0.05023825\n",
      " -0.55949     1.          0.30035132  0.3034519   0.3142498   0.3373552\n",
      "  0.37499002  0.4338489   0.52348375  0.65091044  0.84476     1.        ]\n",
      "[ 3.8256198e-01  6.4380020e-03  2.8235385e-01 -2.2358215e-01\n",
      "  1.1088841e+00 -2.4586916e-07  2.8566658e-01 -1.0000001e+00\n",
      "  0.0000000e+00 -7.7250439e-01  7.9138225e-01 -1.8507934e-01\n",
      " -1.1457461e+00  1.0000000e+00  2.8967595e-01  2.9287252e-01\n",
      "  3.0329397e-01  3.2608554e-01  3.6247829e-01  4.1935819e-01\n",
      "  5.0661391e-01  6.3072520e-01  8.1828070e-01  1.0000000e+00]\n",
      "[ 0.36622426 -0.03270552  0.2664052  -0.23440298  1.0857329  -0.27774984\n",
      "  0.40835905  0.9999997   0.         -0.69366646  1.0000001  -0.3140571\n",
      " -1.1105279   1.          0.27844113  0.28171596  0.29174045  0.31411287\n",
      "  0.3491797   0.40393     0.48882905  0.609531    0.7904889   1.        ]\n",
      "[ 0.34512582 -0.04227013  0.27973723 -0.25975856  1.0926552   0.10791348\n",
      "  0.53155285  1.0000001   0.         -0.65761334  0.46220693 -0.34603083\n",
      " -0.10504571  1.          0.26618558  0.26935408  0.27913275  0.30080074\n",
      "  0.33438995  0.38675842  0.46912545  0.58524466  0.75976324  1.        ]\n",
      "[ 0.32522053 -0.04531198  0.37179887 -0.09357271  1.0981319   0.18429613\n",
      "  0.6612406   1.0001118   0.         -0.72886616 -0.35962787 -0.25654364\n",
      "  0.4301404   0.          0.26266822  0.26579484  0.27642706  0.29788503\n",
      "  0.33121613  0.38334197  0.46339765  0.5780269   0.74954456  1.        ]\n",
      "[ 0.29814902 -0.05725634  0.43010563 -0.05608855  1.1384661   0.58387977\n",
      "  0.7882438   1.0000228   0.         -0.77205926 -0.4034351  -0.1890688\n",
      "  0.50717604  0.          0.26048064  0.26358122  0.27530354  0.29667428\n",
      "  0.32995483  0.382221    0.4597993   0.5729672   0.7422872   1.        ]\n",
      "[ 2.83400267e-01 -3.02910712e-02  4.61077392e-01 -5.10529727e-02\n",
      "  1.13490725e+00  2.53319740e-07  9.15426373e-01  1.00000000e+00\n",
      "  0.00000000e+00 -8.41541350e-01 -9.10903871e-01 -1.00747585e-01\n",
      "  9.19518888e-01  1.00000000e+00  2.58122921e-01  2.61195421e-01\n",
      "  2.74060279e-01  2.95340270e-01  3.28554243e-01  3.80954772e-01\n",
      "  4.55923200e-01  5.67159951e-01  7.34517753e-01  1.00000000e+00]\n",
      "[ 2.6991358e-01 -2.4271898e-02  4.4188008e-01 -3.3799104e-02\n",
      "  1.1349090e+00  1.4901161e-08  7.9964519e-01 -9.9999952e-01\n",
      "  0.0000000e+00 -8.3490998e-01  0.0000000e+00 -9.5018148e-02\n",
      "  1.1348345e-01  1.0000000e+00  2.5655586e-01  2.6068398e-01\n",
      "  2.7360779e-01  2.9493168e-01  3.2809970e-01  3.8078421e-01\n",
      "  4.5332286e-01  5.6287932e-01  7.2875100e-01  1.0000000e+00]\n",
      "[ 0.22499251 -0.08301138  0.43600866 -0.04020927  1.1180302  -0.26069635\n",
      "  0.91975915  1.          0.         -0.83490944  0.         -0.0303874\n",
      "  0.42916527  1.          0.2545166   0.25974917  0.27262664  0.2939506\n",
      "  0.32700828  0.37985805  0.44996426  0.5577505   0.7218791   1.        ]\n",
      "[ 0.17020062 -0.10955796  0.43576178 -0.03169646  1.1113415  -0.07808101\n",
      "  0.92100513  0.          0.         -0.83490807  0.          0.04551113\n",
      "  0.6141899   0.          0.25295675  0.25922427  0.27207568  0.2934353\n",
      "  0.32667243  0.37954625  0.4472128   0.5533163   0.71591246  1.        ]\n",
      "[ 1.0558690e-01 -1.2934476e-01  4.3789485e-01 -2.2892695e-02\n",
      "  1.1086473e+00  5.8233738e-05  8.0931443e-01 -9.9999475e-01\n",
      "  0.0000000e+00 -8.3490467e-01 -1.9669533e-06  1.4113587e-01\n",
      "  7.7716070e-01  0.0000000e+00  2.5279769e-01  2.5906128e-01\n",
      "  2.7194691e-01  2.9333109e-01  3.2686985e-01  3.7808418e-01\n",
      "  4.4492218e-01  5.4950440e-01  7.1075720e-01  1.0000000e+00]\n",
      "[ 3.1582773e-02 -1.4809163e-01  4.7020161e-01 -1.9913908e-02\n",
      "  1.1041210e+00 -4.5657158e-04  1.0053540e+00  1.8213066e+00\n",
      "  1.0000000e+00 -8.3490920e-01  1.5497208e-05  2.5706065e-01\n",
      "  9.4318891e-01  0.0000000e+00  2.5280887e-01  2.5907272e-01\n",
      "  2.7203903e-01  2.9343045e-01  3.2731959e-01  3.7633952e-01\n",
      "  4.4275573e-01  5.4575127e-01  7.0566595e-01  1.0000000e+00]\n",
      "[ 9.4737569e-03 -3.8299002e-02  2.3779529e-01  1.2713276e-01\n",
      "  1.1225692e+00  4.1305885e-02  9.3489671e-01  8.4684193e-03\n",
      "  1.0000000e+00 -8.2657152e-01 -7.6299906e-04  3.1042928e-01\n",
      "  5.2053022e-01  0.0000000e+00  2.5951964e-01  2.6594976e-01\n",
      "  2.7930433e-01  3.0126706e-01  3.3630040e-01  3.8472375e-01\n",
      "  4.5250228e-01  5.5645049e-01  7.1951193e-01  1.0000000e+00]\n",
      "[-8.1618866e-03 -3.5294030e-02  1.9669411e-01  1.5118685e-01\n",
      "  1.1214190e+00 -2.4463743e-02  9.3356621e-01 -4.1754148e-03\n",
      "  1.0000000e+00 -8.2676488e-01  4.5768917e-04  3.7654591e-01\n",
      "  5.4644346e-01  0.0000000e+00  2.6707205e-01  2.7368927e-01\n",
      "  2.8747380e-01  3.1013048e-01  3.4636915e-01  3.9431515e-01\n",
      "  4.6366441e-01  5.6754959e-01  7.3546296e-01  1.0000000e+00]\n",
      "[-2.9929791e-02 -4.3556333e-02  1.9455871e-01  1.6506451e-01\n",
      "  1.1214216e+00  2.2479892e-03  9.3402636e-01  2.1226604e-03\n",
      "  1.0000000e+00 -8.2720411e-01 -9.1105700e-05  4.5428908e-01\n",
      "  6.3979632e-01  0.0000000e+00  2.7524686e-01  2.8208420e-01\n",
      "  2.9631338e-01  3.1987375e-01  3.5725093e-01  4.0476483e-01\n",
      "  4.7583058e-01  5.7903332e-01  7.5292850e-01  1.0000000e+00]\n",
      "[-3.8494766e-02 -1.7142026e-02  1.9533618e-01  1.7010571e-01\n",
      "  1.1213942e+00  1.4901161e-08  9.0396857e-01 -2.5155148e-01\n",
      "  1.0000000e+00 -8.2765681e-01  0.0000000e+00  5.1278049e-01\n",
      "  4.7901186e-01  0.0000000e+00  2.8371114e-01  2.9079625e-01\n",
      "  3.0546489e-01  3.2995668e-01  3.6845183e-01  4.1560891e-01\n",
      "  4.8845780e-01  5.9099460e-01  7.7108425e-01  1.0000000e+00]\n",
      "[-3.3690564e-02  9.7196046e-03  1.8290609e-01  1.7766340e-01\n",
      "  1.1213806e+00  1.4901161e-08  8.4146017e-01 -5.2330780e-01\n",
      "  1.0000000e+00 -7.5100589e-01  9.6832013e-01  3.9561087e-01\n",
      " -1.0000000e+00  0.0000000e+00  2.9252750e-01  2.9986724e-01\n",
      "  3.1499347e-01  3.4044138e-01  3.7853587e-01  4.2697185e-01\n",
      "  5.0060099e-01  6.0368413e-01  7.9178852e-01  1.0000000e+00]\n",
      "[-4.0555871e-03  5.9353884e-02  1.8799923e-01  1.7328496e-01\n",
      "  1.1204668e+00 -9.2089176e-05  7.2350585e-01 -1.0000324e+00\n",
      "  1.0000000e+00 -7.0489436e-01  5.8935034e-01  3.2678443e-01\n",
      " -6.1188793e-01  0.0000000e+00  3.0123800e-01  3.0883038e-01\n",
      "  3.2440871e-01  3.5080564e-01  3.8847694e-01  4.3808752e-01\n",
      "  5.1255506e-01  6.1614960e-01  8.1443101e-01  1.0000000e+00]\n",
      "[ 2.1406449e-02  5.0960101e-02  1.8107533e-01  1.5998194e-01\n",
      "  1.1195296e+00 -1.1920929e-06  6.0695076e-01 -1.0000001e+00\n",
      "  0.0000000e+00 -6.2792093e-01  1.0000010e+00  2.1935087e-01\n",
      " -9.9999857e-01  0.0000000e+00  3.0925331e-01  3.1707948e-01\n",
      "  3.3307394e-01  3.6034960e-01  3.9759707e-01  4.4828334e-01\n",
      "  5.2350044e-01  6.2798524e-01  8.3520377e-01  1.0000000e+00]\n",
      "[ 0.04884939  0.05495703  0.17835742  0.15114895  1.0390238  -0.99999976\n",
      "  0.72854173  1.0000001   0.         -0.554191    0.93855035  0.10470486\n",
      " -0.9999997   1.          0.31687626  0.32492572  0.34138083  0.36943102\n",
      "  0.40625194  0.45795757  0.53387284  0.64049137  0.8549168   1.        ]\n",
      "[ 0.06129068  0.02470608  0.17078833  0.1102487   1.0979507   0.75921106\n",
      "  0.5811634  -1.27804     0.         -0.47178626  1.0670431  -0.00181663\n",
      " -1.0000001   1.          0.3224848   0.3307051   0.34758618  0.37614626\n",
      "  0.41248524  0.46491516  0.54123795  0.6493578   0.8661216   1.        ]\n",
      "[ 0.07738465  0.03206195  0.17366424  0.09117001  1.0879357  -0.10670337\n",
      "  0.70020676  0.96601415  0.         -0.4179995   0.69144166 -0.11578703\n",
      " -0.9999998   0.          0.32725868  0.33562446  0.35288444  0.38187984\n",
      "  0.4176943   0.47072256  0.54731935  0.6566693   0.8752429   1.        ]\n",
      "[ 0.11412673  0.07330631  0.18578474  0.08320895  1.0071604  -0.99999976\n",
      "  0.85300165  1.2592124   0.         -0.4003559   0.23738864 -0.23153913\n",
      " -0.9999998   0.          0.33179113  0.34027278  0.35790318  0.38729674\n",
      "  0.4225435   0.4761235   0.5527044   0.6634004   0.88361233  1.        ]\n",
      "[ 0.15976329  0.09120008  0.21074535  0.07951039  0.92698216 -1.0000001\n",
      "  0.91354513  0.5012603   0.         -0.4526108  -0.62799424 -0.10864305\n",
      "  0.99999976  0.          0.33626455  0.34486055  0.3628719   0.39160022\n",
      "  0.42723864  0.4813461   0.55702126  0.66982234  0.8915616   1.        ]\n",
      "[ 0.18297744  0.04628228  0.19136778  0.05665226  0.94905204  0.28576973\n",
      "  0.7955877  -1.0000001   0.         -0.45079654  0.08049336 -0.1772095\n",
      " -0.8896286   1.          0.33951545  0.34819457  0.36650574  0.39460292\n",
      "  0.4305146   0.4849798   0.5597956   0.6741577   0.89687264  1.        ]\n",
      "[ 0.20657723  0.04761867  0.17669405  0.03902434  0.9507303   0.01755193\n",
      "  0.6769932  -0.99999994  0.         -0.39508983  0.71220994 -0.19003367\n",
      " -0.989477    1.          0.341733    0.35046878  0.36901098  0.39650792\n",
      "  0.43255183  0.48687014  0.56127155  0.6767342   0.89996076  1.        ]\n",
      "[ 0.24228942  0.0714473   0.18639457  0.02264716  0.92275697 -0.32516643\n",
      "  0.5604884  -0.99999994  0.         -0.36793673  0.34882438 -0.30725002\n",
      " -1.0000001   1.          0.3434269   0.352206    0.3709543   0.39780268\n",
      "  0.43392226  0.48800862  0.5619324   0.6782455   0.9017205   1.        ]\n",
      "[ 0.2839413   0.08318774  0.19009422  0.01156844  0.8169711  -1.3142421\n",
      "  0.6828774   0.9999998   0.         -0.3649458   0.05077863 -0.42366874\n",
      " -1.0000001   0.          0.34462422  0.35346222  0.3723619   0.39853367\n",
      "  0.43467903  0.48847672  0.5618639   0.67881435  0.9027203   1.        ]\n",
      "[ 0.33133143  0.09466658  0.20472035 -0.01506747  0.7367377  -1.0000001\n",
      "  0.74880224  0.54029316  0.         -0.4134628  -0.58368397 -0.5227231\n",
      " -0.85339516  0.          0.34463555  0.35358664  0.37249297  0.39790308\n",
      "  0.43395296  0.48731604  0.560009    0.6771016   0.9011626   1.        ]\n",
      "[ 0.3754523   0.08805314  0.20630875 -0.04638095  0.7355202   0.00250024\n",
      "  0.6326322  -1.          0.         -0.4803683  -0.7880475  -0.63758194\n",
      " -0.9999998   0.          0.34316662  0.35219008  0.37102172  0.39562196\n",
      "  0.4314322   0.48421183  0.5560671   0.6726728   0.8954962   1.        ]\n",
      "[ 0.40318057  0.05519843  0.2079959  -0.06631637  0.7912039   0.71902883\n",
      "  0.5190613  -0.9999998   0.         -0.5512476  -0.874161   -0.6348591\n",
      "  0.          0.          0.34071377  0.34978357  0.36848652  0.39223787\n",
      "  0.42771187  0.47980505  0.5507207   0.66642296  0.8870843   1.        ]\n",
      "[ 4.2716196e-01  4.7742773e-02  2.1167077e-01 -9.0715930e-02\n",
      "  8.6857969e-01  1.0000023e+00  4.0771139e-01 -9.9999994e-01\n",
      "  0.0000000e+00 -6.3198066e-01 -1.0000007e+00 -6.3214827e-01\n",
      " -5.1657361e-07  0.0000000e+00  3.3711210e-01  3.4619778e-01\n",
      "  3.6470902e-01  3.8756591e-01  4.2259073e-01  4.7387725e-01\n",
      "  5.4373443e-01  6.5804660e-01  8.7546647e-01  1.0000000e+00]\n",
      "[ 0.43836814  0.02214187  0.21420467 -0.10302725  0.94435084  1.0000004\n",
      "  0.44850582  0.24871762  0.         -0.7128156  -1.0000001  -0.50815785\n",
      "  0.9999997   0.          0.33290496  0.34199157  0.36024934  0.38220942\n",
      "  0.41672474  0.46713728  0.535867    0.64853394  0.8625928   1.        ]\n",
      "[ 0.45431983  0.03151318  0.22328477 -0.12180365  1.0442824   1.2906475\n",
      "  0.34098148 -0.9999998   0.         -0.7941337  -1.0000001  -0.38385975\n",
      "  0.9999998   0.          0.32786182  0.33693087  0.35429788  0.37589514\n",
      "  0.4098158   0.45925283  0.5267463   0.6374184   0.848169    1.        ]\n",
      "[ 0.46277776  0.01662955  0.21128301 -0.12533106  1.1224151   1.0000001\n",
      "  0.29225934 -0.4679835   0.         -0.8241964  -0.34747267 -0.26053143\n",
      "  1.0000001   0.          0.32261375  0.33165258  0.34816858  0.36939225\n",
      "  0.4027042   0.45117217  0.51745254  0.62603426  0.8334129   1.        ]\n",
      "[ 4.72519219e-01  1.93501711e-02  1.94314241e-01 -1.21408574e-01\n",
      "  1.11969733e+00 -2.23517418e-07  4.17479396e-01  9.99999940e-01\n",
      "  0.00000000e+00 -8.27306211e-01  7.45058060e-09 -1.36059523e-01\n",
      "  1.00000036e+00  0.00000000e+00  3.17519009e-01  3.26504320e-01\n",
      "  3.42235267e-01  3.63097250e-01  3.95822197e-01  4.43372846e-01\n",
      "  5.08514047e-01  6.15051091e-01  8.19185972e-01  1.00000000e+00]\n",
      "[ 4.8109117e-01  1.7009551e-02  1.9473036e-01 -1.3812207e-01\n",
      "  1.1174406e+00 -1.5646219e-07  5.4198420e-01  9.9999994e-01\n",
      "  0.0000000e+00 -8.3041531e-01  0.0000000e+00 -2.3277044e-01\n",
      " -1.0999790e+00  1.0000000e+00  3.1172469e-01  3.2054603e-01\n",
      "  3.3547530e-01  3.5592520e-01  3.8798672e-01  4.3454185e-01\n",
      "  4.9846920e-01  6.0262656e-01  8.0311459e-01  1.0000000e+00]\n",
      "[ 4.8588759e-01  1.0584227e-02  1.9076389e-01 -1.5808657e-01\n",
      "  1.1176429e+00  1.3411045e-07  6.6453135e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.2913405e-01  1.5284322e-02 -1.9006586e-01\n",
      " -3.5592428e-01  1.0000000e+00  3.0476031e-01  3.1338456e-01\n",
      "  3.2750881e-01  3.4747308e-01  3.7876076e-01  4.2421743e-01\n",
      "  4.8684084e-01  5.8810908e-01  7.8438210e-01  1.0000000e+00]\n",
      "[ 0.477763   -0.01624009  0.18905449 -0.15709338  1.116391    0.\n",
      "  0.786271    1.0000001   0.         -0.8292244   0.         -0.21647131\n",
      " -0.21289623  1.          0.29801774  0.3064512   0.31977442  0.33926722\n",
      "  0.3698025   0.41418236  0.4755222   0.5739739   0.7661666   1.        ]\n",
      "[ 0.45954895 -0.0365183   0.1872497  -0.16025597  1.1161551   0.\n",
      "  0.90665877  1.          0.         -0.82936805  0.         -0.23111057\n",
      " -0.11741677  1.          0.29109573  0.29933327  0.31185386  0.33086386\n",
      "  0.36062962  0.40391624  0.46395767  0.5595148   0.747539    1.        ]\n",
      "[ 4.3948171e-01 -4.0255446e-02  1.8806183e-01 -1.4754730e-01\n",
      "  1.1162031e+00  8.9138746e-05  9.0679634e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.2978445e-01 -2.9802322e-06 -2.4925971e-01\n",
      " -1.5860550e-01  1.0000000e+00  2.8476581e-01  2.9282427e-01\n",
      "  3.0454913e-01  3.2311383e-01  3.5216671e-01  3.9441538e-01\n",
      "  4.5320907e-01  5.4612899e-01  7.3027724e-01  1.0000000e+00]\n",
      "[ 4.1570517e-01 -4.7608498e-02  2.0637147e-01 -1.4356108e-01\n",
      "  1.1161206e+00 -2.1299720e-04  9.0701902e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3013290e-01  7.0929527e-06 -2.6058114e-01\n",
      " -1.0161308e-01  1.0000000e+00  2.7867186e-01  2.8655785e-01\n",
      "  2.9742631e-01  3.1555685e-01  3.4390998e-01  3.8510340e-01\n",
      "  4.4260752e-01  5.3300261e-01  7.1332592e-01  1.0000000e+00]\n",
      "[ 3.89511079e-01 -5.26129045e-02  2.15647489e-01 -1.24154225e-01\n",
      "  1.11441028e+00  2.46077776e-04  7.91319966e-01 -9.99977350e-01\n",
      "  0.00000000e+00 -8.30583274e-01 -8.13603401e-06 -2.61216879e-01\n",
      " -1.68445110e-02  1.00000000e+00  2.73510545e-01  2.81250477e-01\n",
      "  2.91243136e-01  3.08975697e-01  3.36734891e-01  3.76941383e-01\n",
      "  4.33206022e-01  5.21486402e-01  6.97450936e-01  1.00000000e+00]\n",
      "[ 3.6031625e-01 -5.8836404e-02  2.4340725e-01 -8.7094858e-02\n",
      "  1.0341923e+00 -1.0006216e+00  9.1277742e-01  9.9996263e-01\n",
      "  0.0000000e+00 -8.3146071e-01  1.2725592e-05 -2.6404738e-01\n",
      " -3.6370277e-02  1.0000000e+00  2.7016068e-01  2.7715263e-01\n",
      "  2.8685233e-01  3.0428347e-01  3.3162108e-01  3.7095326e-01\n",
      "  4.2604399e-01  5.1301110e-01  6.8587476e-01  1.0000000e+00]\n",
      "[ 3.2403404e-01 -7.2925940e-02  2.7841645e-01 -5.3752102e-02\n",
      "  9.8636568e-01 -5.9112936e-01  9.1450024e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3216977e-01  5.0663948e-07 -2.2626221e-01\n",
      "  3.0385888e-01  0.0000000e+00  2.6846692e-01  2.7446455e-01\n",
      "  2.8407016e-01  3.0128708e-01  3.2835549e-01  3.6689767e-01\n",
      "  4.2084503e-01  5.0723636e-01  6.7853975e-01  1.0000000e+00]\n",
      "[ 0.27930945 -0.08975767  0.32449716 -0.02462085  0.9855336   0.01781958\n",
      "  0.80044997 -1.          0.         -0.8327351   0.         -0.14789152\n",
      "  0.6364603   0.          0.26825848  0.27311924  0.28267777  0.2997529\n",
      "  0.3266835   0.36447835  0.41725796  0.50374323  0.6748608   1.        ]\n",
      "[ 0.21898267 -0.12072068  0.3328705  -0.01387709  0.9968794   0.14591634\n",
      "  0.92138934  1.          1.         -0.8327896   0.         -0.05922329\n",
      "  0.7275389   1.          0.2685279   0.27223003  0.28175744  0.2987168\n",
      "  0.3253994   0.36263114  0.41425955  0.5010503   0.6710575   1.        ]\n",
      "[ 0.14616792 -0.14563467  0.36357957 -0.0113745   1.0764805   0.99999994\n",
      "  0.9187815  -0.02834438  1.         -0.8329395   0.          0.05905545\n",
      "  0.95715207  1.          0.2683509   0.27139843  0.28089067  0.2977381\n",
      "  0.3237513   0.36079448  0.41117945  0.49836114  0.66722727  1.        ]\n",
      "[ 7.9331741e-02 -1.3359548e-01  3.5650980e-01  9.0285214e-03\n",
      "  1.1450182e+00  8.6064482e-01  9.1948736e-01 -3.6620844e-05\n",
      "  1.0000000e+00 -8.3469480e-01 -1.9669533e-06  1.6821110e-01\n",
      "  8.1839567e-01  1.0000000e+00  2.6849002e-01  2.7153912e-01\n",
      "  2.8097349e-01  2.9782590e-01  3.2324427e-01  3.6022943e-01\n",
      "  4.0948597e-01  4.9740931e-01  6.6568178e-01  1.0000000e+00]\n",
      "[ 6.4071238e-02 -3.4881167e-02  1.8664037e-01  1.2813085e-01\n",
      "  1.1357436e+00  2.6942298e-02  9.3495548e-01  4.7716796e-03\n",
      "  1.0000000e+00 -8.3499706e-01 -5.1599741e-04  2.2954440e-01\n",
      "  4.7234902e-01  0.0000000e+00  2.7452865e-01  2.7764633e-01\n",
      "  2.8725147e-01  3.0448043e-01  3.2996583e-01  3.6679825e-01\n",
      "  4.1693926e-01  5.0778884e-01  6.7878872e-01  1.0000000e+00]\n",
      "[ 5.0601702e-02 -2.6947644e-02  1.4027189e-01  1.3559444e-01\n",
      "  1.1349082e+00 -1.4901161e-08  9.3040633e-01 -5.7618260e-02\n",
      "  1.0000000e+00 -7.6503444e-01  8.9045143e-01  1.1383194e-01\n",
      " -1.0000000e+00  0.0000000e+00  2.8082058e-01  2.8400972e-01\n",
      "  2.9380226e-01  3.1142414e-01  3.3707085e-01  3.7388197e-01\n",
      "  4.2595050e-01  5.1878631e-01  6.9272876e-01  1.0000000e+00]\n",
      "[ 3.54176238e-02 -3.03072184e-02  1.34123147e-01  1.24022596e-01\n",
      "  1.13482130e+00 -3.97133827e-03  9.30096507e-01 -6.70264184e-04\n",
      "  1.00000000e+00 -6.85518444e-01  1.00026965e+00  4.49103117e-03\n",
      " -9.27355587e-01  0.00000000e+00  2.86564171e-01  2.89818525e-01\n",
      "  2.99781114e-01  3.17761570e-01  3.43545139e-01  3.80319655e-01\n",
      "  4.34224665e-01  5.28804660e-01  7.05421686e-01  1.00000000e+00]\n",
      "[ 4.4128899e-02  1.7512240e-02  1.3050811e-01  1.2170631e-01\n",
      "  1.1349425e+00  2.6250631e-04  8.7870109e-01 -4.2831418e-01\n",
      "  1.0000000e+00 -6.1765194e-01  8.5980237e-01 -1.1114454e-01\n",
      " -1.0000436e+00  0.0000000e+00  2.9227933e-01  2.9559860e-01\n",
      "  3.0573100e-01  3.2400519e-01  3.4999475e-01  3.8674390e-01\n",
      "  4.4246843e-01  5.3878677e-01  7.1898693e-01  1.0000000e+00]\n",
      "[ 6.4568490e-02  4.0943600e-02  1.3158107e-01  1.1937180e-01\n",
      "  1.1348547e+00  2.9802322e-08  8.0155772e-01 -6.4769703e-01\n",
      "  1.0000000e+00 -5.5169559e-01  8.4340799e-01 -1.6647685e-01\n",
      " -5.3891134e-01  0.0000000e+00  2.9791206e-01  3.0129528e-01\n",
      "  3.1159467e-01  3.2988524e-01  3.5634646e-01  3.9306331e-01\n",
      "  4.5058629e-01  5.4861599e-01  7.3456728e-01  1.0000000e+00]\n",
      "[ 1.02752835e-01  7.62951300e-02  1.49268523e-01  1.16438448e-01\n",
      "  1.13384593e+00 -6.24954700e-05  6.84061646e-01 -1.00002289e+00\n",
      "  1.00000000e+00 -5.45282185e-01  1.48363829e-01 -1.76547408e-01\n",
      " -1.05525398e+00  1.00000000e+00  3.03473264e-01  3.06906730e-01\n",
      "  3.17380488e-01  3.35657567e-01  3.62581789e-01  3.99213940e-01\n",
      "  4.58550572e-01  5.58643520e-01  7.49951065e-01  1.00000000e+00]\n",
      "[ 1.2823524e-01  5.1435295e-02  1.2610911e-01  1.0402990e-01\n",
      "  1.1339619e+00 -2.9802322e-08  5.6624377e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -4.6857452e-01  1.0000001e+00 -2.2202182e-01\n",
      " -9.3018818e-01  1.0000000e+00  3.0824992e-01  3.1171289e-01\n",
      "  3.2235065e-01  3.4062096e-01  3.6794332e-01  4.0451136e-01\n",
      "  4.6539956e-01  5.6824344e-01  7.6316428e-01  1.0000000e+00]\n",
      "[ 0.1656529   0.07490677  0.13063958  0.08488029  1.1296484  -0.03679413\n",
      "  0.46120125 -0.99069357  1.         -0.41236567  0.7073684  -0.3328203\n",
      " -0.95077705  1.          0.31233     0.31581435  0.32659212  0.34482148\n",
      "  0.37248078  0.40893167  0.47119004  0.57644343  0.77445203  1.        ]\n",
      "[ 0.19874504  0.06624967  0.12452683  0.06867113  1.1289749  -0.00160551\n",
      "  0.33923364 -1.0005401   1.         -0.33352137  1.0003474  -0.43944812\n",
      " -0.9998133   0.          0.31560972  0.31910795  0.3299981   0.34816438\n",
      "  0.3756549   0.4123947   0.4757931   0.58303493  0.7835267   1.        ]\n",
      "[ 2.3155741e-01  6.5686233e-02  1.2690943e-01  5.1395096e-02\n",
      "  1.1271839e+00 -8.9406967e-08  2.2251606e-01 -1.0000000e+00\n",
      "  1.0000000e+00 -2.5895265e-01  9.3959862e-01 -5.1376033e-01\n",
      " -6.6117185e-01  0.0000000e+00  3.1809059e-01  3.2159391e-01\n",
      "  3.3256891e-01  3.5063756e-01  3.7790579e-01  4.1486570e-01\n",
      "  4.7919014e-01  5.8802086e-01  7.9089552e-01  1.0000000e+00]\n",
      "[ 0.26134643  0.05950029  0.12754588  0.03936597  1.1261524   0.\n",
      "  0.10601211 -1.          0.         -0.18209538  0.9999999  -0.6179204\n",
      " -1.0925716   1.          0.31998378  0.32348576  0.33452532  0.3524711\n",
      "  0.37949237  0.41660747  0.48168647  0.5918257   0.7966389   1.        ]\n",
      "[ 2.6703227e-01  1.1373749e-02  1.2933847e-01  4.0791307e-02\n",
      "  1.1243140e+00 -7.4505806e-08  2.2996151e-01  9.9999976e-01\n",
      "  0.0000000e+00 -1.7665198e-01  1.1633797e-01 -5.6144512e-01\n",
      " -1.9868216e-08  1.0000000e+00  3.2180241e-01  3.2530168e-01\n",
      "  3.3640319e-01  3.5421777e-01  3.8098043e-01  4.1847396e-01\n",
      "  4.8405144e-01  5.9548074e-01  8.0217183e-01  1.0000000e+00]\n",
      "[ 2.7788028e-01  2.1702461e-02  1.6289067e-01  4.4291213e-02\n",
      "  1.1207610e+00 -8.9406967e-08  3.4944415e-01  9.5455283e-01\n",
      "  0.0000000e+00 -2.1568120e-01 -4.8898530e-01 -5.2732897e-01\n",
      "  2.9247868e-01  1.0000000e+00  3.2391027e-01  3.2740444e-01\n",
      "  3.3857775e-01  3.5622272e-01  3.8265783e-01  4.2084163e-01\n",
      "  4.8676157e-01  5.9971702e-01  8.0860525e-01  1.0000000e+00]\n",
      "[ 3.0699050e-01  5.8133896e-02  2.0919764e-01  5.1868137e-02\n",
      "  1.1211832e+00 -2.9802322e-08  3.2537234e-01 -2.0699318e-01\n",
      "  0.0000000e+00 -2.9559162e-01 -9.9999982e-01 -4.6924162e-01\n",
      "  4.8429418e-01  1.0000000e+00  3.2642636e-01  3.2991213e-01\n",
      "  3.4093162e-01  3.5859156e-01  3.8460049e-01  4.2363563e-01\n",
      "  4.8995754e-01  6.0477376e-01  8.1631076e-01  1.0000000e+00]\n",
      "[ 3.4174165e-01  6.9467433e-02  2.3435931e-01  6.0084954e-02\n",
      "  1.1192986e+00  9.3996525e-04  2.0935857e-01 -9.9989325e-01\n",
      "  0.0000000e+00 -3.7587941e-01 -1.0018699e+00 -4.0907001e-01\n",
      "  4.9370122e-01  0.0000000e+00  3.2934272e-01  3.3282018e-01\n",
      "  3.4355623e-01  3.6135212e-01  3.8688844e-01  4.2689371e-01\n",
      "  4.9368569e-01  6.1016214e-01  8.2522625e-01  1.0000000e+00]\n",
      "[ 3.7705207e-01  7.0450321e-02  2.2493851e-01  3.0363278e-02\n",
      "  1.1180463e+00  2.9802322e-08  9.3423128e-02 -1.0000000e+00\n",
      "  0.0000000e+00 -4.2659354e-01 -5.9374684e-01 -5.2360427e-01\n",
      " -9.9999970e-01  0.0000000e+00  3.3084065e-01  3.3432868e-01\n",
      "  3.4476691e-01  3.6262551e-01  3.8766229e-01  4.2837182e-01\n",
      "  4.9536234e-01  6.1200714e-01  8.3008945e-01  1.0000000e+00]\n",
      "[ 4.1344935e-01  7.2677925e-02  2.2811107e-01  1.2040295e-02\n",
      "  1.1164668e+00 -5.9604645e-08 -2.2887111e-02 -1.0000000e+00\n",
      "  0.0000000e+00 -4.9006599e-01 -7.4764550e-01 -6.3898981e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.3147603e-01  3.3497071e-01\n",
      "  3.4509006e-01  3.6296540e-01  3.8746536e-01  4.2873079e-01\n",
      "  4.9574807e-01  6.1230963e-01  8.3273530e-01  1.0000000e+00]\n",
      "[ 4.4907963e-01  7.1156211e-02  2.3683271e-01  3.5714861e-03\n",
      "  1.1150278e+00 -2.9802322e-08 -1.3946092e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -5.7125092e-01 -1.0046847e+00 -6.3490832e-01\n",
      " -3.9736431e-08  0.0000000e+00  3.3170870e-01  3.3520585e-01\n",
      "  3.4498563e-01  3.6262137e-01  3.8678318e-01  4.2854911e-01\n",
      "  4.9550930e-01  6.1186075e-01  8.3554512e-01  1.0000000e+00]\n",
      "[ 4.7116473e-01  4.4128194e-02  2.1829215e-01 -1.6859848e-02\n",
      "  1.1109948e+00 -8.9406967e-08 -1.3344288e-02  9.9999934e-01\n",
      "  0.0000000e+00 -6.4859796e-01 -9.6171498e-01 -6.3252151e-01\n",
      "  0.0000000e+00  0.0000000e+00  3.3093923e-01  3.3442828e-01\n",
      "  3.4387442e-01  3.6099657e-01  3.8505015e-01  4.2710236e-01\n",
      "  4.9381384e-01  6.0968584e-01  8.3477581e-01  1.0000000e+00]\n",
      "[ 4.9599022e-01  4.9668003e-02  2.2423902e-01 -3.4174975e-02\n",
      "  1.1089971e+00  1.1920929e-07  5.5665970e-02  5.4831511e-01\n",
      "  0.0000000e+00 -7.2895664e-01 -1.0000000e+00 -6.3104033e-01\n",
      " -7.9472862e-08  0.0000000e+00  3.2936049e-01  3.3283287e-01\n",
      "  3.4192127e-01  3.5850191e-01  3.8238925e-01  4.2459336e-01\n",
      "  4.9089280e-01  6.0604441e-01  8.3128577e-01  1.0000000e+00]\n",
      "[ 5.1447660e-01  3.6894206e-02  2.2709407e-01 -4.2627148e-02\n",
      "  1.1060243e+00  2.5331974e-07  1.8157536e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.0967766e-01 -1.0000000e+00 -5.0650787e-01\n",
      "  9.9999970e-01  0.0000000e+00  3.2736683e-01  3.3067596e-01\n",
      "  3.3953482e-01  3.5555714e-01  3.7924826e-01  4.2153755e-01\n",
      "  4.8734069e-01  6.0164702e-01  8.2640952e-01  1.0000000e+00]\n",
      "[ 5.1731938e-01  5.5060703e-03  2.0588011e-01 -4.6618927e-02\n",
      "  1.1020963e+00  8.9406967e-08  3.3906925e-01  1.2538263e+00\n",
      "  0.0000000e+00 -8.1237537e-01  0.0000000e+00 -3.8661861e-01\n",
      "  9.7247761e-01  0.0000000e+00  3.2515743e-01  3.2816333e-01\n",
      "  3.3695486e-01  3.5245985e-01  3.7594458e-01  4.1824198e-01\n",
      "  4.8351455e-01  5.9693635e-01  8.2062763e-01  1.0000000e+00]\n",
      "[ 5.2063960e-01  6.5976288e-03  2.0833105e-01 -6.1691727e-02\n",
      "  1.0993140e+00 -2.2351742e-07  4.6338284e-01  9.9999982e-01\n",
      "  0.0000000e+00 -8.1480950e-01  7.4505806e-09 -2.6374984e-01\n",
      "  1.0000002e+00  0.0000000e+00  3.2223669e-01  3.2493410e-01\n",
      "  3.3363912e-01  3.4860894e-01  3.7195596e-01  4.1401881e-01\n",
      "  4.7861841e-01  5.9094739e-01  8.1242853e-01  1.0000000e+00]\n",
      "[ 5.2089316e-01  1.6650444e-04  2.2053944e-01 -8.7797426e-02\n",
      "  1.1780956e+00  9.9999934e-01  3.4985173e-01 -9.9999994e-01\n",
      "  0.0000000e+00 -8.1820452e-01  8.0326572e-09 -1.3916790e-01\n",
      "  1.0000002e+00  0.0000000e+00  3.1808528e-01  3.2044977e-01\n",
      "  3.2903469e-01  3.4341380e-01  3.6670002e-01  4.0816849e-01\n",
      "  4.7184426e-01  5.8270735e-01  8.0014044e-01  1.0000000e+00]\n",
      "[ 5.2168471e-01 -7.9319486e-03  2.0337716e-01 -9.0856120e-02\n",
      "  1.1349065e+00 -5.5879354e-08  5.5620050e-01  9.9999982e-01\n",
      "  0.0000000e+00 -8.2254404e-01  3.7252903e-09 -1.5922928e-01\n",
      " -1.1680958e-01  1.0000000e+00  3.1408751e-01  3.1615165e-01\n",
      "  3.2462141e-01  3.3846414e-01  3.6166480e-01  4.0256384e-01\n",
      "  4.6535614e-01  5.7482427e-01  7.8818578e-01  1.0000000e+00]\n",
      "[ 5.0494325e-01 -3.3566535e-02  2.0316565e-01 -8.9898393e-02\n",
      "  1.1335526e+00  2.9802322e-08  6.7866671e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.2263952e-01  0.0000000e+00 -1.5985763e-01\n",
      " -7.5954101e-03  1.0000000e+00  3.0979341e-01  3.1154874e-01\n",
      "  3.1989518e-01  3.3318412e-01  3.5627431e-01  3.9656377e-01\n",
      "  4.5841137e-01  5.6639266e-01  7.7526176e-01  1.0000000e+00]\n",
      "[ 4.8132241e-01 -4.7271095e-02  2.1355879e-01 -8.9191310e-02\n",
      "  1.1326642e+00 -1.6644597e-04  8.0008006e-01  9.9998194e-01\n",
      "  0.0000000e+00 -8.2271451e-01  5.5432320e-06 -1.5275812e-01\n",
      "  5.6905478e-02  1.0000000e+00  3.0550796e-01  3.0693918e-01\n",
      "  3.1516215e-01  3.2787272e-01  3.5087401e-01  3.9055279e-01\n",
      "  4.5145270e-01  5.5793697e-01  7.6245958e-01  1.0000000e+00]\n",
      "[ 4.55035746e-01 -5.26646413e-02  2.30895415e-01 -9.02441144e-02\n",
      "  1.13246679e+00 -1.09910965e-04  9.20403481e-01  9.99988973e-01\n",
      "  0.00000000e+00 -8.22799742e-01  3.66568565e-06 -1.41750455e-01\n",
      "  8.72175023e-02  1.00000000e+00  3.01147401e-01  3.02241594e-01\n",
      "  3.10024410e-01  3.22428703e-01  3.45367908e-01  3.84424031e-01\n",
      "  4.44355994e-01  5.49304008e-01  7.49767482e-01  1.00000000e+00]\n",
      "[ 4.26883757e-01 -5.64178042e-02  2.37398759e-01 -7.72266462e-02\n",
      "  1.13244581e+00  1.71124935e-04  9.20631289e-01  0.00000000e+00\n",
      "  0.00000000e+00 -8.22984219e-01 -5.72204590e-06 -1.24534845e-01\n",
      "  1.37479350e-01  1.00000000e+00  2.97057033e-01  2.98136324e-01\n",
      "  3.05370748e-01  3.17588836e-01  3.40549201e-01  3.79047692e-01\n",
      "  4.38235253e-01  5.41718364e-01  7.39415526e-01  1.00000000e+00]\n",
      "[ 3.96563977e-01 -6.08727895e-02  2.46939957e-01 -6.55293763e-02\n",
      "  1.13115597e+00 -5.06639481e-07  8.23890090e-01 -8.33757401e-01\n",
      "  0.00000000e+00 -8.23421001e-01  5.96046448e-08 -1.00271344e-01\n",
      "  1.90079987e-01  1.00000000e+00  2.93486267e-01  2.94552624e-01\n",
      "  3.01219136e-01  3.13271105e-01  3.36334765e-01  3.74340653e-01\n",
      "  4.33132261e-01  5.35049796e-01  7.30642259e-01  1.00000000e+00]\n",
      "[ 0.34332317 -0.10659646  0.25606257 -0.07727261  1.1259613  -0.06129038\n",
      "  0.94445753  0.9999998   0.         -0.79601055  0.3418589  -0.08744335\n",
      "  0.10564335  1.          0.2892742   0.29032522  0.29639816  0.30825725\n",
      "  0.33137017  0.3687995   0.4270236   0.52722347  0.72006804  1.        ]\n",
      "[ 0.29435512 -0.09827283  0.27542683 -0.06336055  1.1152954  -0.16902071\n",
      "  0.9349072   0.          0.         -0.7791276   0.22020546 -0.06091738\n",
      "  0.21003611  1.          0.2856613   0.2866992   0.2921378   0.30382642\n",
      "  0.32710078  0.36402816  0.42193025  0.520445    0.71136767  1.        ]\n",
      "[ 2.3614579e-01 -1.1658644e-01  2.9690021e-01 -6.4681992e-02\n",
      "  1.1150601e+00 -3.5762787e-07  9.3490696e-01  0.0000000e+00\n",
      "  0.0000000e+00 -7.5428551e-01  3.1236464e-01 -3.1864166e-02\n",
      "  2.3445879e-01  1.0000000e+00  2.8193450e-01  2.8295887e-01\n",
      "  2.8771716e-01  2.9922894e-01  3.2269457e-01  3.5910261e-01\n",
      "  4.1670686e-01  5.1343930e-01  7.0247024e-01  1.0000000e+00]\n",
      "[ 0.20132507 -0.07004397  0.34865132 -0.0486515   1.0449924  -0.8781573\n",
      "  0.93490696  0.          0.         -0.80631644 -0.6308666   0.08143497\n",
      "  0.8990555   1.          0.27890116  0.27940917  0.28388354  0.2956872\n",
      "  0.3190875   0.35505897  0.41273108  0.50761414  0.6962322   1.        ]\n",
      "[ 1.5181611e-01 -9.9783391e-02  3.4556130e-01 -4.2709079e-02\n",
      "  9.6520716e-01 -9.9900180e-01  1.1576746e+00  2.9212935e+00\n",
      "  1.0000000e+00 -8.0783635e-01 -2.0444393e-05  1.4806044e-01\n",
      "  5.3156286e-01  1.0000000e+00  2.7607366e-01  2.7584237e-01\n",
      "  2.8025964e-01  2.9256743e-01  3.1572083e-01  3.5128230e-01\n",
      "  4.0908408e-01  5.0215793e-01  6.9130498e-01  1.0000000e+00]\n",
      "[ 0.07658705 -0.1442248   0.28447673 -0.03511502  1.134171    0.98208326\n",
      "  0.93489385  0.          1.         -0.76062757  0.48782006  0.17924416\n",
      "  0.3378011   1.          0.27356958  0.2727909   0.27715927  0.28981334\n",
      "  0.31274882  0.34795365  0.40572664  0.49738282  0.68627006  1.        ]\n",
      "[ 0.06839733 -0.01944356  0.16338381  0.0738361   1.1362009   0.01570893\n",
      "  0.9349804   0.00280341  0.         -0.79047763 -0.34664604  0.25774193\n",
      "  0.6351283   1.          0.2767829   0.27563283  0.28004673  0.2932587\n",
      "  0.3164668   0.35206482  0.41131204  0.5029406   0.6994479   1.        ]\n",
      "[ 0.05841494 -0.02056411  0.1594514   0.09644058  1.1351553  -0.01535289\n",
      "  0.9349221  -0.00267922  0.         -0.8242963  -0.40928984  0.35229683\n",
      "  0.7670644   1.          0.28101084  0.27948853  0.28396416  0.29780164\n",
      "  0.32136545  0.35749155  0.41852275  0.5103152   0.7160588   1.        ]\n",
      "[ 4.6897132e-02 -2.3221929e-02  1.3578874e-01  9.6444651e-02\n",
      "  1.1349719e+00 -1.4932156e-03  9.3491018e-01 -2.5206804e-04\n",
      "  0.0000000e+00 -8.2459754e-01  2.7745962e-05  3.9624113e-01\n",
      "  3.6166713e-01  1.0000000e+00  2.8527340e-01  2.8342921e-01\n",
      "  2.8796795e-01  3.0238613e-01  3.2629082e-01  3.6297062e-01\n",
      "  4.2572883e-01  5.1932579e-01  7.3247123e-01  1.0000000e+00]\n",
      "[ 3.22168432e-02 -2.98770592e-02  1.21902779e-01  1.15596235e-01\n",
      "  1.13506889e+00  6.69680536e-03  9.34915781e-01  1.73635280e-03\n",
      "  0.00000000e+00 -8.25183272e-01 -1.43289566e-04  4.50740695e-01\n",
      "  4.47518438e-01  1.00000000e+00  2.90247828e-01  2.88304180e-01\n",
      "  2.93048203e-01  3.07957679e-01  3.32280844e-01  3.69634032e-01\n",
      "  4.34364468e-01  5.30132651e-01  7.51069427e-01  1.00000000e+00]\n",
      "[ 1.6934305e-02 -3.0603271e-02  1.2210182e-01  1.2157198e-01\n",
      "  1.1349208e+00 -1.5202463e-03  9.3490720e-01 -4.5790276e-04\n",
      "  0.0000000e+00 -8.2548028e-01  3.4198165e-05  5.0820941e-01\n",
      "  4.7288203e-01  1.0000000e+00  2.9542425e-01  2.9344594e-01\n",
      "  2.9862681e-01  3.1382009e-01  3.3858415e-01  3.7672111e-01\n",
      "  4.4300669e-01  5.4148155e-01  7.6662689e-01  1.0000000e+00]\n",
      "[ 1.1065999e-02 -1.1732629e-02  1.1825460e-01  1.1838215e-01\n",
      "  1.1255437e+00 -1.1724453e-01  9.3490624e-01 -1.9046664e-04\n",
      "  0.0000000e+00 -8.2558703e-01  6.9215894e-06  5.5006731e-01\n",
      "  3.4689203e-01  1.0000000e+00  3.0050486e-01  2.9849252e-01\n",
      "  3.0409813e-01  3.1956980e-01  3.4476650e-01  3.8427323e-01\n",
      "  4.5077276e-01  5.5260581e-01  7.8187644e-01  1.0000000e+00]\n",
      "[-5.1152701e-03 -3.2353118e-02  1.1862107e-01  1.2385744e-01\n",
      "  1.1255914e+00  6.1482191e-04  9.3490767e-01  1.8456578e-04\n",
      "  0.0000000e+00 -8.2593226e-01 -1.3798475e-05  6.1198670e-01\n",
      "  5.0850379e-01  1.0000000e+00  3.0579522e-01  3.0374745e-01\n",
      "  3.0978677e-01  3.2554784e-01  3.5119474e-01  3.9211568e-01\n",
      "  4.5885003e-01  5.6415749e-01  7.9771227e-01  1.0000000e+00]\n",
      "[-0.01620225 -0.02216558  0.11875295  0.12127278  1.1206782  -0.06156473\n",
      "  0.93490684  0.          0.         -0.8261407   0.          0.6658389\n",
      "  0.44450918  1.          0.31098613  0.3089036   0.3153729   0.33141822\n",
      "  0.35750696  0.39982176  0.46678036  0.57550836  0.8132727   1.        ]\n",
      "[ 0.00590055  0.04425447  0.11757836  0.11037139  1.1205019   0.\n",
      "  0.8570209  -0.6524778   0.         -0.82688236  0.          0.5477401\n",
      " -1.0000002   1.          0.3157937   0.31367895  0.3205596   0.33686876\n",
      "  0.36336726  0.40699142  0.4741394   0.58626693  0.83000576  1.        ]\n",
      "[ 4.5469735e-02  7.9155706e-02  1.1686162e-01  1.0883615e-01\n",
      "  1.1194690e+00 -9.1210008e-04  7.3905730e-01 -1.0003196e+00\n",
      "  0.0000000e+00 -8.2779068e-01  2.0802021e-05  4.3048966e-01\n",
      " -9.9983186e-01  0.0000000e+00  3.2058996e-01  3.1844312e-01\n",
      "  3.2573211e-01  3.4230444e-01  3.6921158e-01  4.1413918e-01\n",
      "  4.8147893e-01  5.9731287e-01  8.5145068e-01  1.0000000e+00]\n",
      "[ 8.4918596e-02  7.8860767e-02  1.1701909e-01  9.1571160e-02\n",
      "  1.1180419e+00 -3.3897161e-04  6.2230569e-01 -1.0000298e+00\n",
      "  0.0000000e+00 -8.2905501e-01  9.8645687e-06  3.1412172e-01\n",
      " -9.9976200e-01  0.0000000e+00  3.2457027e-01  3.2239679e-01\n",
      "  3.3006558e-01  3.4684521e-01  3.7410608e-01  4.2017308e-01\n",
      "  4.8761463e-01  6.0666150e-01  8.6978781e-01  1.0000000e+00]\n",
      "[ 0.13656072  0.10315684  0.12071234  0.09028158  1.0609152  -0.68478036\n",
      "  0.604161    0.09400731  1.         -0.83098406  0.          0.2001968\n",
      " -1.0000001   0.          0.32850617  0.3263063   0.33436045  0.35134223\n",
      "  0.37895653  0.4261639   0.49369258  0.615949    0.888049    1.        ]\n",
      "[ 0.17720896  0.08180601  0.1067294   0.08404786  1.0490489  -0.09348691\n",
      "  0.45549166 -0.99999994  1.         -0.7761262   0.703066    0.08913988\n",
      " -1.0000001   0.          0.332195    0.32997045  0.3383669   0.355538\n",
      "  0.3834821   0.43173176  0.49936837  0.62456983  0.90589786  1.        ]\n",
      "[ 0.21355718  0.07295827  0.10128769  0.07089751  1.041939   -0.07347608\n",
      "  0.33866745 -1.          1.         -0.6969527   0.99999994 -0.02592599\n",
      " -0.9999998   0.          0.33523157  0.33304936  0.34169403  0.35902116\n",
      "  0.387239    0.43638766  0.50407237  0.63179564  0.9241364   1.        ]\n",
      "[ 0.25432914  0.08172634  0.10008562  0.05465606  1.0276071  -0.16707024\n",
      "  0.2221911  -0.99999994  0.         -0.6201572   1.0000002  -0.12664199\n",
      " -0.99999976  0.          0.33749148  0.33551177  0.34422037  0.3616639\n",
      "  0.39008948  0.4399778   0.50784916  0.6373959   0.9387062   1.        ]\n",
      "[ 0.30535555  0.10228959  0.08489808  0.05393419  0.96818167 -0.74453664\n",
      "  0.20895743 -0.11333165  0.         -0.547133    0.93404144 -0.23314488\n",
      " -1.          0.          0.33981526  0.33800545  0.34677878  0.36434177\n",
      "  0.39324152  0.44357136  0.5120857   0.6429799   0.9529071   1.        ]\n",
      "[ 0.3669079   0.12330742  0.05976799  0.05650861  0.8941808  -0.92414284\n",
      "  0.20320773 -0.05323845  0.         -0.48802102  0.7529608  -0.34079158\n",
      " -0.99999994  0.          0.34238696  0.3406957   0.34953886  0.36723366\n",
      "  0.39660975  0.44728076  0.5165637   0.6488435   0.96720815  1.        ]\n",
      "[ 0.43809044  0.14249057  0.07112361  0.03072796  0.83934754 -0.64976037\n",
      "  0.08790445 -0.9999998   0.         -0.45256236  0.4450609  -0.4569311\n",
      " -1.0000001   0.          0.34375107  0.3421957   0.35107777  0.3688429\n",
      "  0.39856184  0.44915754  0.5191601   0.6524637   0.97628057  1.        ]\n",
      "[ 0.50913644  0.14214285  0.06839583  0.01228226  0.7597169  -0.997968\n",
      "  0.13182825  0.35604104  0.         -0.43694153  0.20114326 -0.56565166\n",
      " -1.0000001   0.          0.3442473   0.34281996  0.35171828  0.36950946\n",
      "  0.39945024  0.449917    0.5203429   0.65450114  0.9810715   1.        ]\n",
      "[ 0.5841443   0.1500374   0.07536782 -0.00891388  0.6657555  -1.1360884\n",
      "  0.2565995   1.0000001   0.         -0.45869172 -0.2682693  -0.68387866\n",
      " -1.0000002   0.          0.34375086  0.3424604   0.35134935  0.36911607\n",
      "  0.3991623   0.44941562  0.51996267  0.6543252   0.98142517  1.        ]\n",
      "[ 6.6575652e-01  1.6163756e-01  9.4755851e-02 -2.1353910e-02\n",
      "  5.7038748e-01 -1.1444185e+00  3.8329518e-01  1.0000000e+00\n",
      "  0.0000000e+00 -5.4799223e-01 -9.9999988e-01 -6.3490844e-01\n",
      "  2.4835268e-08  0.0000000e+00  3.4276274e-01  3.4165284e-01\n",
      "  3.5052085e-01  3.6823827e-01  3.9838082e-01  4.4832814e-01\n",
      "  5.1892734e-01  6.5332896e-01  9.8042756e-01  1.0000000e+00]\n",
      "[ 0.73800117  0.14443634  0.10323885 -0.05134173  0.576084    0.10068572\n",
      "  0.2695371  -1.          0.         -0.627681   -1.0000001  -0.59417653\n",
      "  0.34218916  0.          0.3401375   0.33921403  0.3480187   0.36560345\n",
      "  0.39563957  0.4451529   0.5152879   0.6486211   0.9723479   1.        ]\n",
      "[ 0.79872733  0.12105171  0.1075462  -0.08337338  0.6508819   0.9999999\n",
      "  0.09771824 -1.6011022   0.         -0.7083704  -1.         -0.55724955\n",
      "  0.2931331   0.          0.33593827  0.33521235  0.3439132   0.36128503\n",
      "  0.39102677  0.43997586  0.5091616   0.64038366  0.9570712   1.        ]\n",
      "[ 0.8557903   0.11374958  0.11212617 -0.09896334  0.72718513  1.0000005\n",
      " -0.02316403 -1.1532868   0.         -0.78922933 -1.         -0.4845003\n",
      "  0.5952146   0.          0.33098647  0.33046466  0.33904225  0.3561629\n",
      "  0.38552174  0.43384284  0.5018497   0.63056713  0.9383442   1.        ]\n",
      "[ 0.8982602   0.0843324   0.10105318 -0.11599633  0.791572    0.97280043\n",
      "  0.12605786  0.9999995   0.         -0.87133646 -1.         -0.36118007\n",
      "  1.0000002   0.          0.32526198  0.32492426  0.33335805  0.35018805\n",
      "  0.37904015  0.42670226  0.49323982  0.6195549   0.915639    1.        ]\n",
      "[ 0.9193505   0.05526767  0.08570248 -0.13605285  0.86554855  1.0000006\n",
      "  0.30135906  1.1955541   0.         -0.8349151   0.         -0.3792572\n",
      "  0.17692067  0.          0.31861275  0.31840825  0.3266729   0.34316474\n",
      "  0.3713286   0.4183295   0.48299456  0.6063965   0.8876223   1.        ]\n",
      "[ 0.9423214   0.0455845   0.09529246 -0.15054384  0.9353202   1.0000007\n",
      "  0.4444561   1.0000001   0.         -0.83490926  0.         -0.43500638\n",
      " -0.43640533  1.          0.31126404  0.31123152  0.3193099   0.33542818\n",
      "  0.36286202  0.40910017  0.47174665  0.5919666   0.85772914  1.        ]\n",
      "[ 9.5760316e-01  3.0264784e-02  1.0080720e-01 -1.5722162e-01\n",
      "  1.0070552e+00  1.0000004e+00  5.8300841e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3490914e-01 -1.4901161e-08 -4.8250794e-01\n",
      " -3.9768508e-01  1.0000000e+00  3.0358055e-01  3.0373153e-01\n",
      "  3.1161526e-01  3.2734296e-01  3.5401812e-01  3.9932787e-01\n",
      "  4.6007705e-01  5.7689631e-01  8.3118194e-01  1.0000000e+00]\n",
      "[ 9.6570283e-01  1.5892316e-02  1.0490856e-01 -1.6289398e-01\n",
      "  1.0810575e+00  1.0000006e+00  7.1592474e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3491510e-01 -7.4505806e-09 -5.2593791e-01\n",
      " -3.6339679e-01  1.0000000e+00  2.9560938e-01  2.9595295e-01\n",
      "  3.0363476e-01  3.1895730e-01  3.4484804e-01  3.8898414e-01\n",
      "  4.4855335e-01  5.6127167e-01  8.0367053e-01  1.0000000e+00]\n",
      "[ 9.6596593e-01  2.7223208e-04  1.0429796e-01 -1.6291538e-01\n",
      "  1.1577890e+00  1.0000000e+00  8.2343554e-01  8.4026980e-01\n",
      "  0.0000000e+00 -8.3491063e-01 -6.9849193e-10 -5.6373000e-01\n",
      " -3.1631699e-01  1.0000000e+00  2.8762400e-01  2.8815946e-01\n",
      "  2.9563898e-01  3.1055564e-01  3.3565933e-01  3.7861940e-01\n",
      "  4.3700802e-01  5.4561460e-01  7.7609617e-01  1.0000000e+00]\n",
      "[ 9.7247916e-01  9.0813134e-03  8.2529694e-02 -1.5164408e-01\n",
      "  1.1349120e+00  5.9604645e-08  1.0628555e+00  1.5896878e+00\n",
      "  0.0000000e+00 -8.3491087e-01  0.0000000e+00 -6.0177064e-01\n",
      " -3.1533396e-01  1.0000000e+00  2.8037873e-01  2.8105551e-01\n",
      "  2.8835064e-01  3.0289882e-01  3.2724786e-01  3.6913139e-01\n",
      "  4.2649585e-01  5.3125930e-01  7.5130135e-01  1.0000000e+00]\n",
      "[ 9.7623020e-01 -1.0962062e-02  8.4283143e-02 -6.9435246e-02\n",
      "  1.1356502e+00  2.4081022e-03  9.3496835e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3509737e-01 -1.3962388e-05 -6.1873758e-01\n",
      " -1.1680836e-01  1.0000000e+00  2.7710983e-01  2.7789730e-01\n",
      "  2.8511044e-01  2.9949147e-01  3.2358769e-01  3.6500272e-01\n",
      "  4.2179635e-01  5.2506268e-01  7.4296457e-01  1.0000000e+00]\n",
      "[ 9.6218163e-01 -2.8412214e-02  1.1699350e-01 -1.7591491e-02\n",
      "  1.1349154e+00 -9.8954141e-04  9.3490720e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3464080e-01  1.0535121e-05 -6.1458611e-01\n",
      "  4.2824004e-02  1.0000000e+00  2.7606398e-01  2.7684847e-01\n",
      "  2.8403282e-01  2.9835138e-01  3.2257298e-01  3.6385816e-01\n",
      "  4.2016953e-01  5.2347410e-01  7.4065340e-01  1.0000000e+00]\n",
      "[ 9.4576877e-01 -3.2825742e-02  1.2955900e-01 -1.1896894e-02\n",
      "  1.1348124e+00 -1.2726039e-03  9.3492901e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3365268e-01  5.8859587e-06 -6.0801470e-01\n",
      "  6.9673158e-02  1.0000000e+00  2.7525437e-01  2.7603656e-01\n",
      "  2.8318921e-01  2.9746526e-01  3.2187167e-01  3.6306709e-01\n",
      "  4.1888243e-01  5.2244121e-01  7.3905605e-01  1.0000000e+00]\n",
      "[ 9.2851013e-01 -3.4539167e-02  1.4300874e-01 -9.7356187e-03\n",
      "  1.1347983e+00 -2.5391579e-05  9.3490648e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3348513e-01  8.3446503e-07 -5.9919775e-01\n",
      "  7.3021099e-02  1.0000000e+00  2.7451989e-01  2.7530000e-01\n",
      "  2.8242177e-01  2.9665911e-01  3.2129058e-01  3.6241165e-01\n",
      "  4.1769683e-01  5.2163291e-01  7.3788375e-01  1.0000000e+00]\n",
      "[ 9.0972847e-01 -3.7576120e-02  1.5460156e-01 -8.4288130e-03\n",
      "  1.1347744e+00  9.7751617e-06  9.3490613e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3348393e-01 -3.1292439e-07 -5.8850992e-01\n",
      "  8.6647056e-02  1.0000000e+00  2.7382183e-01  2.7459997e-01\n",
      "  2.8169066e-01  2.9589117e-01  3.2077852e-01  3.6166805e-01\n",
      "  4.1655657e-01  5.2095872e-01  7.3828602e-01  1.0000000e+00]\n",
      "[ 8.8936061e-01 -4.0750679e-02  1.6668655e-01 -6.9727837e-03\n",
      "  1.1347466e+00  1.4007092e-06  9.3490624e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3348012e-01 -5.9604645e-08 -5.7595992e-01\n",
      "  1.0177020e-01  1.0000000e+00  2.7316678e-01  2.7394304e-01\n",
      "  2.8100273e-01  2.9516852e-01  3.2034466e-01  3.6072573e-01\n",
      "  4.1547123e-01  5.2043509e-01  7.3909217e-01  1.0000000e+00]\n",
      "[ 8.6743969e-01 -4.3860957e-02  1.7328422e-01  1.7258003e-02\n",
      "  1.1346552e+00 -1.0166466e-03  9.3490660e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3336228e-01  3.3527613e-05 -5.6041110e-01\n",
      "  1.2780380e-01  1.0000000e+00  2.7363151e-01  2.7440912e-01\n",
      "  2.8146544e-01  2.9565457e-01  3.2128191e-01  3.6121437e-01\n",
      "  4.1653857e-01  5.2227765e-01  7.4430412e-01  1.0000000e+00]\n",
      "[ 8.4343547e-01 -4.8020102e-02  1.8337263e-01  3.3111941e-02\n",
      "  1.1346638e+00  6.4161420e-04  9.3490469e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3330458e-01 -2.7298927e-05 -5.3483403e-01\n",
      "  2.0080595e-01  1.0000000e+00  2.7481377e-01  2.7559471e-01\n",
      "  2.8266484e-01  2.9691443e-01  3.2311061e-01  3.6261612e-01\n",
      "  4.1897520e-01  5.2566636e-01  7.5245792e-01  1.0000000e+00]\n",
      "[ 8.1755978e-01 -5.1774930e-02  1.9795287e-01  3.6065720e-02\n",
      "  1.1346123e+00 -1.3029575e-04  9.3490660e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3327806e-01  4.3511391e-06 -5.0675666e-01\n",
      "  2.2964424e-01  1.0000000e+00  2.7610454e-01  2.7688915e-01\n",
      "  2.8397459e-01  2.9829019e-01  3.2510221e-01  3.6414802e-01\n",
      "  4.2162892e-01  5.2935457e-01  7.6131451e-01  1.0000000e+00]\n",
      "[ 7.8974265e-01 -5.5662308e-02  2.1290755e-01  3.8895737e-02\n",
      "  1.1345608e+00  9.8347664e-07  9.3490565e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3327168e-01 -2.9802322e-08 -4.7564328e-01\n",
      "  2.5402668e-01  1.0000000e+00  2.7749485e-01  2.7827966e-01\n",
      "  2.8538531e-01  2.9994917e-01  3.2724667e-01  3.6579823e-01\n",
      "  4.2448628e-01  5.3332555e-01  7.7084768e-01  1.0000000e+00]\n",
      "[ 7.5975895e-01 -6.0000584e-02  2.2899662e-01  4.2663857e-02\n",
      "  1.1345004e+00  3.9637089e-06  9.3490636e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3327836e-01 -1.1920929e-07 -4.4090009e-01\n",
      "  2.8331146e-01  1.0000000e+00  2.7902567e-01  2.7979478e-01\n",
      "  2.8693914e-01  3.0210260e-01  3.2959610e-01  3.6761865e-01\n",
      "  4.2761657e-01  5.3767031e-01  7.8123569e-01  1.0000000e+00]\n",
      "[ 7.2894132e-01 -6.1635133e-02  2.3252174e-01  5.0472621e-02\n",
      "  1.1338465e+00  1.5199184e-06  8.6311316e-01 -6.0958964e-01\n",
      "  0.0000000e+00 -8.3315879e-01 -2.0861626e-07 -4.0322638e-01\n",
      "  3.1249419e-01  0.0000000e+00  2.8091109e-01  2.8166506e-01\n",
      "  2.8885716e-01  3.0465639e-01  3.3238229e-01  3.6989135e-01\n",
      "  4.3132743e-01  5.4375631e-01  7.9634178e-01  1.0000000e+00]\n",
      "[ 0.6912369  -0.07570454  0.25622433  0.05484353  1.0983737  -0.44440168\n",
      "  0.98301804  0.99999994  0.         -0.83353204  0.         -0.35541916\n",
      "  0.38386226  0.          0.28294238  0.28367946  0.29092297  0.30742276\n",
      "  0.33540043  0.37233528  0.43534738  0.5509362   0.8141049   1.        ]\n",
      "[ 0.6511506  -0.08033368  0.27872044  0.05028009  1.137849    0.505398\n",
      "  0.8652828  -1.          0.         -0.83371484  0.         -0.30499458\n",
      "  0.40729544  0.          0.28470644  0.28542408  0.29271215  0.30993515\n",
      "  0.3375283   0.37442335  0.4389999   0.55770653  0.83131033  1.        ]\n",
      "[ 0.60153455 -0.09956891  0.30399227  0.05445605  1.1349068  -0.02704757\n",
      "  0.9867493   1.          0.         -0.83427984  0.         -0.24061394\n",
      "  0.5126396   0.          0.28658554  0.28728503  0.29466814  0.3126305\n",
      "  0.33953276  0.37664694  0.4429186   0.56500137  0.8495899   1.        ]\n",
      "[ 5.60051560e-01 -8.31968412e-02  2.99594671e-01  7.13483319e-02\n",
      "  1.13351977e+00  3.16739082e-04  8.70444536e-01 -9.99972820e-01\n",
      "  0.00000000e+00 -8.34461153e-01 -1.04904175e-05 -1.79974675e-01\n",
      "  4.94234651e-01  0.00000000e+00  2.89258152e-01  2.89964169e-01\n",
      "  2.98052520e-01  3.16221207e-01  3.42482507e-01  3.80628467e-01\n",
      "  4.48513865e-01  5.74131131e-01  8.70202601e-01  1.00000000e+00]\n",
      "[ 0.5074969  -0.10532469  0.32854572  0.07602941  1.0932932  -0.5052078\n",
      "  0.99032533  0.99999976  0.         -0.83491296  0.         -0.10231805\n",
      "  0.6244548   0.          0.29204443  0.29275724  0.30161557  0.32000142\n",
      "  0.3455496   0.3852936   0.45448244  0.58342403  0.89220864  1.        ]\n",
      "[ 0.44449547 -0.12595944  0.3599948   0.07103297  1.1485618   0.7016812\n",
      "  0.8803406  -0.9352889   0.         -0.8349059   0.         -0.01046956\n",
      "  0.7454638   0.          0.2944977   0.2952165   0.3048885   0.32347387\n",
      "  0.3482182   0.38958058  0.46002516  0.58970803  0.9106434   1.        ]\n",
      "[ 3.87835830e-01 -1.15327425e-01  3.73788714e-01  9.24064517e-02\n",
      "  1.13490772e+00  2.14576721e-06  8.16188931e-01 -7.96861351e-01\n",
      "  0.00000000e+00 -8.34910035e-01 -2.98023224e-07  8.24269056e-02\n",
      "  7.68516064e-01  0.00000000e+00  2.98017114e-01  2.98844218e-01\n",
      "  3.09303075e-01  3.27217609e-01  3.52112442e-01  3.95359516e-01\n",
      "  4.67382163e-01  5.98184049e-01  9.25368369e-01  1.00000000e+00]\n",
      "[ 0.32266796 -0.13040963  0.39566177  0.10390429  1.072285   -0.77860194\n",
      "  0.9383091   0.9999997   0.         -0.8349053   0.          0.19393313\n",
      "  0.9090658   0.          0.30189043  0.30351174  0.31413394  0.3312065\n",
      "  0.3564048   0.4016831   0.47542042  0.6074593   0.9414309   1.        ]\n",
      "[ 2.5088692e-01 -1.4355253e-01  4.0716645e-01  9.4674714e-02\n",
      "  1.0772318e+00  9.2259347e-02  8.2608724e-01 -1.0000046e+00\n",
      "  0.0000000e+00 -8.3490843e-01 -1.9669533e-06  3.1880689e-01\n",
      "  1.0144457e+00  0.0000000e+00  3.0527112e-01  3.0770126e-01\n",
      "  3.1847009e-01  3.3466193e-01  3.6107722e-01  4.0736064e-01\n",
      "  4.8373169e-01  6.1578470e-01  9.5607030e-01  1.0000000e+00]\n",
      "[ 0.17833652 -0.14549682  0.4105484   0.07836565  1.0767143   0.04744065\n",
      "  0.7177064  -1.          0.         -0.83208877  0.05099893  0.44323313\n",
      "  1.          0.          0.30786738  0.3111027   0.32175162  0.3372741\n",
      "  0.3651651   0.41235074  0.49144548  0.6253748   0.9665312   1.        ]\n",
      "[ 0.10355237 -0.150291    0.41159976  0.07174113  0.999973   -0.9407354\n",
      "  0.8444283   1.          0.         -0.8244205   0.11954212  0.56812274\n",
      "  0.9999998   0.          0.31059712  0.3141244   0.32385445  0.33947837\n",
      "  0.36879802  0.4168807   0.49850056  0.63625675  0.97581005  1.        ]\n",
      "[ 0.01645201 -0.17418995  0.33182806  0.07062858  1.132529    1.6749959\n",
      "  0.72713614 -1.0038707   1.         -0.79834527  0.31938493  0.68859047\n",
      "  0.9993169   0.          0.3135547   0.31711558  0.3261173   0.3418504\n",
      "  0.37239203  0.42129502  0.50515354  0.6463678   0.9848716   1.        ]\n",
      "[-3.8778894e-02 -1.1080207e-01  3.4553966e-01  8.7273166e-02\n",
      "  1.1282955e+00  5.9604645e-08  8.7087798e-01  1.2513362e+00\n",
      "  1.0000000e+00 -7.9944712e-01  4.5467019e-03  8.1197590e-01\n",
      "  1.0000001e+00  0.0000000e+00  3.1736112e-01  3.2096523e-01\n",
      "  3.2921880e-01  3.4551799e-01  3.7701541e-01  4.2690355e-01\n",
      "  5.1337063e-01  6.5869081e-01  9.9640524e-01  1.0000000e+00]\n",
      "[-0.10510258 -0.13035348  0.32711115  0.0737669   1.0969176  -0.0017246\n",
      "  1.0005813   0.99986774  1.         -0.78390193  0.14701337  0.92909706\n",
      "  1.0000403   0.          0.3208064   0.3243741   0.3320181   0.3493532\n",
      "  0.3812002   0.43198302  0.5195492   0.6711196   1.          1.        ]\n",
      "[-1.7241654e-01 -1.3458993e-01  2.6835975e-01  8.6291082e-02\n",
      "  1.2091944e+00  1.4068468e+00  8.8170350e-01 -1.0016118e+00\n",
      "  0.0000000e+00 -7.0306939e-01  1.0016751e+00  9.2857713e-01\n",
      "  1.2252430e-03  0.0000000e+00  3.2458887e-01  3.2755768e-01\n",
      "  3.3527672e-01  3.5356176e-01  3.8588399e-01  4.3748826e-01\n",
      "  5.2563411e-01  6.8538666e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-1.8195321e-01 -3.3818413e-02  2.1573158e-01  1.3808848e-01\n",
      "  1.1349114e+00  2.6673079e-06  1.0369298e+00 -5.8687586e-02\n",
      "  0.0000000e+00 -6.9293231e-01  2.3344520e-01  9.3059444e-01\n",
      " -5.2899122e-07  0.0000000e+00  3.3141491e-01  3.3388984e-01\n",
      "  3.4175807e-01  3.6115044e-01  3.9444330e-01  4.4802147e-01\n",
      "  5.3661537e-01  7.0748430e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-0.19300775 -0.03218477  0.21315533  0.1289048   1.135111   -0.16791281\n",
      "  1.0165125   0.22959732  1.         -0.63782865  0.77446127  0.81446\n",
      " -1.          0.          0.33745506  0.33945614  0.34745556  0.36786577\n",
      "  0.40203     0.45763436  0.5463323   0.72726685  1.          1.        ]\n",
      "[-1.8584783e-01  1.1683297e-02  1.9347106e-01  1.3688993e-01\n",
      "  1.1365469e+00  7.4378401e-04  9.3499357e-01 -4.4666040e-01\n",
      "  1.0000000e+00 -5.9081125e-01  6.1061025e-01  6.9681752e-01\n",
      " -1.0001670e+00  0.0000000e+00  3.4396666e-01  3.4554672e-01\n",
      "  3.5368967e-01  3.7510434e-01  4.1017762e-01  4.6785888e-01\n",
      "  5.5680770e-01  7.4748009e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-0.15665999  0.05826589  0.19631635  0.13388652  1.134909    0.\n",
      "  0.83348256 -0.87451667  1.         -0.5559738   0.4515661   0.5808705\n",
      " -1.0000001   0.          0.35032207  0.35146886  0.3601682   0.38216949\n",
      "  0.4181376   0.4778726   0.5670318   0.7671094   1.          1.        ]\n",
      "[-0.12171761  0.06993829  0.19635554  0.12082312  1.1338264  -0.00370723\n",
      "  0.71505344 -1.0013107   1.         -0.52084345  0.4450988   0.4626487\n",
      " -1.0000709   0.          0.35609937  0.35681316  0.36622134  0.3885924\n",
      "  0.4253871   0.4870359   0.5776833   0.78517157  1.          1.        ]\n",
      "[-9.01823565e-02  6.30481020e-02  1.90256223e-01  1.13233775e-01\n",
      "  1.13284910e+00  4.10079956e-05  5.98350823e-01 -9.99985874e-01\n",
      "  1.00000000e+00 -4.55611706e-01  8.46972704e-01  3.52525592e-01\n",
      " -9.99999225e-01  0.00000000e+00  3.61461908e-01  3.61755550e-01\n",
      "  3.71840119e-01  3.94554406e-01  4.32122469e-01  4.95569557e-01\n",
      "  5.88852704e-01  8.02038908e-01  1.00000000e+00  1.00000000e+00]\n",
      "[-0.04735801  0.0856057   0.19984433  0.10852187  1.0801299  -0.6297094\n",
      "  0.5765255   0.04852417  1.         -0.41342774  0.5544095   0.31969935\n",
      " -0.33951458  0.          0.36630365  0.36651066  0.3772849   0.40042138\n",
      "  0.43866065  0.5038909   0.5997707   0.8151854   1.          1.        ]\n",
      "[-4.1417338e-04  9.4369024e-02  1.8959735e-01  8.9659788e-02\n",
      "  1.0576551e+00 -2.3798311e-01  4.2642707e-01 -9.9999982e-01\n",
      "  1.0000000e+00 -3.4665751e-01  8.6691433e-01  2.1265233e-01\n",
      " -1.0000000e+00  0.0000000e+00  3.7023869e-01  3.7044790e-01\n",
      "  3.8184378e-01  4.0543193e-01  4.4414970e-01  5.0999665e-01\n",
      "  6.0903430e-01  8.2520282e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.05726269  0.11549112  0.19510591  0.07169215  1.0183462  -0.4657143\n",
      "  0.3096844  -1.          1.         -0.29784358  0.6210089   0.09708917\n",
      " -0.99999994  0.          0.37334067  0.37355164  0.38554546  0.4095286\n",
      "  0.44917184  0.514823    0.6168134   0.83345777  1.          1.        ]\n",
      "[ 0.11787804  0.12120566  0.19435367  0.05551951  0.97054803 -0.5774753\n",
      "  0.19412124 -0.99999994  0.         -0.2470371   0.6810069  -0.00431073\n",
      " -1.          0.          0.37565318  0.37586546  0.38841993  0.412739\n",
      "  0.4532491   0.5185695   0.6231203   0.8399928   1.          1.        ]\n",
      "[ 0.18338576  0.13105863  0.20011045  0.03233195  0.91816896 -0.6177068\n",
      "  0.07883692 -1.          0.         -0.21459328  0.41421515 -0.12044847\n",
      " -0.99999994  1.          0.3769209   0.3771339   0.39021137  0.41479242\n",
      "  0.45601887  0.5209022   0.62753046  0.8442911   1.          1.        ]\n",
      "[ 0.26789925  0.16892992  0.22185491  0.0103417   0.83626646 -0.99999994\n",
      " -0.0229578  -0.8883052   0.         -0.25353992 -0.4640296  -0.23122346\n",
      " -0.9999998   0.          0.37717387  0.3777267   0.3909893   0.41577443\n",
      "  0.45761386  0.52191126  0.6307344   0.8465441   1.          1.        ]\n",
      "[ 0.35049024  0.16512787  0.22739181 -0.01969898  0.7945617  -0.4923967\n",
      " -0.13823879 -1.0000001   0.         -0.325032   -0.87441295 -0.34854078\n",
      " -1.0000001   0.          0.3760051   0.37705076  0.39028963  0.41517675\n",
      "  0.4574199   0.52099127  0.6316094   0.8457401   1.          1.        ]\n",
      "[ 0.42213643  0.14305368  0.22358042 -0.05040741  0.81529886  0.27494442\n",
      " -0.24974298 -1.          0.         -0.4085029  -0.99999994 -0.4621979\n",
      " -1.0000002   0.          0.37334642  0.37486196  0.38802397  0.41289994\n",
      "  0.45530814  0.51802725  0.6294477   0.8416747   1.          1.        ]\n",
      "[ 0.48219457  0.11968714  0.22020772 -0.07987716  0.89272803  1.0000005\n",
      " -0.35327375 -1.          0.         -0.49241874 -1.0000001  -0.5770699\n",
      " -1.0000001   0.          0.36926574  0.37123078  0.38426527  0.40902254\n",
      "  0.45136952  0.5131143   0.62439644  0.83450156  1.          1.        ]\n",
      "[ 0.541236    0.11762136  0.22388902 -0.09805893  0.9703926   1.0000006\n",
      " -0.43530655 -0.8184993   0.         -0.5763805  -1.0000001  -0.69254005\n",
      " -1.0000001   0.          0.36432517  0.36673775  0.37962446  0.40419194\n",
      "  0.446353    0.5070367   0.6176645   0.82548493  1.          1.        ]\n",
      "[ 0.593603    0.10250472  0.22215213 -0.10373194  1.0425795   0.9999992\n",
      " -0.39685094  0.16740163  0.         -0.6682737  -1.         -0.63490915\n",
      "  0.          0.          0.35928658  0.3621528   0.37499383  0.39926162\n",
      "  0.44122982  0.50083476  0.6107813   0.8162799   1.          1.        ]\n",
      "[ 0.6400989   0.09246539  0.22108234 -0.12141593  1.1093029   0.9999991\n",
      " -0.25159907  0.9999997   0.         -0.7488335  -1.         -0.6177834\n",
      "  0.13098218  0.          0.3532423   0.3565379   0.36928698  0.39318547\n",
      "  0.43478948  0.49324137  0.60179174  0.8048431   1.          1.        ]\n",
      "[ 7.00531721e-01  1.20677233e-01  2.25181505e-01 -1.24059506e-01\n",
      "  1.10212147e+00  1.78813934e-07 -1.19728565e-01  1.00000012e+00\n",
      "  0.00000000e+00 -8.28703463e-01 -1.00000000e+00 -6.17193460e-01\n",
      " -9.93410776e-09  0.00000000e+00  3.47082615e-01  3.50808471e-01\n",
      "  3.63461465e-01  3.86982948e-01  4.28207338e-01  4.85493153e-01\n",
      "  5.92584074e-01  7.93162882e-01  1.00000000e+00  1.00000000e+00]\n",
      "[ 7.4403960e-01  8.6885072e-02  2.0992616e-01 -1.1879554e-01\n",
      "  1.0969293e+00  4.1723251e-07  9.4529986e-03  1.0000000e+00\n",
      "  0.0000000e+00 -8.3322525e-01  0.0000000e+00 -4.9172509e-01\n",
      "  9.9999970e-01  0.0000000e+00  3.4136429e-01  3.4527731e-01\n",
      "  3.5783374e-01  3.8099104e-01  4.2183536e-01  4.7801325e-01\n",
      "  5.8363545e-01  7.8186941e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.77771884  0.0681774   0.21538694 -0.1443112   1.1233134   0.40648362\n",
      "  0.14399338  0.99999994  0.         -0.8349072   0.         -0.36870944\n",
      "  1.0000004   0.          0.33468756  0.33852404  0.3509373   0.3736483\n",
      "  0.41393867  0.4688818   0.5723165   0.76796556  1.          1.        ]\n",
      "[ 8.1278968e-01  7.1514547e-02  2.1177989e-01 -1.5610315e-01\n",
      "  1.1163919e+00  2.0861626e-07  3.3122647e-01  1.4369307e+00\n",
      "  0.0000000e+00 -8.3490944e-01  0.0000000e+00 -3.0944383e-01\n",
      " -1.4840504e+00  1.0000000e+00  3.2745048e-01  3.3120400e-01\n",
      "  3.4344795e-01  3.6568627e-01  4.0531370e-01  4.5898467e-01\n",
      "  5.5982691e-01  7.5283021e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 8.4832686e-01  7.1124218e-02  2.1523041e-01 -1.7702432e-01\n",
      "  1.1124020e+00  2.9802322e-08  4.6477211e-01  1.0406858e+00\n",
      "  0.0000000e+00 -8.3494848e-01  0.0000000e+00 -3.5259831e-01\n",
      " -5.7971042e-01  1.0000000e+00  3.1918004e-01  3.2283875e-01\n",
      "  3.3487293e-01  3.5672548e-01  3.9538190e-01  4.4767514e-01\n",
      "  5.4530036e-01  7.3545963e-01  9.8816323e-01  1.0000000e+00]\n",
      "[ 8.8018233e-01  6.3578807e-02  2.1695478e-01 -1.8805236e-01\n",
      "  1.1090486e+00 -1.4901161e-07  5.9177923e-01  1.0000000e+00\n",
      "  0.0000000e+00 -8.3491319e-01  0.0000000e+00 -4.2346597e-01\n",
      " -5.6459045e-01  1.0000000e+00  3.1043124e-01  3.1398967e-01\n",
      "  3.2579523e-01  3.4721854e-01  3.8484472e-01  4.3571174e-01\n",
      "  5.2982968e-01  7.1705383e-01  9.6681070e-01  1.0000000e+00]\n",
      "[ 9.0804118e-01  5.5665065e-02  2.1788853e-01 -1.9883907e-01\n",
      "  1.1065822e+00 -2.0861626e-07  7.1686542e-01  9.9999994e-01\n",
      "  0.0000000e+00 -8.3490700e-01  0.0000000e+00 -4.8857248e-01\n",
      " -5.4799944e-01  1.0000000e+00  3.0117390e-01  3.0462623e-01\n",
      "  3.1618270e-01  3.3712906e-01  3.7366188e-01  4.2305332e-01\n",
      "  5.1334792e-01  6.9754547e-01  9.4427979e-01  1.0000000e+00]\n",
      "[ 9.2901868e-01  4.1906726e-02  2.1692595e-01 -2.0613290e-01\n",
      "  1.1050200e+00 -2.9802322e-08  8.5134602e-01  1.0969818e+00\n",
      "  0.0000000e+00 -8.3491033e-01  0.0000000e+00 -5.4956222e-01\n",
      " -5.1205140e-01  1.0000000e+00  2.9156521e-01  2.9490736e-01\n",
      "  3.0620003e-01  3.2663435e-01  3.6202994e-01  4.0991470e-01\n",
      "  4.9672356e-01  6.7727238e-01  9.2093998e-01  1.0000000e+00]\n",
      "[ 9.4847482e-01  3.9018787e-02  2.0790736e-01 -2.0884782e-01\n",
      "  1.1047962e+00  4.4703484e-08  9.0805185e-01  4.6787369e-01\n",
      "  0.0000000e+00 -8.3491069e-01  0.0000000e+00 -6.1727726e-01\n",
      " -5.6767780e-01  1.0000000e+00  2.8181091e-01  2.8513041e-01\n",
      "  2.9605767e-01  3.1594568e-01  3.5018301e-01  3.9657736e-01\n",
      "  4.7984976e-01  6.5665400e-01  8.9731967e-01  1.0000000e+00]\n",
      "[ 9.6872967e-01  4.0988024e-02  2.0385657e-01 -2.0949948e-01\n",
      "  1.1049697e+00 -5.9604645e-08  9.0821946e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3491248e-01  0.0000000e+00 -7.6873016e-01\n",
      " -1.6553450e+00  1.0000000e+00  2.7202010e-01  2.7532256e-01\n",
      "  2.8587392e-01  3.0520242e-01  3.3827555e-01  3.8319030e-01\n",
      "  4.6287879e-01  6.3449407e-01  8.7351412e-01  1.0000000e+00]\n",
      "[ 9.5100534e-01 -2.0380022e-02  9.0297773e-02 -1.5897382e-02\n",
      "  1.1081389e+00 -7.6308846e-04  8.0580509e-01 -9.1368347e-01\n",
      "  0.0000000e+00 -8.3397776e-01  1.0882318e-04 -6.6733670e-01\n",
      "  8.3460838e-02  0.0000000e+00  2.7207285e-01  2.7543202e-01\n",
      "  2.8598759e-01  3.0550569e-01  3.3861166e-01  3.8325971e-01\n",
      "  4.6354043e-01  6.3575953e-01  8.7319160e-01  1.0000000e+00]\n",
      "[ 9.3309742e-01 -2.9832553e-02  1.1221155e-01 -1.9168934e-03\n",
      "  1.0675464e+00 -5.1613218e-01  9.2923129e-01  1.0000557e+00\n",
      "  0.0000000e+00 -8.3436430e-01 -1.3664365e-05 -6.4388657e-01\n",
      "  3.9473068e-02  0.0000000e+00  2.7244201e-01  2.7587777e-01\n",
      "  2.8645045e-01  3.0624005e-01  3.3942562e-01  3.8376084e-01\n",
      "  4.6494564e-01  6.3746256e-01  8.7346131e-01  1.0000000e+00]\n",
      "[ 0.915589   -0.03318184  0.13578035 -0.00349065  1.1107782   0.5452777\n",
      "  0.8118485  -1.          0.         -0.8347525   0.         -0.63769674\n",
      "  0.0523497   0.          0.27241725  0.27593812  0.28651312  0.3065819\n",
      "  0.33980453  0.3837228   0.4657604   0.6378131   0.87263036  1.        ]\n",
      "[ 8.9696145e-01 -3.7172366e-02  1.4759462e-01  8.4457779e-03\n",
      "  1.1107064e+00  1.3411045e-07  8.6405444e-01  4.3282568e-01\n",
      "  0.0000000e+00 -8.3491141e-01 -1.4901161e-08 -6.2673962e-01\n",
      "  9.9869549e-02  0.0000000e+00  2.7278975e-01  2.7640861e-01\n",
      "  2.8700161e-01  3.0741253e-01  3.4063110e-01  3.8422748e-01\n",
      "  4.6738660e-01  6.3906181e-01  8.7264997e-01  1.0000000e+00]\n",
      "[ 8.7893695e-01 -3.6069896e-02  1.4078350e-01  1.5608863e-02\n",
      "  1.1105111e+00  1.3709068e-06  8.3600557e-01 -2.3726623e-01\n",
      "  0.0000000e+00 -8.3488959e-01 -1.7881393e-07 -6.1169708e-01\n",
      "  1.2362188e-01  0.0000000e+00  2.7349675e-01  2.7721420e-01\n",
      "  2.8783810e-01  3.0861014e-01  3.4148395e-01  3.8518950e-01\n",
      "  4.7021407e-01  6.4101803e-01  8.7347865e-01  1.0000000e+00]\n",
      "[ 8.5782731e-01 -4.2251915e-02  1.6341704e-01  2.3119576e-02\n",
      "  1.0882435e+00 -2.7573082e-01  9.5630133e-01  9.9999982e-01\n",
      "  0.0000000e+00 -8.3487433e-01  2.9802322e-08 -5.9181786e-01\n",
      "  1.6458467e-01  0.0000000e+00  2.7455020e-01  2.7838543e-01\n",
      "  2.8905421e-01  3.1026864e-01  3.4275594e-01  3.8662428e-01\n",
      "  4.7399402e-01  6.4379537e-01  8.7497646e-01  1.0000000e+00]\n",
      "[ 0.8343069  -0.04713735  0.18488312  0.01806222  1.1507821   0.7916802\n",
      "  0.8379582  -1.          0.         -0.8348994   0.         -0.5712433\n",
      "  0.1685308   0.          0.27536437  0.2793276   0.29003248  0.31171045\n",
      "  0.3437375   0.3878906   0.4775123   0.64611655  0.87579995  1.        ]\n",
      "[ 8.0983549e-01 -5.1668622e-02  1.9752009e-01  3.6159180e-02\n",
      "  1.1349111e+00  1.7881393e-07  9.7823572e-01  8.7416220e-01\n",
      "  0.0000000e+00 -8.3491462e-01 -2.9802322e-08 -5.4162478e-01\n",
      "  2.4147385e-01  0.0000000e+00  2.7723080e-01  2.8123719e-01\n",
      "  2.9226324e-01  3.1427419e-01  3.4586561e-01  3.9157966e-01\n",
      "  4.8305273e-01  6.5053111e-01  8.7873858e-01  1.0000000e+00]\n",
      "[ 7.8757387e-01 -5.0927572e-02  1.9025508e-01  4.9424659e-02\n",
      "  1.1351612e+00  1.5968084e-04  9.3492830e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3497763e-01 -5.2452087e-06 -5.0854397e-01\n",
      "  2.8731695e-01  0.0000000e+00  2.7972016e-01  2.8376251e-01\n",
      "  2.9528067e-01  3.1751886e-01  3.4873632e-01  3.9615190e-01\n",
      "  4.8973322e-01  6.5625113e-01  8.8314092e-01  1.0000000e+00]\n",
      "[ 7.6259035e-01 -5.0059341e-02  1.8644442e-01  5.6974731e-02\n",
      "  1.1339810e+00 -1.6987324e-06  8.3281851e-01 -8.7763089e-01\n",
      "  0.0000000e+00 -8.3490855e-01  2.3841858e-07 -4.7487593e-01\n",
      "  2.7672535e-01  0.0000000e+00  2.8247058e-01  2.8655273e-01\n",
      "  2.9857779e-01  3.2106432e-01  3.5192344e-01  4.0112048e-01\n",
      "  4.9693879e-01  6.6253918e-01  8.8814497e-01  1.0000000e+00]\n",
      "[ 7.3218906e-01 -6.0869172e-02  2.0911843e-01  5.8090053e-02\n",
      "  1.1332231e+00  2.9802322e-08  7.8041291e-01 -4.5107424e-01\n",
      "  0.0000000e+00 -8.3490080e-01  0.0000000e+00 -4.3525147e-01\n",
      "  3.2490569e-01  0.0000000e+00  2.8526533e-01  2.8938785e-01\n",
      "  3.0196375e-01  3.2470527e-01  3.5514694e-01  4.0624997e-01\n",
      "  5.0443113e-01  6.6895950e-01  8.9309341e-01  1.0000000e+00]\n",
      "[ 0.6987562  -0.06690831  0.22824726  0.05973689  1.1325903   0.\n",
      "  0.7451644  -0.31008065  0.         -0.8349059   0.         -0.39104843\n",
      "  0.35966232  0.          0.28814036  0.2923044   0.30547193  0.32847768\n",
      "  0.35845268  0.41158316  0.51225764  0.67532533  0.898089    1.        ]\n",
      "[ 0.65905285 -0.07942726  0.24847527  0.0591882   1.1322104   0.\n",
      "  0.7660222   0.16586013  0.         -0.8348578   0.         -0.33951592\n",
      "  0.42039332  0.          0.2909785   0.29518354  0.30897793  0.33152688\n",
      "  0.36169818  0.4169447   0.51997024  0.6811573   0.9020152   1.        ]\n",
      "[ 6.2367016e-01 -7.0859842e-02  2.6057073e-01  6.7480117e-02\n",
      "  1.1304235e+00  5.3644180e-07  6.8411577e-01 -7.2339320e-01\n",
      "  0.0000000e+00 -8.3490640e-01 -5.9604645e-08 -2.8881502e-01\n",
      "  4.1244471e-01  0.0000000e+00  2.9422560e-01  2.9873154e-01\n",
      "  3.1294501e-01  3.3494717e-01  3.6542976e-01  4.2297915e-01\n",
      "  5.2846867e-01  6.8783432e-01  9.0561473e-01  1.0000000e+00]\n",
      "[ 0.57802993 -0.09135129  0.28078827  0.06892379  1.0987031  -0.38658065\n",
      "  0.80223036  0.96186066  0.         -0.8349102   0.         -0.22486532\n",
      "  0.5192916   0.          0.29751515  0.30259913  0.31699663  0.33839977\n",
      "  0.36952558  0.42916632  0.53721786  0.69459516  0.9090713   1.        ]\n",
      "[ 0.52626044 -0.10351366  0.3059254   0.06869513  1.0962238  -0.02602458\n",
      "  0.86301446  0.49704966  0.         -0.83491045  0.         -0.15135884\n",
      "  0.595537    0.          0.30078036  0.3064854   0.32106784  0.34180784\n",
      "  0.37491003  0.4364927   0.54611427  0.7013008   0.9122133   1.        ]\n",
      "[ 0.46606746 -0.12036113  0.33303708  0.06488314  1.1653496   0.88072\n",
      "  0.74630785 -1.          0.         -0.83490545  0.         -0.0655762\n",
      "  0.69759005  0.          0.303848    0.31021813  0.32497814  0.34497714\n",
      "  0.3801349   0.44378594  0.5548375   0.7075917   0.914668    1.        ]\n",
      "[ 0.40337735 -0.1302413   0.3501719   0.07497765  1.1349082   0.\n",
      "  0.9340073   0.9999998   0.         -0.8349139   0.          0.03049374\n",
      "  0.80357844  0.          0.30758917  0.31465167  0.32882217  0.3488665\n",
      "  0.38627678  0.45224524  0.5640407   0.71401024  0.91826016  1.        ]\n",
      "[ 3.4155512e-01 -1.2352270e-01  3.7383857e-01  8.9589491e-02\n",
      "  1.1345822e+00  4.1723251e-07  9.3490624e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490729e-01  0.0000000e+00  1.3302499e-01\n",
      "  8.3215427e-01  0.0000000e+00  3.1245786e-01  3.1963214e-01\n",
      "  3.3298716e-01  3.5328537e-01  3.9315096e-01  4.6166730e-01\n",
      "  5.7169694e-01  7.1976310e-01  9.2256433e-01  1.0000000e+00]\n",
      "[ 2.7768585e-01 -1.2778242e-01  3.7539917e-01  9.5858440e-02\n",
      "  1.1321566e+00  3.8307905e-04  8.2265413e-01 -9.9996489e-01\n",
      "  0.0000000e+00 -8.3490950e-01 -1.2993813e-05  2.4429899e-01\n",
      "  9.0906978e-01  0.0000000e+00  3.1759748e-01  3.2488978e-01\n",
      "  3.3742869e-01  3.5860229e-01  4.0038332e-01  4.7153655e-01\n",
      "  5.7980973e-01  7.2598112e-01  9.3301076e-01  1.0000000e+00]\n",
      "[ 2.0744480e-01 -1.4051712e-01  3.8192976e-01  8.6425267e-02\n",
      "  1.1280373e+00 -5.8239698e-04  7.1492112e-01 -1.0000418e+00\n",
      "  0.0000000e+00 -8.3490962e-01  1.3828278e-05  3.6865234e-01\n",
      "  1.0128552e+00  0.0000000e+00  3.2226774e-01  3.2966730e-01\n",
      "  3.4136298e-01  3.6453784e-01  4.0725973e-01  4.8041379e-01\n",
      "  5.8711261e-01  7.3130196e-01  9.4338328e-01  1.0000000e+00]\n",
      "[ 0.13891289 -0.13725688  0.38371548  0.07542897  1.0481986  -0.9810933\n",
      "  0.8417361   1.          0.         -0.83490855  0.          0.49015564\n",
      "  1.0000005   0.          0.3263902   0.33306223  0.34471864  0.36983415\n",
      "  0.41426894  0.48834443  0.5934792   0.73561895  0.9522303   1.        ]\n",
      "[ 0.07133845 -0.13536367  0.3905699   0.05573918  0.9682857  -1.0000005\n",
      "  0.9631361   0.99999994  0.         -0.8349081   0.          0.611022\n",
      "  1.          0.          0.32957634  0.33534324  0.34707946  0.3740407\n",
      "  0.4200263   0.49481314  0.59804773  0.7381791   0.9584545   1.        ]\n",
      "[ 0.00696064 -0.12934718  0.3930289   0.0384013   0.93673986 -0.35741884\n",
      "  0.8524928  -0.9999998   0.         -0.8264475   0.12162125  0.7335107\n",
      "  1.          0.          0.33196425  0.33681342  0.34875283  0.37731394\n",
      "  0.42470333  0.50002265  0.6007906   0.7390563   0.9610166   1.        ]\n",
      "[-0.06996898 -0.15461941  0.38621947  0.02330471  0.9206368  -0.1375171\n",
      "  1.0830834   2.137331    1.         -0.7467179   0.9999997   0.72649497\n",
      " -0.03356394  1.          0.33358082  0.33751908  0.3509359   0.3796758\n",
      "  0.42830792  0.5039868   0.60228467  0.738622    0.96034634  1.        ]\n",
      "[-1.6075362e-01 -1.7571802e-01  3.1902748e-01  3.8827118e-02\n",
      "  1.0403310e+00  1.0038513e+00  9.3489158e-01  6.0145557e-04\n",
      "  1.0000000e+00 -6.5689814e-01  9.9986684e-01  7.3547643e-01\n",
      "  1.8614906e-01  1.0000000e+00  3.3550888e-01  3.3931911e-01\n",
      "  3.5394439e-01  3.8293067e-01  4.3274000e-01  5.0834644e-01\n",
      "  6.0547405e-01  7.4051028e-01  9.6269691e-01  1.0000000e+00]\n",
      "[-0.2438939  -0.16624314  0.30366743  0.03974697  1.1694108   1.6310581\n",
      "  0.81740797 -0.999551    1.         -0.63177365  0.30581516  0.85521215\n",
      "  1.0001022   1.          0.3370212   0.3408486   0.35668996  0.38650292\n",
      "  0.4368423   0.5110928   0.60823     0.74189323  0.9643939   1.        ]\n",
      "[-0.3078585  -0.13505688  0.30852067  0.04092332  1.1349092   0.\n",
      "  1.0219632   1.078137    1.         -0.5582511   1.0000002   0.7426499\n",
      " -0.9999997   1.          0.3387684   0.34261563  0.3597237   0.3904845\n",
      "  0.44114146  0.5141918   0.61138034  0.74365276  0.96657395  1.        ]\n",
      "[-3.5695222e-01 -9.8447219e-02  3.1654486e-01  3.5926629e-02\n",
      "  1.1337779e+00  5.9604645e-08  1.1443887e+00  1.2351762e+00\n",
      "  1.0000000e+00 -4.8759225e-01  8.9592767e-01  6.2517023e-01\n",
      " -9.9999994e-01  0.0000000e+00  3.4020802e-01  3.4411705e-01\n",
      "  3.6243710e-01  3.9411700e-01  4.4504800e-01  5.1685941e-01\n",
      "  6.1402810e-01  7.4485248e-01  9.6803117e-01  1.0000000e+00]\n",
      "[-0.34548908 -0.03757695  0.22938615  0.10047705  1.1599765   0.01490623\n",
      "  1.051094    0.00317537  1.         -0.5118081   0.10479346  0.5934337\n",
      " -0.34735692  0.          0.34640715  0.35122895  0.36992764  0.40285668\n",
      "  0.45472655  0.52610683  0.623508    0.7549261   0.98095644  1.        ]\n",
      "[-3.4099886e-01 -5.7480149e-03  2.0480981e-01  1.2158758e-01\n",
      "  1.1424572e+00 -1.0942705e-03  9.3529236e-01 -2.8228223e-01\n",
      "  1.0000000e+00 -4.7575507e-01  5.4808772e-01  4.7781980e-01\n",
      " -9.9958915e-01  0.0000000e+00  3.5260850e-01  3.5827851e-01\n",
      "  3.7735248e-01  4.1148689e-01  4.6429208e-01  5.3532112e-01\n",
      "  6.3211608e-01  7.6353699e-01  9.9466169e-01  1.0000000e+00]\n",
      "[-3.3066165e-01  2.0241885e-02  2.0444059e-01  1.2779942e-01\n",
      "  1.1348855e+00  1.4901161e-08  8.8823575e-01 -5.7584226e-01\n",
      "  1.0000000e+00 -4.0669024e-01  8.8551676e-01  3.6404389e-01\n",
      " -9.9999982e-01  0.0000000e+00  3.5864043e-01  3.6518416e-01\n",
      "  3.8462576e-01  4.1996580e-01  4.7368374e-01  5.4431099e-01\n",
      "  6.4044571e-01  7.7157372e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-2.97744215e-01  6.58892691e-02  2.08500639e-01  1.21816844e-01\n",
      "  1.13415790e+00 -5.88685274e-04  7.69649804e-01 -1.00020659e+00\n",
      "  1.00000000e+00 -3.54221284e-01  6.63934171e-01  2.46701658e-01\n",
      " -1.00001431e+00  0.00000000e+00  3.64452511e-01  3.71880025e-01\n",
      "  3.91841918e-01  4.28208351e-01  4.82808173e-01  5.52939236e-01\n",
      "  6.48434341e-01  7.79225886e-01  1.00000000e+00  1.00000000e+00]\n",
      "[-2.6563644e-01  6.4076230e-02  2.2410502e-01  1.0846023e-01\n",
      "  1.1330847e+00 -1.0132790e-06  6.5276563e-01 -1.0000001e+00\n",
      "  1.0000000e+00 -3.6647636e-01 -1.0084200e-01  3.7656951e-01\n",
      "  9.9999970e-01  0.0000000e+00  3.6960691e-01  3.7795559e-01\n",
      "  3.9874882e-01  4.3575627e-01  4.9114656e-01  5.6026638e-01\n",
      "  6.5539706e-01  7.8571171e-01  1.0000000e+00  1.0000000e+00]\n",
      "[-0.21749663  0.09619686  0.22019675  0.09670017  1.0741236  -0.7077451\n",
      "  0.6183187   0.02153205  1.         -0.32926923  0.4890771   0.263942\n",
      " -1.0000002   0.          0.37427226  0.38351345  0.4050936   0.44260216\n",
      "  0.49780795  0.5669109   0.6616468   0.7914537   1.          1.        ]\n",
      "[-0.17863292  0.0781162   0.20725149  0.07787773  1.0590304  -0.156344\n",
      "  0.47192496 -0.99999994  1.         -0.26668203  0.8078605   0.15450239\n",
      " -1.0000001   0.          0.3780641   0.38812172  0.41039485  0.44826612\n",
      "  0.5028939   0.5723312   0.6666455   0.7959215   1.          1.        ]\n",
      "[-0.14681402  0.06371591  0.20005001  0.05377145  1.0710278   0.168659\n",
      "  0.35443336 -1.0000001   1.         -0.19482581  0.9094541   0.03879869\n",
      " -0.99999994  0.          0.38079372  0.3914899   0.41435713  0.4524789\n",
      "  0.5064884   0.57609963  0.6698879   0.7985522   1.          1.        ]\n",
      "[-0.1161929   0.06114634  0.19746168  0.03515904  1.083732    0.17177725\n",
      "  0.23801047 -1.          0.         -0.11764927  0.9999998  -0.06605268\n",
      " -1.0000001   0.          0.38315344  0.39391592  0.41730708  0.4555931\n",
      "  0.50894326  0.57860285  0.67167896  0.80007035  1.          1.        ]\n",
      "[-0.04800662  0.13625416  0.24490966  0.02850951  1.0040282  -0.9527118\n",
      "  0.12487996 -0.9999998   0.         -0.17868315 -0.74643373 -0.00216603\n",
      "  0.50301355  0.          0.3855498   0.39637962  0.42038023  0.4588201\n",
      "  0.5113275   0.58097416  0.67312986  0.80323786  1.          1.        ]\n",
      "[ 0.01028617  0.11646008  0.2388042   0.01843941  0.92785233 -0.9081144\n",
      "  0.01181543 -1.          0.         -0.21500164 -0.40558118  0.02618068\n",
      " -0.9222395   1.          0.38740227  0.39828408  0.42284352  0.46138763\n",
      "  0.5130478   0.58261406  0.6738349   0.8053537   1.          1.        ]\n",
      "[ 0.07142769  0.12238338  0.23498097 -0.01182362  0.85413677 -0.8892466\n",
      " -0.10264409 -1.0000001   0.         -0.22946712 -0.22602624 -0.04977655\n",
      " -0.9999998   1.          0.3877685   0.3987518   0.4236614   0.4621707\n",
      "  0.51292443  0.58220947  0.6724034   0.8045167   1.          1.        ]\n",
      "[ 0.13469474  0.12652235  0.23885587 -0.03446125  0.78661406 -0.79207575\n",
      " -0.21690083 -0.99999994  0.         -0.26997235 -0.4906887  -0.167297\n",
      " -1.0000001   0.          0.38716307  0.39852056  0.42341575  0.46179712\n",
      "  0.5115786   0.5804414   0.6695171   0.801703    1.          1.        ]\n",
      "[ 0.19716306  0.12481897  0.24065824 -0.06279272  0.75849766 -0.34409517\n",
      " -0.33395064 -1.0000001   0.         -0.348393   -0.9371647  -0.28039503\n",
      " -0.99999994  0.          0.38522035  0.39690658  0.42170095  0.45982733\n",
      "  0.50855774  0.5767958   0.6646534   0.7961886   1.          1.        ]\n",
      "[ 0.24708854  0.09968045  0.22929439 -0.09193322  0.79799306  0.50356525\n",
      " -0.44724035 -0.99999994  0.         -0.43253836 -1.0000001  -0.3934734\n",
      " -1.0000001   0.          0.38181654  0.39376068  0.4183561   0.45609486\n",
      "  0.5037385   0.57082283  0.6577372   0.7878096   1.          1.        ]\n",
      "[ 0.28929946  0.08411831  0.22369622 -0.11684246  0.87712973  1.0000006\n",
      " -0.55590796 -1.0000001   0.         -0.5173014  -1.0000002  -0.50626636\n",
      " -1.0000001   0.          0.37719265  0.3893427   0.41358805  0.4508967\n",
      "  0.4974069   0.5633115   0.64907056  0.7770095   1.          1.        ]\n",
      "[ 0.3285267   0.07813093  0.21992505 -0.1323155   0.95526785  1.0000001\n",
      " -0.58716166 -0.35832676  0.         -0.60221    -1.         -0.6194627\n",
      " -1.          0.          0.37182742  0.38415015  0.40800193  0.4448067\n",
      "  0.49015877  0.554872    0.6393484   0.7647448   1.          1.        ]\n",
      "[ 0.3554606   0.05356243  0.22115293 -0.12450776  1.0252614   1.0000006\n",
      " -0.45037293  1.0000001   0.         -0.68353444 -1.0000001  -0.49603426\n",
      "  0.99999934  0.          0.36681154  0.3793224   0.40280113  0.4390467\n",
      "  0.48334277  0.5468705   0.6301245   0.753171    1.          1.        ]\n",
      "[ 0.39657563  0.08203101  0.21609072 -0.15586509  1.0475717   0.3745426\n",
      " -0.31878495  0.9999998   0.         -0.7678675  -0.99999994 -0.6097889\n",
      " -0.99999934  0.          0.36034814  0.3729832   0.39600363  0.43122852\n",
      "  0.4747358   0.5370533   0.61883545  0.73873395  0.9824858   1.        ]\n",
      "[ 4.2221627e-01  5.0874792e-02  2.2228988e-01 -1.7674792e-01\n",
      "  1.1173397e+00  9.9999952e-01 -1.7867422e-01  9.9999982e-01\n",
      "  0.0000000e+00 -8.4895164e-01 -9.9999964e-01 -6.0638332e-01\n",
      "  1.9868214e-07  0.0000000e+00  3.5288885e-01  3.6562574e-01\n",
      "  3.8812506e-01  4.2226171e-01  4.6486431e-01  5.2589631e-01\n",
      "  6.0601592e-01  7.2223938e-01  9.5885491e-01  1.0000000e+00]\n",
      "[ 4.4499502e-01  5.0615162e-02  2.0856568e-01 -1.6106859e-01\n",
      "  1.1138740e+00  5.9604645e-08 -1.1527777e-02  1.2993510e+00\n",
      "  0.0000000e+00 -8.3490998e-01  0.0000000e+00 -6.1692929e-01\n",
      " -7.9472862e-08  0.0000000e+00  3.4640270e-01  3.5899046e-01\n",
      "  3.8101858e-01  4.1416314e-01  4.5594865e-01  5.1580793e-01\n",
      "  5.9442323e-01  7.0733476e-01  9.3750715e-01  1.0000000e+00]\n",
      "[ 4.6754500e-01  4.6335679e-02  2.2150010e-01 -1.6869934e-01\n",
      "  1.1107130e+00  2.3841858e-07  1.1559123e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3491439e-01  0.0000000e+00 -4.9658084e-01\n",
      "  9.9999970e-01  0.0000000e+00  3.3966631e-01  3.5200927e-01\n",
      "  3.7353939e-01  4.0562034e-01  4.4650391e-01  5.0514501e-01\n",
      "  5.8216816e-01  6.9184029e-01  9.1709584e-01  1.0000000e+00]\n",
      "[ 4.90479171e-01  4.58710380e-02  2.18005449e-01 -1.87702313e-01\n",
      "  1.10705757e+00 -2.98023224e-08  2.17468858e-01  8.06220949e-01\n",
      "  0.00000000e+00 -8.26658666e-01  1.19351715e-01 -4.31940794e-01\n",
      "  5.24888992e-01  0.00000000e+00  3.32005024e-01  3.44069600e-01\n",
      "  3.65047187e-01  3.96041274e-01  4.35932398e-01  4.93320346e-01\n",
      "  5.68591058e-01  6.76330805e-01  8.95229936e-01  1.00000000e+00]\n",
      "[ 5.1099980e-01  4.0818218e-02  2.2247028e-01 -2.0229974e-01\n",
      "  1.1043251e+00 -1.7881393e-07  3.4359771e-01  9.9999982e-01\n",
      "  0.0000000e+00 -8.3057219e-01  0.0000000e+00 -3.0681312e-01\n",
      "  9.9999970e-01  0.0000000e+00  3.2368436e-01  3.3544657e-01\n",
      "  3.5582942e-01  3.8569069e-01  4.2452139e-01  4.8059511e-01\n",
      "  5.5398524e-01  6.5968621e-01  8.7169361e-01  1.0000000e+00]\n",
      "[ 5.2999520e-01  3.7863772e-02  2.2305484e-01 -2.1904862e-01\n",
      "  1.1013856e+00  1.4901161e-07  4.6951735e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3409327e-01  0.0000000e+00 -1.9709384e-01\n",
      " -1.4669746e+00  1.0000000e+00  3.1457156e-01  3.2600260e-01\n",
      "  3.4574264e-01  3.7443936e-01  4.1213635e-01  4.6684572e-01\n",
      "  5.3821242e-01  6.4177626e-01  8.4625459e-01  1.0000000e+00]\n",
      "[ 5.5014712e-01  4.0181771e-02  2.1946599e-01 -2.4644266e-01\n",
      "  1.0991230e+00 -5.9604645e-08  5.8475244e-01  9.2078322e-01\n",
      "  0.0000000e+00 -8.3471060e-01  0.0000000e+00 -2.8418052e-01\n",
      " -7.9530841e-01  1.0000000e+00  3.0415300e-01  3.1520545e-01\n",
      "  3.3422542e-01  3.6172244e-01  3.9817142e-01  4.5107743e-01\n",
      "  5.2056652e-01  6.2185264e-01  8.1775570e-01  1.0000000e+00]\n",
      "[ 0.56380206  0.02716398  0.22390981 -0.26196513  1.1104288   0.16929843\n",
      "  0.7099577   1.0000001   0.         -0.83490664  0.         -0.34350228\n",
      " -0.8228049   1.          0.29303285  0.3036318   0.32193628  0.3481858\n",
      "  0.38331467  0.43424663  0.501829    0.60072565  0.78784436  1.        ]\n",
      "[ 5.7088029e-01  1.4378983e-02  2.2061451e-01 -2.6302701e-01\n",
      "  1.1095603e+00 -2.2351742e-08  8.3246422e-01  1.0040668e+00\n",
      "  0.0000000e+00 -8.3491379e-01  0.0000000e+00 -4.1901946e-01\n",
      " -8.2690430e-01  1.0000000e+00  2.8180623e-01  2.9193267e-01\n",
      "  3.0953184e-01  3.3454305e-01  3.6829558e-01  4.1729012e-01\n",
      "  4.8287535e-01  5.7948500e-01  7.5841433e-01  1.0000000e+00]\n",
      "[ 5.6409431e-01 -1.1288182e-02  2.1223144e-01 -2.5974780e-01\n",
      "  1.1103940e+00  1.4901161e-08  9.5899379e-01  1.0511259e+00\n",
      "  0.0000000e+00 -8.3491188e-01  0.0000000e+00 -4.7264194e-01\n",
      " -1.3274910e-01  1.0000000e+00  2.7069429e-01  2.8035545e-01\n",
      "  2.9725671e-01  3.2106522e-01  3.5345796e-01  4.0054521e-01\n",
      "  4.6415421e-01  5.5855763e-01  7.2939157e-01  1.0000000e+00]\n",
      "[ 5.4736239e-01 -3.3879466e-02  2.1731934e-01 -1.3869981e-01\n",
      "  1.1146746e+00 -1.5040934e-03  9.3490887e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3260888e-01  5.2496791e-05 -6.0315847e-01\n",
      " -8.4469908e-01  0.0000000e+00  2.6600343e-01  2.7541649e-01\n",
      "  2.9201999e-01  3.1483316e-01  3.4659714e-01  3.9266038e-01\n",
      "  4.5486701e-01  5.4767776e-01  7.1487194e-01  1.0000000e+00]\n",
      "[ 5.1237500e-01 -6.9549434e-02  2.2871262e-01 -3.0339658e-02\n",
      "  1.1099138e+00 -4.5764148e-03  9.3491948e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3610553e-01  1.9362569e-04 -4.9798739e-01\n",
      "  8.6354923e-01  0.0000000e+00  2.6696596e-01  2.7631927e-01\n",
      "  2.9297718e-01  3.1495053e-01  3.4649187e-01  3.9253110e-01\n",
      "  4.5380890e-01  5.4553097e-01  7.1299553e-01  1.0000000e+00]\n",
      "[ 4.7405306e-01 -7.5213559e-02  2.3940423e-01 -5.3267344e-04\n",
      "  1.1070776e+00  2.4409592e-03  9.3491757e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3605748e-01 -1.1000037e-04 -3.6011660e-01\n",
      "  1.1997142e+00  1.0000000e+00  2.6906872e-01  2.7839756e-01\n",
      "  2.9518080e-01  3.1632063e-01  3.4772152e-01  3.9390391e-01\n",
      "  4.5433834e-01  5.4504031e-01  7.1355259e-01  1.0000000e+00]\n",
      "[ 4.3909007e-01 -6.8325631e-02  2.6146442e-01  2.4707181e-02\n",
      "  1.1007128e+00  1.5684962e-04  8.2695055e-01 -9.9998552e-01\n",
      "  0.0000000e+00 -8.3561879e-01 -5.1856041e-06 -3.8770390e-01\n",
      "  4.4906101e-01  0.0000000e+00  2.7237871e-01  2.8174850e-01\n",
      "  2.9835814e-01  3.1900078e-01  3.5034329e-01  3.9574721e-01\n",
      "  4.5630518e-01  5.4615623e-01  7.1653992e-01  1.0000000e+00]\n",
      "[ 3.9829043e-01 -8.0262907e-02  2.7054349e-01  3.1942304e-02\n",
      "  1.0963589e+00  6.2900782e-04  7.1765840e-01 -9.9990940e-01\n",
      "  0.0000000e+00 -8.3538061e-01  1.9444525e-03 -3.1935906e-01\n",
      "  1.0063267e+00  0.0000000e+00  2.7544308e-01  2.8491831e-01\n",
      "  3.0065608e-01  3.2145768e-01  3.5271695e-01  3.9730749e-01\n",
      "  4.5794630e-01  5.4689419e-01  7.1901780e-01  1.0000000e+00]\n",
      "[ 0.34597567 -0.10492193  0.26961133  0.02778802  1.0525706  -0.53462064\n",
      "  0.84056354  1.000009    0.         -0.8225139   0.18258056 -0.21705437\n",
      "  0.7900531   1.          0.27783293  0.28739035  0.30224591  0.32315755\n",
      "  0.35427475  0.39801878  0.45862126  0.54659486  0.71999174  1.        ]\n",
      "[ 0.29715392 -0.09816606  0.31922257  0.04664795  0.9983981  -0.672382\n",
      "  0.96143055  1.          0.         -0.8230532   0.         -0.14177012\n",
      "  0.77248096  0.          0.2813545   0.29103306  0.30486485  0.3259577\n",
      "  0.35697097  0.39975736  0.46044207  0.54734886  0.72292185  1.        ]\n",
      "[ 0.24563816 -0.10332205  0.3593128   0.06146232  1.0062401   0.12086135\n",
      "  0.8462472  -1.          0.         -0.8239508   0.         -0.0310061\n",
      "  0.9064382   0.          0.28570712  0.29553542  0.30823073  0.32926607\n",
      "  0.36049038  0.40222842  0.46307802  0.5488385   0.72768885  1.        ]\n",
      "[ 0.18895724 -0.11386012  0.38787344  0.07325044  0.9349511  -0.8947199\n",
      "  0.9666084   0.9999997   0.         -0.8249485   0.          0.06655741\n",
      "  0.81356573  1.          0.29068795  0.29950625  0.31216112  0.33304894\n",
      "  0.36463198  0.40525302  0.46632993  0.5529084   0.73349845  1.        ]\n",
      "[ 0.11337297 -0.15134445  0.41795465  0.06084196  0.9706032   0.46110418\n",
      "  0.98231685  0.8019748   1.         -0.8205112   0.06604886  0.18817508\n",
      "  0.98253495  0.          0.2951594   0.30266318  0.31545147  0.3361295\n",
      "  0.36681744  0.40737304  0.46853712  0.5579794   0.73764145  1.        ]\n",
      "[ 0.0414908  -0.14271335  0.32829735  0.09412823  1.0811383   1.4899228\n",
      "  0.854759   -1.0000013   1.         -0.8117644   0.10001981  0.30887663\n",
      "  1.0001342   0.          0.30087042  0.3073997   0.3203881   0.34103677\n",
      "  0.37090823  0.41180718  0.47246945  0.5664328   0.74623996  1.        ]\n",
      "[-0.04075454 -0.16441277  0.3344452   0.09128089  1.2058296   1.577559\n",
      "  0.7388326  -0.9989548   1.         -0.7897758   0.26908094  0.42968154\n",
      "  1.0016493   0.          0.3063482   0.31188753  0.32482094  0.345661\n",
      "  0.37467524  0.4158076   0.4756304   0.57436717  0.7549433   1.        ]\n",
      "[-1.11803845e-01 -1.56321913e-01  3.18874389e-01  1.15220755e-01\n",
      "  1.13491058e+00  5.36441803e-07  1.04312801e+00  1.24085045e+00\n",
      "  1.00000000e+00 -7.75740027e-01  3.06223929e-01  5.60827851e-01\n",
      "  9.99999702e-01  0.00000000e+00  3.12246442e-01  3.17892402e-01\n",
      "  3.30742657e-01  3.51962626e-01  3.80206585e-01  4.21753109e-01\n",
      "  4.80879337e-01  5.85321963e-01  7.71666527e-01  1.00000000e+00]\n",
      "[-1.7682692e-01 -1.3047870e-01  3.2533965e-01  1.1824236e-01\n",
      "  1.1336741e+00  5.9604645e-08  1.1945727e+00  1.5450135e+00\n",
      "  1.0000000e+00 -7.6225132e-01  1.8206733e-01  6.8334699e-01\n",
      "  9.9999982e-01  1.0000000e+00  3.1790853e-01  3.2365689e-01\n",
      "  3.3641550e-01  3.5787216e-01  3.8546270e-01  4.2739567e-01\n",
      "  4.8580638e-01  5.9401733e-01  7.8769529e-01  1.0000000e+00]\n",
      "[-0.16516274 -0.05216159  0.24685907  0.17627151  1.166281    0.02198094\n",
      "  1.0880673  -0.00144935  1.         -0.8126678  -0.1839737   0.80532855\n",
      "  0.99842834  0.          0.32821885  0.33415362  0.34707817  0.36817098\n",
      "  0.3965555   0.43950802  0.49793854  0.6106989   0.8181808   1.        ]\n",
      "[-1.6683467e-01 -3.0160638e-02  2.2714137e-01  1.9366665e-01\n",
      "  1.1474842e+00 -5.1985681e-04  9.9880290e-01 -1.8324244e-01\n",
      "  0.0000000e+00 -8.0777043e-01  2.0358457e-01  8.2225066e-01\n",
      "  5.2695036e-02  1.0000000e+00  3.3828089e-01  3.4439760e-01\n",
      "  3.5748431e-01  3.7822279e-01  4.0736365e-01  4.5132992e-01\n",
      "  5.0978076e-01  6.2698048e-01  8.5761362e-01  1.0000000e+00]\n",
      "[-1.5626292e-01  2.1388106e-02  2.2310807e-01  1.9267184e-01\n",
      "  1.1224747e+00 -2.9802322e-08  9.0871233e-01 -6.6198999e-01\n",
      "  0.0000000e+00 -7.4473357e-01  6.5646124e-01  7.2825432e-01\n",
      " -1.0000000e+00  1.0000000e+00  3.4766954e-01  3.5378805e-01\n",
      "  3.6717278e-01  3.8751158e-01  4.1721386e-01  4.6170646e-01\n",
      "  5.2337188e-01  6.4200497e-01  8.9458174e-01  1.0000000e+00]\n",
      "[-0.12999816  0.05268257  0.22276801  0.18768582  1.1220567  -0.00169429\n",
      "  0.7903082  -1.000589    0.         -0.6980559   0.589656    0.6102459\n",
      " -1.0000209   0.          0.35685453  0.36291552  0.37664557  0.3965757\n",
      "  0.4268232   0.4710718   0.53766096  0.6568486   0.9260798   1.        ]\n",
      "[-0.09339383  0.07327452  0.22268657  0.18231907  1.1059678  -0.19074774\n",
      "  0.67307156 -1.0000004   0.         -0.64947945  0.63302416  0.4980865\n",
      " -0.9999998   0.          0.36578742  0.37178746  0.38585314  0.40536863\n",
      "  0.43614244  0.48013562  0.55154455  0.6718008   0.9566894   1.        ]\n",
      "[-0.05872637  0.06947586  0.21876733  0.17128606  1.0856454  -0.23427458\n",
      "  0.55633837 -1.          0.         -0.5807459   0.875636    0.38281828\n",
      " -0.99999994  0.          0.37420243  0.3801378   0.39425442  0.41362014\n",
      "  0.44488424  0.48861137  0.5646044   0.68583566  0.98681706  1.        ]\n",
      "[-0.00592525  0.10550462  0.2282548   0.16264896  1.0027614  -0.99999964\n",
      "  0.52209485  0.05834426  1.         -0.53647214  0.6037271   0.27852267\n",
      " -1.          0.          0.3822447   0.38810185  0.40170217  0.42143372\n",
      "  0.45315385  0.49656776  0.5770428   0.6991336   1.          1.        ]\n",
      "[ 0.05643046  0.12529455  0.22412907  0.14751913  0.94636595 -0.7171378\n",
      "  0.36912    -0.99999976  1.         -0.4984181   0.4923221   0.16801733\n",
      " -1.0000001   0.          0.38968146  0.3954586   0.40855667  0.42862496\n",
      "  0.46076077  0.50385773  0.5871688   0.71137595  1.          1.        ]\n",
      "[ 0.10789005  0.10309843  0.21497777  0.12364134  0.91868025 -0.31752536\n",
      "  0.25245166 -1.0000001   1.         -0.43999195  0.7403259   0.05253494\n",
      " -1.0000001   0.          0.39591107  0.40159726  0.4141983   0.4344448\n",
      "  0.46700943  0.5097557   0.5950558   0.7228465   1.          1.        ]\n",
      "[ 0.15329844  0.09084162  0.20939249  0.09942099  0.91531205 -0.03240329\n",
      "  0.13614428 -1.          0.         -0.3774032   0.8239324  -0.0498389\n",
      " -0.99999994  0.          0.4009132   0.4065242   0.41862646  0.43899274\n",
      "  0.4714811   0.5145898   0.6012189   0.73311716  1.          1.        ]\n",
      "[ 0.19551258  0.08438935  0.21007596  0.06692767  0.9501624   0.45725077\n",
      "  0.02161735 -1.          0.         -0.33644578  0.5197931  -0.1668284\n",
      " -0.9999998   0.          0.40427533  0.4099334   0.42151755  0.44193593\n",
      "  0.47395816  0.51903164  0.60519403  0.7402507   1.          1.        ]\n",
      "[ 0.2446366   0.09791678  0.22381876  0.03493306  1.0064139   0.72883993\n",
      " -0.08738697 -0.99999994  0.         -0.3544023  -0.19556826 -0.27989078\n",
      " -0.9999998   0.          0.4061677   0.4118522   0.4228624   0.44325978\n",
      "  0.4747383   0.5214541   0.60695875  0.74430984  1.          1.        ]\n",
      "[ 0.30140817  0.1130533   0.24198918  0.00315279  1.0832095   1.0000006\n",
      " -0.19099939 -1.          0.         -0.43770108 -0.98980606 -0.393584\n",
      " -0.9999998   0.          0.40660557  0.41229624  0.42266676  0.44296914\n",
      "  0.4738171   0.5218754   0.6065192   0.74532807  1.          1.        ]\n",
      "[ 0.35819888  0.11307497  0.24724717 -0.01542736  1.1605408   1.0000012\n",
      " -0.2950319  -1.          0.         -0.5218741  -1.0000006  -0.5077592\n",
      " -1.0000004   0.          0.40618008  0.41154617  0.42157233  0.4417384\n",
      "  0.4719199   0.52111304  0.60479695  0.7445386   1.          1.        ]\n",
      "[ 4.3235722e-01  1.3941965e-01  2.4929829e-01 -1.4008510e-02\n",
      "  1.1349205e+00  1.1920929e-07 -3.3799446e-01 -6.1210912e-01\n",
      "  0.0000000e+00 -6.0980195e-01 -1.0000001e+00 -6.2040901e-01\n",
      " -1.0000001e+00  0.0000000e+00  4.0612221e-01  4.1085145e-01\n",
      "  4.2086068e-01  4.4090804e-01  4.7043836e-01  5.2085471e-01\n",
      "  6.0362107e-01  7.4451888e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 4.9728110e-01  1.2975459e-01  2.5219095e-01 -1.9993575e-02\n",
      "  1.1340287e+00 -5.9604645e-08 -3.8013983e-01 -3.8550243e-01\n",
      "  0.0000000e+00 -6.8962246e-01 -1.0000000e+00 -6.2004292e-01\n",
      "  3.9736431e-08  0.0000000e+00  4.0549839e-01  4.0958059e-01\n",
      "  4.1955885e-01  4.3946031e-01  4.6831498e-01  5.1982027e-01\n",
      "  6.0160267e-01  7.4331445e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 5.5515093e-01  1.1559180e-01  2.3897749e-01 -3.7668377e-02\n",
      "  1.1270621e+00 -1.7881393e-07 -2.4964547e-01  9.9999982e-01\n",
      "  0.0000000e+00 -7.6956004e-01 -9.9999994e-01 -6.1941612e-01\n",
      " -1.9868216e-08  0.0000000e+00  4.0401953e-01  4.0748706e-01\n",
      "  4.1740572e-01  4.3713754e-01  4.6532810e-01  5.1762664e-01\n",
      "  5.9839374e-01  7.4031258e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 6.11646116e-01  1.12806514e-01  2.42711991e-01 -5.64515106e-02\n",
      "  1.12059689e+00  3.57627869e-07 -1.18766904e-01  1.00000012e+00\n",
      "  0.00000000e+00 -8.49546790e-01 -1.00000000e+00 -6.18689775e-01\n",
      "  0.00000000e+00  0.00000000e+00  4.01651889e-01  4.04493809e-01\n",
      "  4.14267808e-01  4.33851272e-01  4.61344182e-01  5.14215529e-01\n",
      "  5.93872666e-01  7.35449314e-01  1.00000000e+00  1.00000000e+00]\n",
      "[ 6.4777756e-01  7.9170689e-02  2.3047468e-01 -4.9932100e-02\n",
      "  1.1194772e+00  4.1723251e-07  1.2180567e-02  1.0000001e+00\n",
      "  0.0000000e+00 -8.3490700e-01  0.0000000e+00 -5.1104283e-01\n",
      "  9.9999970e-01  0.0000000e+00  3.9955735e-01  4.0181637e-01\n",
      "  4.1145793e-01  4.3090856e-01  4.5775431e-01  5.1118970e-01\n",
      "  5.8993971e-01  7.3135644e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 6.8443072e-01  7.4798152e-02  2.3138326e-01 -6.7359656e-02\n",
      "  1.1154752e+00 -3.2782555e-07  1.4156562e-01  9.9999982e-01\n",
      "  0.0000000e+00 -8.3491081e-01  0.0000000e+00 -3.8997722e-01\n",
      "  1.0000004e+00  0.0000000e+00  3.9661118e-01  3.9827222e-01\n",
      "  4.0776134e-01  4.2703724e-01  4.5319912e-01  5.0699592e-01\n",
      "  5.8471352e-01  7.2563839e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 7.1908516e-01  7.0756495e-02  2.3249643e-01 -8.4640436e-02\n",
      "  1.1117299e+00  5.0663948e-07  2.7085602e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3490753e-01  0.0000000e+00 -2.6893127e-01\n",
      "  9.9999976e-01  0.0000000e+00  3.9284250e-01  3.9390102e-01\n",
      "  4.0321970e-01  4.2210573e-01  4.4773352e-01  5.0167710e-01\n",
      "  5.7825208e-01  7.1790975e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 7.5643623e-01  7.6253437e-02  2.3550549e-01 -9.8379441e-02\n",
      "  1.1108478e+00  1.1920929e-07  3.2416296e-01  4.0749288e-01\n",
      "  0.0000000e+00 -8.3490813e-01  0.0000000e+00 -1.4762926e-01\n",
      "  9.9999970e-01  0.0000000e+00  3.8835171e-01  3.8886628e-01\n",
      "  3.9799982e-01  4.1626126e-01  4.4153419e-01  4.9545911e-01\n",
      "  5.7080013e-01  7.0858341e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 8.0028552e-01  8.9394189e-02  2.3664680e-01 -1.0912038e-01\n",
      "  1.1110530e+00  5.9604645e-08  2.5533795e-01 -5.9667850e-01\n",
      "  0.0000000e+00 -8.3490616e-01  0.0000000e+00 -2.5886178e-02\n",
      "  9.9999970e-01  0.0000000e+00  3.8281253e-01  3.8331977e-01\n",
      "  3.9225736e-01  4.0988755e-01  4.3477350e-01  4.8854312e-01\n",
      "  5.6258363e-01  6.9800442e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.8296691   0.05873594  0.23219714 -0.1335221   1.1040897  -0.04115346\n",
      "  0.38274622  0.9999997   0.         -0.8349094   0.         -0.08164108\n",
      " -0.4699622   1.          0.37613982  0.3766382   0.38535652  0.40234548\n",
      "  0.42677352  0.48007396  0.552671    0.68520683  1.          1.        ]\n",
      "[ 8.5723281e-01  5.5095185e-02  2.3584451e-01 -1.5032357e-01\n",
      "  1.1006877e+00  2.0861626e-07  5.0984693e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3491355e-01  0.0000000e+00 -1.3913000e-01\n",
      " -4.8394012e-01  1.0000000e+00  3.6866793e-01  3.6915642e-01\n",
      "  3.7763715e-01  3.9396557e-01  4.1788483e-01  4.7052374e-01\n",
      "  5.4156411e-01  6.7092186e-01  9.9131256e-01  1.0000000e+00]\n",
      "[ 8.8396019e-01  5.3445205e-02  2.3737764e-01 -1.6185699e-01\n",
      "  1.0986540e+00  5.9604645e-08  6.0734904e-01  7.7537602e-01\n",
      "  0.0000000e+00 -8.3490884e-01  0.0000000e+00 -1.9752526e-01\n",
      " -4.9125108e-01  1.0000000e+00  3.6064491e-01  3.6112279e-01\n",
      "  3.6935386e-01  3.8501182e-01  4.0838745e-01  4.6022412e-01\n",
      "  5.2963305e-01  6.5548980e-01  9.6942657e-01  1.0000000e+00]\n",
      "[ 0.89851004  0.02904736  0.24979903 -0.18393326  1.1484575   0.65248543\n",
      "  0.6649934   0.42963925  0.         -0.83490986  0.         -0.25321507\n",
      " -0.46549454  1.          0.35154998  0.3519864   0.35996974  0.37490928\n",
      "  0.39767155  0.44850025  0.5161029   0.63789564  0.9444629   1.        ]\n",
      "[ 9.1564608e-01  3.2306850e-02  2.4017584e-01 -1.8762022e-01\n",
      "  1.1349082e+00  1.4901161e-08  8.4730482e-01  1.2778988e+00\n",
      "  0.0000000e+00 -8.3491194e-01  0.0000000e+00 -3.1104767e-01\n",
      " -4.7886801e-01  0.0000000e+00  3.4237084e-01  3.4273016e-01\n",
      "  3.5050353e-01  3.6475191e-01  3.8708642e-01  4.3662849e-01\n",
      "  5.0244331e-01  6.2005687e-01  9.1914278e-01  1.0000000e+00]\n",
      "[ 0.9367187   0.04223315  0.23076919 -0.18763986  1.1348324   0.\n",
      "  0.8560039   0.07019933  0.         -0.83491164  0.         -0.3698324\n",
      " -0.49350253  0.          0.33313128  0.33341658  0.34097874  0.35455832\n",
      "  0.37646487  0.4246475   0.4887673   0.60203606  0.8935568   1.        ]\n",
      "[ 9.5656568e-01  3.9792996e-02  2.2451256e-01 -1.9459079e-01\n",
      "  1.1348021e+00 -1.4901161e-08  8.2145929e-01 -2.8960061e-01\n",
      "  0.0000000e+00 -8.3491188e-01  0.0000000e+00 -4.2837167e-01\n",
      " -4.9106082e-01  0.0000000e+00  3.2357511e-01  3.2378855e-01\n",
      "  3.3113232e-01  3.4405431e-01  3.6544421e-01  4.1221637e-01\n",
      "  4.7466841e-01  5.8331537e-01  8.6530727e-01  1.0000000e+00]\n",
      "[ 0.976339    0.03961001  0.21684635 -0.20030612  1.1342353   0.\n",
      "  0.72731364 -0.7978378   0.         -0.83491343  0.         -0.4870714\n",
      " -0.49237856  0.          0.31377003  0.3139142   0.321034    0.33331344\n",
      "  0.35410348  0.39942414  0.46021125  0.56402946  0.83390146  1.        ]\n",
      "[ 9.9224281e-01  3.1851478e-02  2.1127182e-01 -2.0561907e-01\n",
      "  1.1329291e+00 -1.9371510e-07  6.1073422e-01 -1.0000001e+00\n",
      "  0.0000000e+00 -8.3490711e-01  0.0000000e+00 -5.4387057e-01\n",
      " -4.7564936e-01  0.0000000e+00  3.0372554e-01  3.0380222e-01\n",
      "  3.1069270e-01  3.2233903e-01  3.4246004e-01  3.8629052e-01\n",
      "  4.4540793e-01  5.4421234e-01  8.0154896e-01  1.0000000e+00]\n",
      "[ 9.9770540e-01  1.1067097e-02  2.1012689e-01 -2.1536376e-01\n",
      "  1.1326804e+00 -2.9802322e-08  5.5757761e-01 -4.4961157e-01\n",
      "  0.0000000e+00 -8.3490944e-01  0.0000000e+00 -5.9649754e-01\n",
      " -4.3939802e-01  0.0000000e+00  2.9320469e-01  2.9321405e-01\n",
      "  2.9986435e-01  3.1087276e-01  3.3023849e-01  3.7250474e-01\n",
      "  4.2990932e-01  5.2339447e-01  7.6748222e-01  1.0000000e+00]\n",
      "[ 9.9345058e-01 -7.7509717e-03  2.1011178e-01 -2.1966572e-01\n",
      "  1.1329861e+00  1.1175871e-08  5.7790422e-01  1.6696377e-01\n",
      "  0.0000000e+00 -8.3491141e-01 -3.7252903e-09 -7.1886575e-01\n",
      " -1.0883226e+00  1.0000000e+00  2.8246504e-01  2.8240702e-01\n",
      "  2.8881225e-01  2.9917863e-01  3.1775334e-01  3.5842168e-01\n",
      "  4.1409114e-01  5.0271565e-01  7.3393482e-01  1.0000000e+00]\n",
      "[ 9.6345133e-01 -5.3568497e-02  2.6299205e-01 -1.4258607e-01\n",
      "  1.1350102e+00  1.5874505e-03  7.0101118e-01  9.9941319e-01\n",
      "  0.0000000e+00 -8.3417493e-01  8.5830688e-06 -6.6694760e-01\n",
      " -1.5540719e-01  1.0000000e+00  2.7523255e-01  2.7515545e-01\n",
      "  2.8123614e-01  2.9101786e-01  3.0975115e-01  3.4939530e-01\n",
      "  4.0345386e-01  4.8977822e-01  7.1371156e-01  1.0000000e+00]\n",
      "[ 9.2557335e-01 -7.2591327e-02  3.0736244e-01 -8.1670068e-02\n",
      "  1.1349804e+00 -5.0023198e-04  8.2413971e-01  1.0000976e+00\n",
      "  0.0000000e+00 -8.3451200e-01 -1.1622906e-06 -6.3968110e-01\n",
      "  4.0055335e-02  1.0000000e+00  2.7077025e-01  2.7069443e-01\n",
      "  2.7603495e-01  2.8563577e-01  3.0526063e-01  3.4433007e-01\n",
      "  3.9688328e-01  4.8196417e-01  7.0355010e-01  1.0000000e+00]\n",
      "[ 8.8644749e-01 -7.8254923e-02  3.2203853e-01 -7.5902790e-02\n",
      "  1.1345329e+00 -1.3239980e-03  9.4463563e-01  1.0000705e+00\n",
      "  0.0000000e+00 -8.3397239e-01  3.1292439e-06 -6.1740589e-01\n",
      "  3.2606009e-01  1.0000000e+00  2.6636446e-01  2.6628983e-01\n",
      "  2.7086058e-01  2.8028142e-01  3.0087519e-01  3.3938333e-01\n",
      "  3.9039290e-01  4.7433153e-01  6.9377154e-01  1.0000000e+00]\n",
      "[ 8.5156739e-01 -7.3642455e-02  2.9562098e-01  2.3528816e-02\n",
      "  1.1300914e+00 -4.7712624e-03  9.3491638e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3573377e-01  2.0664930e-04 -5.8197737e-01\n",
      "  3.0857489e-01  0.0000000e+00  2.6796994e-01  2.6789486e-01\n",
      "  2.7177116e-01  2.8122365e-01  3.0367917e-01  3.4185821e-01\n",
      "  3.9268360e-01  4.7963682e-01  7.0369297e-01  1.0000000e+00]\n",
      "[ 8.1236774e-01 -7.9185151e-02  2.9664278e-01  6.1606571e-02\n",
      "  1.1249976e+00  4.0018559e-04  9.1234434e-01 -2.4325396e-01\n",
      "  0.0000000e+00 -8.3551115e-01 -6.2733889e-05 -5.5954385e-01\n",
      "  3.2929346e-01  1.0000000e+00  2.7077526e-01  2.7069944e-01\n",
      "  2.7387181e-01  2.8339738e-01  3.0794838e-01  3.4537658e-01\n",
      "  3.9690787e-01  4.8748288e-01  7.1871334e-01  1.0000000e+00]\n",
      "[ 7.6866537e-01 -8.7560870e-02  2.9988456e-01  5.0900981e-02\n",
      "  1.1225336e+00 -1.0862947e-03  9.1569376e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3528239e-01  2.1807611e-02 -4.9734640e-01\n",
      "  3.5029855e-01  1.0000000e+00  2.7267915e-01  2.7202401e-01\n",
      "  2.7505821e-01  2.8518757e-01  3.1114167e-01  3.4774846e-01\n",
      "  4.0000010e-01  4.9347633e-01  7.3121500e-01  1.0000000e+00]\n",
      "[ 7.2290814e-01 -9.1612890e-02  3.1820783e-01  5.4244079e-02\n",
      "  1.1220504e+00 -2.3841858e-07  9.1656673e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.2697105e-01  6.5991163e-02 -4.6140170e-01\n",
      "  3.7735569e-01  1.0000000e+00  2.7435768e-01  2.7292931e-01\n",
      "  2.7597362e-01  2.8791609e-01  3.1411850e-01  3.4983096e-01\n",
      "  4.0277088e-01  4.9912545e-01  7.4327087e-01  1.0000000e+00]\n",
      "[ 6.8042457e-01 -8.5206360e-02  3.2586846e-01  6.4218819e-02\n",
      "  1.1201369e+00  2.3245811e-06  8.1003380e-01 -9.2762041e-01\n",
      "  0.0000000e+00 -8.2698822e-01 -2.9802322e-07 -4.0814435e-01\n",
      "  4.3397710e-01  1.0000000e+00  2.7647734e-01  2.7425152e-01\n",
      "  2.7731058e-01  2.9115647e-01  3.1765381e-01  3.5247269e-01\n",
      "  4.0620807e-01  5.0575322e-01  7.5706178e-01  1.0000000e+00]\n",
      "[ 0.63313615 -0.09497077  0.3497249   0.06923111  1.0662932  -0.671145\n",
      "  0.93110514  0.9999998   0.         -0.8275795   0.         -0.34595895\n",
      "  0.49895775  0.          0.2787483   0.27566457  0.2787394   0.2946323\n",
      "  0.320968    0.35530287  0.40989193  0.51405424  0.7686606   1.        ]\n",
      "[ 0.5838016  -0.0988995   0.37326857  0.06858072  1.0480744  -0.22267711\n",
      "  0.93219876  0.          0.         -0.82795596  0.         -0.27911234\n",
      "  0.53676695  0.          0.28012243  0.27692157  0.28092816  0.298053\n",
      "  0.3234017   0.35799694  0.413438    0.5246547   0.77894986  1.        ]\n",
      "[ 0.52781683 -0.11201643  0.40200332  0.06791382  1.0490437   0.01650673\n",
      "  0.93297493  0.          0.         -0.8278094   0.         -0.20404756\n",
      "  0.6172113   0.          0.28120053  0.27798733  0.2840905   0.30140805\n",
      "  0.32568568  0.36070275  0.4168168   0.5353353   0.7891419   1.        ]\n",
      "[ 0.4656637  -0.12435511  0.4309712   0.06982347  1.0644977   0.1979239\n",
      "  0.9337748   0.          0.         -0.8278144   0.         -0.1164422\n",
      "  0.70951587  0.          0.28219524  0.2789707   0.28731173  0.3048257\n",
      "  0.32794917  0.36362866  0.42241806  0.5463886   0.7995853   1.        ]\n",
      "[ 0.39656913 -0.13831702  0.4607113   0.06932008  1.1296875   0.8346999\n",
      "  0.8175167  -1.          0.         -0.8286808   0.         -0.012447\n",
      "  0.8169627   0.          0.28297722  0.2806403   0.29046205  0.30725506\n",
      "  0.3300465   0.36639315  0.4279792   0.55671453  0.8083374   1.        ]\n",
      "[ 3.21787477e-01 -1.49717212e-01  4.88256067e-01  8.12595561e-02\n",
      "  1.12923896e+00 -5.96046448e-08  9.38640475e-01  9.99999821e-01\n",
      "  0.00000000e+00 -8.29472959e-01  0.00000000e+00  1.06164694e-01\n",
      "  9.50213909e-01  0.00000000e+00  2.84150273e-01  2.84212530e-01\n",
      "  2.94159293e-01  3.09691399e-01  3.32663566e-01  3.69767368e-01\n",
      "  4.34440374e-01  5.67246556e-01  8.18084955e-01  1.00000000e+00]\n",
      "[ 2.4604180e-01 -1.5171482e-01  4.8539749e-01  8.1990182e-02\n",
      "  1.1300033e+00 -4.3169856e-03  9.3490732e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3011812e-01  1.4120340e-04  2.3129803e-01\n",
      "  1.0217773e+00  0.0000000e+00  2.8533515e-01  2.8778258e-01\n",
      "  2.9785430e-01  3.1213337e-01  3.3551231e-01  3.7314582e-01\n",
      "  4.4089437e-01  5.7775897e-01  8.2782662e-01  1.0000000e+00]\n",
      "[ 1.7525668e-01 -1.4202370e-01  4.8487329e-01  7.5109355e-02\n",
      "  1.1270258e+00 -1.4364719e-05  8.2322311e-01 -1.0000011e+00\n",
      "  0.0000000e+00 -8.3031011e-01  1.4926314e-02  3.5612369e-01\n",
      "  1.0000010e+00  0.0000000e+00  2.8776821e-01  2.9103625e-01\n",
      "  3.0025178e-01  3.1424284e-01  3.3818737e-01  3.7659824e-01\n",
      "  4.4835624e-01  5.8755296e-01  8.3637238e-01  1.0000000e+00]\n",
      "[ 0.10730175 -0.13657546  0.48968667  0.06324763  1.1024834  -0.24163681\n",
      "  0.7571918   1.8035374   1.         -0.8310129   0.01463592  0.48134965\n",
      "  1.          0.          0.2904119   0.29370993  0.30166873  0.3157258\n",
      "  0.34018403  0.3808038   0.4562463   0.59691286  0.84076756  1.        ]\n",
      "[ 4.0036049e-02 -1.3450465e-01  4.0809622e-01  9.0230569e-02\n",
      "  1.0994095e+00  9.7274780e-04  8.7114716e-01  1.0000781e+00\n",
      "  1.0000000e+00 -7.5523871e-01  9.4808728e-01  4.8785251e-01\n",
      "  4.6675246e-02  0.0000000e+00  2.9439157e-01  2.9773483e-01\n",
      "  3.0467114e-01  3.1891981e-01  3.4392208e-01  3.8678816e-01\n",
      "  4.6609432e-01  6.0912979e-01  8.4875089e-01  1.0000000e+00]\n",
      "[-0.02818262 -0.13636285  0.4135303   0.08324721  1.0986142  -0.00492913\n",
      "  0.99245846  0.9999998   1.         -0.74613976  0.10870546  0.6085581\n",
      "  1.0000001   0.          0.2980163   0.30066472  0.30729887  0.32199344\n",
      "  0.3472367   0.3922814   0.47531354  0.62053317  0.85585403  1.        ]\n",
      "[-0.10255058 -0.14872594  0.35936803  0.09281772  1.2171546   1.4954442\n",
      "  0.87474173 -1.0000001   1.         -0.7262264   0.24939865  0.7299095\n",
      "  0.99999976  0.          0.3020484   0.3037802   0.3104831   0.32561654\n",
      "  0.35114378  0.39828786  0.4846386   0.63254404  0.864166    1.        ]\n",
      "[-0.13914245 -0.08981086  0.3121528   0.1376954   1.1349077   0.\n",
      "  1.1076936   0.447258    1.         -0.6584344   0.99999964  0.6702939\n",
      " -0.58287764  0.          0.30874997  0.30966327  0.31649595  0.33220112\n",
      "  0.3595464   0.40810457  0.49768287  0.64752805  0.87641776  1.        ]\n",
      "[-1.6442432e-01 -6.0178235e-02  3.1379738e-01  1.2896436e-01\n",
      "  1.1351053e+00 -2.3841858e-06  1.1342832e+00  6.1644340e-01\n",
      "  1.0000000e+00 -5.8604479e-01  1.0000021e+00  5.5702811e-01\n",
      " -9.9999666e-01  0.0000000e+00  3.1473944e-01  3.1484625e-01\n",
      "  3.2185617e-01  3.3802617e-01  3.6721009e-01  4.1873294e-01\n",
      "  5.0945443e-01  6.6086990e-01  8.8618213e-01  1.0000000e+00]\n",
      "[-1.5094136e-01 -3.8642514e-02  2.6827797e-01  1.4290652e-01\n",
      "  1.1599118e+00 -4.4703484e-08  1.0461861e+00 -1.7885158e-02\n",
      "  1.0000000e+00 -5.4439062e-01  1.0000004e+00  4.5436883e-01\n",
      " -9.9999934e-01  0.0000000e+00  3.2235718e-01  3.2207704e-01\n",
      "  3.2946545e-01  3.4601778e-01  3.7713963e-01  4.3190166e-01\n",
      "  5.2430767e-01  6.7808694e-01  9.0039361e-01  1.0000000e+00]\n",
      "[-1.4615436e-01 -1.0830880e-04  2.1776170e-01  1.6922018e-01\n",
      "  1.1399938e+00 -2.3341272e-08  9.3519086e-01 -3.9407769e-01\n",
      "  1.0000000e+00 -4.7051162e-01  1.0000001e+00  3.4141225e-01\n",
      " -9.9999994e-01  0.0000000e+00  3.2999942e-01  3.2971263e-01\n",
      "  3.3746177e-01  3.5441583e-01  3.8739398e-01  4.4530451e-01\n",
      "  5.3951651e-01  6.9579363e-01  9.1557908e-01  1.0000000e+00]\n",
      "[-1.18517816e-01  5.49119227e-02  2.23863587e-01  1.61328226e-01\n",
      "  1.13490260e+00  2.98023224e-08  8.40052903e-01 -8.99932563e-01\n",
      "  1.00000000e+00 -4.20667857e-01  6.45460725e-01  2.27812767e-01\n",
      " -9.99999940e-01  0.00000000e+00  3.37079018e-01  3.36786062e-01\n",
      "  3.44889194e-01  3.62216413e-01  3.97010893e-01  4.57976431e-01\n",
      "  5.54324985e-01  7.11157382e-01  9.30969477e-01  1.00000000e+00]\n",
      "[-0.08678751  0.06353085  0.22097756  0.15161687  1.1339478  -0.00312293\n",
      "  0.72150326 -1.0011251   1.         -0.3558666   0.81934464  0.11119473\n",
      " -1.0000919   0.          0.34371784  0.34341913  0.3518614   0.37041357\n",
      "  0.4060717   0.46995202  0.5684896   0.7256184   0.9473663   1.        ]\n",
      "[-0.05670103  0.06008787  0.21707821  0.1362154   1.1328343  -0.00414243\n",
      "  0.6043131  -1.0014492   1.         -0.27860287  1.0008997   0.00554186\n",
      " -0.99926656  0.          0.34959778  0.34929395  0.35805142  0.37781423\n",
      "  0.4143674   0.4803404   0.5812468   0.7385377   0.96192944  1.        ]\n",
      "[-0.02421117  0.06499434  0.2178605   0.11671203  1.1257793  -0.06866866\n",
      "  0.48747396 -1.0000001   0.         -0.20504616  0.9353132  -0.10882592\n",
      " -0.99999994  0.          0.35459796  0.35434473  0.36333746  0.38422737\n",
      "  0.42252862  0.48913643  0.5924105   0.74969     0.9743733   1.        ]\n",
      "[ 0.01825312  0.08478341  0.22633551  0.09624447  1.1011637  -0.2885746\n",
      "  0.3719592  -1.          0.         -0.1624166   0.55796385 -0.21674299\n",
      " -0.99999994  0.          0.3586472   0.35855258  0.36765215  0.38960445\n",
      "  0.42951545  0.49660313  0.60193443  0.75872374  0.98454225  1.        ]\n",
      "[ 5.6694675e-02  7.6844297e-02  2.2584113e-01  7.0906840e-02\n",
      "  1.0993537e+00 -1.7881393e-07  2.5566995e-01 -1.0000001e+00\n",
      "  1.0000000e+00 -1.2407012e-01  4.8898169e-01 -3.3344269e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.6151880e-01  3.6157945e-01\n",
      "  3.7075582e-01  3.9365467e-01  4.3495768e-01  5.0234169e-01\n",
      "  6.0896391e-01  7.6435506e-01  9.9226463e-01  1.0000000e+00]\n",
      "[ 0.09621575  0.07882936  0.24782448  0.06012867  1.1152879   0.21422493\n",
      "  0.14045715 -1.          0.         -0.16605903 -0.48631996 -0.20927\n",
      "  0.9793257   0.          0.36383733  0.3640669   0.37330636  0.3971664\n",
      "  0.4398485   0.5074269   0.6142777   0.7690052   0.998701    1.        ]\n",
      "[ 0.14390182  0.09532531  0.25345123  0.04899415  1.0936096  -0.25952566\n",
      "  0.06514215 -0.643701    0.         -0.2259748  -0.72638315 -0.08664083\n",
      "  1.0000001   0.          0.36565912  0.3660592   0.3755891   0.40013564\n",
      "  0.44412345  0.5118154   0.6187854   0.7727489   1.          1.        ]\n",
      "[ 0.20150392  0.11521655  0.2920457   0.05939721  1.0495751  -0.5141123\n",
      " -0.0501976  -0.9999998   0.         -0.35107738 -1.5592949   0.00373548\n",
      "  0.7359888   1.          0.36789054  0.36848706  0.3789379   0.4037033\n",
      "  0.44921717  0.5170613   0.6241971   0.7773047   1.          1.        ]\n",
      "[ 0.23773743  0.07230895  0.26358867  0.02240824  1.0717435   0.28267288\n",
      " -0.16625059 -1.0000001   0.         -0.38271356 -0.35940814 -0.10911679\n",
      " -0.99999994  1.          0.36838433  0.36915553  0.38036224  0.40522075\n",
      "  0.4518418   0.51960534  0.6265471   0.7786247   1.          1.        ]\n",
      "[ 0.26837173  0.06095865  0.26791304 -0.01189441  1.1497397   0.99365485\n",
      " -0.27638054 -1.0000001   0.         -0.44462848 -0.7210604  -0.2217238\n",
      " -1.          0.          0.36733332  0.3681755   0.38006678  0.40547335\n",
      "  0.45235592  0.5200103   0.6261713   0.77692336  1.          1.        ]\n",
      "[ 3.2022631e-01  9.8766185e-02  2.7957380e-01 -1.4441903e-02\n",
      "  1.1349138e+00  5.9604645e-08 -3.7924922e-01 -9.9999982e-01\n",
      "  0.0000000e+00 -5.3180403e-01 -1.0000002e+00 -3.3210754e-01\n",
      " -1.0000004e+00  0.0000000e+00  3.6643174e-01  3.6727184e-01\n",
      "  3.7987712e-01  4.0607876e-01  4.5272821e-01  5.2059335e-01\n",
      "  6.2596643e-01  7.7536547e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 3.6479348e-01  8.9071684e-02  2.7240759e-01 -2.9249744e-02\n",
      "  1.1342373e+00 -5.9604645e-08 -4.6548533e-01 -7.3700881e-01\n",
      "  0.0000000e+00 -6.0188645e-01 -8.3360773e-01 -4.4696605e-01\n",
      " -1.0000001e+00  0.0000000e+00  3.6468831e-01  3.6552444e-01\n",
      "  3.7877977e-01  4.0565604e-01  4.5189568e-01  5.1987046e-01\n",
      "  6.2431943e-01  7.7225763e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 4.0859798e-01  8.7552711e-02  2.6945993e-01 -4.7520384e-02\n",
      "  1.1339802e+00 -5.9604645e-08 -4.9462712e-01 -2.5700608e-01\n",
      "  0.0000000e+00 -6.8608409e-01 -9.9999994e-01 -5.6063974e-01\n",
      " -9.9999958e-01  0.0000000e+00  3.6208543e-01  3.6291558e-01\n",
      "  3.7676799e-01  4.0421045e-01  4.4995457e-01  5.1784527e-01\n",
      "  6.2122118e-01  7.6756907e-01  9.9808079e-01  1.0000000e+00]\n",
      "[ 4.4561839e-01  7.3952407e-02  2.5347579e-01 -6.2540881e-02\n",
      "  1.1289364e+00 -5.9604645e-08 -3.6837578e-01  9.9999976e-01\n",
      "  0.0000000e+00 -7.7064830e-01 -1.0000000e+00 -6.7423069e-01\n",
      " -9.9999970e-01  0.0000000e+00  3.5879120e-01  3.5998538e-01\n",
      "  3.7398437e-01  4.0186280e-01  4.4705385e-01  5.1468050e-01\n",
      "  6.1689305e-01  7.6160413e-01  9.9022120e-01  1.0000000e+00]\n",
      "[ 4.7915137e-01  6.5854400e-02  2.6147735e-01 -7.1326025e-02\n",
      "  1.1240011e+00  2.3841858e-07 -2.4305952e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.6411458e-01 -1.0705854e+00 -6.3490868e-01\n",
      "  0.0000000e+00  0.0000000e+00  3.5513243e-01  3.5696802e-01\n",
      "  3.7084964e-01  3.9916152e-01  4.4375166e-01  5.1105666e-01\n",
      "  6.1197466e-01  7.5481832e-01  9.8147333e-01  1.0000000e+00]\n",
      "[ 4.9112847e-01  3.5696797e-02  2.4244249e-01 -7.2734073e-02\n",
      "  1.1251645e+00  5.9604645e-08 -1.0365045e-01  1.0787847e+00\n",
      "  0.0000000e+00 -8.3490950e-01  0.0000000e+00 -6.3494444e-01\n",
      " -5.9604645e-08  0.0000000e+00  3.5152823e-01  3.5393068e-01\n",
      "  3.6769417e-01  3.9635339e-01  4.4037268e-01  5.0731587e-01\n",
      "  6.0688227e-01  7.4807262e-01  9.7282684e-01  1.0000000e+00]\n",
      "[ 5.0749362e-01  3.2907873e-02  2.4726373e-01 -8.6807318e-02\n",
      "  1.1218861e+00 -2.6822090e-07  2.1977305e-02  9.9999982e-01\n",
      "  0.0000000e+00 -8.3491707e-01  0.0000000e+00 -5.9431171e-01\n",
      "  3.3589339e-01  0.0000000e+00  3.4705061e-01  3.5003760e-01\n",
      "  3.6364973e-01  3.9259356e-01  4.3594235e-01  5.0235367e-01\n",
      "  6.0041988e-01  7.3985243e-01  9.6203166e-01  1.0000000e+00]\n",
      "[ 5.2054811e-01  2.7206413e-02  2.5309658e-01 -9.7046375e-02\n",
      "  1.1192350e+00  2.3841858e-07  1.4801836e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3491760e-01  0.0000000e+00 -4.7417128e-01\n",
      "  9.9999976e-01  0.0000000e+00  3.4207827e-01  3.4565657e-01\n",
      "  3.5913190e-01  3.8828731e-01  4.3091029e-01  4.9669117e-01\n",
      "  5.9317768e-01  7.3080158e-01  9.5001805e-01  1.0000000e+00]\n",
      "[ 5.32130063e-01  2.42239386e-02  2.53415436e-01 -1.13564394e-01\n",
      "  1.11675882e+00 -2.53319740e-07  2.74038911e-01  9.99999821e-01\n",
      "  0.00000000e+00 -8.34920645e-01  0.00000000e+00 -3.53974342e-01\n",
      "  1.00000024e+00  0.00000000e+00  3.36321712e-01  3.40481192e-01\n",
      "  3.54304045e-01  3.83067489e-01  4.24883693e-01  4.89863396e-01\n",
      "  5.84675670e-01  7.20461786e-01  9.36063528e-01  1.00000000e+00]\n",
      "[ 5.4077119e-01  1.7190669e-02  2.5042832e-01 -1.2762068e-01\n",
      "  1.1139028e+00  1.9371510e-07  3.9898598e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.2602823e-01  1.5469028e-01 -2.2938383e-01\n",
      "  1.0000001e+00  0.0000000e+00  3.2989007e-01  3.3461523e-01\n",
      "  3.4873483e-01  3.7704620e-01  4.1798797e-01  4.8201492e-01\n",
      "  5.7508153e-01  7.0901972e-01  9.2043513e-01  1.0000000e+00]\n",
      "[ 5.5035228e-01  1.9024247e-02  2.5408876e-01 -1.4672206e-01\n",
      "  1.1115150e+00 -1.2665987e-07  5.2364540e-01  9.9999994e-01\n",
      "  0.0000000e+00 -8.2921219e-01  0.0000000e+00 -1.0479820e-01\n",
      "  1.0000002e+00  0.0000000e+00  3.2300889e-01  3.2784566e-01\n",
      "  3.4221303e-01  3.6999491e-01  4.0996671e-01  4.7285065e-01\n",
      "  5.6405067e-01  6.9563466e-01  9.0258259e-01  1.0000000e+00]\n",
      "[ 5.6894875e-01  3.7170764e-02  2.5567880e-01 -1.5511824e-01\n",
      "  1.1116138e+00  2.9802322e-08  4.9533486e-01 -2.4077439e-01\n",
      "  0.0000000e+00 -8.3274984e-01  0.0000000e+00 -1.5306580e-01\n",
      " -1.3367887e+00  1.0000000e+00  3.1596050e-01  3.2069170e-01\n",
      "  3.3528256e-01  3.6250183e-01  4.0146437e-01  4.6312270e-01\n",
      "  5.5241013e-01  6.8155175e-01  8.8379031e-01  1.0000000e+00]\n",
      "[ 5.8941960e-01  4.1692987e-02  2.4576084e-01 -1.7770986e-01\n",
      "  1.1121424e+00  2.9802322e-08  4.1800773e-01 -6.5220457e-01\n",
      "  0.0000000e+00 -8.0518180e-01  3.2308266e-01 -1.8591142e-01\n",
      " -1.0000000e+00  1.0000000e+00  3.0771989e-01  3.1232771e-01\n",
      "  3.2703269e-01  3.5358217e-01  3.9142546e-01  4.5158330e-01\n",
      "  5.3886467e-01  6.6532630e-01  8.6210436e-01  1.0000000e+00]\n",
      "[ 0.6052973   0.03178614  0.23464371 -0.19102381  1.0666015  -0.54938924\n",
      "  0.54061925  0.9999998   0.         -0.7705553   0.44380406 -0.30347013\n",
      " -1.          1.          0.2989667   0.30344346  0.31820056  0.34391764\n",
      "  0.3807159   0.4392482   0.5245067   0.6482039   0.83920306  1.        ]\n",
      "[ 0.62127817  0.03190217  0.24598008 -0.20568098  1.0275588  -0.47409606\n",
      "  0.662768    1.          0.         -0.7652197   0.070049   -0.3753363\n",
      " -0.82325536  1.          0.28954348  0.29387915  0.30867556  0.33349255\n",
      "  0.36917534  0.42594996  0.5089133   0.62979835  0.8145815   1.        ]\n",
      "[ 0.6359568   0.02937212  0.26416975 -0.22546402  1.0057733  -0.26794264\n",
      "  0.7843454   0.99999994  0.         -0.81405663 -0.58970696 -0.36130857\n",
      " -0.10586429  1.          0.27916214  0.28334236  0.29816586  0.32199767\n",
      "  0.35645056  0.4112812   0.49164292  0.60954756  0.7877594   1.        ]\n",
      "[ 6.2369472e-01 -2.4777658e-02  2.4991682e-01 -1.8478435e-01\n",
      "  1.0845068e+00  9.9961346e-01  6.6797471e-01 -1.0000228e+00\n",
      "  0.0000000e+00 -8.2046103e-01  7.9721212e-06 -5.1805925e-01\n",
      " -9.4550115e-01  0.0000000e+00  2.7065372e-01  2.7516958e-01\n",
      "  2.8965160e-01  3.1263664e-01  3.4608793e-01  3.9937109e-01\n",
      "  4.7750100e-01  5.9278864e-01  7.6573694e-01  1.0000000e+00]\n",
      "[ 5.9690404e-01 -5.6807198e-02  2.4806574e-01 -3.9347097e-02\n",
      "  1.1579357e+00  9.8373318e-01  5.5394542e-01 -1.0006608e+00\n",
      "  0.0000000e+00 -8.3271664e-01  3.2475591e-04 -5.0299001e-01\n",
      "  5.0304294e-02  0.0000000e+00  2.6945436e-01  2.7459663e-01\n",
      "  2.8904849e-01  3.1167775e-01  3.4502643e-01  3.9836580e-01\n",
      "  4.7558346e-01  5.8945513e-01  7.6131040e-01  1.0000000e+00]\n",
      "[ 5.6163782e-01 -7.5355195e-02  2.3693152e-01  2.2421272e-02\n",
      "  1.1341753e+00  3.9713085e-03  7.2296774e-01  1.0003456e+00\n",
      "  0.0000000e+00 -8.3523172e-01 -1.7699599e-04 -3.9533949e-01\n",
      "  1.0006913e+00  0.0000000e+00  2.7098623e-01  2.7679145e-01\n",
      "  2.9135883e-01  3.1383270e-01  3.4744194e-01  4.0138724e-01\n",
      "  4.7800487e-01  5.9120780e-01  7.6355356e-01  1.0000000e+00]\n",
      "[ 5.2268308e-01 -7.7172324e-02  2.5473440e-01  6.8293169e-02\n",
      "  1.1338341e+00  2.0682812e-05  7.8460622e-01  5.0113219e-01\n",
      "  0.0000000e+00 -8.3497053e-01 -4.0829182e-06 -2.6333404e-01\n",
      "  1.0026217e+00  1.0000000e+00  2.7433431e-01  2.8090066e-01\n",
      "  2.9568428e-01  3.1810528e-01  3.5245097e-01  4.0691450e-01\n",
      "  4.8308471e-01  5.9621644e-01  7.7023232e-01  1.0000000e+00]\n",
      "[ 0.47777292 -0.08998139  0.25551713  0.06022803  1.1296533  -0.04437727\n",
      "  0.9056866   1.0000163   0.         -0.83191687  0.06991765 -0.19454443\n",
      "  0.3283107   1.          0.277223    0.28454262  0.29951793  0.321853\n",
      "  0.35687205  0.41105267  0.48742324  0.6003723   0.7760118   1.        ]\n",
      "[ 4.3766242e-01 -8.0253288e-02  2.7869624e-01  6.9569752e-02\n",
      "  1.1294012e+00  2.3841858e-07  9.0634108e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.2870108e-01  0.0000000e+00 -1.2845945e-01\n",
      "  5.2437782e-01  0.0000000e+00  2.8097048e-01  2.8870845e-01\n",
      "  3.0363029e-01  3.2615900e-01  3.6193809e-01  4.1583592e-01\n",
      "  4.9246612e-01  6.0464120e-01  7.8279912e-01  1.0000000e+00]\n",
      "[ 3.9605799e-01 -8.3462164e-02  2.8646532e-01  8.2441069e-02\n",
      "  1.1271966e+00  1.8733740e-04  7.9189622e-01 -9.9998266e-01\n",
      "  0.0000000e+00 -8.2903403e-01 -6.1988831e-06 -5.7138681e-02\n",
      "  5.7963723e-01  0.0000000e+00  2.8564560e-01  2.9351234e-01\n",
      "  3.0829278e-01  3.3116740e-01  3.6780035e-01  4.2146367e-01\n",
      "  4.9846157e-01  6.0883081e-01  7.9102206e-01  1.0000000e+00]\n",
      "[ 0.34934396 -0.09394357  0.3096152   0.09092461  1.1150122  -0.10509533\n",
      "  0.6825994  -1.0000001   0.         -0.8303358   0.          0.02653247\n",
      "  0.6696203   0.          0.29076844  0.29877624  0.3134055   0.3366595\n",
      "  0.37422594  0.42764074  0.50504804  0.61346006  0.8000694   1.        ]\n",
      "[ 0.29082215 -0.11738493  0.33553064  0.09829444  1.0647717  -0.61091673\n",
      "  0.76706433  0.66200167  0.         -0.83122486  0.          0.13099635\n",
      "  0.8414448   0.          0.2962623   0.3044214   0.31888515  0.34274822\n",
      "  0.38111517  0.4342558   0.51209635  0.61838996  0.8099088   1.        ]\n",
      "[ 0.22517283 -0.13154852  0.35933715  0.08942086  1.0813644   0.25444895\n",
      "  0.6566194  -1.          0.         -0.8322108   0.          0.24870133\n",
      "  0.9452057   0.          0.30138016  0.3095077   0.32393533  0.348495\n",
      "  0.38733077  0.44026592  0.51723266  0.62242264  0.8201292   1.        ]\n",
      "[ 0.14674993 -0.15712993  0.36564377  0.08016463  1.0621852  -0.22660273\n",
      "  0.7809223   1.          0.         -0.8231574   0.12836999  0.3732611\n",
      "  1.0000027   0.          0.30601352  0.31383047  0.32845962  0.35367593\n",
      "  0.392       0.44510207  0.52145296  0.6255815   0.8289851   1.        ]\n",
      "[ 0.04986021 -0.19379288  0.36680475  0.05238375  1.1027242   0.51862353\n",
      "  0.9026915   1.          0.         -0.79456705  0.3515507   0.49447095\n",
      "  1.0000002   0.          0.30928582  0.31676233  0.33152816  0.35727707\n",
      "  0.39498594  0.4479212   0.52362394  0.6265424   0.8341882   1.        ]\n",
      "[-2.7697695e-02 -1.5532345e-01  3.7297115e-01  5.0566554e-02\n",
      "  1.1019555e+00  2.9802322e-07  9.0496528e-01  0.0000000e+00\n",
      "  0.0000000e+00 -7.8335446e-01  1.5941399e-01  6.1986589e-01\n",
      "  1.0000001e+00  0.0000000e+00  3.1251383e-01  3.1964305e-01\n",
      "  3.3465010e-01  3.6082390e-01  3.9790189e-01  4.5065609e-01\n",
      "  5.2568871e-01  6.2898439e-01  8.3922124e-01  1.0000000e+00]\n",
      "[-1.00037426e-01 -1.45203948e-01  3.76034409e-01  4.16015238e-02\n",
      "  1.09854102e+00  5.96046448e-08  9.22924876e-01  1.71355593e+00\n",
      "  1.00000000e+00 -7.75020540e-01  1.23615146e-01  7.43784189e-01\n",
      "  1.00000012e+00  0.00000000e+00  3.15134168e-01  3.22092593e-01\n",
      "  3.37487817e-01  3.63883555e-01  4.00290936e-01  4.52804714e-01\n",
      "  5.27098656e-01  6.30630970e-01  8.43786120e-01  1.00000000e+00]\n",
      "[-1.8974988e-01 -1.7793861e-01  2.9983225e-01  5.9602808e-02\n",
      "  1.1647706e+00  9.9983978e-01  9.2151976e-01 -8.3198147e-06\n",
      "  1.0000000e+00 -7.4002773e-01  4.0776312e-01  8.6285299e-01\n",
      "  1.0000046e+00  0.0000000e+00  3.1833637e-01  3.2536548e-01\n",
      "  3.4113538e-01  3.6781642e-01  4.0380499e-01  4.5630541e-01\n",
      "  5.3021324e-01  6.3436127e-01  8.5321844e-01  1.0000000e+00]\n",
      "[-0.19840613 -0.04752461  0.2376764   0.14159061  1.1443887   0.03028542\n",
      "  0.9353873   0.00696838  1.         -0.6779215   0.9951217   0.7488928\n",
      " -1.0059458   0.          0.3260513   0.33325076  0.34960118  0.37620762\n",
      "  0.41299182  0.46614888  0.5396441   0.6467723   0.8769662   1.        ]\n",
      "[-0.19390103  0.00850597  0.2290197   0.14563286  1.1348697  -0.00401816\n",
      "  0.9054363  -0.4529856   1.         -0.6273925   0.64684814  0.6322306\n",
      " -0.9995255   0.          0.3334002   0.34076196  0.3576674   0.38417497\n",
      "  0.42156193  0.4752851   0.54785717  0.6585729   0.89958084  1.        ]\n",
      "[-0.17364769  0.04055132  0.22658741  0.15029037  1.1349099   0.\n",
      "  0.8118262  -0.790045    1.         -0.5616523   0.8415898   0.518273\n",
      " -0.9999998   0.          0.34098366  0.34852958  0.36598435  0.39241043\n",
      "  0.43015775  0.48402864  0.5564175   0.67094743  0.92012614  1.        ]\n",
      "[-0.14427549  0.05886022  0.22504868  0.1414643   1.1339083  -0.00263751\n",
      "  0.6934884  -1.0009017   1.         -0.492262    0.87669486  0.40126848\n",
      " -1.0000533   0.          0.34818095  0.35605305  0.37388462  0.40021247\n",
      "  0.43828928  0.4922763   0.5644553   0.682881    0.9386472   1.        ]\n",
      "[-0.11462636  0.05926772  0.2224879   0.12611428  1.129528   -0.04413253\n",
      "  0.5769517  -1.0000001   1.         -0.41826326  0.97322506  0.29644424\n",
      " -1.          0.          0.35460407  0.3627815   0.38095     0.40714487\n",
      "  0.44548824  0.49952653  0.5714394   0.6933845   0.9550441   1.        ]\n",
      "[-0.07973249  0.06982403  0.22360615  0.11374178  1.0982692  -0.36873278\n",
      "  0.46111667 -1.          0.         -0.34056938  0.99999964  0.17175615\n",
      " -1.4612755   1.          0.36048713  0.36895677  0.38743454  0.41346768\n",
      "  0.45203093  0.50607014  0.5776699   0.7028761   0.9699462   1.        ]\n",
      "[-0.02745481  0.10455953  0.23367423  0.09160545  1.0619581  -0.4419296\n",
      "  0.3449242  -1.0000001   1.         -0.3133464   0.3463936   0.06405377\n",
      " -0.9999998   1.          0.36543486  0.37417924  0.39257368  0.41872302\n",
      "  0.457415    0.51134807  0.5825236   0.7105594   0.9832924   1.        ]\n",
      "[ 0.01840874  0.09174639  0.22902201  0.06835855  1.0479047  -0.15006107\n",
      "  0.22865874 -1.          1.         -0.27990246  0.42854    -0.0523684\n",
      " -1.          0.          0.36927557  0.37826365  0.39633742  0.42273745\n",
      "  0.4614706   0.5152093   0.58647764  0.7162106   0.99351126  1.        ]\n",
      "[ 0.04643808  0.05591697  0.21423669  0.04392691  1.0861865   0.48961812\n",
      "  0.11360121 -1.0000001   0.         -0.21144794  0.8815767  -0.16098225\n",
      " -1.0000001   0.          0.37184665  0.3810377   0.39877707  0.42531642\n",
      "  0.46402323  0.51748514  0.589073    0.7197413   1.          1.        ]\n",
      "[ 0.09677109  0.10065028  0.2321232   0.03044473  1.0474235  -0.48049772\n",
      "  0.12916112  0.12274102  0.         -0.21357624 -0.01442224 -0.27825856\n",
      " -0.9999998   0.          0.373942    0.38333446  0.4006931   0.42708886\n",
      "  0.465957    0.51890594  0.5908585   0.7227369   1.          1.        ]\n",
      "[ 0.15149578  0.10935114  0.24498948 -0.00169435  1.0559648   0.13045001\n",
      "  0.01403892 -1.          0.         -0.25397208 -0.48270494 -0.39450514\n",
      " -1.0000001   0.          0.37468082  0.38413587  0.401043    0.42720196\n",
      "  0.4656962   0.5178358   0.5903664   0.7227764   1.          1.        ]\n",
      "[ 0.20206277  0.10073     0.25209925 -0.03444913  1.1154382   0.7716892\n",
      " -0.09428    -1.0000001   0.         -0.33790922 -0.9999997  -0.49066818\n",
      " -0.85574704  0.          0.3739205   0.38335636  0.3997471   0.42557627\n",
      "  0.46349326  0.5148137   0.5875008   0.71972173  1.          1.        ]\n",
      "[ 2.6251423e-01  1.2080268e-01  2.5741339e-01 -3.6029216e-02\n",
      "  1.1143862e+00  5.9604645e-08 -1.8187726e-01 -7.6156396e-01\n",
      "  0.0000000e+00 -4.1929451e-01 -1.0000000e+00 -5.6831956e-01\n",
      " -6.6195041e-01  0.0000000e+00  3.7313914e-01  3.8255528e-01\n",
      "  3.9842302e-01  4.2391789e-01  4.6125013e-01  5.1174110e-01\n",
      "  5.8458310e-01  7.1660697e-01  9.9831355e-01  1.0000000e+00]\n",
      "[ 3.23882967e-01  1.22665875e-01  2.76144534e-01 -3.98814045e-02\n",
      "  1.11280239e+00 -2.38418579e-07 -2.97092676e-01 -1.00000000e+00\n",
      "  0.00000000e+00 -5.32674730e-01 -1.40713656e+00 -4.46068764e-01\n",
      "  9.99999702e-01  0.00000000e+00  3.72216403e-01  3.81609261e-01\n",
      "  3.96913916e-01  4.22045827e-01  4.58746344e-01  5.08343935e-01\n",
      "  5.81327915e-01  7.13100553e-01  9.93922710e-01  1.00000000e+00]\n",
      "[ 3.7187693e-01  9.5924512e-02  2.5481448e-01 -5.1857743e-02\n",
      "  1.1102316e+00 -5.9604645e-08 -2.4779165e-01  3.6982748e-01\n",
      "  0.0000000e+00 -6.1406296e-01 -1.0000001e+00 -3.2277060e-01\n",
      "  1.0000001e+00  0.0000000e+00  3.7063134e-01  3.7956572e-01\n",
      "  3.9474544e-01  4.1950259e-01  4.5557669e-01  5.0431132e-01\n",
      "  5.7722026e-01  7.0841569e-01  9.8772645e-01  1.0000000e+00]\n",
      "[ 4.1622111e-01  8.8514708e-02  2.4032910e-01 -7.6588288e-02\n",
      "  1.1056349e+00  5.9604645e-08 -1.2576461e-01  9.4875783e-01\n",
      "  0.0000000e+00 -6.7021841e-01 -6.9501400e-01 -3.2380319e-01\n",
      " -2.4619928e-02  0.0000000e+00  3.6784413e-01  3.7628603e-01\n",
      "  3.9133459e-01  4.1566837e-01  4.5107615e-01  4.9892992e-01\n",
      "  5.7140452e-01  7.0144689e-01  9.7810781e-01  1.0000000e+00]\n",
      "[ 4.5870411e-01  8.4788702e-02  2.3248944e-01 -1.0086255e-01\n",
      "  1.1003673e+00  2.3841858e-07  3.2706261e-03  1.0000001e+00\n",
      "  0.0000000e+00 -7.0086706e-01 -3.5763633e-01 -4.4074321e-01\n",
      " -9.9999982e-01  0.0000000e+00  3.6388579e-01  3.7183124e-01\n",
      "  3.8670164e-01  4.1055790e-01  4.4524792e-01  4.9218512e-01\n",
      "  5.6388408e-01  6.9221646e-01  9.6511793e-01  1.0000000e+00]\n",
      "[ 5.07660270e-01  9.77432355e-02  2.52513081e-01 -1.20384797e-01\n",
      "  1.09622073e+00 -5.96046448e-08  1.02960944e-01  7.61497557e-01\n",
      "  0.00000000e+00 -7.81911910e-01 -9.99999881e-01 -4.81890440e-01\n",
      " -3.61350626e-01  0.00000000e+00  3.59077007e-01  3.66475970e-01\n",
      "  3.81132185e-01  4.04442817e-01  4.38324481e-01  4.84241426e-01\n",
      "  5.54953814e-01  6.81188583e-01  9.49524045e-01  1.00000000e+00]\n",
      "[ 0.54537445  0.0749129   0.25439915 -0.15862408  1.140809    0.66238505\n",
      "  0.22585511  0.868913    0.         -0.8665468  -0.9999999  -0.58433545\n",
      " -0.9108736   0.          0.3524597   0.359275    0.37353578  0.39630577\n",
      "  0.42926452  0.47405484  0.543278    0.6665662   0.92862177  1.        ]\n",
      "[ 5.6663990e-01  5.3778961e-02  2.2914657e-01 -1.5152630e-01\n",
      "  1.1348908e+00  2.3841858e-07  4.7529495e-01  1.8746353e+00\n",
      "  0.0000000e+00 -8.3491653e-01  0.0000000e+00 -7.1059215e-01\n",
      " -8.7547952e-01  0.0000000e+00  3.4618035e-01  3.5247999e-01\n",
      "  3.6631724e-01  3.8864720e-01  4.2077315e-01  4.6455720e-01\n",
      "  5.3233731e-01  6.5281570e-01  9.0891290e-01  1.0000000e+00]\n",
      "[ 5.9412003e-01  5.6203686e-02  2.5055516e-01 -1.4553440e-01\n",
      "  1.1323814e+00  2.9802322e-07  6.0208070e-01  1.0000001e+00\n",
      "  0.0000000e+00 -8.3491284e-01  0.0000000e+00 -5.9014356e-01\n",
      "  9.9999946e-01  0.0000000e+00  3.4014007e-01  3.4587514e-01\n",
      "  3.5926697e-01  3.8116714e-01  4.1241488e-01  4.5511812e-01\n",
      "  5.2156365e-01  6.3936377e-01  8.8972807e-01  1.0000000e+00]\n",
      "[ 6.2083709e-01  5.4709520e-02  2.5165588e-01 -1.6101237e-01\n",
      "  1.1308695e+00 -2.9802322e-08  7.1765220e-01  9.2379528e-01\n",
      "  0.0000000e+00 -8.3490747e-01  0.0000000e+00 -4.6963859e-01\n",
      "  1.0000001e+00  0.0000000e+00  3.3319321e-01  3.3852315e-01\n",
      "  3.5144591e-01  3.7286934e-01  4.0319392e-01  4.4477543e-01\n",
      "  5.0968152e-01  6.2445855e-01  8.6839485e-01  1.0000000e+00]\n",
      "[ 0.647615    0.05485631  0.2519914  -0.17591809  1.1303375   0.\n",
      "  0.8130462   0.7731412   0.         -0.83491975  0.         -0.3490343\n",
      "  1.0000001   0.          0.32524896  0.33045182  0.34288374  0.36378524\n",
      "  0.39314547  0.43356892  0.4967362   0.6081566   0.8449941   1.        ]\n",
      "[ 0.68325573  0.07284126  0.24700971 -0.18372945  1.1308465   0.\n",
      "  0.767465   -0.38814595  0.         -0.83491355  0.         -0.38969088\n",
      " -1.5066563   1.          0.31693578  0.32200566  0.33394206  0.3542985\n",
      "  0.38268647  0.4219531   0.48326433  0.59114397  0.82078373  1.        ]\n",
      "[ 7.2111011e-01  7.6455705e-02  2.3290184e-01 -2.0251477e-01\n",
      "  1.1310276e+00 -2.6822090e-07  6.4944589e-01 -1.0000000e+00\n",
      "  0.0000000e+00 -8.1314707e-01  2.9869363e-01 -4.1871727e-01\n",
      " -8.1125623e-01  1.0000000e+00  3.0758175e-01  3.1250200e-01\n",
      "  3.2392350e-01  3.4366921e-01  3.7105009e-01  4.0914512e-01\n",
      "  4.6828157e-01  5.7231569e-01  7.9437035e-01  1.0000000e+00]\n",
      "[ 0.75246876  0.06271293  0.22913812 -0.21999985  1.0832691  -0.5840795\n",
      "  0.77135277  0.99999976  0.         -0.7864026   0.33672568 -0.5308348\n",
      " -0.8215361   0.          0.29753458  0.3022941   0.3131829   0.3321533\n",
      "  0.35861441  0.39551282  0.4522724   0.5525928   0.7660534   1.        ]\n",
      "[ 0.79210204  0.07927436  0.26270744 -0.2374897   1.0556803  -0.34009427\n",
      "  0.83171797  0.49538183  0.         -0.8557086  -0.8659461  -0.53772485\n",
      " -0.13509434  0.          0.286709    0.29129535  0.30159524  0.31970003\n",
      "  0.3451691   0.3807327   0.43496135  0.53127605  0.73550314  1.        ]\n",
      "[ 0.79796356  0.01931435  0.2512101  -0.25382602  1.137722    0.9999999\n",
      "  0.7181852  -1.0000001   0.         -0.83492064  0.         -0.61724806\n",
      " -0.5104345   0.          0.27509165  0.2794132   0.289192    0.3064275\n",
      "  0.3308392   0.36506763  0.4165158   0.5085409   0.70280266  1.        ]\n",
      "[ 7.6987147e-01 -5.5787064e-02  2.5245258e-01 -1.6700956e-01\n",
      "  1.1349086e+00  2.4220347e-03  8.4567988e-01  9.9980122e-01\n",
      "  0.0000000e+00 -8.3490592e-01 -2.1785498e-05 -6.1786127e-01\n",
      "  2.3246062e-01  1.0000000e+00  2.6746872e-01  2.7145982e-01\n",
      "  2.8096026e-01  2.9745147e-01  3.2114807e-01  3.5421702e-01\n",
      "  4.0402868e-01  4.9321231e-01  6.7977166e-01  1.0000000e+00]\n",
      "[ 7.4047518e-01 -6.1783109e-02  2.5350147e-01 -2.7801439e-02\n",
      "  1.1219411e+00 -9.2615813e-02  9.7115636e-01  1.0003492e+00\n",
      "  0.0000000e+00 -8.3510566e-01 -2.2292137e-05 -5.8754241e-01\n",
      "  2.8146055e-01  1.0000000e+00  2.6695395e-01  2.7069339e-01\n",
      "  2.8016704e-01  2.9616451e-01  3.1975856e-01  3.5202688e-01\n",
      "  4.0220737e-01  4.9113062e-01  6.7859083e-01  1.0000000e+00]\n",
      "[ 7.09691107e-01 -6.43897727e-02  2.53340989e-01  1.55608775e-02\n",
      "  1.12753320e+00 -4.76241112e-04  9.34915066e-01  0.00000000e+00\n",
      "  0.00000000e+00 -8.35610449e-01  2.02059746e-05 -5.60374737e-01\n",
      "  2.68352658e-01  0.00000000e+00  2.68887550e-01  2.72403181e-01\n",
      "  2.81936675e-01  2.97528058e-01  3.21230769e-01  3.52824122e-01\n",
      "  4.04062659e-01  4.93614793e-01  6.83674395e-01  1.00000000e+00]\n",
      "[ 6.7540479e-01 -6.9415972e-02  2.7288041e-01  2.2109978e-02\n",
      "  1.1245906e+00 -4.6283007e-05  9.3491352e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3546185e-01  6.5565109e-07 -5.4075956e-01\n",
      "  3.0362615e-01  1.0000000e+00  2.7077696e-01  2.7404970e-01\n",
      "  2.8364080e-01  2.9878855e-01  3.2253453e-01  3.5344934e-01\n",
      "  4.0577236e-01  4.9593177e-01  6.8816721e-01  1.0000000e+00]\n",
      "[ 6.3837993e-01 -7.3960260e-02  2.7533871e-01  1.3641754e-02\n",
      "  1.1238980e+00 -1.7881393e-07  9.3490779e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3509970e-01  1.2175977e-02 -4.8461962e-01\n",
      "  3.0005026e-01  1.0000000e+00  2.7170527e-01  2.7479088e-01\n",
      "  2.8440791e-01  2.9907516e-01  3.2209623e-01  3.5296905e-01\n",
      "  4.0613064e-01  4.9657243e-01  6.9018972e-01  1.0000000e+00]\n",
      "[ 6.0036719e-01 -7.6384246e-02  3.0025074e-01  1.8520892e-02\n",
      "  1.1232281e+00  2.0369887e-04  9.3490791e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3503848e-01 -8.8214874e-06 -4.5092440e-01\n",
      "  3.4838614e-01  1.0000000e+00  2.7259004e-01  2.7568570e-01\n",
      "  2.8485927e-01  2.9948094e-01  3.2171515e-01  3.5255143e-01\n",
      "  4.0665081e-01  4.9781591e-01  6.9263142e-01  1.0000000e+00]\n",
      "[ 5.5930984e-01 -8.2116060e-02  3.2244360e-01  2.1497345e-02\n",
      "  1.1231261e+00 -5.4502487e-04  9.3490124e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490843e-01  1.8835068e-05 -4.0252113e-01\n",
      "  3.9472997e-01  0.0000000e+00  2.7348465e-01  2.7659047e-01\n",
      "  2.8521687e-01  2.9985690e-01  3.2124481e-01  3.5203600e-01\n",
      "  4.0712643e-01  4.9936369e-01  6.9510025e-01  1.0000000e+00]\n",
      "[ 5.1556635e-01 -8.7539770e-02  3.4257317e-01  2.5980193e-02\n",
      "  1.1227388e+00  2.3841858e-07  9.1650879e-01 -1.6014047e-01\n",
      "  0.0000000e+00 -8.3486193e-01  0.0000000e+00 -3.4795892e-01\n",
      "  4.4372132e-01  0.0000000e+00  2.7457595e-01  2.7769417e-01\n",
      "  2.8574201e-01  3.0040902e-01  3.2090244e-01  3.5260481e-01\n",
      "  4.0788591e-01  5.0128597e-01  6.9811195e-01  1.0000000e+00]\n",
      "[ 4.6759054e-01 -9.5972128e-02  3.6904299e-01  2.7963953e-02\n",
      "  1.1224140e+00 -4.1723251e-07  9.1738784e-01  0.0000000e+00\n",
      "  0.0000000e+00 -8.3490771e-01  0.0000000e+00 -2.8516769e-01\n",
      "  5.0543737e-01  0.0000000e+00  2.7573869e-01  2.7887011e-01\n",
      "  2.8629407e-01  3.0095384e-01  3.2051823e-01  3.5325545e-01\n",
      "  4.0886319e-01  5.0333124e-01  7.0132077e-01  1.0000000e+00]\n",
      "[ 4.1653579e-01 -1.0214312e-01  3.9053202e-01  3.3317894e-02\n",
      "  1.1218297e+00  5.3644180e-07  8.9151955e-01 -2.2832958e-01\n",
      "  0.0000000e+00 -8.3490485e-01 -5.9604645e-08 -2.1518898e-01\n",
      "  5.6831795e-01  0.0000000e+00  2.7713406e-01  2.7967480e-01\n",
      "  2.8704858e-01  3.0074564e-01  3.2029647e-01  3.5415870e-01\n",
      "  4.1014916e-01  5.0582111e-01  7.0605469e-01  1.0000000e+00]\n",
      "[ 3.6270118e-01 -1.0781669e-01  4.0292287e-01  4.3402929e-02\n",
      "  1.1191870e+00  1.4913082e-04  7.7931166e-01 -9.9998617e-01\n",
      "  0.0000000e+00 -8.3490604e-01 -4.9471855e-06 -1.3667977e-01\n",
      "  6.4137548e-01  0.0000000e+00  2.7898049e-01  2.8083944e-01\n",
      "  2.8824392e-01  3.0095130e-01  3.2051551e-01  3.5561615e-01\n",
      "  4.1209313e-01  5.0919181e-01  7.1224552e-01  1.0000000e+00]\n",
      "[ 0.28766662 -0.15027475  0.4305061   0.03997422  1.1036134  -0.18269658\n",
      "  0.9015231   0.99999976  0.         -0.81666934  0.2293657  -0.05283403\n",
      "  0.67844623  0.          0.28058222  0.28171197  0.28913942  0.3007843\n",
      "  0.320483    0.3566922   0.4136055   0.51238304  0.71777594  1.        ]\n",
      "[ 0.22171317 -0.13225782  0.4611097   0.05344494  1.0708457  -0.39731324\n",
      "  0.9043939   0.          0.         -0.81756485  0.          0.05434555\n",
      "  0.8591842   0.          0.28225663  0.28316844  0.28996375  0.30115125\n",
      "  0.3221255   0.35852027  0.41601744  0.51880044  0.7252131   1.        ]\n",
      "[ 0.14671847 -0.15045102  0.49253953  0.04971876  1.0854795   0.22119182\n",
      "  0.85578847  1.2720056   1.         -0.8188334   0.00553644  0.18020147\n",
      "  0.999413    0.          0.2834182   0.28433377  0.28994933  0.30113626\n",
      "  0.32342598  0.3601083   0.41818783  0.5248028   0.7346123   1.        ]\n",
      "[ 6.8362899e-02 -1.5614957e-01  4.6391472e-01  3.6499955e-02\n",
      "  1.0992719e+00  2.5005668e-01  9.7001183e-01  1.0000000e+00\n",
      "  1.0000000e+00 -8.1901383e-01  5.9604645e-08  3.0570936e-01\n",
      "  1.0000544e+00  0.0000000e+00  2.8406918e-01  2.8498685e-01\n",
      "  2.8950167e-01  3.0067134e-01  3.2413459e-01  3.6113459e-01\n",
      "  4.2020908e-01  5.2945054e-01  7.4569708e-01  1.0000000e+00]\n",
      "[-0.01821693 -0.17224763  0.43387714  0.03118639  1.2042485   1.0510455\n",
      "  0.9349048   0.          1.         -0.77923995  0.49281615  0.38035756\n",
      "  0.51852196  1.          0.28439265  0.2846185   0.2887998   0.30069312\n",
      "  0.32446465  0.36171937  0.42164284  0.5331602   0.75495744  1.        ]\n",
      "[-6.6277536e-04 -3.6595408e-02  2.9390106e-01  1.3528213e-01\n",
      "  1.1560446e+00  1.8315375e-02  9.5770895e-01  3.5640697e-03\n",
      "  1.0000000e+00 -8.5001135e-01 -4.1250592e-01  5.3007823e-01\n",
      "  9.9981397e-01  1.0000000e+00  2.9150432e-01  2.9099983e-01\n",
      "  2.9527488e-01  3.0835176e-01  3.3272877e-01  3.7115794e-01\n",
      "  4.3354249e-01  5.4922503e-01  7.8722513e-01  1.0000000e+00]\n",
      "[-1.02146845e-02 -4.35015708e-02  2.28690490e-01  1.80845186e-01\n",
      "  1.14574957e+00 -1.48536861e-02  9.53436375e-01 -2.80630589e-03\n",
      "  1.00000000e+00 -8.35823298e-01  2.75880098e-04  5.56263745e-01\n",
      "  6.99488819e-01  1.00000000e+00  3.00206512e-01  2.99121290e-01\n",
      "  3.03515673e-01  3.17736775e-01  3.42870802e-01  3.82657975e-01\n",
      "  4.47819114e-01  5.67450821e-01  8.24625850e-01  1.00000000e+00]\n",
      "[-2.4678705e-02 -4.0441081e-02  2.0731157e-01  1.8483208e-01\n",
      "  1.1387774e+00 -2.4080276e-04  9.3512070e-01 -6.1924934e-02\n",
      "  1.0000000e+00 -8.2860583e-01  1.8396127e-01  6.0740805e-01\n",
      "  3.0227488e-02  1.0000000e+00  3.0864614e-01  3.0701408e-01\n",
      "  3.1152439e-01  3.2683936e-01  3.5286194e-01  3.9380851e-01\n",
      "  4.6170121e-01  5.8510327e-01  8.6003977e-01  1.0000000e+00]\n",
      "[-0.02944594 -0.00947134  0.19729476  0.18830039  1.1349009   0.\n",
      "  0.90405697 -0.35476413  1.         -0.7575043   0.85568297  0.5680062\n",
      " -0.5354027   0.          0.3170791   0.31492257  0.3196933   0.3359357\n",
      "  0.36284202  0.4053368   0.47718972  0.60271007  0.8881214   1.        ]\n",
      "[-9.6614109e-03  3.9613426e-02  2.0072888e-01  1.8417256e-01\n",
      "  1.1345813e+00  4.4703484e-08  8.0917031e-01 -7.9844528e-01\n",
      "  1.0000000e+00 -7.1239430e-01  5.7092619e-01  5.1005077e-01\n",
      " -5.0371462e-01  0.0000000e+00  3.2533550e-01  3.2273948e-01\n",
      "  3.2826480e-01  3.4494272e-01  3.7272686e-01  4.1699842e-01\n",
      "  4.9256086e-01  6.2079984e-01  9.1598803e-01  1.0000000e+00]\n",
      "[ 0.02271699  0.06486136  0.19882314  0.1738406   1.1304208  -0.03940693\n",
      "  0.6913278  -1.0000001   1.         -0.65781194  0.69214034  0.39307284\n",
      " -1.          0.          0.33277982  0.3301244   0.33638233  0.35347268\n",
      "  0.38209164  0.42805773  0.5071622   0.63827604  0.9411474   1.        ]\n",
      "[ 0.05536006  0.06531741  0.19631615  0.16281055  1.1118628  -0.21697448\n",
      "  0.5752416  -1.          0.         -0.59165907  0.8629761   0.2849751\n",
      " -1.          0.          0.33967867  0.33696818  0.3439338   0.3614078\n",
      "  0.39080855  0.43836844  0.52081025  0.6545928   0.9623576   1.        ]\n",
      "[ 0.10056754  0.09051926  0.1977214   0.14913924  1.0878146  -0.2815231\n",
      "  0.459638   -0.99999976  1.         -0.53563243  0.7163162   0.17017376\n",
      " -1.          0.          0.34600258  0.34324166  0.35089463  0.36878777\n",
      "  0.39885056  0.44790307  0.5334765   0.669713    0.9819853   1.        ]\n",
      "[ 0.15249343  0.10388424  0.19847342  0.13386615  1.0532953  -0.414652\n",
      "  0.34406263 -1.          1.         -0.48597896  0.65813434  0.06489193\n",
      " -1.0000001   0.          0.3516047   0.34879908  0.35711464  0.37544104\n",
      "  0.4060462   0.45646465  0.5437617   0.684552    0.99962914  1.        ]\n",
      "[ 0.20950261  0.11410934  0.20052312  0.11582085  1.0077426  -0.53665376\n",
      "  0.2287103  -1.          1.         -0.44245964  0.55673057 -0.05000138\n",
      " -0.99999994  0.          0.35639444  0.3535506   0.36250135  0.38121414\n",
      "  0.41238064  0.46393228  0.55274683  0.6998382   1.          1.        ]\n",
      "[ 0.2698333   0.12065037  0.20168754  0.09915125  0.9479857  -0.7225697\n",
      "  0.11413914 -1.          0.         -0.4009974   0.5471004  -0.15557659\n",
      " -1.0000001   0.          0.36038443  0.3578044   0.36706856  0.38612178\n",
      "  0.41806263  0.4710531   0.5604543   0.7131857   1.          1.        ]\n",
      "[ 3.4319440e-01  1.4676140e-01  2.1388698e-01  7.8174800e-02\n",
      "  8.6955124e-01 -9.3126619e-01  4.3296814e-04 -1.0000000e+00\n",
      "  1.0000000e+00 -3.9743763e-01  5.1097214e-02 -2.7220702e-01\n",
      " -9.9999982e-01  0.0000000e+00  3.6341381e-01  3.6131647e-01\n",
      "  3.7067157e-01  3.9001471e-01  4.2263523e-01  4.7703442e-01\n",
      "  5.6668347e-01  7.2435993e-01  1.0000000e+00  1.0000000e+00]\n",
      "[ 0.4051639   0.12393168  0.2071565   0.05219908  0.83287126 -0.43771777\n",
      " -0.1155715  -1.0000001   0.         -0.37812847  0.25033814 -0.38650024\n",
      " -1.0000001   0.          0.36520115  0.36356932  0.37298277  0.39253995\n",
      "  0.42568702  0.48119184  0.57087535  0.7323769   1.          1.        ]\n",
      "[ 0.46517113  0.11976843  0.22007376  0.01426344  0.86186963  0.39821982\n",
      " -0.31166267 -1.7252754   0.         -0.40033436 -0.2553922  -0.49938655\n",
      " -0.9999998   0.          0.36514983  0.36400974  0.37343457  0.39310592\n",
      "  0.42658862  0.4828288   0.5721987   0.73612654  1.          1.        ]\n",
      "[ 0.5198691   0.10897785  0.22666015 -0.01677964  0.9397206   1.0000002\n",
      " -0.4970044  -1.671445    0.         -0.44983488 -0.58512604 -0.6160711\n",
      " -0.99999976  0.          0.36359805  0.36296263  0.37236038  0.3920623\n",
      "  0.42571908  0.4823796   0.5711572   0.7363585   1.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import time\n",
    "\n",
    "env = gym.make('BipedalWalker-v3')\n",
    "env.reset()\n",
    "\n",
    "observation = env.reset()\n",
    "while True:\n",
    "    env.render()\n",
    "    print(observation)\n",
    "    action = new_trainer.compute_action(observation)\n",
    "\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    #time.sleep(.01)\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 22:03:57 (running for 00:00:00.12)<br>Memory usage on this node: 9.8/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/1 GPUs, 0.0/10.47 GiB heap, 0.0/5.24 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO_2022-01-10_22-03-56<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_7faa0_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 22:03:57,129\tERROR syncer.py:111 -- Log sync requires rsync to be installed.\n",
      " pid=9860)\u001b[0m 2022-01-10 22:04:00,195\tINFO trainer.py:722 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also want to then set `eager_tracing=True` in order to reach similar execution speed as with static-graph mode.\n",
      " pid=9860)\u001b[0m 2022-01-10 22:04:00,195\tINFO ppo.py:166 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      " pid=9860)\u001b[0m 2022-01-10 22:04:00,196\tINFO trainer.py:743 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      " pid=15192)\u001b[0m 2022-01-10 22:04:03,863\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      " pid=9860)\u001b[0m 2022-01-10 22:04:05,425\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 22:04:06 (running for 00:00:09.43)<br>Memory usage on this node: 12.8/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/1 GPUs, 0.0/10.47 GiB heap, 0.0/5.24 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO_2022-01-10_22-03-56<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc           </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_7faa0_00000</td><td>RUNNING </td><td>127.0.0.1:9860</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " pid=9860)\u001b[0m 2022-01-10 22:04:06,363\tWARNING util.py:57 -- Install gputil for GPU system monitoring.\n",
      " pid=9860)\u001b[0m 2022-01-10 22:04:06,448\tINFO trainable.py:467 -- Restored on 127.0.0.1 from checkpoint: C:\\Users\\user\\ray_results\\PPO_2022-01-10_22-03-56\\PPO_BipedalWalker-v3_7faa0_00000_0_2022-01-10_22-03-57\\tmp1od85z21restore_from_object\\checkpoint-125\n",
      " pid=9860)\u001b[0m 2022-01-10 22:04:06,448\tINFO trainable.py:475 -- Current state after restoring: {'_iteration': 125, '_timesteps_total': 0, '_time_total': 1534.4250679016113, '_episodes_total': 414}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 22:04:07 (running for 00:00:10.52)<br>Memory usage on this node: 12.8/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/1 GPUs, 0.0/10.47 GiB heap, 0.0/5.24 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO_2022-01-10_22-03-56<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc           </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_7faa0_00000</td><td>RUNNING </td><td>127.0.0.1:9860</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " pid=9860)\u001b[0m 2022-01-10 22:04:10,865\tWARNING deprecation.py:45 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 22:04:12 (running for 00:00:15.56)<br>Memory usage on this node: 12.8/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/1 GPUs, 0.0/10.47 GiB heap, 0.0/5.24 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO_2022-01-10_22-03-56<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc           </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_7faa0_00000</td><td>RUNNING </td><td>127.0.0.1:9860</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_BipedalWalker-v3_7faa0_00000:\n",
      "  agent_timesteps_total: 504000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-01-10_22-04-15\n",
      "  done: false\n",
      "  episode_len_mean: 1600.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 194.93711068465123\n",
      "  episode_reward_mean: 192.35657362883296\n",
      "  episode_reward_min: 189.77603657301466\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 416\n",
      "  experiment_id: c4c0d297f8ed484b8308f2aa3f1df6fa\n",
      "  hostname: LAPTOP-AGKSCH3K\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.6472886204719543\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.023644592612981796\n",
      "          model: {}\n",
      "          policy_loss: -0.020526038482785225\n",
      "          total_loss: 2.978245258331299\n",
      "          vf_explained_var: 0.7964268922805786\n",
      "          vf_loss: 2.9940426349639893\n",
      "    num_agent_steps_sampled: 504000\n",
      "    num_agent_steps_trained: 504000\n",
      "    num_steps_sampled: 504000\n",
      "    num_steps_trained: 504000\n",
      "    num_steps_trained_this_iter: 0\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  num_healthy_workers: 2\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.553846153846152\n",
      "    ram_util_percent: 53.53076923076923\n",
      "  pid: 9860\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0824934241177141\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.32550236512755587\n",
      "    mean_inference_ms: 1.684851672636277\n",
      "    mean_raw_obs_processing_ms: 0.06928573781880422\n",
      "  time_since_restore: 8.620869636535645\n",
      "  time_this_iter_s: 8.620869636535645\n",
      "  time_total_s: 1543.045937538147\n",
      "  timers:\n",
      "    learn_throughput: 953.356\n",
      "    learn_time_ms: 4195.705\n",
      "    load_throughput: 0.0\n",
      "    load_time_ms: 0.0\n",
      "    sample_throughput: 888.312\n",
      "    sample_time_ms: 4502.922\n",
      "    update_time_ms: 1.995\n",
      "  timestamp: 1641873855\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_this_iter: 0\n",
      "  timesteps_total: 504000\n",
      "  training_iteration: 126\n",
      "  trial_id: 7faa0_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 22:04:17,093\tWARNING tune.py:582 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-01-10 22:04:17 (running for 00:00:20.15)<br>Memory usage on this node: 12.8/23.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/12 CPUs, 0/1 GPUs, 0.0/10.47 GiB heap, 0.0/5.24 GiB objects<br>Result logdir: C:\\Users\\user\\ray_results\\PPO_2022-01-10_22-03-56<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BipedalWalker-v3_7faa0_00000</td><td>RUNNING </td><td>127.0.0.1:9860</td><td style=\"text-align: right;\">   126</td><td style=\"text-align: right;\">         1543.05</td><td style=\"text-align: right;\">504000</td><td style=\"text-align: right;\"> 192.357</td><td style=\"text-align: right;\">             194.937</td><td style=\"text-align: right;\">             189.776</td><td style=\"text-align: right;\">              1600</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " pid=9860)\u001b[0m Traceback (most recent call last):\n",
      " pid=9860)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 618, in ray._raylet.execute_task\n",
      " pid=9860)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 659, in ray._raylet.execute_task\n",
      " pid=9860)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 625, in ray._raylet.execute_task\n",
      " pid=9860)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 629, in ray._raylet.execute_task\n",
      " pid=9860)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 578, in ray._raylet.execute_task.function_executor\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 609, in actor_method_executor\n",
      " pid=9860)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 451, in _resume_span\n",
      " pid=9860)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\tune\\trainable.py\", line 314, in train\n",
      " pid=9860)\u001b[0m     result = self.step()\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 451, in _resume_span\n",
      " pid=9860)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\rllib\\agents\\trainer.py\", line 880, in step\n",
      " pid=9860)\u001b[0m     raise e\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\rllib\\agents\\trainer.py\", line 867, in step\n",
      " pid=9860)\u001b[0m     result = self.step_attempt()\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 451, in _resume_span\n",
      " pid=9860)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\rllib\\agents\\trainer.py\", line 920, in step_attempt\n",
      " pid=9860)\u001b[0m     step_results = next(self.train_exec_impl)\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\util\\iter.py\", line 756, in __next__\n",
      " pid=9860)\u001b[0m     return next(self.built_iterator)\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\util\\iter.py\", line 783, in apply_foreach\n",
      " pid=9860)\u001b[0m     for item in it:\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\util\\iter.py\", line 783, in apply_foreach\n",
      " pid=9860)\u001b[0m     for item in it:\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\util\\iter.py\", line 843, in apply_filter\n",
      " pid=9860)\u001b[0m     for item in it:\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\util\\iter.py\", line 843, in apply_filter\n",
      " pid=9860)\u001b[0m     for item in it:\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\util\\iter.py\", line 783, in apply_foreach\n",
      " pid=9860)\u001b[0m     for item in it:\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\util\\iter.py\", line 783, in apply_foreach\n",
      " pid=9860)\u001b[0m     for item in it:\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\util\\iter.py\", line 783, in apply_foreach\n",
      " pid=9860)\u001b[0m     for item in it:\n",
      " pid=9860)\u001b[0m   [Previous line repeated 1 more time]\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\util\\iter.py\", line 876, in apply_flatten\n",
      " pid=9860)\u001b[0m     for item in it:\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\util\\iter.py\", line 783, in apply_foreach\n",
      " pid=9860)\u001b[0m     for item in it:\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\util\\iter.py\", line 783, in apply_foreach\n",
      " pid=9860)\u001b[0m     for item in it:\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\util\\iter.py\", line 783, in apply_foreach\n",
      " pid=9860)\u001b[0m     for item in it:\n",
      " pid=9860)\u001b[0m   [Previous line repeated 1 more time]\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\util\\iter.py\", line 471, in base_iterator\n",
      " pid=9860)\u001b[0m     yield ray.get(futures, timeout=timeout)\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      " pid=9860)\u001b[0m     return func(*args, **kwargs)\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\worker.py\", line 1715, in get\n",
      " pid=9860)\u001b[0m     raise value\n",
      " pid=9860)\u001b[0m ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
      " pid=9860)\u001b[0m \n",
      " pid=9860)\u001b[0m During handling of the above exception, another exception occurred:\n",
      " pid=9860)\u001b[0m \n",
      " pid=9860)\u001b[0m Traceback (most recent call last):\n",
      " pid=9860)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 759, in ray._raylet.task_execution_handler\n",
      " pid=9860)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 580, in ray._raylet.execute_task\n",
      " pid=9860)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 716, in ray._raylet.execute_task\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\_private\\utils.py\", line 117, in push_error_to_driver\n",
      " pid=9860)\u001b[0m     worker.core_worker.push_error(job_id, error_type, message, time.time())\n",
      " pid=9860)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 2072, in ray._raylet.CoreWorker.push_error\n",
      " pid=9860)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 160, in ray._raylet.check_status\n",
      " pid=9860)\u001b[0m ray.exceptions.RaySystemError: System error: Unknown error\n",
      " pid=9860)\u001b[0m \n",
      " pid=9860)\u001b[0m During handling of the above exception, another exception occurred:\n",
      " pid=9860)\u001b[0m \n",
      " pid=9860)\u001b[0m Traceback (most recent call last):\n",
      " pid=9860)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 783, in ray._raylet.task_execution_handler\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\_private\\utils.py\", line 117, in push_error_to_driver\n",
      " pid=9860)\u001b[0m     worker.core_worker.push_error(job_id, error_type, message, time.time())\n",
      " pid=9860)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 2072, in ray._raylet.CoreWorker.push_error\n",
      " pid=9860)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 160, in ray._raylet.check_status\n",
      " pid=9860)\u001b[0m ray.exceptions.RaySystemError: System error: Unknown error\n",
      " pid=9860)\u001b[0m Exception ignored in: 'ray._raylet.task_execution_handler'\n",
      " pid=9860)\u001b[0m Traceback (most recent call last):\n",
      " pid=9860)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 783, in ray._raylet.task_execution_handler\n",
      " pid=9860)\u001b[0m   File \"c:\\Users\\user\\Desktop\\RLLIBTUTORIAL\\venv\\lib\\site-packages\\ray\\_private\\utils.py\", line 117, in push_error_to_driver\n",
      " pid=9860)\u001b[0m     worker.core_worker.push_error(job_id, error_type, message, time.time())\n",
      " pid=9860)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 2072, in ray._raylet.CoreWorker.push_error\n",
      " pid=9860)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 160, in ray._raylet.check_status\n",
      " pid=9860)\u001b[0m ray.exceptions.RaySystemError: System error: Unknown error\n",
      "2022-01-10 22:04:17,321\tERROR tune.py:622 -- Trials did not complete: [PPO_BipedalWalker-v3_7faa0_00000]\n",
      "2022-01-10 22:04:17,322\tINFO tune.py:626 -- Total run time: 20.41 seconds (20.15 seconds for the tuning loop).\n",
      "2022-01-10 22:04:17,322\tWARNING tune.py:630 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    }
   ],
   "source": [
    "stop = {\n",
    "    'timesteps_total': 1000000\n",
    "}\n",
    "\n",
    "analysis = tune.run(\n",
    "    PPOTrainer,\n",
    "    config=config,\n",
    "    stop=stop,\n",
    "    checkpoint_at_end=True,\n",
    "    checkpoint_freq=1000,\n",
    "    restore = \"C:\\\\Users\\\\user\\\\ray_results\\\\PPO\\\\PPO_BipedalWalker-v3_59aed_00000_0_lr=5e-05_2022-01-10_21-19-56\\\\checkpoint_000125\\\\checkpoint-125\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ffbfbf2a84a64db9becb059b77ee3407db977cd70714f8c89e89e5565c72b3f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
